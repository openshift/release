---
apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/enable-ds-eviction: "true"
      k8s.ovn.org/pod-networks: '{"default":{"ip_addresses":["10.131.0.7/23"],"mac_address":"0a:58:0a:83:00:07","gateway_ips":["10.131.0.1"],"routes":[{"dest":"10.128.0.0/14","nextHop":"10.131.0.1"},{"dest":"172.30.0.0/16","nextHop":"10.131.0.1"},{"dest":"100.64.0.0/16","nextHop":"10.131.0.1"}],"ip_address":"10.131.0.7/23","gateway_ip":"10.131.0.1"}}'
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "ovn-kubernetes",
            "interface": "eth0",
            "ips": [
                "10.131.0.7"
            ],
            "mac": "0a:58:0a:83:00:07",
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-06-11T11:01:02Z"
    generateName: dns-default-
    labels:
      controller-revision-hash: 658d7c47c8
      dns.operator.openshift.io/daemonset-dns: default
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.ovn.org/pod-networks: {}
      manager: ci-op-9xx71rvq-1e28e-w667k-worker-centralus1-k2hfp
      operation: Update
      subresource: status
      time: "2024-06-11T11:01:02Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cluster-autoscaler.kubernetes.io/enable-ds-eviction: {}
            f:target.workload.openshift.io/management: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:controller-revision-hash: {}
            f:dns.operator.openshift.io/daemonset-dns: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"cab48d34-0810-482e-83dc-102b3224f3fe"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"dns"}:
              .: {}
              f:args: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":5353,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
                k:{"containerPort":5353,"protocol":"UDP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
            k:{"name":"kube-rbac-proxy"}:
              .: {}
              f:args: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":9154,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/tls/private"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"config-volume"}:
              .: {}
              f:configMap:
                .: {}
                f:defaultMode: {}
                f:items: {}
                f:name: {}
              f:name: {}
            k:{"name":"metrics-tls"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:secretName: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-06-11T11:01:02Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus-daemon
      operation: Update
      subresource: status
      time: "2024-06-11T11:01:03Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodReadyToStartContainers"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:hostIPs: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.131.0.7"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-06-11T11:01:18Z"
    name: dns-default-6qw2v
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: dns-default
      uid: cab48d34-0810-482e-83dc-102b3224f3fe
    resourceVersion: "22455"
    uid: e3cd9cd3-8bee-4a25-9d9d-0d6b60eab479
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ci-op-9xx71rvq-1e28e-w667k-worker-centralus1-k2hfp
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      command:
      - coredns
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: dns
      ports:
      - containerPort: 5353
        name: dns
        protocol: UDP
      - containerPort: 5353
        name: dns-tcp
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        requests:
          cpu: 50m
          memory: 70Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fkd99
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:9154
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:9153/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9154
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 40Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: metrics-tls
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-fkd99
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: ci-op-9xx71rvq-1e28e-w667k-worker-centralus1-k2hfp
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: dns
    serviceAccountName: dns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: dns-default
      name: config-volume
    - name: metrics-tls
      secret:
        defaultMode: 420
        secretName: dns-default-metrics-tls
    - name: kube-api-access-fkd99
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:01:09Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:01:02Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:01:18Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:01:18Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:01:02Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://6452b68c0b94956b7ac249d7d0ff3b232d6f298e63208ea0b8a21d18a1bc67ad
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      lastState: {}
      name: dns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T11:01:08Z"
    - containerID: cri-o://3b94341ab311f3cf6429c1dd7348b71e815d18e327cd2ad37a8a1358eddebc44
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T11:01:09Z"
    hostIP: 10.0.128.4
    hostIPs:
    - ip: 10.0.128.4
    phase: Running
    podIP: 10.131.0.7
    podIPs:
    - ip: 10.131.0.7
    qosClass: Burstable
    startTime: "2024-06-11T11:01:02Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/enable-ds-eviction: "true"
      k8s.ovn.org/pod-networks: '{"default":{"ip_addresses":["10.130.0.16/23"],"mac_address":"0a:58:0a:82:00:10","gateway_ips":["10.130.0.1"],"routes":[{"dest":"10.128.0.0/14","nextHop":"10.130.0.1"},{"dest":"172.30.0.0/16","nextHop":"10.130.0.1"},{"dest":"100.64.0.0/16","nextHop":"10.130.0.1"}],"ip_address":"10.130.0.16/23","gateway_ip":"10.130.0.1"}}'
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "ovn-kubernetes",
            "interface": "eth0",
            "ips": [
                "10.130.0.16"
            ],
            "mac": "0a:58:0a:82:00:10",
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-06-11T10:48:37Z"
    generateName: dns-default-
    labels:
      controller-revision-hash: 658d7c47c8
      dns.operator.openshift.io/daemonset-dns: default
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.ovn.org/pod-networks: {}
      manager: ci-op-9xx71rvq-1e28e-w667k-master-2
      operation: Update
      subresource: status
      time: "2024-06-11T10:48:37Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cluster-autoscaler.kubernetes.io/enable-ds-eviction: {}
            f:target.workload.openshift.io/management: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:controller-revision-hash: {}
            f:dns.operator.openshift.io/daemonset-dns: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"cab48d34-0810-482e-83dc-102b3224f3fe"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"dns"}:
              .: {}
              f:args: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":5353,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
                k:{"containerPort":5353,"protocol":"UDP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
            k:{"name":"kube-rbac-proxy"}:
              .: {}
              f:args: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":9154,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/tls/private"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"config-volume"}:
              .: {}
              f:configMap:
                .: {}
                f:defaultMode: {}
                f:items: {}
                f:name: {}
              f:name: {}
            k:{"name":"metrics-tls"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:secretName: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-06-11T10:48:37Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus-daemon
      operation: Update
      subresource: status
      time: "2024-06-11T10:48:53Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodReadyToStartContainers"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:hostIPs: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.130.0.16"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-06-11T10:49:11Z"
    name: dns-default-9h9cc
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: dns-default
      uid: cab48d34-0810-482e-83dc-102b3224f3fe
    resourceVersion: "10147"
    uid: f8d52308-628d-4c6a-bed4-808052d0fc02
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ci-op-9xx71rvq-1e28e-w667k-master-2
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      command:
      - coredns
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: dns
      ports:
      - containerPort: 5353
        name: dns
        protocol: UDP
      - containerPort: 5353
        name: dns-tcp
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        requests:
          cpu: 50m
          memory: 70Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-f94g2
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:9154
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:9153/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9154
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 40Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: metrics-tls
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-f94g2
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: ci-op-9xx71rvq-1e28e-w667k-master-2
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: dns
    serviceAccountName: dns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: dns-default
      name: config-volume
    - name: metrics-tls
      secret:
        defaultMode: 420
        secretName: dns-default-metrics-tls
    - name: kube-api-access-f94g2
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:59Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:49:11Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:49:11Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://eedf18f62588474451b680b7e7555e067500620c5c73d1b4cbb852a9632b96c3
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      lastState: {}
      name: dns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T10:48:59Z"
    - containerID: cri-o://757426f9f7154129b7e77dc548b472e34d38bbf1c2bd448d7453c1d14f8a4918
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T10:48:59Z"
    hostIP: 10.0.0.7
    hostIPs:
    - ip: 10.0.0.7
    phase: Running
    podIP: 10.130.0.16
    podIPs:
    - ip: 10.130.0.16
    qosClass: Burstable
    startTime: "2024-06-11T10:48:37Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/enable-ds-eviction: "true"
      k8s.ovn.org/pod-networks: '{"default":{"ip_addresses":["10.129.2.12/23"],"mac_address":"0a:58:0a:81:02:0c","gateway_ips":["10.129.2.1"],"routes":[{"dest":"10.128.0.0/14","nextHop":"10.129.2.1"},{"dest":"172.30.0.0/16","nextHop":"10.129.2.1"},{"dest":"100.64.0.0/16","nextHop":"10.129.2.1"}],"ip_address":"10.129.2.12/23","gateway_ip":"10.129.2.1"}}'
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "ovn-kubernetes",
            "interface": "eth0",
            "ips": [
                "10.129.2.12"
            ],
            "mac": "0a:58:0a:81:02:0c",
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-06-11T11:00:59Z"
    generateName: dns-default-
    labels:
      controller-revision-hash: 658d7c47c8
      dns.operator.openshift.io/daemonset-dns: default
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.ovn.org/pod-networks: {}
      manager: ci-op-9xx71rvq-1e28e-w667k-worker-centralus3-hgn49
      operation: Update
      subresource: status
      time: "2024-06-11T11:00:59Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cluster-autoscaler.kubernetes.io/enable-ds-eviction: {}
            f:target.workload.openshift.io/management: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:controller-revision-hash: {}
            f:dns.operator.openshift.io/daemonset-dns: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"cab48d34-0810-482e-83dc-102b3224f3fe"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"dns"}:
              .: {}
              f:args: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":5353,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
                k:{"containerPort":5353,"protocol":"UDP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
            k:{"name":"kube-rbac-proxy"}:
              .: {}
              f:args: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":9154,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/tls/private"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"config-volume"}:
              .: {}
              f:configMap:
                .: {}
                f:defaultMode: {}
                f:items: {}
                f:name: {}
              f:name: {}
            k:{"name":"metrics-tls"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:secretName: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-06-11T11:00:59Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus-daemon
      operation: Update
      subresource: status
      time: "2024-06-11T11:01:00Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodReadyToStartContainers"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:hostIPs: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.129.2.12"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-06-11T11:01:26Z"
    name: dns-default-g5zzn
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: dns-default
      uid: cab48d34-0810-482e-83dc-102b3224f3fe
    resourceVersion: "22897"
    uid: 4c435c6f-6398-4c04-8a28-76ccb6258270
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ci-op-9xx71rvq-1e28e-w667k-worker-centralus3-hgn49
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      command:
      - coredns
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: dns
      ports:
      - containerPort: 5353
        name: dns
        protocol: UDP
      - containerPort: 5353
        name: dns-tcp
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        requests:
          cpu: 50m
          memory: 70Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-wrts2
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:9154
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:9153/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9154
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 40Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: metrics-tls
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-wrts2
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: ci-op-9xx71rvq-1e28e-w667k-worker-centralus3-hgn49
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: dns
    serviceAccountName: dns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: dns-default
      name: config-volume
    - name: metrics-tls
      secret:
        defaultMode: 420
        secretName: dns-default-metrics-tls
    - name: kube-api-access-wrts2
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:01:15Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:00:59Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:01:26Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:01:26Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:00:59Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://158ff3c65649968ce550b986ffaa20eea7cdec774ca33d1d10e5ac89a311036e
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      lastState: {}
      name: dns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T11:01:14Z"
    - containerID: cri-o://dce0bea4dc529224e3736cdba9d16c143f858e2735503451ac4842af9c44c893
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T11:01:14Z"
    hostIP: 10.0.128.5
    hostIPs:
    - ip: 10.0.128.5
    phase: Running
    podIP: 10.129.2.12
    podIPs:
    - ip: 10.129.2.12
    qosClass: Burstable
    startTime: "2024-06-11T11:00:59Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/enable-ds-eviction: "true"
      k8s.ovn.org/pod-networks: '{"default":{"ip_addresses":["10.129.0.43/23"],"mac_address":"0a:58:0a:81:00:2b","gateway_ips":["10.129.0.1"],"routes":[{"dest":"10.128.0.0/14","nextHop":"10.129.0.1"},{"dest":"172.30.0.0/16","nextHop":"10.129.0.1"},{"dest":"100.64.0.0/16","nextHop":"10.129.0.1"}],"ip_address":"10.129.0.43/23","gateway_ip":"10.129.0.1"}}'
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "ovn-kubernetes",
            "interface": "eth0",
            "ips": [
                "10.129.0.43"
            ],
            "mac": "0a:58:0a:81:00:2b",
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-06-11T10:48:37Z"
    generateName: dns-default-
    labels:
      controller-revision-hash: 658d7c47c8
      dns.operator.openshift.io/daemonset-dns: default
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.ovn.org/pod-networks: {}
      manager: ci-op-9xx71rvq-1e28e-w667k-master-1
      operation: Update
      subresource: status
      time: "2024-06-11T10:48:37Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cluster-autoscaler.kubernetes.io/enable-ds-eviction: {}
            f:target.workload.openshift.io/management: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:controller-revision-hash: {}
            f:dns.operator.openshift.io/daemonset-dns: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"cab48d34-0810-482e-83dc-102b3224f3fe"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"dns"}:
              .: {}
              f:args: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":5353,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
                k:{"containerPort":5353,"protocol":"UDP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
            k:{"name":"kube-rbac-proxy"}:
              .: {}
              f:args: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":9154,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/tls/private"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"config-volume"}:
              .: {}
              f:configMap:
                .: {}
                f:defaultMode: {}
                f:items: {}
                f:name: {}
              f:name: {}
            k:{"name":"metrics-tls"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:secretName: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-06-11T10:48:37Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus-daemon
      operation: Update
      subresource: status
      time: "2024-06-11T10:48:53Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodReadyToStartContainers"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:hostIPs: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.129.0.43"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-06-11T10:49:08Z"
    name: dns-default-kmxpr
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: dns-default
      uid: cab48d34-0810-482e-83dc-102b3224f3fe
    resourceVersion: "10076"
    uid: 0fc4b1ad-665e-4de4-a8cd-a8704a0a07fb
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ci-op-9xx71rvq-1e28e-w667k-master-1
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      command:
      - coredns
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: dns
      ports:
      - containerPort: 5353
        name: dns
        protocol: UDP
      - containerPort: 5353
        name: dns-tcp
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        requests:
          cpu: 50m
          memory: 70Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-w7l7l
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:9154
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:9153/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9154
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 40Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: metrics-tls
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-w7l7l
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: ci-op-9xx71rvq-1e28e-w667k-master-1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: dns
    serviceAccountName: dns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: dns-default
      name: config-volume
    - name: metrics-tls
      secret:
        defaultMode: 420
        secretName: dns-default-metrics-tls
    - name: kube-api-access-w7l7l
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:58Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:49:08Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:49:08Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://ea6696f4115236302234dd72389183b374d39b2ea576e180c502c98480ec61de
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      lastState: {}
      name: dns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T10:48:58Z"
    - containerID: cri-o://8a43de0303cb16b9c73a5f45920fb3afa1305e8ce520f2a7a25986156ea871b6
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T10:48:58Z"
    hostIP: 10.0.0.6
    hostIPs:
    - ip: 10.0.0.6
    phase: Running
    podIP: 10.129.0.43
    podIPs:
    - ip: 10.129.0.43
    qosClass: Burstable
    startTime: "2024-06-11T10:48:37Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/enable-ds-eviction: "true"
      k8s.ovn.org/pod-networks: '{"default":{"ip_addresses":["10.128.2.7/23"],"mac_address":"0a:58:0a:80:02:07","gateway_ips":["10.128.2.1"],"routes":[{"dest":"10.128.0.0/14","nextHop":"10.128.2.1"},{"dest":"172.30.0.0/16","nextHop":"10.128.2.1"},{"dest":"100.64.0.0/16","nextHop":"10.128.2.1"}],"ip_address":"10.128.2.7/23","gateway_ip":"10.128.2.1"}}'
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "ovn-kubernetes",
            "interface": "eth0",
            "ips": [
                "10.128.2.7"
            ],
            "mac": "0a:58:0a:80:02:07",
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-06-11T11:01:00Z"
    generateName: dns-default-
    labels:
      controller-revision-hash: 658d7c47c8
      dns.operator.openshift.io/daemonset-dns: default
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.ovn.org/pod-networks: {}
      manager: ci-op-9xx71rvq-1e28e-w667k-worker-centralus2-xnvk9
      operation: Update
      subresource: status
      time: "2024-06-11T11:01:00Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cluster-autoscaler.kubernetes.io/enable-ds-eviction: {}
            f:target.workload.openshift.io/management: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:controller-revision-hash: {}
            f:dns.operator.openshift.io/daemonset-dns: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"cab48d34-0810-482e-83dc-102b3224f3fe"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"dns"}:
              .: {}
              f:args: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":5353,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
                k:{"containerPort":5353,"protocol":"UDP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
            k:{"name":"kube-rbac-proxy"}:
              .: {}
              f:args: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":9154,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/tls/private"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"config-volume"}:
              .: {}
              f:configMap:
                .: {}
                f:defaultMode: {}
                f:items: {}
                f:name: {}
              f:name: {}
            k:{"name":"metrics-tls"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:secretName: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-06-11T11:01:00Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus-daemon
      operation: Update
      subresource: status
      time: "2024-06-11T11:01:00Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodReadyToStartContainers"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:hostIPs: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.128.2.7"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-06-11T11:01:18Z"
    name: dns-default-t22wm
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: dns-default
      uid: cab48d34-0810-482e-83dc-102b3224f3fe
    resourceVersion: "22473"
    uid: 5dd97e0f-641e-4b68-9549-e7dd86030475
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ci-op-9xx71rvq-1e28e-w667k-worker-centralus2-xnvk9
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      command:
      - coredns
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: dns
      ports:
      - containerPort: 5353
        name: dns
        protocol: UDP
      - containerPort: 5353
        name: dns-tcp
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        requests:
          cpu: 50m
          memory: 70Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vrbzb
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:9154
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:9153/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9154
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 40Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: metrics-tls
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-vrbzb
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: ci-op-9xx71rvq-1e28e-w667k-worker-centralus2-xnvk9
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: dns
    serviceAccountName: dns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: dns-default
      name: config-volume
    - name: metrics-tls
      secret:
        defaultMode: 420
        secretName: dns-default-metrics-tls
    - name: kube-api-access-vrbzb
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:01:07Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:01:00Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:01:18Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:01:18Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T11:01:00Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://bb33948304242e0528fe3af7bbc667b4a1d0d0d7579979c0bdc88fe3d780a299
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      lastState: {}
      name: dns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T11:01:06Z"
    - containerID: cri-o://3accd38b5fb9ebe5a9ba69a432a7e1b496608592b53f15098695ac16682ad18e
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T11:01:06Z"
    hostIP: 10.0.128.6
    hostIPs:
    - ip: 10.0.128.6
    phase: Running
    podIP: 10.128.2.7
    podIPs:
    - ip: 10.128.2.7
    qosClass: Burstable
    startTime: "2024-06-11T11:01:00Z"
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cluster-autoscaler.kubernetes.io/enable-ds-eviction: "true"
      k8s.ovn.org/pod-networks: '{"default":{"ip_addresses":["10.128.0.17/23"],"mac_address":"0a:58:0a:80:00:11","gateway_ips":["10.128.0.1"],"routes":[{"dest":"10.128.0.0/14","nextHop":"10.128.0.1"},{"dest":"172.30.0.0/16","nextHop":"10.128.0.1"},{"dest":"100.64.0.0/16","nextHop":"10.128.0.1"}],"ip_address":"10.128.0.17/23","gateway_ip":"10.128.0.1"}}'
      k8s.v1.cni.cncf.io/network-status: |-
        [{
            "name": "ovn-kubernetes",
            "interface": "eth0",
            "ips": [
                "10.128.0.17"
            ],
            "mac": "0a:58:0a:80:00:11",
            "default": true,
            "dns": {}
        }]
    creationTimestamp: "2024-06-11T10:48:37Z"
    generateName: dns-default-
    labels:
      controller-revision-hash: 658d7c47c8
      dns.operator.openshift.io/daemonset-dns: default
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.ovn.org/pod-networks: {}
      manager: ci-op-9xx71rvq-1e28e-w667k-master-0
      operation: Update
      subresource: status
      time: "2024-06-11T10:48:37Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:cluster-autoscaler.kubernetes.io/enable-ds-eviction: {}
            f:target.workload.openshift.io/management: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:controller-revision-hash: {}
            f:dns.operator.openshift.io/daemonset-dns: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"cab48d34-0810-482e-83dc-102b3224f3fe"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"dns"}:
              .: {}
              f:args: {}
              f:command: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:livenessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":5353,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
                k:{"containerPort":5353,"protocol":"UDP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:readinessProbe:
                .: {}
                f:failureThreshold: {}
                f:httpGet:
                  .: {}
                  f:path: {}
                  f:port: {}
                  f:scheme: {}
                f:initialDelaySeconds: {}
                f:periodSeconds: {}
                f:successThreshold: {}
                f:timeoutSeconds: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/coredns"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
            k:{"name":"kube-rbac-proxy"}:
              .: {}
              f:args: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:ports:
                .: {}
                k:{"containerPort":9154,"protocol":"TCP"}:
                  .: {}
                  f:containerPort: {}
                  f:name: {}
                  f:protocol: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/tls/private"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
                  f:readOnly: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"config-volume"}:
              .: {}
              f:configMap:
                .: {}
                f:defaultMode: {}
                f:items: {}
                f:name: {}
              f:name: {}
            k:{"name":"metrics-tls"}:
              .: {}
              f:name: {}
              f:secret:
                .: {}
                f:defaultMode: {}
                f:secretName: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-06-11T10:48:37Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            f:k8s.v1.cni.cncf.io/network-status: {}
      manager: multus-daemon
      operation: Update
      subresource: status
      time: "2024-06-11T10:48:53Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodReadyToStartContainers"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:hostIPs: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.128.0.17"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-06-11T10:56:12Z"
    name: dns-default-tfrnn
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: dns-default
      uid: cab48d34-0810-482e-83dc-102b3224f3fe
    resourceVersion: "18190"
    uid: 2df641e9-6a11-4b68-b983-2cdf52aaabde
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ci-op-9xx71rvq-1e28e-w667k-master-0
    containers:
    - args:
      - -conf
      - /etc/coredns/Corefile
      command:
      - coredns
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      imagePullPolicy: IfNotPresent
      livenessProbe:
        failureThreshold: 5
        httpGet:
          path: /health
          port: 8080
          scheme: HTTP
        initialDelaySeconds: 60
        periodSeconds: 10
        successThreshold: 1
        timeoutSeconds: 5
      name: dns
      ports:
      - containerPort: 5353
        name: dns
        protocol: UDP
      - containerPort: 5353
        name: dns-tcp
        protocol: TCP
      readinessProbe:
        failureThreshold: 3
        httpGet:
          path: /ready
          port: 8181
          scheme: HTTP
        initialDelaySeconds: 10
        periodSeconds: 3
        successThreshold: 1
        timeoutSeconds: 3
      resources:
        requests:
          cpu: 50m
          memory: 70Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/coredns
        name: config-volume
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xqpc5
        readOnly: true
    - args:
      - --logtostderr
      - --secure-listen-address=:9154
      - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_RSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256,TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256
      - --upstream=http://127.0.0.1:9153/
      - --tls-cert-file=/etc/tls/private/tls.crt
      - --tls-private-key-file=/etc/tls/private/tls.key
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      imagePullPolicy: IfNotPresent
      name: kube-rbac-proxy
      ports:
      - containerPort: 9154
        name: metrics
        protocol: TCP
      resources:
        requests:
          cpu: 10m
          memory: 40Mi
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/tls/private
        name: metrics-tls
        readOnly: true
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-xqpc5
        readOnly: true
    dnsPolicy: Default
    enableServiceLinks: true
    nodeName: ci-op-9xx71rvq-1e28e-w667k-master-0
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: dns
    serviceAccountName: dns
    terminationGracePeriodSeconds: 30
    tolerations:
    - key: node-role.kubernetes.io/master
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/disk-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/memory-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/pid-pressure
      operator: Exists
    - effect: NoSchedule
      key: node.kubernetes.io/unschedulable
      operator: Exists
    volumes:
    - configMap:
        defaultMode: 420
        items:
        - key: Corefile
          path: Corefile
        name: dns-default
      name: config-volume
    - name: metrics-tls
      secret:
        defaultMode: 420
        secretName: dns-default-metrics-tls
    - name: kube-api-access-xqpc5
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:49:04Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:49:14Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:49:14Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://90bd4e364759bd4824a43e157423fe91070789c9d809584f0bc8a9284caebb0c
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:db5c50d6151f584e498cd06f68ef6504fd0a35ff24943ecb50156062881d608e
      lastState: {}
      name: dns
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T10:49:02Z"
    - containerID: cri-o://b5fc166f2aa115301321222174b88d83ceaf595f349e94e0ed090d7b43dfbe7b
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
      lastState: {}
      name: kube-rbac-proxy
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T10:49:03Z"
    hostIP: 10.0.0.8
    hostIPs:
    - ip: 10.0.0.8
    phase: Running
    podIP: 10.128.0.17
    podIPs:
    - ip: 10.128.0.17
    qosClass: Burstable
    startTime: "2024-06-11T10:48:37Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-06-11T10:56:25Z"
    generateName: node-resolver-
    labels:
      controller-revision-hash: f988c7b7b
      dns.operator.openshift.io/daemonset-node-resolver: ""
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:target.workload.openshift.io/management: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:controller-revision-hash: {}
            f:dns.operator.openshift.io/daemonset-node-resolver: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"aadb4651-e71a-4b8a-b008-787fd00c7133"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"dns-node-resolver"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"CLUSTER_DOMAIN"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NAMESERVER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SERVICES"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/hosts"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"hosts-file"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-06-11T10:56:25Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodReadyToStartContainers"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:hostIPs: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.0.128.4"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-06-11T11:00:20Z"
    name: node-resolver-7wq8n
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-resolver
      uid: aadb4651-e71a-4b8a-b008-787fd00c7133
    resourceVersion: "21178"
    uid: d8d03a2d-05f0-4e40-a600-c8b244124364
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ci-op-9xx71rvq-1e28e-w667k-worker-centralus1-k2hfp
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -uo pipefail

        trap 'jobs -p | xargs kill || true; wait; exit 0' TERM

        OPENSHIFT_MARKER="openshift-generated-node-resolver"
        HOSTS_FILE="/etc/hosts"
        TEMP_FILE="/etc/hosts.tmp"

        IFS=', ' read -r -a services <<< "${SERVICES}"

        # Make a temporary file with the old hosts file's attributes.
        if ! cp -f --attributes-only "${HOSTS_FILE}" "${TEMP_FILE}"; then
          echo "Failed to preserve hosts file. Exiting."
          exit 1
        fi

        while true; do
          declare -A svc_ips
          for svc in "${services[@]}"; do
            # Fetch service IP from cluster dns if present. We make several tries
            # to do it: IPv4, IPv6, IPv4 over TCP and IPv6 over TCP. The two last ones
            # are for deployments with Kuryr on older OpenStack (OSP13) - those do not
            # support UDP loadbalancers and require reaching DNS through TCP.
            cmds=('dig -t A @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t AAAA @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t A +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t AAAA +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"')
            for i in ${!cmds[*]}
            do
              ips=($(eval "${cmds[i]}"))
              if [[ "$?" -eq 0 && "${#ips[@]}" -ne 0 ]]; then
                svc_ips["${svc}"]="${ips[@]}"
                break
              fi
            done
          done

          # Update /etc/hosts only if we get valid service IPs
          # We will not update /etc/hosts when there is coredns service outage or api unavailability
          # Stale entries could exist in /etc/hosts if the service is deleted
          if [[ -n "${svc_ips[*]-}" ]]; then
            # Build a new hosts file from /etc/hosts with our custom entries filtered out
            if ! sed --silent "/# ${OPENSHIFT_MARKER}/d; w ${TEMP_FILE}" "${HOSTS_FILE}"; then
              # Only continue rebuilding the hosts entries if its original content is preserved
              sleep 60 & wait
              continue
            fi

            # Append resolver entries for services
            rc=0
            for svc in "${!svc_ips[@]}"; do
              for ip in ${svc_ips[${svc}]}; do
                echo "${ip} ${svc} ${svc}.${CLUSTER_DOMAIN} # ${OPENSHIFT_MARKER}" >> "${TEMP_FILE}" || rc=$?
              done
            done
            if [[ $rc -ne 0 ]]; then
              sleep 60 & wait
              continue
            fi


            # TODO: Update /etc/hosts atomically to avoid any inconsistent behavior
            # Replace /etc/hosts with our modified version if needed
            cmp "${TEMP_FILE}" "${HOSTS_FILE}" || cp -f "${TEMP_FILE}" "${HOSTS_FILE}"
            # TEMP_FILE is not removed to avoid file create/delete and attributes copy churn
          fi
          sleep 60 & wait
          unset svc_ips
        done
      env:
      - name: SERVICES
        value: image-registry.openshift-image-registry.svc
      - name: NAMESERVER
        value: 172.30.0.10
      - name: CLUSTER_DOMAIN
        value: cluster.local
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      imagePullPolicy: IfNotPresent
      name: dns-node-resolver
      resources:
        requests:
          cpu: 5m
          memory: 21Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/hosts
        name: hosts-file
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-6hclj
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ci-op-9xx71rvq-1e28e-w667k-worker-centralus1-k2hfp
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-resolver
    serviceAccountName: node-resolver
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/hosts
        type: File
      name: hosts-file
    - name: kube-api-access-6hclj
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:57:22Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:56:46Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:57:22Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:57:22Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:56:25Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://aa3f9ab1fd0c2742dcaa9ed9d3c5bdd10b5cf01d26d6ea09bd624ffb0fc84e8c
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      lastState: {}
      name: dns-node-resolver
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T10:57:22Z"
    hostIP: 10.0.128.4
    hostIPs:
    - ip: 10.0.128.4
    phase: Running
    podIP: 10.0.128.4
    podIPs:
    - ip: 10.0.128.4
    qosClass: Burstable
    startTime: "2024-06-11T10:56:46Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-06-11T10:48:37Z"
    generateName: node-resolver-
    labels:
      controller-revision-hash: f988c7b7b
      dns.operator.openshift.io/daemonset-node-resolver: ""
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:target.workload.openshift.io/management: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:controller-revision-hash: {}
            f:dns.operator.openshift.io/daemonset-node-resolver: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"aadb4651-e71a-4b8a-b008-787fd00c7133"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"dns-node-resolver"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"CLUSTER_DOMAIN"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NAMESERVER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SERVICES"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/hosts"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"hosts-file"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-06-11T10:48:37Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodReadyToStartContainers"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:hostIPs: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.0.0.6"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-06-11T10:48:51Z"
    name: node-resolver-kl72g
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-resolver
      uid: aadb4651-e71a-4b8a-b008-787fd00c7133
    resourceVersion: "9275"
    uid: fd073769-4f2c-4965-9a22-3d999cb69634
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ci-op-9xx71rvq-1e28e-w667k-master-1
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -uo pipefail

        trap 'jobs -p | xargs kill || true; wait; exit 0' TERM

        OPENSHIFT_MARKER="openshift-generated-node-resolver"
        HOSTS_FILE="/etc/hosts"
        TEMP_FILE="/etc/hosts.tmp"

        IFS=', ' read -r -a services <<< "${SERVICES}"

        # Make a temporary file with the old hosts file's attributes.
        if ! cp -f --attributes-only "${HOSTS_FILE}" "${TEMP_FILE}"; then
          echo "Failed to preserve hosts file. Exiting."
          exit 1
        fi

        while true; do
          declare -A svc_ips
          for svc in "${services[@]}"; do
            # Fetch service IP from cluster dns if present. We make several tries
            # to do it: IPv4, IPv6, IPv4 over TCP and IPv6 over TCP. The two last ones
            # are for deployments with Kuryr on older OpenStack (OSP13) - those do not
            # support UDP loadbalancers and require reaching DNS through TCP.
            cmds=('dig -t A @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t AAAA @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t A +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t AAAA +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"')
            for i in ${!cmds[*]}
            do
              ips=($(eval "${cmds[i]}"))
              if [[ "$?" -eq 0 && "${#ips[@]}" -ne 0 ]]; then
                svc_ips["${svc}"]="${ips[@]}"
                break
              fi
            done
          done

          # Update /etc/hosts only if we get valid service IPs
          # We will not update /etc/hosts when there is coredns service outage or api unavailability
          # Stale entries could exist in /etc/hosts if the service is deleted
          if [[ -n "${svc_ips[*]-}" ]]; then
            # Build a new hosts file from /etc/hosts with our custom entries filtered out
            if ! sed --silent "/# ${OPENSHIFT_MARKER}/d; w ${TEMP_FILE}" "${HOSTS_FILE}"; then
              # Only continue rebuilding the hosts entries if its original content is preserved
              sleep 60 & wait
              continue
            fi

            # Append resolver entries for services
            rc=0
            for svc in "${!svc_ips[@]}"; do
              for ip in ${svc_ips[${svc}]}; do
                echo "${ip} ${svc} ${svc}.${CLUSTER_DOMAIN} # ${OPENSHIFT_MARKER}" >> "${TEMP_FILE}" || rc=$?
              done
            done
            if [[ $rc -ne 0 ]]; then
              sleep 60 & wait
              continue
            fi


            # TODO: Update /etc/hosts atomically to avoid any inconsistent behavior
            # Replace /etc/hosts with our modified version if needed
            cmp "${TEMP_FILE}" "${HOSTS_FILE}" || cp -f "${TEMP_FILE}" "${HOSTS_FILE}"
            # TEMP_FILE is not removed to avoid file create/delete and attributes copy churn
          fi
          sleep 60 & wait
          unset svc_ips
        done
      env:
      - name: SERVICES
        value: image-registry.openshift-image-registry.svc
      - name: NAMESERVER
        value: 172.30.0.10
      - name: CLUSTER_DOMAIN
        value: cluster.local
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      imagePullPolicy: IfNotPresent
      name: dns-node-resolver
      resources:
        requests:
          cpu: 5m
          memory: 21Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/hosts
        name: hosts-file
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-qfwrz
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ci-op-9xx71rvq-1e28e-w667k-master-1
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-resolver
    serviceAccountName: node-resolver
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/hosts
        type: File
      name: hosts-file
    - name: kube-api-access-qfwrz
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:51Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:51Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:51Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://75fe04ff700eaf0aa5938bcc459d21a382341dc470e9170521681afe667bbf75
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      lastState: {}
      name: dns-node-resolver
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T10:48:51Z"
    hostIP: 10.0.0.6
    hostIPs:
    - ip: 10.0.0.6
    phase: Running
    podIP: 10.0.0.6
    podIPs:
    - ip: 10.0.0.6
    qosClass: Burstable
    startTime: "2024-06-11T10:48:37Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-06-11T10:56:26Z"
    generateName: node-resolver-
    labels:
      controller-revision-hash: f988c7b7b
      dns.operator.openshift.io/daemonset-node-resolver: ""
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:target.workload.openshift.io/management: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:controller-revision-hash: {}
            f:dns.operator.openshift.io/daemonset-node-resolver: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"aadb4651-e71a-4b8a-b008-787fd00c7133"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"dns-node-resolver"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"CLUSTER_DOMAIN"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NAMESERVER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SERVICES"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/hosts"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"hosts-file"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-06-11T10:56:26Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodReadyToStartContainers"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:hostIPs: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.0.128.6"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-06-11T11:00:20Z"
    name: node-resolver-l8bk2
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-resolver
      uid: aadb4651-e71a-4b8a-b008-787fd00c7133
    resourceVersion: "21175"
    uid: ba53d109-49cb-4ee1-bdcc-0d4694a76d13
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ci-op-9xx71rvq-1e28e-w667k-worker-centralus2-xnvk9
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -uo pipefail

        trap 'jobs -p | xargs kill || true; wait; exit 0' TERM

        OPENSHIFT_MARKER="openshift-generated-node-resolver"
        HOSTS_FILE="/etc/hosts"
        TEMP_FILE="/etc/hosts.tmp"

        IFS=', ' read -r -a services <<< "${SERVICES}"

        # Make a temporary file with the old hosts file's attributes.
        if ! cp -f --attributes-only "${HOSTS_FILE}" "${TEMP_FILE}"; then
          echo "Failed to preserve hosts file. Exiting."
          exit 1
        fi

        while true; do
          declare -A svc_ips
          for svc in "${services[@]}"; do
            # Fetch service IP from cluster dns if present. We make several tries
            # to do it: IPv4, IPv6, IPv4 over TCP and IPv6 over TCP. The two last ones
            # are for deployments with Kuryr on older OpenStack (OSP13) - those do not
            # support UDP loadbalancers and require reaching DNS through TCP.
            cmds=('dig -t A @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t AAAA @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t A +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t AAAA +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"')
            for i in ${!cmds[*]}
            do
              ips=($(eval "${cmds[i]}"))
              if [[ "$?" -eq 0 && "${#ips[@]}" -ne 0 ]]; then
                svc_ips["${svc}"]="${ips[@]}"
                break
              fi
            done
          done

          # Update /etc/hosts only if we get valid service IPs
          # We will not update /etc/hosts when there is coredns service outage or api unavailability
          # Stale entries could exist in /etc/hosts if the service is deleted
          if [[ -n "${svc_ips[*]-}" ]]; then
            # Build a new hosts file from /etc/hosts with our custom entries filtered out
            if ! sed --silent "/# ${OPENSHIFT_MARKER}/d; w ${TEMP_FILE}" "${HOSTS_FILE}"; then
              # Only continue rebuilding the hosts entries if its original content is preserved
              sleep 60 & wait
              continue
            fi

            # Append resolver entries for services
            rc=0
            for svc in "${!svc_ips[@]}"; do
              for ip in ${svc_ips[${svc}]}; do
                echo "${ip} ${svc} ${svc}.${CLUSTER_DOMAIN} # ${OPENSHIFT_MARKER}" >> "${TEMP_FILE}" || rc=$?
              done
            done
            if [[ $rc -ne 0 ]]; then
              sleep 60 & wait
              continue
            fi


            # TODO: Update /etc/hosts atomically to avoid any inconsistent behavior
            # Replace /etc/hosts with our modified version if needed
            cmp "${TEMP_FILE}" "${HOSTS_FILE}" || cp -f "${TEMP_FILE}" "${HOSTS_FILE}"
            # TEMP_FILE is not removed to avoid file create/delete and attributes copy churn
          fi
          sleep 60 & wait
          unset svc_ips
        done
      env:
      - name: SERVICES
        value: image-registry.openshift-image-registry.svc
      - name: NAMESERVER
        value: 172.30.0.10
      - name: CLUSTER_DOMAIN
        value: cluster.local
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      imagePullPolicy: IfNotPresent
      name: dns-node-resolver
      resources:
        requests:
          cpu: 5m
          memory: 21Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/hosts
        name: hosts-file
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-8464k
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ci-op-9xx71rvq-1e28e-w667k-worker-centralus2-xnvk9
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-resolver
    serviceAccountName: node-resolver
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/hosts
        type: File
      name: hosts-file
    - name: kube-api-access-8464k
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:57:37Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:56:44Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:57:37Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:57:37Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:56:26Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://f7dd10f86c2675b5ad40a8590510fc2ae4ab03103957c21659da54cde4fda389
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      lastState: {}
      name: dns-node-resolver
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T10:57:36Z"
    hostIP: 10.0.128.6
    hostIPs:
    - ip: 10.0.128.6
    phase: Running
    podIP: 10.0.128.6
    podIPs:
    - ip: 10.0.128.6
    qosClass: Burstable
    startTime: "2024-06-11T10:56:44Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-06-11T10:48:37Z"
    generateName: node-resolver-
    labels:
      controller-revision-hash: f988c7b7b
      dns.operator.openshift.io/daemonset-node-resolver: ""
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:target.workload.openshift.io/management: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:controller-revision-hash: {}
            f:dns.operator.openshift.io/daemonset-node-resolver: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"aadb4651-e71a-4b8a-b008-787fd00c7133"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"dns-node-resolver"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"CLUSTER_DOMAIN"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NAMESERVER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SERVICES"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/hosts"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"hosts-file"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-06-11T10:48:37Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodReadyToStartContainers"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:hostIPs: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.0.0.8"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-06-11T10:56:12Z"
    name: node-resolver-p2bm7
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-resolver
      uid: aadb4651-e71a-4b8a-b008-787fd00c7133
    resourceVersion: "18177"
    uid: 9ae6ef7e-37ff-43a3-816b-e7f9e74583be
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ci-op-9xx71rvq-1e28e-w667k-master-0
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -uo pipefail

        trap 'jobs -p | xargs kill || true; wait; exit 0' TERM

        OPENSHIFT_MARKER="openshift-generated-node-resolver"
        HOSTS_FILE="/etc/hosts"
        TEMP_FILE="/etc/hosts.tmp"

        IFS=', ' read -r -a services <<< "${SERVICES}"

        # Make a temporary file with the old hosts file's attributes.
        if ! cp -f --attributes-only "${HOSTS_FILE}" "${TEMP_FILE}"; then
          echo "Failed to preserve hosts file. Exiting."
          exit 1
        fi

        while true; do
          declare -A svc_ips
          for svc in "${services[@]}"; do
            # Fetch service IP from cluster dns if present. We make several tries
            # to do it: IPv4, IPv6, IPv4 over TCP and IPv6 over TCP. The two last ones
            # are for deployments with Kuryr on older OpenStack (OSP13) - those do not
            # support UDP loadbalancers and require reaching DNS through TCP.
            cmds=('dig -t A @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t AAAA @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t A +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t AAAA +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"')
            for i in ${!cmds[*]}
            do
              ips=($(eval "${cmds[i]}"))
              if [[ "$?" -eq 0 && "${#ips[@]}" -ne 0 ]]; then
                svc_ips["${svc}"]="${ips[@]}"
                break
              fi
            done
          done

          # Update /etc/hosts only if we get valid service IPs
          # We will not update /etc/hosts when there is coredns service outage or api unavailability
          # Stale entries could exist in /etc/hosts if the service is deleted
          if [[ -n "${svc_ips[*]-}" ]]; then
            # Build a new hosts file from /etc/hosts with our custom entries filtered out
            if ! sed --silent "/# ${OPENSHIFT_MARKER}/d; w ${TEMP_FILE}" "${HOSTS_FILE}"; then
              # Only continue rebuilding the hosts entries if its original content is preserved
              sleep 60 & wait
              continue
            fi

            # Append resolver entries for services
            rc=0
            for svc in "${!svc_ips[@]}"; do
              for ip in ${svc_ips[${svc}]}; do
                echo "${ip} ${svc} ${svc}.${CLUSTER_DOMAIN} # ${OPENSHIFT_MARKER}" >> "${TEMP_FILE}" || rc=$?
              done
            done
            if [[ $rc -ne 0 ]]; then
              sleep 60 & wait
              continue
            fi


            # TODO: Update /etc/hosts atomically to avoid any inconsistent behavior
            # Replace /etc/hosts with our modified version if needed
            cmp "${TEMP_FILE}" "${HOSTS_FILE}" || cp -f "${TEMP_FILE}" "${HOSTS_FILE}"
            # TEMP_FILE is not removed to avoid file create/delete and attributes copy churn
          fi
          sleep 60 & wait
          unset svc_ips
        done
      env:
      - name: SERVICES
        value: image-registry.openshift-image-registry.svc
      - name: NAMESERVER
        value: 172.30.0.10
      - name: CLUSTER_DOMAIN
        value: cluster.local
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      imagePullPolicy: IfNotPresent
      name: dns-node-resolver
      resources:
        requests:
          cpu: 5m
          memory: 21Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/hosts
        name: hosts-file
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-4rrxn
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ci-op-9xx71rvq-1e28e-w667k-master-0
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-resolver
    serviceAccountName: node-resolver
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/hosts
        type: File
      name: hosts-file
    - name: kube-api-access-4rrxn
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:38Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:38Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:38Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://c587dc153e0bd22970f55ea59d8343e4e191f067c4d74f64b5de67421451c31f
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      lastState: {}
      name: dns-node-resolver
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T10:48:38Z"
    hostIP: 10.0.0.8
    hostIPs:
    - ip: 10.0.0.8
    phase: Running
    podIP: 10.0.0.8
    podIPs:
    - ip: 10.0.0.8
    qosClass: Burstable
    startTime: "2024-06-11T10:48:37Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-06-11T10:56:31Z"
    generateName: node-resolver-
    labels:
      controller-revision-hash: f988c7b7b
      dns.operator.openshift.io/daemonset-node-resolver: ""
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:target.workload.openshift.io/management: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:controller-revision-hash: {}
            f:dns.operator.openshift.io/daemonset-node-resolver: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"aadb4651-e71a-4b8a-b008-787fd00c7133"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"dns-node-resolver"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"CLUSTER_DOMAIN"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NAMESERVER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SERVICES"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/hosts"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"hosts-file"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-06-11T10:56:31Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodReadyToStartContainers"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:hostIPs: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.0.128.5"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-06-11T10:59:42Z"
    name: node-resolver-qs9t5
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-resolver
      uid: aadb4651-e71a-4b8a-b008-787fd00c7133
    resourceVersion: "20794"
    uid: c55818a3-faa3-419a-9f0e-191c0e874692
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ci-op-9xx71rvq-1e28e-w667k-worker-centralus3-hgn49
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -uo pipefail

        trap 'jobs -p | xargs kill || true; wait; exit 0' TERM

        OPENSHIFT_MARKER="openshift-generated-node-resolver"
        HOSTS_FILE="/etc/hosts"
        TEMP_FILE="/etc/hosts.tmp"

        IFS=', ' read -r -a services <<< "${SERVICES}"

        # Make a temporary file with the old hosts file's attributes.
        if ! cp -f --attributes-only "${HOSTS_FILE}" "${TEMP_FILE}"; then
          echo "Failed to preserve hosts file. Exiting."
          exit 1
        fi

        while true; do
          declare -A svc_ips
          for svc in "${services[@]}"; do
            # Fetch service IP from cluster dns if present. We make several tries
            # to do it: IPv4, IPv6, IPv4 over TCP and IPv6 over TCP. The two last ones
            # are for deployments with Kuryr on older OpenStack (OSP13) - those do not
            # support UDP loadbalancers and require reaching DNS through TCP.
            cmds=('dig -t A @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t AAAA @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t A +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t AAAA +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"')
            for i in ${!cmds[*]}
            do
              ips=($(eval "${cmds[i]}"))
              if [[ "$?" -eq 0 && "${#ips[@]}" -ne 0 ]]; then
                svc_ips["${svc}"]="${ips[@]}"
                break
              fi
            done
          done

          # Update /etc/hosts only if we get valid service IPs
          # We will not update /etc/hosts when there is coredns service outage or api unavailability
          # Stale entries could exist in /etc/hosts if the service is deleted
          if [[ -n "${svc_ips[*]-}" ]]; then
            # Build a new hosts file from /etc/hosts with our custom entries filtered out
            if ! sed --silent "/# ${OPENSHIFT_MARKER}/d; w ${TEMP_FILE}" "${HOSTS_FILE}"; then
              # Only continue rebuilding the hosts entries if its original content is preserved
              sleep 60 & wait
              continue
            fi

            # Append resolver entries for services
            rc=0
            for svc in "${!svc_ips[@]}"; do
              for ip in ${svc_ips[${svc}]}; do
                echo "${ip} ${svc} ${svc}.${CLUSTER_DOMAIN} # ${OPENSHIFT_MARKER}" >> "${TEMP_FILE}" || rc=$?
              done
            done
            if [[ $rc -ne 0 ]]; then
              sleep 60 & wait
              continue
            fi


            # TODO: Update /etc/hosts atomically to avoid any inconsistent behavior
            # Replace /etc/hosts with our modified version if needed
            cmp "${TEMP_FILE}" "${HOSTS_FILE}" || cp -f "${TEMP_FILE}" "${HOSTS_FILE}"
            # TEMP_FILE is not removed to avoid file create/delete and attributes copy churn
          fi
          sleep 60 & wait
          unset svc_ips
        done
      env:
      - name: SERVICES
        value: image-registry.openshift-image-registry.svc
      - name: NAMESERVER
        value: 172.30.0.10
      - name: CLUSTER_DOMAIN
        value: cluster.local
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      imagePullPolicy: IfNotPresent
      name: dns-node-resolver
      resources:
        requests:
          cpu: 5m
          memory: 21Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/hosts
        name: hosts-file
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-pc9np
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ci-op-9xx71rvq-1e28e-w667k-worker-centralus3-hgn49
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-resolver
    serviceAccountName: node-resolver
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/hosts
        type: File
      name: hosts-file
    - name: kube-api-access-pc9np
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:57:13Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:56:32Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:57:13Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:57:13Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:56:31Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://16aa269fad5eaa55e11f80b0f85c87dd4dc2498be148184cbc7399c064f7998c
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      lastState: {}
      name: dns-node-resolver
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T10:57:13Z"
    hostIP: 10.0.128.5
    hostIPs:
    - ip: 10.0.128.5
    phase: Running
    podIP: 10.0.128.5
    podIPs:
    - ip: 10.0.128.5
    qosClass: Burstable
    startTime: "2024-06-11T10:56:32Z"
- apiVersion: v1
  kind: Pod
  metadata:
    creationTimestamp: "2024-06-11T10:48:37Z"
    generateName: node-resolver-
    labels:
      controller-revision-hash: f988c7b7b
      dns.operator.openshift.io/daemonset-node-resolver: ""
      pod-template-generation: "1"
    managedFields:
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:metadata:
          f:annotations:
            .: {}
            f:target.workload.openshift.io/management: {}
          f:generateName: {}
          f:labels:
            .: {}
            f:controller-revision-hash: {}
            f:dns.operator.openshift.io/daemonset-node-resolver: {}
            f:pod-template-generation: {}
          f:ownerReferences:
            .: {}
            k:{"uid":"aadb4651-e71a-4b8a-b008-787fd00c7133"}: {}
        f:spec:
          f:affinity:
            .: {}
            f:nodeAffinity:
              .: {}
              f:requiredDuringSchedulingIgnoredDuringExecution: {}
          f:containers:
            k:{"name":"dns-node-resolver"}:
              .: {}
              f:command: {}
              f:env:
                .: {}
                k:{"name":"CLUSTER_DOMAIN"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"NAMESERVER"}:
                  .: {}
                  f:name: {}
                  f:value: {}
                k:{"name":"SERVICES"}:
                  .: {}
                  f:name: {}
                  f:value: {}
              f:image: {}
              f:imagePullPolicy: {}
              f:name: {}
              f:resources:
                .: {}
                f:requests:
                  .: {}
                  f:cpu: {}
                  f:memory: {}
              f:securityContext:
                .: {}
                f:privileged: {}
              f:terminationMessagePath: {}
              f:terminationMessagePolicy: {}
              f:volumeMounts:
                .: {}
                k:{"mountPath":"/etc/hosts"}:
                  .: {}
                  f:mountPath: {}
                  f:name: {}
          f:dnsPolicy: {}
          f:enableServiceLinks: {}
          f:hostNetwork: {}
          f:nodeSelector: {}
          f:priorityClassName: {}
          f:restartPolicy: {}
          f:schedulerName: {}
          f:securityContext: {}
          f:serviceAccount: {}
          f:serviceAccountName: {}
          f:terminationGracePeriodSeconds: {}
          f:tolerations: {}
          f:volumes:
            .: {}
            k:{"name":"hosts-file"}:
              .: {}
              f:hostPath:
                .: {}
                f:path: {}
                f:type: {}
              f:name: {}
      manager: kube-controller-manager
      operation: Update
      time: "2024-06-11T10:48:37Z"
    - apiVersion: v1
      fieldsType: FieldsV1
      fieldsV1:
        f:status:
          f:conditions:
            k:{"type":"ContainersReady"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Initialized"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"PodReadyToStartContainers"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
            k:{"type":"Ready"}:
              .: {}
              f:lastProbeTime: {}
              f:lastTransitionTime: {}
              f:status: {}
              f:type: {}
          f:containerStatuses: {}
          f:hostIP: {}
          f:hostIPs: {}
          f:phase: {}
          f:podIP: {}
          f:podIPs:
            .: {}
            k:{"ip":"10.0.0.7"}:
              .: {}
              f:ip: {}
          f:startTime: {}
      manager: kubelet
      operation: Update
      subresource: status
      time: "2024-06-11T10:48:38Z"
    name: node-resolver-vprmw
    namespace: openshift-dns
    ownerReferences:
    - apiVersion: apps/v1
      blockOwnerDeletion: true
      controller: true
      kind: DaemonSet
      name: node-resolver
      uid: aadb4651-e71a-4b8a-b008-787fd00c7133
    resourceVersion: "8704"
    uid: 365e2749-85ab-4dc0-9910-761975665b3d
  spec:
    affinity:
      nodeAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          nodeSelectorTerms:
          - matchFields:
            - key: metadata.name
              operator: In
              values:
              - ci-op-9xx71rvq-1e28e-w667k-master-2
    containers:
    - command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        set -uo pipefail

        trap 'jobs -p | xargs kill || true; wait; exit 0' TERM

        OPENSHIFT_MARKER="openshift-generated-node-resolver"
        HOSTS_FILE="/etc/hosts"
        TEMP_FILE="/etc/hosts.tmp"

        IFS=', ' read -r -a services <<< "${SERVICES}"

        # Make a temporary file with the old hosts file's attributes.
        if ! cp -f --attributes-only "${HOSTS_FILE}" "${TEMP_FILE}"; then
          echo "Failed to preserve hosts file. Exiting."
          exit 1
        fi

        while true; do
          declare -A svc_ips
          for svc in "${services[@]}"; do
            # Fetch service IP from cluster dns if present. We make several tries
            # to do it: IPv4, IPv6, IPv4 over TCP and IPv6 over TCP. The two last ones
            # are for deployments with Kuryr on older OpenStack (OSP13) - those do not
            # support UDP loadbalancers and require reaching DNS through TCP.
            cmds=('dig -t A @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t AAAA @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t A +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"'
                  'dig -t AAAA +tcp +retry=0 @"${NAMESERVER}" +short "${svc}.${CLUSTER_DOMAIN}"|grep -v "^;"')
            for i in ${!cmds[*]}
            do
              ips=($(eval "${cmds[i]}"))
              if [[ "$?" -eq 0 && "${#ips[@]}" -ne 0 ]]; then
                svc_ips["${svc}"]="${ips[@]}"
                break
              fi
            done
          done

          # Update /etc/hosts only if we get valid service IPs
          # We will not update /etc/hosts when there is coredns service outage or api unavailability
          # Stale entries could exist in /etc/hosts if the service is deleted
          if [[ -n "${svc_ips[*]-}" ]]; then
            # Build a new hosts file from /etc/hosts with our custom entries filtered out
            if ! sed --silent "/# ${OPENSHIFT_MARKER}/d; w ${TEMP_FILE}" "${HOSTS_FILE}"; then
              # Only continue rebuilding the hosts entries if its original content is preserved
              sleep 60 & wait
              continue
            fi

            # Append resolver entries for services
            rc=0
            for svc in "${!svc_ips[@]}"; do
              for ip in ${svc_ips[${svc}]}; do
                echo "${ip} ${svc} ${svc}.${CLUSTER_DOMAIN} # ${OPENSHIFT_MARKER}" >> "${TEMP_FILE}" || rc=$?
              done
            done
            if [[ $rc -ne 0 ]]; then
              sleep 60 & wait
              continue
            fi


            # TODO: Update /etc/hosts atomically to avoid any inconsistent behavior
            # Replace /etc/hosts with our modified version if needed
            cmp "${TEMP_FILE}" "${HOSTS_FILE}" || cp -f "${TEMP_FILE}" "${HOSTS_FILE}"
            # TEMP_FILE is not removed to avoid file create/delete and attributes copy churn
          fi
          sleep 60 & wait
          unset svc_ips
        done
      env:
      - name: SERVICES
        value: image-registry.openshift-image-registry.svc
      - name: NAMESERVER
        value: 172.30.0.10
      - name: CLUSTER_DOMAIN
        value: cluster.local
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      imagePullPolicy: IfNotPresent
      name: dns-node-resolver
      resources:
        requests:
          cpu: 5m
          memory: 21Mi
      securityContext:
        privileged: true
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: FallbackToLogsOnError
      volumeMounts:
      - mountPath: /etc/hosts
        name: hosts-file
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-g5rm2
        readOnly: true
    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    hostNetwork: true
    nodeName: ci-op-9xx71rvq-1e28e-w667k-master-2
    nodeSelector:
      kubernetes.io/os: linux
    preemptionPolicy: PreemptLowerPriority
    priority: 2000001000
    priorityClassName: system-node-critical
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: node-resolver
    serviceAccountName: node-resolver
    terminationGracePeriodSeconds: 30
    tolerations:
    - operator: Exists
    volumes:
    - hostPath:
        path: /etc/hosts
        type: File
      name: hosts-file
    - name: kube-api-access-g5rm2
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
        - configMap:
            items:
            - key: service-ca.crt
              path: service-ca.crt
            name: openshift-service-ca.crt
  status:
    conditions:
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:38Z"
      status: "True"
      type: PodReadyToStartContainers
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:37Z"
      status: "True"
      type: Initialized
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:38Z"
      status: "True"
      type: Ready
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:38Z"
      status: "True"
      type: ContainersReady
    - lastProbeTime: null
      lastTransitionTime: "2024-06-11T10:48:37Z"
      status: "True"
      type: PodScheduled
    containerStatuses:
    - containerID: cri-o://e259ab39aad12dd44f4baa67cd046a6abc5bdd0b731736a4601d391da7807c04
      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:685c1ecb542461771adb7ed00ff73f21046cfacb3f65e656b4168cb6cc0e1dcd
      lastState: {}
      name: dns-node-resolver
      ready: true
      restartCount: 0
      started: true
      state:
        running:
          startedAt: "2024-06-11T10:48:38Z"
    hostIP: 10.0.0.7
    hostIPs:
    - ip: 10.0.0.7
    phase: Running
    podIP: 10.0.0.7
    podIPs:
    - ip: 10.0.0.7
    qosClass: Burstable
    startTime: "2024-06-11T10:48:37Z"
kind: PodList
metadata:
  resourceVersion: "39908"
