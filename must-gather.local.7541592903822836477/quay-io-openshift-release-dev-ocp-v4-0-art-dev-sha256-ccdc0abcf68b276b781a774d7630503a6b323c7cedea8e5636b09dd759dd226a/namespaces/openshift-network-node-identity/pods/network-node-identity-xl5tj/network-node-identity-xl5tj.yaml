---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    openshift.io/scc: hostnetwork-v2
    seccomp.security.alpha.kubernetes.io/pod: runtime/default
  creationTimestamp: "2024-06-11T10:47:10Z"
  generateName: network-node-identity-
  labels:
    app: network-node-identity
    component: network
    controller-revision-hash: 9d576f5f9
    kubernetes.io/os: linux
    openshift.io/component: network
    pod-template-generation: "1"
    type: infra
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:target.workload.openshift.io/management: {}
        f:generateName: {}
        f:labels:
          .: {}
          f:app: {}
          f:component: {}
          f:controller-revision-hash: {}
          f:kubernetes.io/os: {}
          f:openshift.io/component: {}
          f:pod-template-generation: {}
          f:type: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"b875a6a5-e8c0-40a3-ab61-b17d9bcb02ac"}: {}
      f:spec:
        f:affinity:
          .: {}
          f:nodeAffinity:
            .: {}
            f:requiredDuringSchedulingIgnoredDuringExecution: {}
        f:containers:
          k:{"name":"approver"}:
            .: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"LOGLEVEL"}:
                .: {}
                f:name: {}
                f:value: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/env"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/var/run/ovnkube-identity-config"}:
                .: {}
                f:mountPath: {}
                f:name: {}
          k:{"name":"webhook"}:
            .: {}
            f:command: {}
            f:env:
              .: {}
              k:{"name":"KUBERNETES_NODE_NAME"}:
                .: {}
                f:name: {}
                f:valueFrom:
                  .: {}
                  f:fieldRef: {}
              k:{"name":"LOGLEVEL"}:
                .: {}
                f:name: {}
                f:value: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/env"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/etc/webhook-cert/"}:
                .: {}
                f:mountPath: {}
                f:name: {}
              k:{"mountPath":"/var/run/ovnkube-identity-config"}:
                .: {}
                f:mountPath: {}
                f:name: {}
        f:dnsPolicy: {}
        f:enableServiceLinks: {}
        f:hostNetwork: {}
        f:nodeSelector: {}
        f:priorityClassName: {}
        f:restartPolicy: {}
        f:schedulerName: {}
        f:securityContext: {}
        f:serviceAccount: {}
        f:serviceAccountName: {}
        f:terminationGracePeriodSeconds: {}
        f:tolerations: {}
        f:volumes:
          .: {}
          k:{"name":"env-overrides"}:
            .: {}
            f:configMap:
              .: {}
              f:defaultMode: {}
              f:name: {}
              f:optional: {}
            f:name: {}
          k:{"name":"ovnkube-identity-cm"}:
            .: {}
            f:configMap:
              .: {}
              f:defaultMode: {}
              f:items: {}
              f:name: {}
            f:name: {}
          k:{"name":"webhook-cert"}:
            .: {}
            f:name: {}
            f:secret:
              .: {}
              f:defaultMode: {}
              f:secretName: {}
    manager: kube-controller-manager
    operation: Update
    time: "2024-06-11T10:47:10Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions:
          k:{"type":"ContainersReady"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Initialized"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"PodReadyToStartContainers"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Ready"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
        f:containerStatuses: {}
        f:hostIP: {}
        f:hostIPs: {}
        f:phase: {}
        f:podIP: {}
        f:podIPs:
          .: {}
          k:{"ip":"10.0.0.7"}:
            .: {}
            f:ip: {}
        f:startTime: {}
    manager: kubelet
    operation: Update
    subresource: status
    time: "2024-06-11T11:04:38Z"
  name: network-node-identity-xl5tj
  namespace: openshift-network-node-identity
  ownerReferences:
  - apiVersion: apps/v1
    blockOwnerDeletion: true
    controller: true
    kind: DaemonSet
    name: network-node-identity
    uid: b875a6a5-e8c0-40a3-ab61-b17d9bcb02ac
  resourceVersion: "23928"
  uid: 389945c2-9545-4fff-ad8d-832758350bd0
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchFields:
          - key: metadata.name
            operator: In
            values:
            - ci-op-9xx71rvq-1e28e-w667k-master-2
  containers:
  - command:
    - /bin/bash
    - -c
    - |
      set -xe
      if [[ -f "/env/_master" ]]; then
        set -o allexport
        source "/env/_master"
        set +o allexport
      fi
      # OVN-K will try to remove hybrid overlay node annotations even when the hybrid overlay is not enabled.
      # https://github.com/ovn-org/ovn-kubernetes/blob/ac6820df0b338a246f10f412cd5ec903bd234694/go-controller/pkg/ovn/master.go#L791
      ho_enable="--enable-hybrid-overlay"
      echo "I$(date "+%m%d %H:%M:%S.%N") - network-node-identity - start webhook"
      # extra-allowed-user: service account `ovn-kubernetes-control-plane`
      # sets pod annotations in multi-homing layer3 network controller (cluster-manager)
      exec /usr/bin/ovnkube-identity  --k8s-apiserver=https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443 \
          --webhook-cert-dir="/etc/webhook-cert" \
          --webhook-host=127.0.0.1 \
          --webhook-port=9743 \
          ${ho_enable} \
          --enable-interconnect \
          --disable-approver \
          --extra-allowed-user="system:serviceaccount:openshift-ovn-kubernetes:ovn-kubernetes-control-plane" \
          --wait-for-kubernetes-api=200s \
          --pod-admission-conditions="/var/run/ovnkube-identity-config/additional-pod-admission-cond.json" \
          --loglevel="${LOGLEVEL}"
    env:
    - name: LOGLEVEL
      value: "2"
    - name: KUBERNETES_NODE_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: spec.nodeName
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f51f47793a3eda34f600e1e7eab027bc309b914eb8ea948765cf1a03549b34e4
    imagePullPolicy: IfNotPresent
    name: webhook
    resources:
      requests:
        cpu: 10m
        memory: 50Mi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      runAsNonRoot: true
      runAsUser: 1000540000
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/webhook-cert/
      name: webhook-cert
    - mountPath: /env
      name: env-overrides
    - mountPath: /var/run/ovnkube-identity-config
      name: ovnkube-identity-cm
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-sgzxx
      readOnly: true
  - command:
    - /bin/bash
    - -c
    - |
      set -xe
      if [[ -f "/env/_master" ]]; then
        set -o allexport
        source "/env/_master"
        set +o allexport
      fi

      echo "I$(date "+%m%d %H:%M:%S.%N") - network-node-identity - start approver"
      exec /usr/bin/ovnkube-identity  --k8s-apiserver=https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443 \
          --disable-webhook \
          --csr-acceptance-conditions="/var/run/ovnkube-identity-config/additional-cert-acceptance-cond.json" \
          --loglevel="${LOGLEVEL}"
    env:
    - name: LOGLEVEL
      value: "4"
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f51f47793a3eda34f600e1e7eab027bc309b914eb8ea948765cf1a03549b34e4
    imagePullPolicy: IfNotPresent
    name: approver
    resources:
      requests:
        cpu: 10m
        memory: 50Mi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      runAsNonRoot: true
      runAsUser: 1000540000
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /env
      name: env-overrides
    - mountPath: /var/run/ovnkube-identity-config
      name: ovnkube-identity-cm
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: kube-api-access-sgzxx
      readOnly: true
  dnsPolicy: Default
  enableServiceLinks: true
  hostNetwork: true
  nodeName: ci-op-9xx71rvq-1e28e-w667k-master-2
  nodeSelector:
    beta.kubernetes.io/os: linux
    node-role.kubernetes.io/master: ""
  preemptionPolicy: PreemptLowerPriority
  priority: 2000001000
  priorityClassName: system-node-critical
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext:
    fsGroup: 1000540000
    seLinuxOptions:
      level: s0:c23,c17
    seccompProfile:
      type: RuntimeDefault
    supplementalGroups:
    - 1000540000
  serviceAccount: network-node-identity
  serviceAccountName: network-node-identity
  terminationGracePeriodSeconds: 200
  tolerations:
  - operator: Exists
  volumes:
  - name: webhook-cert
    secret:
      defaultMode: 420
      secretName: network-node-identity-cert
  - configMap:
      defaultMode: 420
      name: env-overrides
      optional: true
    name: env-overrides
  - configMap:
      defaultMode: 420
      items:
      - key: additional-cert-acceptance-cond.json
        path: additional-cert-acceptance-cond.json
      - key: additional-pod-admission-cond.json
        path: additional-pod-admission-cond.json
      name: ovnkube-identity-cm
    name: ovnkube-identity-cm
  - name: kube-api-access-sgzxx
    projected:
      defaultMode: 420
      sources:
      - serviceAccountToken:
          expirationSeconds: 3607
          path: token
      - configMap:
          items:
          - key: ca.crt
            path: ca.crt
          name: kube-root-ca.crt
      - downwardAPI:
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
            path: namespace
      - configMap:
          items:
          - key: service-ca.crt
            path: service-ca.crt
          name: openshift-service-ca.crt
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:47:23Z"
    status: "True"
    type: PodReadyToStartContainers
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:47:10Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T11:04:38Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T11:04:38Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:47:10Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: cri-o://2568be23aae4960f0f03703f5f074c889b13dd58e5989bd1a14d684a479bbd2c
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f51f47793a3eda34f600e1e7eab027bc309b914eb8ea948765cf1a03549b34e4
    imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f51f47793a3eda34f600e1e7eab027bc309b914eb8ea948765cf1a03549b34e4
    lastState:
      terminated:
        containerID: cri-o://a82a0317c830d2cee05f8030d8db32fbdf1fef80adf4be9a5c110574c6071820
        exitCode: 1
        finishedAt: "2024-06-11T11:04:23Z"
        message: |
          known node in 51.701µs
          I0611 11:03:12.775823       1 reflector.go:800] sigs.k8s.io/controller-runtime/pkg/cache/internal/informers.go:105: Watch close - *v1.CertificateSigningRequest total 30 items received
          I0611 11:03:43.777586       1 with_retry.go:234] Got a Retry-After 1s response for attempt 1 to https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/certificates.k8s.io/v1/certificatesigningrequests?allowWatchBookmarks=true&resourceVersion=23494&timeoutSeconds=558&watch=true
          E0611 11:03:53.043964       1 leaderelection.go:332] error retrieving resource lock openshift-network-node-identity/ovnkube-identity: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity": context deadline exceeded
          I0611 11:03:53.044030       1 leaderelection.go:285] failed to renew lease openshift-network-node-identity/ovnkube-identity: timed out waiting for the condition
          I0611 11:04:14.778749       1 with_retry.go:234] Got a Retry-After 1s response for attempt 2 to https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/certificates.k8s.io/v1/certificatesigningrequests?allowWatchBookmarks=true&resourceVersion=23494&timeoutSeconds=558&watch=true
          E0611 11:04:23.044497       1 leaderelection.go:308] Failed to release lock: Put "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/coordination.k8s.io/v1/namespaces/openshift-network-node-identity/leases/ovnkube-identity": dial tcp 10.0.0.4:6443: i/o timeout
          error running approver: leader election lost
          I0611 11:04:23.044614       1 recorder.go:104] "ci-op-9xx71rvq-1e28e-w667k-master-2_b3cb6253-4785-47ef-b8ca-ac67bbfed3c3 stopped leading" logger="events" type="Normal" object={"kind":"Lease","namespace":"openshift-network-node-identity","name":"ovnkube-identity","uid":"ef847523-365a-4c4e-8c0d-f6aa1dd10fac","apiVersion":"coordination.k8s.io/v1","resourceVersion":"23626"} reason="LeaderElection"
        reason: Error
        startedAt: "2024-06-11T10:55:23Z"
    name: approver
    ready: true
    restartCount: 2
    started: true
    state:
      running:
        startedAt: "2024-06-11T11:04:37Z"
  - containerID: cri-o://57af800d7c5ce0368eca0a14e90b3a79b856caf67569496e4e9817811f0e6f09
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f51f47793a3eda34f600e1e7eab027bc309b914eb8ea948765cf1a03549b34e4
    imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:f51f47793a3eda34f600e1e7eab027bc309b914eb8ea948765cf1a03549b34e4
    lastState: {}
    name: webhook
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: "2024-06-11T10:47:22Z"
  hostIP: 10.0.0.7
  hostIPs:
  - ip: 10.0.0.7
  phase: Running
  podIP: 10.0.0.7
  podIPs:
  - ip: 10.0.0.7
  qosClass: Burstable
  startTime: "2024-06-11T10:47:10Z"
