2024-06-11T11:01:45.738565538Z + timeout 3m /bin/bash -exuo pipefail -c 'while [ -n "$(ss -Htanop \( sport = 10357 \))" ]; do sleep 1; done'
2024-06-11T11:01:45.744244856Z ++ ss -Htanop '(' sport = 10357 ')'
2024-06-11T11:01:45.749428172Z + '[' -n '' ']'
2024-06-11T11:01:45.750018974Z + exec cluster-policy-controller start --config=/etc/kubernetes/static-pod-resources/configmaps/cluster-policy-controller-config/config.yaml --kubeconfig=/etc/kubernetes/static-pod-resources/configmaps/controller-manager-kubeconfig/kubeconfig --namespace=openshift-kube-controller-manager -v=2
2024-06-11T11:01:45.839320551Z I0611 11:01:45.839075       1 leaderelection.go:122] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2024-06-11T11:01:45.840516855Z I0611 11:01:45.840476       1 observer_polling.go:159] Starting file observer
2024-06-11T11:01:45.842273960Z I0611 11:01:45.842200       1 builder.go:299] cluster-policy-controller version 4.16.0-202406061206.p0.geaea543.assembly.stream.el9-eaea543-eaea543f4c845a7b65705f12e162cc121bb12f88
2024-06-11T11:01:45.843697665Z I0611 11:01:45.843640       1 dynamic_serving_content.go:113] "Loaded a new cert/key pair" name="serving-cert::/etc/kubernetes/static-pod-resources/secrets/serving-cert/tls.crt::/etc/kubernetes/static-pod-resources/secrets/serving-cert/tls.key"
2024-06-11T11:01:46.505743924Z I0611 11:01:46.505673       1 requestheader_controller.go:244] Loaded a new request header values for RequestHeaderAuthRequestController
2024-06-11T11:01:46.512916346Z I0611 11:01:46.512861       1 maxinflight.go:139] "Initialized nonMutatingChan" len=400
2024-06-11T11:01:46.512916346Z I0611 11:01:46.512888       1 maxinflight.go:145] "Initialized mutatingChan" len=200
2024-06-11T11:01:46.512954246Z I0611 11:01:46.512920       1 maxinflight.go:116] "Set denominator for readonly requests" limit=400
2024-06-11T11:01:46.512954246Z I0611 11:01:46.512930       1 maxinflight.go:120] "Set denominator for mutating requests" limit=200
2024-06-11T11:01:46.517385960Z I0611 11:01:46.517302       1 secure_serving.go:57] Forcing use of http/1.1 only
2024-06-11T11:01:46.517420960Z I0611 11:01:46.517400       1 genericapiserver.go:523] MuxAndDiscoveryComplete has all endpoints registered and discovery information is complete
2024-06-11T11:01:46.518408363Z W0611 11:01:46.518313       1 builder.go:358] unable to get control plane topology, using HA cluster values for leader election: infrastructures.config.openshift.io "cluster" is forbidden: User "system:kube-controller-manager" cannot get resource "infrastructures" in API group "config.openshift.io" at the cluster scope
2024-06-11T11:01:46.518543063Z I0611 11:01:46.518441       1 event.go:364] Event(v1.ObjectReference{Kind:"Pod", Namespace:"openshift-kube-controller-manager", Name:"kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ControlPlaneTopology' unable to get control plane topology, using HA cluster values for leader election: infrastructures.config.openshift.io "cluster" is forbidden: User "system:kube-controller-manager" cannot get resource "infrastructures" in API group "config.openshift.io" at the cluster scope
2024-06-11T11:01:46.519053565Z I0611 11:01:46.518992       1 leaderelection.go:250] attempting to acquire leader lease openshift-kube-controller-manager/cluster-policy-controller-lock...
2024-06-11T11:01:46.522447275Z I0611 11:01:46.522382       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2024-06-11T11:01:46.522474176Z I0611 11:01:46.522391       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2024-06-11T11:01:46.522517176Z I0611 11:01:46.522478       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2024-06-11T11:01:46.522738976Z I0611 11:01:46.522525       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-06-11T11:01:46.522738976Z I0611 11:01:46.522553       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-06-11T11:01:46.522738976Z I0611 11:01:46.522551       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
2024-06-11T11:01:46.523326278Z I0611 11:01:46.523280       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/etc/kubernetes/static-pod-resources/secrets/serving-cert/tls.crt::/etc/kubernetes/static-pod-resources/secrets/serving-cert/tls.key"
2024-06-11T11:01:46.523831280Z I0611 11:01:46.523778       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/etc/kubernetes/static-pod-resources/secrets/serving-cert/tls.crt::/etc/kubernetes/static-pod-resources/secrets/serving-cert/tls.key" certDetail="\"kube-controller-manager.openshift-kube-controller-manager.svc\" [serving] validServingFor=[kube-controller-manager.openshift-kube-controller-manager.svc,kube-controller-manager.openshift-kube-controller-manager.svc.cluster.local] issuer=\"openshift-service-serving-signer@1718102902\" (2024-06-11 10:48:45 +0000 UTC to 2026-06-11 10:48:46 +0000 UTC (now=2024-06-11 11:01:46.52374798 +0000 UTC))"
2024-06-11T11:01:46.524383781Z I0611 11:01:46.524336       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1718103706\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1718103706\" (2024-06-11 10:01:45 +0000 UTC to 2025-06-11 10:01:45 +0000 UTC (now=2024-06-11 11:01:46.524312281 +0000 UTC))"
2024-06-11T11:01:46.524431782Z I0611 11:01:46.524380       1 secure_serving.go:213] Serving securely on [::]:10357
2024-06-11T11:01:46.524446082Z I0611 11:01:46.524430       1 genericapiserver.go:671] [graceful-termination] waiting for shutdown to be initiated
2024-06-11T11:01:46.524475782Z I0611 11:01:46.524455       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2024-06-11T11:01:46.527192190Z I0611 11:01:46.527125       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.528014593Z I0611 11:01:46.527959       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.528785095Z I0611 11:01:46.528744       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.534549013Z I0611 11:01:46.534480       1 leaderelection.go:260] successfully acquired lease openshift-kube-controller-manager/cluster-policy-controller-lock
2024-06-11T11:01:46.534654813Z I0611 11:01:46.534590       1 event.go:364] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-controller-manager", Name:"cluster-policy-controller-lock", UID:"4b49b737-9d34-4ce1-ae1e-5ab8d3a60903", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"23107", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' ci-op-9xx71rvq-1e28e-w667k-master-0_471fce2f-74ab-41d9-9fc9-d1deb857f4cc became leader
2024-06-11T11:01:46.544153243Z I0611 11:01:46.544066       1 policy_controller.go:78] Starting "openshift.io/podsecurity-admission-label-syncer"
2024-06-11T11:01:46.548481456Z I0611 11:01:46.548436       1 policy_controller.go:88] Started "openshift.io/podsecurity-admission-label-syncer"
2024-06-11T11:01:46.548609157Z I0611 11:01:46.548566       1 base_controller.go:67] Waiting for caches to sync for pod-security-admission-label-synchronization-controller
2024-06-11T11:01:46.548679057Z I0611 11:01:46.548569       1 policy_controller.go:78] Starting "openshift.io/privileged-namespaces-psa-label-syncer"
2024-06-11T11:01:46.553803473Z I0611 11:01:46.553732       1 policy_controller.go:88] Started "openshift.io/privileged-namespaces-psa-label-syncer"
2024-06-11T11:01:46.553803473Z I0611 11:01:46.553761       1 policy_controller.go:78] Starting "openshift.io/namespace-security-allocation"
2024-06-11T11:01:46.553831773Z I0611 11:01:46.553790       1 privileged_namespaces_controller.go:75] "Starting" controller="privileged-namespaces-psa-label-syncer"
2024-06-11T11:01:46.553831773Z I0611 11:01:46.553812       1 shared_informer.go:311] Waiting for caches to sync for privileged-namespaces-psa-label-syncer
2024-06-11T11:01:46.562053199Z I0611 11:01:46.561983       1 policy_controller.go:88] Started "openshift.io/namespace-security-allocation"
2024-06-11T11:01:46.562053199Z I0611 11:01:46.562016       1 policy_controller.go:78] Starting "openshift.io/resourcequota"
2024-06-11T11:01:46.562116399Z I0611 11:01:46.562086       1 base_controller.go:67] Waiting for caches to sync for namespace-security-allocation-controller
2024-06-11T11:01:46.610817250Z I0611 11:01:46.610754       1 policy_controller.go:88] Started "openshift.io/resourcequota"
2024-06-11T11:01:46.610817250Z I0611 11:01:46.610778       1 policy_controller.go:78] Starting "openshift.io/cluster-quota-reconciliation"
2024-06-11T11:01:46.610855050Z I0611 11:01:46.610812       1 resource_quota_controller.go:294] "Starting resource quota controller"
2024-06-11T11:01:46.610855050Z I0611 11:01:46.610835       1 shared_informer.go:311] Waiting for caches to sync for resource quota
2024-06-11T11:01:46.610906151Z I0611 11:01:46.610872       1 resource_quota_monitor.go:305] "QuotaMonitor running"
2024-06-11T11:01:46.623343089Z I0611 11:01:46.623299       1 shared_informer.go:318] Caches are synced for RequestHeaderAuthRequestController
2024-06-11T11:01:46.623343089Z I0611 11:01:46.623328       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-06-11T11:01:46.623415689Z I0611 11:01:46.623385       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-06-11T11:01:46.623588090Z I0611 11:01:46.623548       1 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:02 +0000 UTC to 2024-06-12 10:19:02 +0000 UTC (now=2024-06-11 11:01:46.62350759 +0000 UTC))"
2024-06-11T11:01:46.624394892Z I0611 11:01:46.624317       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/etc/kubernetes/static-pod-resources/secrets/serving-cert/tls.crt::/etc/kubernetes/static-pod-resources/secrets/serving-cert/tls.key" certDetail="\"kube-controller-manager.openshift-kube-controller-manager.svc\" [serving] validServingFor=[kube-controller-manager.openshift-kube-controller-manager.svc,kube-controller-manager.openshift-kube-controller-manager.svc.cluster.local] issuer=\"openshift-service-serving-signer@1718102902\" (2024-06-11 10:48:45 +0000 UTC to 2026-06-11 10:48:46 +0000 UTC (now=2024-06-11 11:01:46.624278392 +0000 UTC))"
2024-06-11T11:01:46.625064495Z I0611 11:01:46.624952       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1718103706\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1718103706\" (2024-06-11 10:01:45 +0000 UTC to 2025-06-11 10:01:45 +0000 UTC (now=2024-06-11 11:01:46.624921394 +0000 UTC))"
2024-06-11T11:01:46.625275495Z I0611 11:01:46.625245       1 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:00 +0000 UTC to 2034-06-09 10:19:00 +0000 UTC (now=2024-06-11 11:01:46.625216195 +0000 UTC))"
2024-06-11T11:01:46.625315495Z I0611 11:01:46.625296       1 tlsconfig.go:178] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2024-06-12 10:19:05 +0000 UTC (now=2024-06-11 11:01:46.625272795 +0000 UTC))"
2024-06-11T11:01:46.625382996Z I0611 11:01:46.625362       1 tlsconfig.go:178] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2025-06-11 10:19:05 +0000 UTC (now=2024-06-11 11:01:46.625313495 +0000 UTC))"
2024-06-11T11:01:46.625445096Z I0611 11:01:46.625427       1 tlsconfig.go:178] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2025-06-11 10:19:05 +0000 UTC (now=2024-06-11 11:01:46.625383996 +0000 UTC))"
2024-06-11T11:01:46.625500596Z I0611 11:01:46.625467       1 tlsconfig.go:178] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:01 +0000 UTC to 2034-06-09 10:19:01 +0000 UTC (now=2024-06-11 11:01:46.625444796 +0000 UTC))"
2024-06-11T11:01:46.625538096Z I0611 11:01:46.625521       1 tlsconfig.go:178] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1718102903\" [] issuer=\"kubelet-signer\" (2024-06-11 10:48:22 +0000 UTC to 2024-06-12 10:19:05 +0000 UTC (now=2024-06-11 11:01:46.625499996 +0000 UTC))"
2024-06-11T11:01:46.625579896Z I0611 11:01:46.625562       1 tlsconfig.go:178] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1718102900\" [] issuer=\"<self>\" (2024-06-11 10:48:20 +0000 UTC to 2025-06-11 10:48:21 +0000 UTC (now=2024-06-11 11:01:46.625537296 +0000 UTC))"
2024-06-11T11:01:46.625617796Z I0611 11:01:46.625600       1 tlsconfig.go:178] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:02 +0000 UTC to 2024-06-12 10:19:02 +0000 UTC (now=2024-06-11 11:01:46.625579896 +0000 UTC))"
2024-06-11T11:01:46.626531499Z I0611 11:01:46.626363       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/etc/kubernetes/static-pod-resources/secrets/serving-cert/tls.crt::/etc/kubernetes/static-pod-resources/secrets/serving-cert/tls.key" certDetail="\"kube-controller-manager.openshift-kube-controller-manager.svc\" [serving] validServingFor=[kube-controller-manager.openshift-kube-controller-manager.svc,kube-controller-manager.openshift-kube-controller-manager.svc.cluster.local] issuer=\"openshift-service-serving-signer@1718102902\" (2024-06-11 10:48:45 +0000 UTC to 2026-06-11 10:48:46 +0000 UTC (now=2024-06-11 11:01:46.626269798 +0000 UTC))"
2024-06-11T11:01:46.627353202Z I0611 11:01:46.627315       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1718103706\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1718103706\" (2024-06-11 10:01:45 +0000 UTC to 2025-06-11 10:01:45 +0000 UTC (now=2024-06-11 11:01:46.627287701 +0000 UTC))"
2024-06-11T11:01:46.757595107Z I0611 11:01:46.757529       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="controllerrevisions.apps"
2024-06-11T11:01:46.757804007Z I0611 11:01:46.757755       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="poddisruptionbudgets.policy"
2024-06-11T11:01:46.757870208Z I0611 11:01:46.757844       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="egressqoses.k8s.ovn.org"
2024-06-11T11:01:46.757923608Z I0611 11:01:46.757901       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="controlplanemachinesets.machine.openshift.io"
2024-06-11T11:01:46.757968008Z I0611 11:01:46.757944       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="egressrouters.network.operator.openshift.io"
2024-06-11T11:01:46.758117708Z I0611 11:01:46.758014       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="operatorpkis.network.operator.openshift.io"
2024-06-11T11:01:46.758173108Z I0611 11:01:46.758145       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="ingresscontrollers.operator.openshift.io"
2024-06-11T11:01:46.758682910Z I0611 11:01:46.758209       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="metal3remediationtemplates.infrastructure.cluster.x-k8s.io"
2024-06-11T11:01:46.758682910Z I0611 11:01:46.758262       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="probes.monitoring.coreos.com"
2024-06-11T11:01:46.758682910Z I0611 11:01:46.758310       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="operatorconditions.operators.coreos.com"
2024-06-11T11:01:46.758682910Z I0611 11:01:46.758348       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="daemonsets.apps"
2024-06-11T11:01:46.758682910Z I0611 11:01:46.758398       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="rolebindingrestrictions.authorization.openshift.io"
2024-06-11T11:01:46.758682910Z I0611 11:01:46.758439       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="machines.machine.openshift.io"
2024-06-11T11:01:46.758682910Z I0611 11:01:46.758495       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="servicemonitors.monitoring.coreos.com"
2024-06-11T11:01:46.758682910Z I0611 11:01:46.758542       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="podmonitors.monitoring.coreos.com"
2024-06-11T11:01:46.758682910Z I0611 11:01:46.758601       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="rolebindings.rbac.authorization.k8s.io"
2024-06-11T11:01:46.758682910Z I0611 11:01:46.758658       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="machinehealthchecks.machine.openshift.io"
2024-06-11T11:01:46.758796310Z I0611 11:01:46.758766       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="hostfirmwarecomponents.metal3.io"
2024-06-11T11:01:46.758848311Z I0611 11:01:46.758826       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="catalogsources.operators.coreos.com"
2024-06-11T11:01:46.759462412Z I0611 11:01:46.759409       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="leases.coordination.k8s.io"
2024-06-11T11:01:46.759660013Z I0611 11:01:46.759608       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="metal3remediations.infrastructure.cluster.x-k8s.io"
2024-06-11T11:01:46.759685513Z I0611 11:01:46.759673       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="dnsrecords.ingress.operator.openshift.io"
2024-06-11T11:01:46.759746913Z I0611 11:01:46.759698       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="installplans.operators.coreos.com"
2024-06-11T11:01:46.759789814Z I0611 11:01:46.759766       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="roles.rbac.authorization.k8s.io"
2024-06-11T11:01:46.759873914Z I0611 11:01:46.759841       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="alertmanagers.monitoring.coreos.com"
2024-06-11T11:01:46.759913914Z I0611 11:01:46.759892       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="alertingrules.monitoring.openshift.io"
2024-06-11T11:01:46.760060114Z I0611 11:01:46.760013       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="ippools.whereabouts.cni.cncf.io"
2024-06-11T11:01:46.760193415Z I0611 11:01:46.760167       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="replicasets.apps"
2024-06-11T11:01:46.760462216Z I0611 11:01:46.760313       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="csistoragecapacities.storage.k8s.io"
2024-06-11T11:01:46.760771517Z I0611 11:01:46.760741       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="baremetalhosts.metal3.io"
2024-06-11T11:01:46.760805217Z I0611 11:01:46.760788       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="dataimages.metal3.io"
2024-06-11T11:01:46.760848017Z I0611 11:01:46.760818       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="prometheuses.monitoring.coreos.com"
2024-06-11T11:01:46.760879017Z I0611 11:01:46.760859       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="profiles.tuned.openshift.io"
2024-06-11T11:01:46.760905317Z I0611 11:01:46.760892       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="jobs.batch"
2024-06-11T11:01:46.760947717Z I0611 11:01:46.760926       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="ingresses.networking.k8s.io"
2024-06-11T11:01:46.760960317Z I0611 11:01:46.760952       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="ipaddresses.ipam.cluster.x-k8s.io"
2024-06-11T11:01:46.760981217Z I0611 11:01:46.760972       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="thanosrulers.monitoring.coreos.com"
2024-06-11T11:01:46.761009717Z I0611 11:01:46.760990       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="prometheusrules.monitoring.coreos.com"
2024-06-11T11:01:46.761081318Z I0611 11:01:46.761029       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="tuneds.tuned.openshift.io"
2024-06-11T11:01:46.761102318Z I0611 11:01:46.761092       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="ipaddressclaims.ipam.cluster.x-k8s.io"
2024-06-11T11:01:46.761133418Z I0611 11:01:46.761114       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="alertmanagerconfigs.monitoring.coreos.com"
2024-06-11T11:01:46.761148718Z I0611 11:01:46.761139       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="clusterserviceversions.operators.coreos.com"
2024-06-11T11:01:46.761182818Z I0611 11:01:46.761165       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="machineautoscalers.autoscaling.openshift.io"
2024-06-11T11:01:46.761198018Z I0611 11:01:46.761189       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="credentialsrequests.cloudcredential.openshift.io"
2024-06-11T11:01:46.761234218Z I0611 11:01:46.761212       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="projecthelmchartrepositories.helm.openshift.io"
2024-06-11T11:01:46.761246518Z I0611 11:01:46.761238       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="hostfirmwaresettings.metal3.io"
2024-06-11T11:01:46.761275718Z I0611 11:01:46.761258       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="subscriptions.operators.coreos.com"
2024-06-11T11:01:46.761290718Z I0611 11:01:46.761281       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="volumesnapshots.snapshot.storage.k8s.io"
2024-06-11T11:01:46.761317618Z I0611 11:01:46.761300       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="limitranges"
2024-06-11T11:01:46.761329618Z I0611 11:01:46.761322       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="statefulsets.apps"
2024-06-11T11:01:46.761359418Z I0611 11:01:46.761342       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="networkpolicies.networking.k8s.io"
2024-06-11T11:01:46.761371618Z I0611 11:01:46.761364       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="egressfirewalls.k8s.ovn.org"
2024-06-11T11:01:46.761399419Z I0611 11:01:46.761382       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="machinesets.machine.openshift.io"
2024-06-11T11:01:46.761414219Z I0611 11:01:46.761405       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="bmceventsubscriptions.metal3.io"
2024-06-11T11:01:46.761450619Z I0611 11:01:46.761427       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="alertrelabelconfigs.monitoring.openshift.io"
2024-06-11T11:01:46.761462719Z I0611 11:01:46.761453       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="podtemplates"
2024-06-11T11:01:46.761490319Z I0611 11:01:46.761474       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="deployments.apps"
2024-06-11T11:01:46.761508919Z I0611 11:01:46.761499       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="horizontalpodautoscalers.autoscaling"
2024-06-11T11:01:46.761532419Z I0611 11:01:46.761521       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="egressservices.k8s.ovn.org"
2024-06-11T11:01:46.761570519Z I0611 11:01:46.761549       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="firmwareschemas.metal3.io"
2024-06-11T11:01:46.761585619Z I0611 11:01:46.761576       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="overlappingrangeipreservations.whereabouts.cni.cncf.io"
2024-06-11T11:01:46.761612119Z I0611 11:01:46.761595       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="endpoints"
2024-06-11T11:01:46.761651819Z I0611 11:01:46.761631       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="preprovisioningimages.metal3.io"
2024-06-11T11:01:46.761698019Z I0611 11:01:46.761679       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="operatorgroups.operators.coreos.com"
2024-06-11T11:01:46.761739420Z I0611 11:01:46.761722       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="serviceaccounts"
2024-06-11T11:01:46.761754420Z I0611 11:01:46.761746       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="cronjobs.batch"
2024-06-11T11:01:46.761805120Z I0611 11:01:46.761767       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="endpointslices.discovery.k8s.io"
2024-06-11T11:01:46.761805120Z I0611 11:01:46.761794       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="network-attachment-definitions.k8s.cni.cncf.io"
2024-06-11T11:01:46.761835520Z I0611 11:01:46.761821       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="hardwaredata.metal3.io"
2024-06-11T11:01:46.761863920Z I0611 11:01:46.761843       1 policy_controller.go:88] Started "openshift.io/cluster-quota-reconciliation"
2024-06-11T11:01:46.761863920Z I0611 11:01:46.761855       1 policy_controller.go:78] Starting "openshift.io/cluster-csr-approver"
2024-06-11T11:01:46.761913020Z I0611 11:01:46.761884       1 clusterquotamapping.go:127] Starting ClusterQuotaMappingController controller
2024-06-11T11:01:46.761925320Z I0611 11:01:46.761909       1 reconciliation_controller.go:140] Starting the cluster quota reconciliation controller
2024-06-11T11:01:46.761979820Z I0611 11:01:46.761952       1 resource_quota_monitor.go:305] "QuotaMonitor running"
2024-06-11T11:01:46.768644741Z I0611 11:01:46.768604       1 reconciliation_controller.go:207] syncing resource quota controller with updated resources from discovery: added: [/v1, Resource=configmaps /v1, Resource=endpoints /v1, Resource=events /v1, Resource=limitranges /v1, Resource=persistentvolumeclaims /v1, Resource=pods /v1, Resource=podtemplates /v1, Resource=replicationcontrollers /v1, Resource=resourcequotas /v1, Resource=secrets /v1, Resource=serviceaccounts /v1, Resource=services apps/v1, Resource=controllerrevisions apps/v1, Resource=daemonsets apps/v1, Resource=deployments apps/v1, Resource=replicasets apps/v1, Resource=statefulsets authorization.openshift.io/v1, Resource=rolebindingrestrictions autoscaling.openshift.io/v1beta1, Resource=machineautoscalers autoscaling/v2, Resource=horizontalpodautoscalers batch/v1, Resource=cronjobs batch/v1, Resource=jobs cloudcredential.openshift.io/v1, Resource=credentialsrequests coordination.k8s.io/v1, Resource=leases discovery.k8s.io/v1, Resource=endpointslices events.k8s.io/v1, Resource=events helm.openshift.io/v1beta1, Resource=projecthelmchartrepositories infrastructure.cluster.x-k8s.io/v1beta1, Resource=metal3remediations infrastructure.cluster.x-k8s.io/v1beta1, Resource=metal3remediationtemplates ingress.operator.openshift.io/v1, Resource=dnsrecords ipam.cluster.x-k8s.io/v1beta1, Resource=ipaddressclaims ipam.cluster.x-k8s.io/v1beta1, Resource=ipaddresses k8s.cni.cncf.io/v1, Resource=network-attachment-definitions k8s.ovn.org/v1, Resource=egressfirewalls k8s.ovn.org/v1, Resource=egressqoses k8s.ovn.org/v1, Resource=egressservices machine.openshift.io/v1, Resource=controlplanemachinesets machine.openshift.io/v1beta1, Resource=machinehealthchecks machine.openshift.io/v1beta1, Resource=machines machine.openshift.io/v1beta1, Resource=machinesets metal3.io/v1alpha1, Resource=baremetalhosts metal3.io/v1alpha1, Resource=bmceventsubscriptions metal3.io/v1alpha1, Resource=dataimages metal3.io/v1alpha1, Resource=firmwareschemas metal3.io/v1alpha1, Resource=hardwaredata metal3.io/v1alpha1, Resource=hostfirmwarecomponents metal3.io/v1alpha1, Resource=hostfirmwaresettings metal3.io/v1alpha1, Resource=preprovisioningimages monitoring.coreos.com/v1, Resource=alertmanagers monitoring.coreos.com/v1, Resource=podmonitors monitoring.coreos.com/v1, Resource=probes monitoring.coreos.com/v1, Resource=prometheuses monitoring.coreos.com/v1, Resource=prometheusrules monitoring.coreos.com/v1, Resource=servicemonitors monitoring.coreos.com/v1, Resource=thanosrulers monitoring.coreos.com/v1beta1, Resource=alertmanagerconfigs monitoring.openshift.io/v1, Resource=alertingrules monitoring.openshift.io/v1, Resource=alertrelabelconfigs network.operator.openshift.io/v1, Resource=egressrouters network.operator.openshift.io/v1, Resource=operatorpkis networking.k8s.io/v1, Resource=ingresses networking.k8s.io/v1, Resource=networkpolicies operator.openshift.io/v1, Resource=ingresscontrollers operators.coreos.com/v1, Resource=operatorgroups operators.coreos.com/v1alpha1, Resource=catalogsources operators.coreos.com/v1alpha1, Resource=clusterserviceversions operators.coreos.com/v1alpha1, Resource=installplans operators.coreos.com/v1alpha1, Resource=subscriptions operators.coreos.com/v2, Resource=operatorconditions policy/v1, Resource=poddisruptionbudgets rbac.authorization.k8s.io/v1, Resource=rolebindings rbac.authorization.k8s.io/v1, Resource=roles snapshot.storage.k8s.io/v1, Resource=volumesnapshots storage.k8s.io/v1, Resource=csistoragecapacities tuned.openshift.io/v1, Resource=profiles tuned.openshift.io/v1, Resource=tuneds whereabouts.cni.cncf.io/v1alpha1, Resource=ippools whereabouts.cni.cncf.io/v1alpha1, Resource=overlappingrangeipreservations], removed: []
2024-06-11T11:01:46.949457303Z I0611 11:01:46.949376       1 policy_controller.go:88] Started "openshift.io/cluster-csr-approver"
2024-06-11T11:01:46.949457303Z I0611 11:01:46.949411       1 policy_controller.go:91] Started Origin Controllers
2024-06-11T11:01:46.949659904Z I0611 11:01:46.949604       1 base_controller.go:67] Waiting for caches to sync for WebhookAuthenticatorCertApprover_csr-approver-controller
2024-06-11T11:01:46.955461522Z I0611 11:01:46.955420       1 reflector.go:351] Caches populated for *v2.HorizontalPodAutoscaler from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.961609341Z I0611 11:01:46.961564       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.981537603Z W0611 11:01:46.981467       1 reflector.go:539] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:01:46.981630203Z I0611 11:01:46.981589       1 reflector.go:351] Caches populated for *v1.CSIStorageCapacity from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.984131611Z E0611 11:01:46.981650       1 reflector.go:147] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: Failed to watch *v1.ImageStream: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:01:46.986462318Z I0611 11:01:46.981487       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.986718719Z I0611 11:01:46.981793       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.986718719Z I0611 11:01:46.983143       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.986856220Z I0611 11:01:46.983334       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.987108620Z I0611 11:01:46.984193       1 reflector.go:351] Caches populated for *v1.NetworkPolicy from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.990188330Z I0611 11:01:46.990150       1 reflector.go:351] Caches populated for *v1.SecurityContextConstraints from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.993342640Z I0611 11:01:46.990706       1 reflector.go:351] Caches populated for *v1.Job from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.993579640Z I0611 11:01:46.990858       1 reflector.go:351] Caches populated for *v1.CronJob from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.993781041Z I0611 11:01:46.990973       1 reflector.go:351] Caches populated for *v1.StatefulSet from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.994409843Z I0611 11:01:46.991065       1 reflector.go:351] Caches populated for *v1.ClusterResourceQuota from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.995502646Z I0611 11:01:46.995454       1 reflector.go:351] Caches populated for *v1.Lease from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.996119148Z I0611 11:01:46.996083       1 reflector.go:351] Caches populated for *v1.EndpointSlice from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.996926951Z I0611 11:01:46.996879       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:46.998962257Z I0611 11:01:46.998916       1 reflector.go:351] Caches populated for *v1.Ingress from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.000749863Z I0611 11:01:47.000708       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.001025664Z I0611 11:01:47.000992       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.001169964Z I0611 11:01:46.998930       1 reflector.go:351] Caches populated for *v1.CertificateSigningRequest from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.001356765Z I0611 11:01:47.001319       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.002016567Z I0611 11:01:47.001974       1 reflector.go:351] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.003794772Z I0611 11:01:47.003758       1 reflector.go:351] Caches populated for *v1.ControllerRevision from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.016391711Z I0611 11:01:47.016229       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.030924457Z I0611 11:01:47.030860       1 reflector.go:351] Caches populated for *v1.DaemonSet from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.033706065Z I0611 11:01:47.033639       1 reflector.go:351] Caches populated for *v1.Role from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.036496874Z E0611 11:01:47.036454       1 podsecurity_label_sync_controller.go:420] failed to determine whether namespace "openshift-image-registry" should be enqueued: namespace "openshift-image-registry" not found
2024-06-11T11:01:47.037015076Z E0611 11:01:47.036982       1 podsecurity_label_sync_controller.go:420] failed to determine whether namespace "openshift-machine-api" should be enqueued: namespace "openshift-machine-api" not found
2024-06-11T11:01:47.037736678Z E0611 11:01:47.037701       1 podsecurity_label_sync_controller.go:420] failed to determine whether namespace "openshift-service-ca" should be enqueued: namespace "openshift-service-ca" not found
2024-06-11T11:01:47.039544283Z I0611 11:01:47.039502       1 reflector.go:351] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.041172388Z I0611 11:01:47.039649       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "azure-disk-csi-driver-operator-clusterrole" not found
2024-06-11T11:01:47.041206489Z I0611 11:01:47.041172       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "openshift-csi-main-attacher-role" not found
2024-06-11T11:01:47.041206489Z I0611 11:01:47.041195       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "openshift-csi-main-provisioner-role" not found
2024-06-11T11:01:47.041221789Z I0611 11:01:47.041208       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "openshift-csi-main-resizer-role" not found
2024-06-11T11:01:47.041234489Z I0611 11:01:47.041221       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "openshift-csi-main-snapshotter-role" not found
2024-06-11T11:01:47.042137191Z I0611 11:01:47.042069       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "openshift-csi-resizer-storageclass-reader-role" not found
2024-06-11T11:01:47.042137191Z I0611 11:01:47.042122       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "openshift-csi-provisioner-volumesnapshot-reader-role" not found
2024-06-11T11:01:47.042170692Z I0611 11:01:47.042139       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "azure-disk-kube-rbac-proxy-role" not found
2024-06-11T11:01:47.042170692Z I0611 11:01:47.042151       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "azure-disk-privileged-role" not found
2024-06-11T11:01:47.042201492Z I0611 11:01:47.042181       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "azure-file-csi-driver-role" not found
2024-06-11T11:01:47.042201492Z I0611 11:01:47.042197       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "azure-file-csi-driver-operator-clusterrole" not found
2024-06-11T11:01:47.042220292Z I0611 11:01:47.042212       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "openshift-csi-main-attacher-role" not found
2024-06-11T11:01:47.042281692Z I0611 11:01:47.042243       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "openshift-csi-main-provisioner-role" not found
2024-06-11T11:01:47.042373592Z I0611 11:01:47.042346       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "openshift-csi-main-resizer-role" not found
2024-06-11T11:01:47.042481093Z I0611 11:01:47.042427       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "openshift-csi-resizer-storageclass-reader-role" not found
2024-06-11T11:01:47.042593993Z I0611 11:01:47.042567       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "azure-file-kube-rbac-proxy-role" not found
2024-06-11T11:01:47.042661993Z I0611 11:01:47.042643       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "azure-file-privileged-role" not found
2024-06-11T11:01:47.042881794Z I0611 11:01:47.042652       1 reflector.go:351] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.043560596Z I0611 11:01:47.043523       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "openshift-csi-snapshot-controller-runner" not found
2024-06-11T11:01:47.043658096Z I0611 11:01:47.043629       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "view" not found
2024-06-11T11:01:47.043727896Z I0611 11:01:47.043705       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:auth-delegator" not found
2024-06-11T11:01:47.043913897Z I0611 11:01:47.043869       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:scc:anyuid" not found
2024-06-11T11:01:47.044029297Z I0611 11:01:47.044002       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "whereabouts-cni" not found
2024-06-11T11:01:47.044364898Z I0611 11:01:47.044299       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:operator-lifecycle-manager" not found
2024-06-11T11:01:47.044364898Z I0611 11:01:47.044344       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-pruner" not found
2024-06-11T11:01:47.044441699Z I0611 11:01:47.044403       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:node-bootstrapper" not found
2024-06-11T11:01:47.044565699Z I0611 11:01:47.044530       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:node-controller" not found
2024-06-11T11:01:47.044565699Z I0611 11:01:47.044559       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:persistent-volume-binder" not found
2024-06-11T11:01:47.044603499Z I0611 11:01:47.044571       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:pod-garbage-collector" not found
2024-06-11T11:01:47.044603499Z I0611 11:01:47.044584       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:pv-protection-controller" not found
2024-06-11T11:01:47.044603499Z I0611 11:01:47.044595       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:pvc-protection-controller" not found
2024-06-11T11:01:47.044620099Z I0611 11:01:47.044609       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:replicaset-controller" not found
2024-06-11T11:01:47.044632999Z I0611 11:01:47.044622       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:replication-controller" not found
2024-06-11T11:01:47.044645099Z I0611 11:01:47.044636       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:resourcequota-controller" not found
2024-06-11T11:01:47.044659599Z I0611 11:01:47.044650       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:root-ca-cert-publisher" not found
2024-06-11T11:01:47.044674199Z I0611 11:01:47.044666       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:route-controller" not found
2024-06-11T11:01:47.044687299Z I0611 11:01:47.044678       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:service-account-controller" not found
2024-06-11T11:01:47.044699499Z I0611 11:01:47.044691       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:service-ca-cert-publisher" not found
2024-06-11T11:01:47.044714099Z I0611 11:01:47.044703       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:service-controller" not found
2024-06-11T11:01:47.044736400Z I0611 11:01:47.044717       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:statefulset-controller" not found
2024-06-11T11:01:47.044736400Z I0611 11:01:47.044731       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:ttl-after-finished-controller" not found
2024-06-11T11:01:47.044752800Z I0611 11:01:47.044744       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:controller:ttl-controller" not found
2024-06-11T11:01:47.044765800Z I0611 11:01:47.044755       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:deployer" not found
2024-06-11T11:01:47.044778000Z I0611 11:01:47.044767       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:discovery" not found
2024-06-11T11:01:47.044789800Z I0611 11:01:47.044777       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-builder" not found
2024-06-11T11:01:47.044801800Z I0611 11:01:47.044789       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-puller" not found
2024-06-11T11:01:47.044813700Z I0611 11:01:47.044802       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:kube-controller-manager" not found
2024-06-11T11:01:47.044828600Z I0611 11:01:47.044819       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:kube-dns" not found
2024-06-11T11:01:47.044840200Z I0611 11:01:47.044833       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:kube-scheduler" not found
2024-06-11T11:01:47.044854400Z I0611 11:01:47.044845       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:master" not found
2024-06-11T11:01:47.044865900Z I0611 11:01:47.044857       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:metrics-server" not found
2024-06-11T11:01:47.044910800Z I0611 11:01:47.044871       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:monitoring" not found
2024-06-11T11:01:47.044910800Z I0611 11:01:47.044904       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:node" not found
2024-06-11T11:01:47.044926200Z I0611 11:01:47.044917       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:node-admin" not found
2024-06-11T11:01:47.044937600Z I0611 11:01:47.044927       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:node-admin" not found
2024-06-11T11:01:47.044956600Z I0611 11:01:47.044941       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:node-bootstrapper" not found
2024-06-11T11:01:47.044956600Z I0611 11:01:47.044953       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:node-proxier" not found
2024-06-11T11:01:47.044971300Z I0611 11:01:47.044965       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:node-proxier" not found
2024-06-11T11:01:47.044985400Z I0611 11:01:47.044977       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:oauth-token-deleter" not found
2024-06-11T11:01:47.045020600Z I0611 11:01:47.044992       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:build-config-change-controller" not found
2024-06-11T11:01:47.045060601Z I0611 11:01:47.045018       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:build-controller" not found
2024-06-11T11:01:47.045060601Z I0611 11:01:47.045031       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:cluster-csr-approver-controller" not found
2024-06-11T11:01:47.045082201Z I0611 11:01:47.045064       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:cluster-quota-reconciliation-controller" not found
2024-06-11T11:01:47.045093901Z I0611 11:01:47.045082       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:default-rolebindings-controller" not found
2024-06-11T11:01:47.045112701Z I0611 11:01:47.045094       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:deployer-controller" not found
2024-06-11T11:01:47.045112701Z I0611 11:01:47.045107       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:deploymentconfig-controller" not found
2024-06-11T11:01:47.045127801Z I0611 11:01:47.045119       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:horizontal-pod-autoscaler" not found
2024-06-11T11:01:47.045141901Z I0611 11:01:47.045134       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:image-import-controller" not found
2024-06-11T11:01:47.045155901Z I0611 11:01:47.045148       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:image-trigger-controller" not found
2024-06-11T11:01:47.045262601Z I0611 11:01:47.045214       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.046294804Z I0611 11:01:47.046248       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:check-endpoints-crd-reader" not found
2024-06-11T11:01:47.046294804Z I0611 11:01:47.046252       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:deployer" not found
2024-06-11T11:01:47.046294804Z I0611 11:01:47.046282       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-builder" not found
2024-06-11T11:01:47.046329505Z I0611 11:01:47.046294       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:check-endpoints-node-reader" not found
2024-06-11T11:01:47.046329505Z I0611 11:01:47.046313       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:machine-approver" not found
2024-06-11T11:01:47.046345505Z I0611 11:01:47.046327       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:namespace-security-allocation-controller" not found
2024-06-11T11:01:47.046345505Z I0611 11:01:47.046337       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-puller" not found
2024-06-11T11:01:47.046358905Z I0611 11:01:47.046344       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:origin-namespace-controller" not found
2024-06-11T11:01:47.046358905Z I0611 11:01:47.046354       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:deployer" not found
2024-06-11T11:01:47.046396705Z I0611 11:01:47.046359       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:podsecurity-admission-label-syncer-controller" not found
2024-06-11T11:01:47.046396705Z I0611 11:01:47.046369       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-builder" not found
2024-06-11T11:01:47.046396705Z I0611 11:01:47.046371       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:privileged-namespaces-psa-label-syncer" not found
2024-06-11T11:01:47.046396705Z I0611 11:01:47.046380       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-puller" not found
2024-06-11T11:01:47.046396705Z I0611 11:01:47.046386       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:pv-recycler-controller" not found
2024-06-11T11:01:47.046427505Z I0611 11:01:47.046398       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:resourcequota-controller" not found
2024-06-11T11:01:47.046427505Z I0611 11:01:47.046411       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:service-ca" not found
2024-06-11T11:01:47.046427505Z I0611 11:01:47.046418       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:deployer" not found
2024-06-11T11:01:47.046427505Z I0611 11:01:47.046422       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:service-ingress-ip-controller" not found
2024-06-11T11:01:47.046442605Z I0611 11:01:47.046430       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-builder" not found
2024-06-11T11:01:47.046442605Z I0611 11:01:47.046436       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:serviceaccount-controller" not found
2024-06-11T11:01:47.046455405Z I0611 11:01:47.046443       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-puller" not found
2024-06-11T11:01:47.046455405Z I0611 11:01:47.046448       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:serviceaccount-pull-secrets-controller" not found
2024-06-11T11:01:47.046673706Z I0611 11:01:47.046464       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:template-instance-controller" not found
2024-06-11T11:01:47.046673706Z I0611 11:01:47.046542       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:template-instance-finalizer-controller" not found
2024-06-11T11:01:47.046673706Z I0611 11:01:47.046564       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:template-service-broker" not found
2024-06-11T11:01:47.046673706Z I0611 11:01:47.046580       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:controller:unidling-controller" not found
2024-06-11T11:01:47.046673706Z I0611 11:01:47.046591       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:discovery" not found
2024-06-11T11:01:47.046673706Z I0611 11:01:47.046631       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:openshift-controller-manager" not found
2024-06-11T11:01:47.046673706Z I0611 11:01:47.046653       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:openshift-controller-manager:image-trigger-controller" not found
2024-06-11T11:01:47.046702706Z I0611 11:01:47.046668       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:openshift-controller-manager:ingress-to-route-controller" not found
2024-06-11T11:01:47.046702706Z I0611 11:01:47.046686       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:openshift-controller-manager:update-buildconfig-status" not found
2024-06-11T11:01:47.046723906Z I0611 11:01:47.046699       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:openshift-route-controller-manager" not found
2024-06-11T11:01:47.046723906Z I0611 11:01:47.046716       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:operator:cloud-controller-manager" not found
2024-06-11T11:01:47.046739206Z I0611 11:01:47.046730       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:operator:etcd-backup-role" not found
2024-06-11T11:01:47.047326408Z I0611 11:01:47.046754       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:kube-scheduler" not found
2024-06-11T11:01:47.047326408Z I0611 11:01:47.046794       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:public-info-viewer" not found
2024-06-11T11:01:47.047326408Z I0611 11:01:47.046805       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:scc:restricted-v2" not found
2024-06-11T11:01:47.047326408Z I0611 11:01:47.046818       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:tokenreview-openshift-controller-manager" not found
2024-06-11T11:01:47.047326408Z I0611 11:01:47.046850       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:tokenreview-openshift-route-controller-manager" not found
2024-06-11T11:01:47.047326408Z I0611 11:01:47.046868       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:openshift:useroauthaccesstoken-manager" not found
2024-06-11T11:01:47.047326408Z I0611 11:01:47.046902       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:public-info-viewer" not found
2024-06-11T11:01:47.047326408Z I0611 11:01:47.046956       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:scope-impersonation" not found
2024-06-11T11:01:47.047326408Z I0611 11:01:47.046968       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:sdn-reader" not found
2024-06-11T11:01:47.047326408Z I0611 11:01:47.046986       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:service-account-issuer-discovery" not found
2024-06-11T11:01:47.047326408Z I0611 11:01:47.046997       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:volume-scheduler" not found
2024-06-11T11:01:47.047326408Z I0611 11:01:47.047008       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:webhook" not found
2024-06-11T11:01:47.048401011Z I0611 11:01:47.048364       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:deployer" not found
2024-06-11T11:01:47.048507311Z I0611 11:01:47.048463       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-builder" not found
2024-06-11T11:01:47.048588512Z I0611 11:01:47.048565       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-puller" not found
2024-06-11T11:01:47.048790212Z I0611 11:01:47.048760       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:deployer" not found
2024-06-11T11:01:47.048950713Z I0611 11:01:47.048829       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-builder" not found
2024-06-11T11:01:47.048950713Z I0611 11:01:47.048855       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-puller" not found
2024-06-11T11:01:47.048950713Z I0611 11:01:47.048898       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:deployer" not found
2024-06-11T11:01:47.048950713Z I0611 11:01:47.048923       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-builder" not found
2024-06-11T11:01:47.048950713Z I0611 11:01:47.048936       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-puller" not found
2024-06-11T11:01:47.049061413Z I0611 11:01:47.049008       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:deployer" not found
2024-06-11T11:01:47.049203113Z I0611 11:01:47.049153       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-builder" not found
2024-06-11T11:01:47.049242914Z I0611 11:01:47.049198       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve clusterrole from role ref: clusterrole.rbac.authorization.k8s.io "system:image-puller" not found
2024-06-11T11:01:47.049924616Z I0611 11:01:47.049873       1 base_controller.go:73] Caches are synced for WebhookAuthenticatorCertApprover_csr-approver-controller 
2024-06-11T11:01:47.049924616Z I0611 11:01:47.049916       1 base_controller.go:110] Starting #1 worker of WebhookAuthenticatorCertApprover_csr-approver-controller controller ...
2024-06-11T11:01:47.051514921Z E0611 11:01:47.051475       1 podsecurity_label_sync_controller.go:420] failed to determine whether namespace "openshift-image-registry" should be enqueued: namespace "openshift-image-registry" not found
2024-06-11T11:01:47.051663921Z E0611 11:01:47.051630       1 podsecurity_label_sync_controller.go:420] failed to determine whether namespace "openshift-machine-api" should be enqueued: namespace "openshift-machine-api" not found
2024-06-11T11:01:47.052805825Z E0611 11:01:47.052760       1 podsecurity_label_sync_controller.go:420] failed to determine whether namespace "openshift-service-ca" should be enqueued: namespace "openshift-service-ca" not found
2024-06-11T11:01:47.061410251Z I0611 11:01:47.061218       1 reflector.go:351] Caches populated for *v1.Deployment from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.065781565Z I0611 11:01:47.065739       1 reflector.go:351] Caches populated for *v1.ReplicaSet from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.148170621Z I0611 11:01:47.148095       1 reflector.go:351] Caches populated for *v1.ResourceQuota from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.151492932Z I0611 11:01:47.151456       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.346432438Z I0611 11:01:47.346355       1 reflector.go:351] Caches populated for *v1.ReplicationController from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.351387353Z I0611 11:01:47.351319       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.546530060Z I0611 11:01:47.546396       1 reflector.go:351] Caches populated for *v1.LimitRange from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.551615076Z I0611 11:01:47.551578       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.751689598Z I0611 11:01:47.751631       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.752384700Z I0611 11:01:47.752324       1 reflector.go:351] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.953642226Z I0611 11:01:47.953565       1 request.go:697] Waited for 1.002281316s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/monitoring.coreos.com/v1beta1/alertmanagerconfigs?limit=500&resourceVersion=0
2024-06-11T11:01:47.955932533Z I0611 11:01:47.955868       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.959812245Z I0611 11:01:47.959752       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:47.962329753Z I0611 11:01:47.962289       1 base_controller.go:73] Caches are synced for namespace-security-allocation-controller 
2024-06-11T11:01:47.962329753Z I0611 11:01:47.962317       1 base_controller.go:110] Starting #1 worker of namespace-security-allocation-controller controller ...
2024-06-11T11:01:47.962375353Z I0611 11:01:47.962352       1 namespace_scc_allocation_controller.go:111] Repairing SCC UID Allocations
2024-06-11T11:01:48.046218514Z W0611 11:01:48.046160       1 reflector.go:539] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:01:48.046218514Z E0611 11:01:48.046200       1 reflector.go:147] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: Failed to watch *v1.ImageStream: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:01:48.054905741Z I0611 11:01:48.054809       1 shared_informer.go:318] Caches are synced for privileged-namespaces-psa-label-syncer
2024-06-11T11:01:48.152433744Z I0611 11:01:48.152369       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:48.332487104Z I0611 11:01:48.332398       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:48.352450966Z I0611 11:01:48.352403       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:48.356667879Z I0611 11:01:48.356617       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:48.546976171Z I0611 11:01:48.546915       1 reflector.go:351] Caches populated for *v1.PodTemplate from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:48.551935686Z I0611 11:01:48.551896       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:48.751876308Z I0611 11:01:48.751790       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:48.760118434Z I0611 11:01:48.760047       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:48.848867410Z I0611 11:01:48.848806       1 base_controller.go:73] Caches are synced for pod-security-admission-label-synchronization-controller 
2024-06-11T11:01:48.848867410Z I0611 11:01:48.848832       1 base_controller.go:110] Starting #1 worker of pod-security-admission-label-synchronization-controller controller ...
2024-06-11T11:01:48.955651342Z I0611 11:01:48.955538       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:49.146300334Z I0611 11:01:49.146215       1 request.go:697] Waited for 2.195207226s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0
2024-06-11T11:01:49.155265062Z I0611 11:01:49.155195       1 reflector.go:351] Caches populated for *v1.PersistentVolumeClaim from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:49.156855467Z I0611 11:01:49.156770       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:49.352793877Z I0611 11:01:49.352728       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:49.414383668Z I0611 11:01:49.414280       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:49.527676620Z I0611 11:01:49.527565       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:49.557449413Z I0611 11:01:49.557375       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:49.753546823Z I0611 11:01:49.753460       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:49.804928282Z I0611 11:01:49.804858       1 namespace_scc_allocation_controller.go:116] Repair complete
2024-06-11T11:01:49.951909540Z I0611 11:01:49.951827       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:50.150543357Z I0611 11:01:50.150460       1 request.go:697] Waited for 3.198899847s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/k8s.cni.cncf.io/v1/network-attachment-definitions?limit=500&resourceVersion=0
2024-06-11T11:01:50.152612964Z I0611 11:01:50.152548       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:50.352452885Z I0611 11:01:50.352393       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:50.552252206Z I0611 11:01:50.552188       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:50.699257163Z W0611 11:01:50.699151       1 reflector.go:539] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:01:50.699382464Z E0611 11:01:50.699347       1 reflector.go:147] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: Failed to watch *v1.ImageStream: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:01:50.752837830Z I0611 11:01:50.752768       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:50.952527351Z I0611 11:01:50.952461       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:51.151008968Z I0611 11:01:51.150942       1 request.go:697] Waited for 4.199273158s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/operators.coreos.com/v1alpha1/installplans?limit=500&resourceVersion=0
2024-06-11T11:01:51.152796474Z I0611 11:01:51.152730       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:51.352069293Z I0611 11:01:51.351982       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:51.552111315Z I0611 11:01:51.552028       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:51.752250636Z I0611 11:01:51.752182       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:51.952234769Z I0611 11:01:51.952176       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:52.152143901Z I0611 11:01:52.151885       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:52.350123926Z I0611 11:01:52.350022       1 request.go:697] Waited for 5.398201315s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/metal3.io/v1alpha1/firmwareschemas?limit=500&resourceVersion=0
2024-06-11T11:01:52.351635231Z I0611 11:01:52.351585       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:52.552605867Z I0611 11:01:52.552543       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:52.752030697Z I0611 11:01:52.751973       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:52.952211231Z I0611 11:01:52.952138       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:53.152208963Z I0611 11:01:53.152154       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:53.350550589Z I0611 11:01:53.350452       1 request.go:697] Waited for 6.398453278s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/machine.openshift.io/v1beta1/machines?limit=500&resourceVersion=0
2024-06-11T11:01:53.353260999Z I0611 11:01:53.353217       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:53.552022127Z I0611 11:01:53.551952       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:53.751915859Z I0611 11:01:53.751838       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:53.952844795Z I0611 11:01:53.952685       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:54.155089535Z I0611 11:01:54.154337       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:54.184412743Z W0611 11:01:54.184338       1 reflector.go:539] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:01:54.184613644Z E0611 11:01:54.184570       1 reflector.go:147] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: Failed to watch *v1.ImageStream: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:01:54.350945053Z I0611 11:01:54.350886       1 request.go:697] Waited for 7.39863164s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/machine.openshift.io/v1beta1/machinehealthchecks?limit=500&resourceVersion=0
2024-06-11T11:01:54.352773659Z I0611 11:01:54.352734       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:54.553148093Z I0611 11:01:54.553090       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:54.752696724Z I0611 11:01:54.752646       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:01:54.753751728Z I0611 11:01:54.753702       1 reconciliation_controller.go:224] synced cluster resource quota controller
2024-06-11T11:01:54.763193662Z I0611 11:01:54.763150       1 reconciliation_controller.go:149] Caches are synced
2024-06-11T11:02:05.230476404Z W0611 11:02:05.230416       1 reflector.go:539] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:02:05.230476404Z E0611 11:02:05.230451       1 reflector.go:147] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: Failed to watch *v1.ImageStream: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:02:23.300933578Z W0611 11:02:23.300875       1 reflector.go:539] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:02:23.300933578Z E0611 11:02:23.300911       1 reflector.go:147] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: Failed to watch *v1.ImageStream: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:03:01.417561442Z W0611 11:03:01.417488       1 reflector.go:539] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:03:01.417561442Z E0611 11:03:01.417543       1 reflector.go:147] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: Failed to watch *v1.ImageStream: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:03:40.008530226Z I0611 11:03:40.008451       1 request.go:697] Waited for 1.173793093s, retries: 1, retry-after: 1s - retry-reason: due to retryable error, error: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/monitoring.coreos.com/v1/probes?allowWatchBookmarks=true&resourceVersion=23511&timeout=8m18s&timeoutSeconds=498&watch=true": dial tcp 10.0.0.4:6443: i/o timeout - request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/monitoring.coreos.com/v1/probes?allowWatchBookmarks=true&resourceVersion=23511&timeout=8m18s&timeoutSeconds=498&watch=true
2024-06-11T11:03:41.009278469Z I0611 11:03:41.009216       1 request.go:697] Waited for 2.158965263s, retries: 1, retry-after: 1s - retry-reason: due to retryable error, error: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/metal3.io/v1alpha1/hardwaredata?allowWatchBookmarks=true&resourceVersion=23512&timeout=6m46s&timeoutSeconds=406&watch=true": dial tcp 10.0.0.4:6443: i/o timeout - request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/metal3.io/v1alpha1/hardwaredata?allowWatchBookmarks=true&resourceVersion=23512&timeout=6m46s&timeoutSeconds=406&watch=true
2024-06-11T11:03:42.208390028Z I0611 11:03:42.208299       1 request.go:697] Waited for 3.348511839s, retries: 1, retry-after: 1s - retry-reason: due to retryable error, error: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/machine.openshift.io/v1beta1/machines?allowWatchBookmarks=true&resourceVersion=23545&timeout=6m42s&timeoutSeconds=402&watch=true": dial tcp 10.0.0.4:6443: i/o timeout - request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/machine.openshift.io/v1beta1/machines?allowWatchBookmarks=true&resourceVersion=23545&timeout=6m42s&timeoutSeconds=402&watch=true
2024-06-11T11:03:43.208884498Z I0611 11:03:43.208782       1 request.go:697] Waited for 4.342119521s, retries: 1, retry-after: 1s - retry-reason: due to retryable error, error: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/whereabouts.cni.cncf.io/v1alpha1/overlappingrangeipreservations?allowWatchBookmarks=true&resourceVersion=23502&timeout=6m38s&timeoutSeconds=398&watch=true": dial tcp 10.0.0.4:6443: i/o timeout - request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/whereabouts.cni.cncf.io/v1alpha1/overlappingrangeipreservations?allowWatchBookmarks=true&resourceVersion=23502&timeout=6m38s&timeoutSeconds=398&watch=true
2024-06-11T11:03:44.208943484Z I0611 11:03:44.208858       1 request.go:697] Waited for 5.331318427s, retries: 1, retry-after: 1s - retry-reason: due to retryable error, error: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/machine.openshift.io/v1beta1/machinesets?allowWatchBookmarks=true&resourceVersion=23581&timeout=5m20s&timeoutSeconds=320&watch=true": dial tcp 10.0.0.4:6443: i/o timeout - request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/machine.openshift.io/v1beta1/machinesets?allowWatchBookmarks=true&resourceVersion=23581&timeout=5m20s&timeoutSeconds=320&watch=true
2024-06-11T11:03:45.209231725Z I0611 11:03:45.209142       1 request.go:697] Waited for 6.323627481s, retries: 1, retry-after: 1s - retry-reason: due to retryable error, error: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/operators.coreos.com/v1alpha1/subscriptions?allowWatchBookmarks=true&resourceVersion=23517&timeout=9m26s&timeoutSeconds=566&watch=true": dial tcp 10.0.0.4:6443: i/o timeout - request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/operators.coreos.com/v1alpha1/subscriptions?allowWatchBookmarks=true&resourceVersion=23517&timeout=9m26s&timeoutSeconds=566&watch=true
2024-06-11T11:03:46.409301931Z I0611 11:03:46.409221       1 request.go:697] Waited for 7.512328208s, retries: 1, retry-after: 1s - retry-reason: due to retryable error, error: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/infrastructure.cluster.x-k8s.io/v1beta1/metal3remediationtemplates?allowWatchBookmarks=true&resourceVersion=23560&timeout=9m2s&timeoutSeconds=542&watch=true": dial tcp 10.0.0.4:6443: i/o timeout - request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/infrastructure.cluster.x-k8s.io/v1beta1/metal3remediationtemplates?allowWatchBookmarks=true&resourceVersion=23560&timeout=9m2s&timeoutSeconds=542&watch=true
2024-06-11T11:03:46.644390639Z E0611 11:03:46.644297       1 resource_quota_controller.go:440] failed to discover resources: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/api": dial tcp 10.0.0.4:6443: i/o timeout
2024-06-11T11:03:54.775761529Z I0611 11:03:54.775674       1 reconciliation_controller.go:171] error occurred GetQuotableResources err=failed to discover resources: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/api": dial tcp 10.0.0.4:6443: i/o timeout
2024-06-11T11:03:54.775761529Z E0611 11:03:54.775704       1 reconciliation_controller.go:172] failed to discover resources: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/api": dial tcp 10.0.0.4:6443: i/o timeout
2024-06-11T11:03:55.599278048Z E0611 11:03:55.599182       1 leaderelection.go:332] error retrieving resource lock openshift-kube-controller-manager/cluster-policy-controller-lock: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager/leases/cluster-policy-controller-lock?timeout=1m47s": dial tcp 10.0.0.4:6443: i/o timeout
2024-06-11T11:04:16.763694115Z W0611 11:04:16.763553       1 reflector.go:539] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: failed to list *v1.ImageStream: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/image.openshift.io/v1/imagestreams?limit=500&resourceVersion=0": dial tcp 10.0.0.4:6443: i/o timeout
2024-06-11T11:04:16.763780815Z I0611 11:04:16.763715       1 trace.go:236] Trace[435660888]: "Reflector ListAndWatch" name:k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229 (11-Jun-2024 11:03:51.762) (total time: 25000ms):
2024-06-11T11:04:16.763780815Z Trace[435660888]: ---"Objects listed" error:Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/image.openshift.io/v1/imagestreams?limit=500&resourceVersion=0": dial tcp 10.0.0.4:6443: i/o timeout 25000ms (11:04:16.763)
2024-06-11T11:04:16.763780815Z Trace[435660888]: [25.000735197s] [25.000735197s] END
2024-06-11T11:04:16.763780815Z E0611 11:04:16.763743       1 reflector.go:147] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: Failed to watch *v1.ImageStream: failed to list *v1.ImageStream: Get "https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/image.openshift.io/v1/imagestreams?limit=500&resourceVersion=0": dial tcp 10.0.0.4:6443: i/o timeout
2024-06-11T11:04:22.454085452Z I0611 11:04:22.450820       1 reflector.go:351] Caches populated for *v1.PersistentVolumeClaim from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.504955177Z I0611 11:04:22.504884       1 reflector.go:351] Caches populated for *v1.Lease from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.529935388Z I0611 11:04:22.529872       1 reflector.go:351] Caches populated for *v1.CertificateSigningRequest from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.551786985Z I0611 11:04:22.551086       1 reflector.go:351] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.564921844Z I0611 11:04:22.564845       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.567143454Z I0611 11:04:22.567099       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.581796319Z I0611 11:04:22.581730       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.585850337Z I0611 11:04:22.585812       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.588470748Z I0611 11:04:22.587540       1 reflector.go:351] Caches populated for *v1.Role from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.619687487Z I0611 11:04:22.619618       1 reflector.go:351] Caches populated for *v1.ControllerRevision from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.629751932Z I0611 11:04:22.629014       1 reflector.go:351] Caches populated for *v1.Job from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.641466084Z I0611 11:04:22.641403       1 reflector.go:351] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.655193945Z I0611 11:04:22.655141       1 reflector.go:351] Caches populated for *v2.HorizontalPodAutoscaler from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.687273487Z I0611 11:04:22.687198       1 reflector.go:351] Caches populated for *v1.EndpointSlice from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.690282500Z I0611 11:04:22.690245       1 reflector.go:351] Caches populated for *v1.ReplicationController from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.694959721Z I0611 11:04:22.694902       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.717405921Z I0611 11:04:22.717353       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.746484750Z I0611 11:04:22.746372       1 reflector.go:351] Caches populated for *v1.Deployment from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.772376665Z I0611 11:04:22.772311       1 reflector.go:351] Caches populated for *v1.ResourceQuota from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.798466081Z I0611 11:04:22.797907       1 reflector.go:351] Caches populated for *v1.ReplicaSet from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.807294920Z I0611 11:04:22.807202       1 reflector.go:351] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.836379749Z I0611 11:04:22.836310       1 reflector.go:351] Caches populated for *v1.PodTemplate from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.867870189Z I0611 11:04:22.867810       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.914125494Z I0611 11:04:22.912073       1 reflector.go:351] Caches populated for *v1.Ingress from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.915238499Z I0611 11:04:22.915165       1 reflector.go:351] Caches populated for *v1.NetworkPolicy from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.948477847Z I0611 11:04:22.948423       1 reflector.go:351] Caches populated for *v1.StatefulSet from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.953973871Z I0611 11:04:22.953924       1 reflector.go:351] Caches populated for *v1.CSIStorageCapacity from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:22.986083514Z I0611 11:04:22.983641       1 reflector.go:351] Caches populated for *v1.ClusterResourceQuota from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.022503376Z I0611 11:04:23.022444       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.053088611Z I0611 11:04:23.051697       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.056373926Z I0611 11:04:23.056334       1 reflector.go:351] Caches populated for *v1.CronJob from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.090516278Z I0611 11:04:23.090450       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.099113016Z I0611 11:04:23.099068       1 reflector.go:351] Caches populated for *v1.DaemonSet from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.117178896Z I0611 11:04:23.117101       1 reflector.go:351] Caches populated for *v1.LimitRange from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.137668787Z I0611 11:04:23.137602       1 reflector.go:351] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.137728487Z I0611 11:04:23.137602       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.161653493Z I0611 11:04:23.161059       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.178308567Z I0611 11:04:23.178259       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.233134811Z I0611 11:04:23.231513       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.248780780Z I0611 11:04:23.245926       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.264096048Z I0611 11:04:23.262430       1 reflector.go:351] Caches populated for *v1.SecurityContextConstraints from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.308813247Z I0611 11:04:23.308751       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.309372049Z I0611 11:04:23.309305       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.399390149Z I0611 11:04:23.398358       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.429627783Z I0611 11:04:23.428138       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.530742032Z I0611 11:04:23.530666       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.539803373Z I0611 11:04:23.539740       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.588881890Z I0611 11:04:23.588821       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.659408204Z I0611 11:04:23.659339       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.692791052Z I0611 11:04:23.692716       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.743600777Z I0611 11:04:23.743535       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:23.852469795Z I0611 11:04:23.852406       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:24.063150922Z I0611 11:04:24.063002       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:24.251806688Z I0611 11:04:24.251731       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:24.454296055Z I0611 11:04:24.453893       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:24.653800701Z I0611 11:04:24.653728       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:24.854717956Z I0611 11:04:24.854638       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:25.049877370Z I0611 11:04:25.049744       1 request.go:697] Waited for 1.111993756s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/machine.openshift.io/v1beta1/machinehealthchecks?resourceVersion=23560
2024-06-11T11:04:25.051692983Z I0611 11:04:25.051645       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:25.251936334Z I0611 11:04:25.251872       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:25.451931283Z I0611 11:04:25.451842       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:25.651559329Z I0611 11:04:25.651499       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:25.852066582Z I0611 11:04:25.851973       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:26.049829014Z I0611 11:04:26.049758       1 request.go:697] Waited for 2.007722745s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/operators.coreos.com/v1alpha1/installplans?resourceVersion=23549
2024-06-11T11:04:26.051988730Z I0611 11:04:26.051946       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:26.251617176Z I0611 11:04:26.251554       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:26.456128658Z I0611 11:04:26.456009       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:26.652178078Z I0611 11:04:26.652109       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:26.878429817Z I0611 11:04:26.878341       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:27.050307462Z I0611 11:04:27.050238       1 request.go:697] Waited for 2.842305691s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/ipam.cluster.x-k8s.io/v1beta1/ipaddressclaims?resourceVersion=23554
2024-06-11T11:04:27.061720545Z I0611 11:04:27.061646       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:27.254500642Z I0611 11:04:27.254438       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:27.452582377Z I0611 11:04:27.452479       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:27.655872149Z I0611 11:04:27.655441       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:27.852195272Z I0611 11:04:27.852079       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:28.052438022Z I0611 11:04:28.052375       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:28.250566058Z I0611 11:04:28.250487       1 request.go:697] Waited for 3.842173135s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/monitoring.coreos.com/v1/prometheusrules?resourceVersion=23511
2024-06-11T11:04:28.254588987Z I0611 11:04:28.254524       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:28.455472842Z I0611 11:04:28.455398       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:28.651488662Z I0611 11:04:28.651433       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:28.851793013Z I0611 11:04:28.851716       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:29.051219558Z I0611 11:04:29.051155       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:29.253146721Z I0611 11:04:29.253085       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:29.450016747Z I0611 11:04:29.449960       1 request.go:697] Waited for 4.931650428s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/tuned.openshift.io/v1/profiles?resourceVersion=23510
2024-06-11T11:04:29.458655510Z I0611 11:04:29.458340       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:29.652199312Z I0611 11:04:29.652118       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:29.851287154Z I0611 11:04:29.851222       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:30.061370976Z I0611 11:04:30.061302       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:30.252221194Z I0611 11:04:30.252173       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:04:30.452056630Z I0611 11:04:30.451978       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:05:16.259824869Z W0611 11:05:16.259767       1 reflector.go:539] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:05:16.259824869Z E0611 11:05:16.259803       1 reflector.go:147] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: Failed to watch *v1.ImageStream: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:06:02.823275442Z W0611 11:06:02.823156       1 reflector.go:539] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:06:02.823275442Z E0611 11:06:02.823191       1 reflector.go:147] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: Failed to watch *v1.ImageStream: failed to list *v1.ImageStream: the server could not find the requested resource (get imagestreams.image.openshift.io)
2024-06-11T11:06:24.860056826Z I0611 11:06:24.859955       1 resource_quota_controller.go:470] "syncing resource quota controller with updated resources from discovery" diff="added: [image.openshift.io/v1, Resource=imagestreams], removed: []"
2024-06-11T11:06:24.860142826Z W0611 11:06:24.860081       1 shared_informer.go:591] resyncPeriod 8m39.266876013s is smaller than resyncCheckPeriod 10m0s and the informer has already started. Changing it to 10m0s
2024-06-11T11:06:24.860215527Z I0611 11:06:24.860170       1 shared_informer.go:311] Waiting for caches to sync for resource quota
2024-06-11T11:06:24.860290027Z I0611 11:06:24.860249       1 reconciliation_controller.go:207] syncing resource quota controller with updated resources from discovery: added: [apps.openshift.io/v1, Resource=deploymentconfigs build.openshift.io/v1, Resource=buildconfigs build.openshift.io/v1, Resource=builds image.openshift.io/v1, Resource=imagestreams], removed: []
2024-06-11T11:06:24.860421228Z I0611 11:06:24.860377       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="deploymentconfigs.apps.openshift.io"
2024-06-11T11:06:24.860461328Z I0611 11:06:24.860431       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="builds.build.openshift.io"
2024-06-11T11:06:24.860509728Z I0611 11:06:24.860480       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="buildconfigs.build.openshift.io"
2024-06-11T11:06:24.866708155Z W0611 11:06:24.866665       1 warnings.go:70] apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
2024-06-11T11:06:24.866852856Z I0611 11:06:24.866807       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:06:24.866883556Z I0611 11:06:24.866702       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:06:24.866928156Z I0611 11:06:24.866744       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:06:24.872201179Z W0611 11:06:24.872158       1 warnings.go:70] apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
2024-06-11T11:06:45.966772868Z I0611 11:06:45.966704       1 reflector.go:351] Caches populated for *v1.ImageStream from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:06:46.011148767Z I0611 11:06:46.011081       1 shared_informer.go:318] Caches are synced for resource quota
2024-06-11T11:06:46.061107391Z I0611 11:06:46.061019       1 shared_informer.go:318] Caches are synced for resource quota
2024-06-11T11:06:46.061107391Z I0611 11:06:46.061067       1 reconciliation_controller.go:224] synced cluster resource quota controller
2024-06-11T11:06:46.061107391Z I0611 11:06:46.061086       1 resource_quota_controller.go:496] "synced quota controller"
2024-06-11T11:06:48.330909201Z I0611 11:06:48.330817       1 event.go:364] Event(v1.ObjectReference{Kind:"Pod", Namespace:"openshift-kube-controller-manager", Name:"kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'CreatedSCCRanges' created SCC ranges for openshift-console namespace
2024-06-11T11:06:49.095655657Z I0611 11:06:49.095577       1 event.go:364] Event(v1.ObjectReference{Kind:"Pod", Namespace:"openshift-kube-controller-manager", Name:"kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'CreatedSCCRanges' created SCC ranges for openshift-console-operator namespace
2024-06-11T11:06:49.737820879Z I0611 11:06:49.737328       1 event.go:364] Event(v1.ObjectReference{Kind:"Pod", Namespace:"openshift-kube-controller-manager", Name:"kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'CreatedSCCRanges' created SCC ranges for openshift-console-user-settings namespace
2024-06-11T11:07:16.082112260Z I0611 11:07:16.082048       1 reconciliation_controller.go:207] syncing resource quota controller with updated resources from discovery: added: [route.openshift.io/v1, Resource=routes template.openshift.io/v1, Resource=templateinstances template.openshift.io/v1, Resource=templates], removed: []
2024-06-11T11:07:16.082200160Z I0611 11:07:16.082172       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="routes.route.openshift.io"
2024-06-11T11:07:16.082255660Z I0611 11:07:16.082235       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="templateinstances.template.openshift.io"
2024-06-11T11:07:16.082298161Z I0611 11:07:16.082276       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="templates.template.openshift.io"
2024-06-11T11:07:16.089530397Z I0611 11:07:16.089484       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:07:16.091392106Z I0611 11:07:16.091351       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:07:16.092446611Z I0611 11:07:16.092263       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:07:16.183282562Z I0611 11:07:16.183193       1 reconciliation_controller.go:224] synced cluster resource quota controller
2024-06-11T11:08:19.241492603Z W0611 11:08:19.241418       1 warnings.go:70] apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
2024-06-11T11:09:50.932140668Z W0611 11:09:50.932076       1 warnings.go:70] apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
2024-06-11T11:11:11.840830400Z W0611 11:11:11.840761       1 reflector.go:462] k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229: watch of *v1.PartialObjectMetadata ended with: an error on the server ("unable to decode an event from the watch stream: stream error: stream ID 573; INTERNAL_ERROR; received from peer") has prevented the request from succeeding
2024-06-11T11:11:13.292450071Z I0611 11:11:13.292356       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:15.073340483Z I0611 11:12:15.073173       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:15.891661406Z W0611 11:12:15.891537       1 warnings.go:70] apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
2024-06-11T11:12:16.967355738Z I0611 11:12:16.967253       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:17.217229770Z I0611 11:12:17.217166       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:18.680220170Z I0611 11:12:18.680166       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:18.692412935Z I0611 11:12:18.692346       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:18.694297545Z I0611 11:12:18.694241       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:18.711952339Z I0611 11:12:18.711911       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:18.731144742Z I0611 11:12:18.731102       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:18.753154559Z I0611 11:12:18.753103       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:18.754799268Z I0611 11:12:18.754756       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:18.769826748Z I0611 11:12:18.769793       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:18.772900364Z I0611 11:12:18.772825       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:18.831137875Z I0611 11:12:18.831079       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:18.887445275Z I0611 11:12:18.887381       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:19.082992017Z I0611 11:12:19.082941       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:19.283543587Z I0611 11:12:19.283451       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:19.481006940Z I0611 11:12:19.480909       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:19.679952900Z I0611 11:12:19.679881       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:19.880662170Z I0611 11:12:19.880600       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:20.077568820Z I0611 11:12:20.077513       1 request.go:697] Waited for 1.110960724s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/infrastructure.cluster.x-k8s.io/v1beta1/metal3remediations?resourceVersion=31715
2024-06-11T11:12:20.079510231Z I0611 11:12:20.079470       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:20.281296506Z I0611 11:12:20.281240       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:20.480612369Z I0611 11:12:20.480537       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:20.680203533Z I0611 11:12:20.680144       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:20.880629402Z I0611 11:12:20.880515       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:21.079515762Z I0611 11:12:21.079453       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:21.277853520Z I0611 11:12:21.277782       1 request.go:697] Waited for 2.236370223s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/tuned.openshift.io/v1/tuneds?resourceVersion=31700
2024-06-11T11:12:21.279843530Z I0611 11:12:21.279799       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:21.479854497Z I0611 11:12:21.479792       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:21.680740668Z I0611 11:12:21.680664       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:21.881671939Z I0611 11:12:21.881602       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:22.084932423Z I0611 11:12:22.084384       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:22.279093658Z I0611 11:12:22.278324       1 request.go:697] Waited for 3.129706686s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/monitoring.openshift.io/v1/alertrelabelconfigs?resourceVersion=30887
2024-06-11T11:12:22.280994268Z I0611 11:12:22.280947       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:22.481609738Z I0611 11:12:22.481545       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:22.679447092Z I0611 11:12:22.679390       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:22.879631960Z I0611 11:12:22.879434       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:23.080603431Z I0611 11:12:23.080515       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:23.280533597Z I0611 11:12:23.280426       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:23.477392447Z I0611 11:12:23.477331       1 request.go:697] Waited for 4.269357962s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/whereabouts.cni.cncf.io/v1alpha1/overlappingrangeipreservations?resourceVersion=30906
2024-06-11T11:12:23.480578564Z I0611 11:12:23.480537       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:23.681999438Z I0611 11:12:23.681927       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:23.880418796Z I0611 11:12:23.880340       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:24.079664658Z I0611 11:12:24.079610       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:24.279992526Z I0611 11:12:24.279926       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:24.478153982Z I0611 11:12:24.478076       1 request.go:697] Waited for 5.149106553s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/machine.openshift.io/v1/controlplanemachinesets?resourceVersion=30964
2024-06-11T11:12:24.483020308Z I0611 11:12:24.482969       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:24.680335252Z I0611 11:12:24.680273       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:24.881910118Z I0611 11:12:24.881822       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:25.082244876Z I0611 11:12:25.082194       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:25.282533734Z I0611 11:12:25.282472       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:25.478676671Z I0611 11:12:25.478595       1 request.go:697] Waited for 6.041303264s due to client-side throttling, not priority and fairness, request: GET:https://api-int.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/apis/whereabouts.cni.cncf.io/v1alpha1/ippools?resourceVersion=31473
2024-06-11T11:12:25.484346201Z I0611 11:12:25.483964       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:25.682759949Z I0611 11:12:25.682702       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:12:25.884819917Z I0611 11:12:25.884754       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:16:16.336422829Z I0611 11:16:16.336338       1 reconciliation_controller.go:207] syncing resource quota controller with updated resources from discovery: added: [controlplane.operator.openshift.io/v1alpha1, Resource=podnetworkconnectivitychecks], removed: []
2024-06-11T11:16:16.336491029Z I0611 11:16:16.336479       1 resource_quota_monitor.go:224] "QuotaMonitor created object count evaluator" resource="podnetworkconnectivitychecks.controlplane.operator.openshift.io"
2024-06-11T11:16:16.339297636Z I0611 11:16:16.339255       1 reflector.go:351] Caches populated for *v1.PartialObjectMetadata from k8s.io/client-go@v0.29.1/tools/cache/reflector.go:229
2024-06-11T11:16:16.437531071Z I0611 11:16:16.437483       1 reconciliation_controller.go:224] synced cluster resource quota controller
2024-06-11T11:17:37.897682019Z W0611 11:17:37.897609       1 warnings.go:70] apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
2024-06-11T11:26:02.904967642Z W0611 11:26:02.904858       1 warnings.go:70] apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
2024-06-11T11:26:20.223285103Z I0611 11:26:20.222390       1 event.go:364] Event(v1.ObjectReference{Kind:"Pod", Namespace:"openshift-kube-controller-manager", Name:"kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'CreatedSCCRanges' created SCC ranges for test-ssh-bastion namespace
2024-06-11T11:28:08.461867928Z I0611 11:28:08.461773       1 event.go:364] Event(v1.ObjectReference{Kind:"Pod", Namespace:"openshift-kube-controller-manager", Name:"kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'CreatedSCCRanges' created SCC ranges for openshift-windows-machine-config-operator namespace
2024-06-11T11:28:27.178409705Z I0611 11:28:27.178346       1 sccrolecache.go:466] failed to retrieve a role for a rolebinding ref: couldn't retrieve role from role ref: role.rbac.authorization.k8s.io "prometheus-k8s" not found
2024-06-11T11:32:17.898564875Z W0611 11:32:17.898501       1 warnings.go:70] apps.openshift.io/v1 DeploymentConfig is deprecated in v4.14+, unavailable in v4.10000+
2024-06-11T11:33:39.900593120Z I0611 11:33:39.900522       1 event.go:364] Event(v1.ObjectReference{Kind:"Pod", Namespace:"openshift-kube-controller-manager", Name:"kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0", UID:"", APIVersion:"", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'CreatedSCCRanges' created SCC ranges for openshift-must-gather-nrc2g namespace
