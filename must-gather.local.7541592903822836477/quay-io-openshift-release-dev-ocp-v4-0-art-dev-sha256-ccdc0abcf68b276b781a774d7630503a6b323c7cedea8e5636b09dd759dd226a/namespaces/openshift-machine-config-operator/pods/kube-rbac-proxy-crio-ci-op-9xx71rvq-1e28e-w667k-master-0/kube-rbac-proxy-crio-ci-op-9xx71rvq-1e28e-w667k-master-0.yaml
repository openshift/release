---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubernetes.io/config.hash: edcf8a6ae0478e0309b67e2fa77ecaa4
    kubernetes.io/config.mirror: edcf8a6ae0478e0309b67e2fa77ecaa4
    kubernetes.io/config.seen: "2024-06-11T10:44:02.061867940Z"
    kubernetes.io/config.source: file
    openshift.io/scc: privileged
    target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
  creationTimestamp: "2024-06-11T10:44:49Z"
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:kubernetes.io/config.hash: {}
          f:kubernetes.io/config.mirror: {}
          f:kubernetes.io/config.seen: {}
          f:kubernetes.io/config.source: {}
          f:target.workload.openshift.io/management: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"22305409-ad20-4f74-a793-ace67c4f2a7f"}: {}
      f:spec:
        f:containers:
          k:{"name":"kube-rbac-proxy-crio"}:
            .: {}
            f:args: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":9637,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:protocol: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:securityContext:
              .: {}
              f:privileged: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/etc/kubernetes"}:
                .: {}
                f:mountPath: {}
                f:mountPropagation: {}
                f:name: {}
              k:{"mountPath":"/var/lib/kubelet"}:
                .: {}
                f:mountPath: {}
                f:mountPropagation: {}
                f:name: {}
        f:dnsPolicy: {}
        f:enableServiceLinks: {}
        f:hostNetwork: {}
        f:initContainers:
          .: {}
          k:{"name":"setup"}:
            .: {}
            f:args: {}
            f:command: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:securityContext:
              .: {}
              f:privileged: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/var"}:
                .: {}
                f:mountPath: {}
                f:mountPropagation: {}
                f:name: {}
        f:nodeName: {}
        f:priorityClassName: {}
        f:restartPolicy: {}
        f:schedulerName: {}
        f:securityContext: {}
        f:terminationGracePeriodSeconds: {}
        f:tolerations: {}
        f:volumes:
          .: {}
          k:{"name":"etc-kube"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
          k:{"name":"var-lib-kubelet"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
    manager: kubelet
    operation: Update
    time: "2024-06-11T10:44:49Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions:
          .: {}
          k:{"type":"ContainersReady"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Initialized"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"PodReadyToStartContainers"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"PodScheduled"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Ready"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
        f:containerStatuses: {}
        f:hostIP: {}
        f:hostIPs: {}
        f:initContainerStatuses: {}
        f:phase: {}
        f:podIP: {}
        f:podIPs:
          .: {}
          k:{"ip":"10.0.0.8"}:
            .: {}
            f:ip: {}
        f:startTime: {}
    manager: kubelet
    operation: Update
    subresource: status
    time: "2024-06-11T10:56:12Z"
  name: kube-rbac-proxy-crio-ci-op-9xx71rvq-1e28e-w667k-master-0
  namespace: openshift-machine-config-operator
  ownerReferences:
  - apiVersion: v1
    controller: true
    kind: Node
    name: ci-op-9xx71rvq-1e28e-w667k-master-0
    uid: 22305409-ad20-4f74-a793-ace67c4f2a7f
  resourceVersion: "18178"
  uid: 75f9fcfa-f85c-4f5b-bd4d-97a69955fbe6
spec:
  containers:
  - args:
    - --secure-listen-address=:9637
    - --config-file=/etc/kubernetes/crio-metrics-proxy.cfg
    - --client-ca-file=/etc/kubernetes/kubelet-ca.crt
    - --logtostderr=true
    - --kubeconfig=/var/lib/kubelet/kubeconfig
    - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
    - --upstream=http://127.0.0.1:9537
    - --tls-cert-file=/var/lib/kubelet/pki/kubelet-server-current.pem
    - --tls-private-key-file=/var/lib/kubelet/pki/kubelet-server-current.pem
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    imagePullPolicy: IfNotPresent
    name: kube-rbac-proxy-crio
    ports:
    - containerPort: 9637
      hostPort: 9637
      protocol: TCP
    resources:
      requests:
        cpu: 20m
        memory: 50Mi
    securityContext:
      privileged: true
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/kubernetes
      mountPropagation: HostToContainer
      name: etc-kube
    - mountPath: /var/lib/kubelet
      mountPropagation: HostToContainer
      name: var-lib-kubelet
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  hostNetwork: true
  initContainers:
  - args:
    - |
      echo -n "Waiting for kubelet key and certificate to be available"
      while [ -n "$(test -e /var/lib/kubelet/pki/kubelet-server-current.pem)" ] ; do
        echo -n "."
        sleep 1
        (( tries += 1 ))
        if [[ "${tries}" -gt 10 ]]; then
          echo "Timed out waiting for kubelet key and cert."
          exit 1
        fi
      done
    command:
    - /bin/bash
    - -ec
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    imagePullPolicy: IfNotPresent
    name: setup
    resources:
      requests:
        cpu: 5m
        memory: 50Mi
    securityContext:
      privileged: true
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /var
      mountPropagation: HostToContainer
      name: var-lib-kubelet
  nodeName: ci-op-9xx71rvq-1e28e-w667k-master-0
  preemptionPolicy: PreemptLowerPriority
  priority: 2000000000
  priorityClassName: system-cluster-critical
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/memory-pressure
    operator: Exists
  volumes:
  - hostPath:
      path: /etc/kubernetes
      type: ""
    name: etc-kube
  - hostPath:
      path: /var/lib/kubelet
      type: ""
    name: var-lib-kubelet
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:44:08Z"
    status: "True"
    type: PodReadyToStartContainers
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:44:08Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:45:39Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:45:39Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:44:02Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: cri-o://1ddf591865329935b4490be6c29d158a37bbe3b4278249793ea7875d1fa490e4
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    lastState:
      terminated:
        containerID: cri-o://98a9759a23b3ad472560084ce9597dcfd9ba7b95cd31e109cca07be2c178decf
        exitCode: 1
        finishedAt: "2024-06-11T10:44:49Z"
        message: "W0611 10:44:49.368855       1 deprecated.go:66] \n==== Removed Flag
          Warning ======================\n\nlogtostderr is removed in the k8s upstream
          and has no effect any more.\n\n===============================================\n\t\t\nI0611
          10:44:49.368962       1 kube-rbac-proxy.go:530] Reading config file: /etc/kubernetes/crio-metrics-proxy.cfg\nI0611
          10:44:49.370864       1 kube-rbac-proxy.go:233] Valid token audiences: \nI0611
          10:44:49.371249       1 kube-rbac-proxy.go:347] Reading certificate files\nE0611
          10:44:49.371300       1 run.go:74] \"command failed\" err=\"failed to initialize
          certificate reloader: error loading certificates: error loading certificate:
          open /var/lib/kubelet/pki/kubelet-server-current.pem: no such file or directory\"\n"
        reason: Error
        startedAt: "2024-06-11T10:44:49Z"
    name: kube-rbac-proxy-crio
    ready: true
    restartCount: 4
    started: true
    state:
      running:
        startedAt: "2024-06-11T10:45:39Z"
  hostIP: 10.0.0.8
  hostIPs:
  - ip: 10.0.0.8
  initContainerStatuses:
  - containerID: cri-o://386dc1047c2f3bad0f5862c7ca47dcef4bb1a49b76ade5da4906b1b8f58f713f
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    lastState: {}
    name: setup
    ready: true
    restartCount: 0
    started: false
    state:
      terminated:
        containerID: cri-o://386dc1047c2f3bad0f5862c7ca47dcef4bb1a49b76ade5da4906b1b8f58f713f
        exitCode: 0
        finishedAt: "2024-06-11T10:44:07Z"
        reason: Completed
        startedAt: "2024-06-11T10:44:07Z"
  phase: Running
  podIP: 10.0.0.8
  podIPs:
  - ip: 10.0.0.8
  qosClass: Burstable
  startTime: "2024-06-11T10:44:02Z"
