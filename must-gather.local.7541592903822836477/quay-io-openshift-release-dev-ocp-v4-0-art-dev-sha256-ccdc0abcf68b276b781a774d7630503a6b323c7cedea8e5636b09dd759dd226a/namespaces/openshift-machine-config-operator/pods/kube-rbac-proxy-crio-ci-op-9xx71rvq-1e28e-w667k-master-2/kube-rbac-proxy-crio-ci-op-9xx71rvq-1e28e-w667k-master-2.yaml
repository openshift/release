---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubernetes.io/config.hash: 921dc3333bbc4b6c2e5b577d2fd67536
    kubernetes.io/config.mirror: 921dc3333bbc4b6c2e5b577d2fd67536
    kubernetes.io/config.seen: "2024-06-11T10:43:53.090869634Z"
    kubernetes.io/config.source: file
    openshift.io/scc: privileged
    target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
  creationTimestamp: "2024-06-11T10:44:18Z"
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:kubernetes.io/config.hash: {}
          f:kubernetes.io/config.mirror: {}
          f:kubernetes.io/config.seen: {}
          f:kubernetes.io/config.source: {}
          f:target.workload.openshift.io/management: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"c38a426b-71b4-4f4b-8329-4811787725c6"}: {}
      f:spec:
        f:containers:
          k:{"name":"kube-rbac-proxy-crio"}:
            .: {}
            f:args: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":9637,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:protocol: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:securityContext:
              .: {}
              f:privileged: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/etc/kubernetes"}:
                .: {}
                f:mountPath: {}
                f:mountPropagation: {}
                f:name: {}
              k:{"mountPath":"/var/lib/kubelet"}:
                .: {}
                f:mountPath: {}
                f:mountPropagation: {}
                f:name: {}
        f:dnsPolicy: {}
        f:enableServiceLinks: {}
        f:hostNetwork: {}
        f:initContainers:
          .: {}
          k:{"name":"setup"}:
            .: {}
            f:args: {}
            f:command: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:securityContext:
              .: {}
              f:privileged: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/var"}:
                .: {}
                f:mountPath: {}
                f:mountPropagation: {}
                f:name: {}
        f:nodeName: {}
        f:priorityClassName: {}
        f:restartPolicy: {}
        f:schedulerName: {}
        f:securityContext: {}
        f:terminationGracePeriodSeconds: {}
        f:tolerations: {}
        f:volumes:
          .: {}
          k:{"name":"etc-kube"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
          k:{"name":"var-lib-kubelet"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
    manager: kubelet
    operation: Update
    time: "2024-06-11T10:44:18Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions:
          .: {}
          k:{"type":"ContainersReady"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Initialized"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"PodReadyToStartContainers"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"PodScheduled"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Ready"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
        f:containerStatuses: {}
        f:hostIP: {}
        f:hostIPs: {}
        f:initContainerStatuses: {}
        f:phase: {}
        f:podIP: {}
        f:podIPs:
          .: {}
          k:{"ip":"10.0.0.7"}:
            .: {}
            f:ip: {}
        f:startTime: {}
    manager: kubelet
    operation: Update
    subresource: status
    time: "2024-06-11T10:45:28Z"
  name: kube-rbac-proxy-crio-ci-op-9xx71rvq-1e28e-w667k-master-2
  namespace: openshift-machine-config-operator
  ownerReferences:
  - apiVersion: v1
    controller: true
    kind: Node
    name: ci-op-9xx71rvq-1e28e-w667k-master-2
    uid: c38a426b-71b4-4f4b-8329-4811787725c6
  resourceVersion: "3976"
  uid: 60593e9a-e660-416c-a949-2a9efd136f5f
spec:
  containers:
  - args:
    - --secure-listen-address=:9637
    - --config-file=/etc/kubernetes/crio-metrics-proxy.cfg
    - --client-ca-file=/etc/kubernetes/kubelet-ca.crt
    - --logtostderr=true
    - --kubeconfig=/var/lib/kubelet/kubeconfig
    - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
    - --upstream=http://127.0.0.1:9537
    - --tls-cert-file=/var/lib/kubelet/pki/kubelet-server-current.pem
    - --tls-private-key-file=/var/lib/kubelet/pki/kubelet-server-current.pem
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    imagePullPolicy: IfNotPresent
    name: kube-rbac-proxy-crio
    ports:
    - containerPort: 9637
      hostPort: 9637
      protocol: TCP
    resources:
      requests:
        cpu: 20m
        memory: 50Mi
    securityContext:
      privileged: true
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/kubernetes
      mountPropagation: HostToContainer
      name: etc-kube
    - mountPath: /var/lib/kubelet
      mountPropagation: HostToContainer
      name: var-lib-kubelet
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  hostNetwork: true
  initContainers:
  - args:
    - |
      echo -n "Waiting for kubelet key and certificate to be available"
      while [ -n "$(test -e /var/lib/kubelet/pki/kubelet-server-current.pem)" ] ; do
        echo -n "."
        sleep 1
        (( tries += 1 ))
        if [[ "${tries}" -gt 10 ]]; then
          echo "Timed out waiting for kubelet key and cert."
          exit 1
        fi
      done
    command:
    - /bin/bash
    - -ec
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    imagePullPolicy: IfNotPresent
    name: setup
    resources:
      requests:
        cpu: 5m
        memory: 50Mi
    securityContext:
      privileged: true
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /var
      mountPropagation: HostToContainer
      name: var-lib-kubelet
  nodeName: ci-op-9xx71rvq-1e28e-w667k-master-2
  preemptionPolicy: PreemptLowerPriority
  priority: 2000000000
  priorityClassName: system-cluster-critical
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/memory-pressure
    operator: Exists
  volumes:
  - hostPath:
      path: /etc/kubernetes
      type: ""
    name: etc-kube
  - hostPath:
      path: /var/lib/kubelet
      type: ""
    name: var-lib-kubelet
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:44:03Z"
    status: "True"
    type: PodReadyToStartContainers
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:44:03Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:45:28Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:45:28Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:43:53Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: cri-o://f75c259bc5d633cafc91fffeb34c93782247b590408854dd407894f7200dfed5
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    lastState:
      terminated:
        containerID: cri-o://80f437884e6a2f75731b1f8b0324b1b0064a938c32548393868dab88d12a10dd
        exitCode: 1
        finishedAt: "2024-06-11T10:44:47Z"
        message: "W0611 10:44:47.338326       1 deprecated.go:66] \n==== Removed Flag
          Warning ======================\n\nlogtostderr is removed in the k8s upstream
          and has no effect any more.\n\n===============================================\n\t\t\nI0611
          10:44:47.338431       1 kube-rbac-proxy.go:530] Reading config file: /etc/kubernetes/crio-metrics-proxy.cfg\nI0611
          10:44:47.340076       1 kube-rbac-proxy.go:233] Valid token audiences: \nI0611
          10:44:47.340294       1 kube-rbac-proxy.go:347] Reading certificate files\nE0611
          10:44:47.340365       1 run.go:74] \"command failed\" err=\"failed to initialize
          certificate reloader: error loading certificates: error loading certificate:
          open /var/lib/kubelet/pki/kubelet-server-current.pem: no such file or directory\"\n"
        reason: Error
        startedAt: "2024-06-11T10:44:47Z"
    name: kube-rbac-proxy-crio
    ready: true
    restartCount: 4
    started: true
    state:
      running:
        startedAt: "2024-06-11T10:45:28Z"
  hostIP: 10.0.0.7
  hostIPs:
  - ip: 10.0.0.7
  initContainerStatuses:
  - containerID: cri-o://a2cdd4ac2e88ebf872d8f6dc6bdad54151016b6ad6043cdde3b0d3396cf08c99
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    lastState: {}
    name: setup
    ready: true
    restartCount: 0
    started: false
    state:
      terminated:
        containerID: cri-o://a2cdd4ac2e88ebf872d8f6dc6bdad54151016b6ad6043cdde3b0d3396cf08c99
        exitCode: 0
        finishedAt: "2024-06-11T10:44:02Z"
        reason: Completed
        startedAt: "2024-06-11T10:44:02Z"
  phase: Running
  podIP: 10.0.0.7
  podIPs:
  - ip: 10.0.0.7
  qosClass: Burstable
  startTime: "2024-06-11T10:43:53Z"
