---
apiVersion: v1
kind: Pod
metadata:
  annotations:
    kubernetes.io/config.hash: 7c0573f666d5e542150fa41029a3b8d0
    kubernetes.io/config.mirror: 7c0573f666d5e542150fa41029a3b8d0
    kubernetes.io/config.seen: "2024-06-11T10:55:07.367015849Z"
    kubernetes.io/config.source: file
    openshift.io/scc: privileged
    target.workload.openshift.io/management: '{"effect": "PreferredDuringScheduling"}'
  creationTimestamp: "2024-06-11T10:56:50Z"
  managedFields:
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:metadata:
        f:annotations:
          .: {}
          f:kubernetes.io/config.hash: {}
          f:kubernetes.io/config.mirror: {}
          f:kubernetes.io/config.seen: {}
          f:kubernetes.io/config.source: {}
          f:target.workload.openshift.io/management: {}
        f:ownerReferences:
          .: {}
          k:{"uid":"94a9d13d-a17c-4b9f-bb4d-e0a0acb3fb68"}: {}
      f:spec:
        f:containers:
          k:{"name":"kube-rbac-proxy-crio"}:
            .: {}
            f:args: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:ports:
              .: {}
              k:{"containerPort":9637,"protocol":"TCP"}:
                .: {}
                f:containerPort: {}
                f:hostPort: {}
                f:protocol: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:securityContext:
              .: {}
              f:privileged: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/etc/kubernetes"}:
                .: {}
                f:mountPath: {}
                f:mountPropagation: {}
                f:name: {}
              k:{"mountPath":"/var/lib/kubelet"}:
                .: {}
                f:mountPath: {}
                f:mountPropagation: {}
                f:name: {}
        f:dnsPolicy: {}
        f:enableServiceLinks: {}
        f:hostNetwork: {}
        f:initContainers:
          .: {}
          k:{"name":"setup"}:
            .: {}
            f:args: {}
            f:command: {}
            f:image: {}
            f:imagePullPolicy: {}
            f:name: {}
            f:resources:
              .: {}
              f:requests:
                .: {}
                f:cpu: {}
                f:memory: {}
            f:securityContext:
              .: {}
              f:privileged: {}
            f:terminationMessagePath: {}
            f:terminationMessagePolicy: {}
            f:volumeMounts:
              .: {}
              k:{"mountPath":"/var"}:
                .: {}
                f:mountPath: {}
                f:mountPropagation: {}
                f:name: {}
        f:nodeName: {}
        f:priorityClassName: {}
        f:restartPolicy: {}
        f:schedulerName: {}
        f:securityContext: {}
        f:terminationGracePeriodSeconds: {}
        f:tolerations: {}
        f:volumes:
          .: {}
          k:{"name":"etc-kube"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
          k:{"name":"var-lib-kubelet"}:
            .: {}
            f:hostPath:
              .: {}
              f:path: {}
              f:type: {}
            f:name: {}
    manager: kubelet
    operation: Update
    time: "2024-06-11T10:56:50Z"
  - apiVersion: v1
    fieldsType: FieldsV1
    fieldsV1:
      f:status:
        f:conditions:
          .: {}
          k:{"type":"ContainersReady"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Initialized"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"PodReadyToStartContainers"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"PodScheduled"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
          k:{"type":"Ready"}:
            .: {}
            f:lastProbeTime: {}
            f:lastTransitionTime: {}
            f:status: {}
            f:type: {}
        f:containerStatuses: {}
        f:hostIP: {}
        f:hostIPs: {}
        f:initContainerStatuses: {}
        f:phase: {}
        f:podIP: {}
        f:podIPs:
          .: {}
          k:{"ip":"10.0.128.6"}:
            .: {}
            f:ip: {}
        f:startTime: {}
    manager: kubelet
    operation: Update
    subresource: status
    time: "2024-06-11T11:06:10Z"
  name: kube-rbac-proxy-crio-ci-op-9xx71rvq-1e28e-w667k-worker-centralus2-xnvk9
  namespace: openshift-machine-config-operator
  ownerReferences:
  - apiVersion: v1
    controller: true
    kind: Node
    name: ci-op-9xx71rvq-1e28e-w667k-worker-centralus2-xnvk9
    uid: 94a9d13d-a17c-4b9f-bb4d-e0a0acb3fb68
  resourceVersion: "24515"
  uid: 128ad98d-3269-437b-b2f2-ae6399eb568f
spec:
  containers:
  - args:
    - --secure-listen-address=:9637
    - --config-file=/etc/kubernetes/crio-metrics-proxy.cfg
    - --client-ca-file=/etc/kubernetes/kubelet-ca.crt
    - --logtostderr=true
    - --kubeconfig=/var/lib/kubelet/kubeconfig
    - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
    - --upstream=http://127.0.0.1:9537
    - --tls-cert-file=/var/lib/kubelet/pki/kubelet-server-current.pem
    - --tls-private-key-file=/var/lib/kubelet/pki/kubelet-server-current.pem
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    imagePullPolicy: IfNotPresent
    name: kube-rbac-proxy-crio
    ports:
    - containerPort: 9637
      hostPort: 9637
      protocol: TCP
    resources:
      requests:
        cpu: 20m
        memory: 50Mi
    securityContext:
      privileged: true
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /etc/kubernetes
      mountPropagation: HostToContainer
      name: etc-kube
    - mountPath: /var/lib/kubelet
      mountPropagation: HostToContainer
      name: var-lib-kubelet
  dnsPolicy: ClusterFirst
  enableServiceLinks: true
  hostNetwork: true
  initContainers:
  - args:
    - |
      echo -n "Waiting for kubelet key and certificate to be available"
      while [ -n "$(test -e /var/lib/kubelet/pki/kubelet-server-current.pem)" ] ; do
        echo -n "."
        sleep 1
        (( tries += 1 ))
        if [[ "${tries}" -gt 10 ]]; then
          echo "Timed out waiting for kubelet key and cert."
          exit 1
        fi
      done
    command:
    - /bin/bash
    - -ec
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    imagePullPolicy: IfNotPresent
    name: setup
    resources:
      requests:
        cpu: 5m
        memory: 50Mi
    securityContext:
      privileged: true
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: FallbackToLogsOnError
    volumeMounts:
    - mountPath: /var
      mountPropagation: HostToContainer
      name: var-lib-kubelet
  nodeName: ci-op-9xx71rvq-1e28e-w667k-worker-centralus2-xnvk9
  preemptionPolicy: PreemptLowerPriority
  priority: 2000000000
  priorityClassName: system-cluster-critical
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    operator: Exists
  - effect: NoSchedule
    key: node.kubernetes.io/memory-pressure
    operator: Exists
  volumes:
  - hostPath:
      path: /etc/kubernetes
      type: ""
    name: etc-kube
  - hostPath:
      path: /var/lib/kubelet
      type: ""
    name: var-lib-kubelet
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:55:12Z"
    status: "True"
    type: PodReadyToStartContainers
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:55:12Z"
    status: "True"
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T11:06:10Z"
    status: "True"
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T11:06:10Z"
    status: "True"
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: "2024-06-11T10:55:07Z"
    status: "True"
    type: PodScheduled
  containerStatuses:
  - containerID: cri-o://46b273853ff4062e0c47d13144378376112f3b319565702485aa5eea22ee9257
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    lastState:
      terminated:
        containerID: cri-o://4eb3da58ab82c6f94ea656ee88a2af21c9dd9f59e6a22eee84d3bea285a6fd3b
        exitCode: 1
        finishedAt: "2024-06-11T11:00:59Z"
        message: "W0611 11:00:59.436096       1 deprecated.go:66] \n==== Removed Flag
          Warning ======================\n\nlogtostderr is removed in the k8s upstream
          and has no effect any more.\n\n===============================================\n\t\t\nI0611
          11:00:59.436198       1 kube-rbac-proxy.go:530] Reading config file: /etc/kubernetes/crio-metrics-proxy.cfg\nI0611
          11:00:59.438239       1 kube-rbac-proxy.go:233] Valid token audiences: \nI0611
          11:00:59.438568       1 kube-rbac-proxy.go:347] Reading certificate files\nI0611
          11:00:59.438679       1 dynamic_cafile_content.go:157] \"Starting controller\"
          name=\"client-ca::/etc/kubernetes/kubelet-ca.crt\"\nI0611 11:00:59.438711
          \      1 dynamic_cafile_content.go:171] \"Shutting down controller\" name=\"client-ca::/etc/kubernetes/kubelet-ca.crt\"\nE0611
          11:00:59.438763       1 run.go:74] \"command failed\" err=\"failed to initialize
          certificate reloader: error loading certificates: error loading certificate:
          open /var/lib/kubelet/pki/kubelet-server-current.pem: no such file or directory\"\n"
        reason: Error
        startedAt: "2024-06-11T11:00:59Z"
    name: kube-rbac-proxy-crio
    ready: true
    restartCount: 7
    started: true
    state:
      running:
        startedAt: "2024-06-11T11:06:09Z"
  hostIP: 10.0.128.6
  hostIPs:
  - ip: 10.0.128.6
  initContainerStatuses:
  - containerID: cri-o://f4f07c8397da4631c1d6161a8c05caeeb23921c655926bce2d285d4ba5d31c7c
    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    imageID: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:592ec166fee1aabf6b7dfd82cdd541e5cb608f99c7cc41c9ad3841dd1b854776
    lastState: {}
    name: setup
    ready: true
    restartCount: 0
    started: false
    state:
      terminated:
        containerID: cri-o://f4f07c8397da4631c1d6161a8c05caeeb23921c655926bce2d285d4ba5d31c7c
        exitCode: 0
        finishedAt: "2024-06-11T10:55:12Z"
        reason: Completed
        startedAt: "2024-06-11T10:55:12Z"
  phase: Running
  podIP: 10.0.128.6
  podIPs:
  - ip: 10.0.128.6
  qosClass: Burstable
  startTime: "2024-06-11T10:55:07Z"
