2024-06-11T10:49:39.523814331Z I0611 10:49:39.523660       1 cmd.go:241] Using service-serving-cert provided certificates
2024-06-11T10:49:39.523814331Z I0611 10:49:39.523783       1 leaderelection.go:122] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2024-06-11T10:49:39.524756961Z I0611 10:49:39.524705       1 observer_polling.go:159] Starting file observer
2024-06-11T10:49:39.542907938Z I0611 10:49:39.542851       1 builder.go:299] kube-apiserver-operator version 4.16.0-202406061206.p0.gd790493.assembly.stream.el9-d790493-d790493cfc43fd33450ca27633cbe37aa17427d2
2024-06-11T10:49:40.085080569Z I0611 10:49:40.085012       1 secure_serving.go:57] Forcing use of http/1.1 only
2024-06-11T10:49:40.085080569Z W0611 10:49:40.085041       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2024-06-11T10:49:40.085080569Z W0611 10:49:40.085049       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2024-06-11T10:49:40.086696321Z I0611 10:49:40.086664       1 leaderelection.go:250] attempting to acquire leader lease openshift-kube-apiserver-operator/kube-apiserver-operator-lock...
2024-06-11T10:49:40.087237138Z I0611 10:49:40.087205       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2024-06-11T10:49:40.087251138Z I0611 10:49:40.087227       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2024-06-11T10:49:40.087262639Z I0611 10:49:40.087238       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2024-06-11T10:49:40.087262639Z I0611 10:49:40.087255       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-06-11T10:49:40.087273739Z I0611 10:49:40.087262       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-06-11T10:49:40.087284439Z I0611 10:49:40.087242       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
2024-06-11T10:49:40.087883658Z I0611 10:49:40.087837       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2024-06-11T10:49:40.088487377Z I0611 10:49:40.088452       1 secure_serving.go:213] Serving securely on [::]:8443
2024-06-11T10:49:40.088508678Z I0611 10:49:40.088485       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2024-06-11T10:49:40.093588740Z I0611 10:49:40.093543       1 leaderelection.go:260] successfully acquired lease openshift-kube-apiserver-operator/kube-apiserver-operator-lock
2024-06-11T10:49:40.093781746Z I0611 10:49:40.093740       1 event.go:364] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator-lock", UID:"db8182ba-9a02-4a86-be4d-7ecea660904b", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"11443", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' kube-apiserver-operator-648fdc585-xghvk_0f560b16-7d46-4495-af60-7cf077d9a197 became leader
2024-06-11T10:49:40.094308162Z I0611 10:49:40.094256       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2024-06-11T10:49:40.097110252Z I0611 10:49:40.097050       1 starter.go:140] FeatureGates initialized: knownFeatureGates=[AdminNetworkPolicy AlibabaPlatform AutomatedEtcdBackup AzureWorkloadIdentity BareMetalLoadBalancer BuildCSIVolumes CSIDriverSharedResource ChunkSizeMiB CloudDualStackNodeIPs ClusterAPIInstall ClusterAPIInstallAWS ClusterAPIInstallAzure ClusterAPIInstallGCP ClusterAPIInstallIBMCloud ClusterAPIInstallNutanix ClusterAPIInstallOpenStack ClusterAPIInstallPowerVS ClusterAPIInstallVSphere DNSNameResolver DisableKubeletCloudCredentialProviders DynamicResourceAllocation EtcdBackendQuota EventedPLEG Example ExternalCloudProvider ExternalCloudProviderAzure ExternalCloudProviderExternal ExternalCloudProviderGCP ExternalOIDC ExternalRouteCertificate GCPClusterHostedDNS GCPLabelsTags GatewayAPI HardwareSpeed ImagePolicy InsightsConfig InsightsConfigAPI InsightsOnDemandDataGather InstallAlternateInfrastructureAWS KMSv1 MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MachineConfigNodes ManagedBootImages MaxUnavailableStatefulSet MetricsCollectionProfiles MetricsServer MixedCPUsAllocation NetworkDiagnosticsConfig NetworkLiveMigration NewOLM NodeDisruptionPolicy NodeSwap OnClusterBuild OpenShiftPodSecurityAdmission PinnedImages PlatformOperators PrivateHostedZoneAWS RouteExternalCertificate ServiceAccountTokenNodeBinding ServiceAccountTokenNodeBindingValidation ServiceAccountTokenPodNodeInfo SignatureStores SigstoreImageVerification TranslateStreamCloseWebsocketRequests UpgradeStatus VSphereControlPlaneMachineSet VSphereDriverConfiguration VSphereMultiVCenters VSphereStaticIPs ValidatingAdmissionPolicy VolumeGroupSnapshot]
2024-06-11T10:49:40.097595867Z I0611 10:49:40.097525       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AdminNetworkPolicy", "AlibabaPlatform", "AzureWorkloadIdentity", "BareMetalLoadBalancer", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ClusterAPIInstallAWS", "ClusterAPIInstallNutanix", "ClusterAPIInstallOpenStack", "ClusterAPIInstallVSphere", "DisableKubeletCloudCredentialProviders", "ExternalCloudProvider", "ExternalCloudProviderAzure", "ExternalCloudProviderExternal", "ExternalCloudProviderGCP", "HardwareSpeed", "KMSv1", "MetricsServer", "NetworkDiagnosticsConfig", "NetworkLiveMigration", "PrivateHostedZoneAWS", "VSphereControlPlaneMachineSet", "VSphereDriverConfiguration", "VSphereStaticIPs"}, Disabled:[]v1.FeatureGateName{"AutomatedEtcdBackup", "CSIDriverSharedResource", "ChunkSizeMiB", "ClusterAPIInstall", "ClusterAPIInstallAzure", "ClusterAPIInstallGCP", "ClusterAPIInstallIBMCloud", "ClusterAPIInstallPowerVS", "DNSNameResolver", "DynamicResourceAllocation", "EtcdBackendQuota", "EventedPLEG", "Example", "ExternalOIDC", "ExternalRouteCertificate", "GCPClusterHostedDNS", "GCPLabelsTags", "GatewayAPI", "ImagePolicy", "InsightsConfig", "InsightsConfigAPI", "InsightsOnDemandDataGather", "InstallAlternateInfrastructureAWS", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MachineConfigNodes", "ManagedBootImages", "MaxUnavailableStatefulSet", "MetricsCollectionProfiles", "MixedCPUsAllocation", "NewOLM", "NodeDisruptionPolicy", "NodeSwap", "OnClusterBuild", "OpenShiftPodSecurityAdmission", "PinnedImages", "PlatformOperators", "RouteExternalCertificate", "ServiceAccountTokenNodeBinding", "ServiceAccountTokenNodeBindingValidation", "ServiceAccountTokenPodNodeInfo", "SignatureStores", "SigstoreImageVerification", "TranslateStreamCloseWebsocketRequests", "UpgradeStatus", "VSphereMultiVCenters", "ValidatingAdmissionPolicy", "VolumeGroupSnapshot"}}
2024-06-11T10:49:40.129670986Z I0611 10:49:40.129609       1 base_controller.go:67] Waiting for caches to sync for SCCReconcileController
2024-06-11T10:49:40.130127001Z I0611 10:49:40.130075       1 base_controller.go:67] Waiting for caches to sync for MissingStaticPodController
2024-06-11T10:49:40.130240305Z I0611 10:49:40.130195       1 base_controller.go:67] Waiting for caches to sync for BoundSATokenSignerController
2024-06-11T10:49:40.130361208Z I0611 10:49:40.130337       1 base_controller.go:67] Waiting for caches to sync for ResourceSyncController
2024-06-11T10:49:40.130528214Z I0611 10:49:40.130498       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateController
2024-06-11T10:49:40.130600716Z I0611 10:49:40.130570       1 base_controller.go:67] Waiting for caches to sync for auditPolicyController
2024-06-11T10:49:40.130621417Z I0611 10:49:40.130597       1 base_controller.go:67] Waiting for caches to sync for RemoveStaleConditionsController
2024-06-11T10:49:40.130621417Z I0611 10:49:40.130617       1 base_controller.go:67] Waiting for caches to sync for ConnectivityCheckController
2024-06-11T10:49:40.130665818Z I0611 10:49:40.130627       1 base_controller.go:67] Waiting for caches to sync for PruneController
2024-06-11T10:49:40.130665818Z I0611 10:49:40.130642       1 base_controller.go:67] Waiting for caches to sync for WorkerLatencyProfile
2024-06-11T10:49:40.130665818Z I0611 10:49:40.130661       1 base_controller.go:67] Waiting for caches to sync for UnsupportedConfigOverridesController
2024-06-11T10:49:40.130684319Z I0611 10:49:40.130673       1 base_controller.go:67] Waiting for caches to sync for LoggingSyncer
2024-06-11T10:49:40.130684319Z I0611 10:49:40.130676       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateFallback
2024-06-11T10:49:40.130696319Z I0611 10:49:40.130687       1 base_controller.go:67] Waiting for caches to sync for GuardController
2024-06-11T10:49:40.130707519Z I0611 10:49:40.130661       1 base_controller.go:67] Waiting for caches to sync for StartupMonitorPodCondition
2024-06-11T10:49:40.130707519Z I0611 10:49:40.130635       1 base_controller.go:67] Waiting for caches to sync for KubeletVersionSkewController
2024-06-11T10:49:40.130722120Z I0611 10:49:40.130714       1 base_controller.go:67] Waiting for caches to sync for ServiceAccountIssuerController
2024-06-11T10:49:40.130771921Z I0611 10:49:40.130733       1 base_controller.go:67] Waiting for caches to sync for PodSecurityReadinessController
2024-06-11T10:49:40.130771921Z I0611 10:49:40.130743       1 base_controller.go:73] Caches are synced for PodSecurityReadinessController 
2024-06-11T10:49:40.130771921Z I0611 10:49:40.130751       1 base_controller.go:110] Starting #1 worker of PodSecurityReadinessController controller ...
2024-06-11T10:49:40.131008329Z I0611 10:49:40.130954       1 base_controller.go:67] Waiting for caches to sync for KubeAPIServerStaticResources
2024-06-11T10:49:40.131008329Z I0611 10:49:40.130966       1 base_controller.go:67] Waiting for caches to sync for RevisionController
2024-06-11T10:49:40.131008329Z I0611 10:49:40.130986       1 base_controller.go:67] Waiting for caches to sync for TargetConfigController
2024-06-11T10:49:40.131028730Z I0611 10:49:40.131008       1 base_controller.go:67] Waiting for caches to sync for NodeKubeconfigController
2024-06-11T10:49:40.131039730Z I0611 10:49:40.131027       1 base_controller.go:67] Waiting for caches to sync for ConfigObserver
2024-06-11T10:49:40.131087831Z I0611 10:49:40.131063       1 certrotationcontroller.go:886] Starting CertRotation
2024-06-11T10:49:40.131100032Z I0611 10:49:40.131083       1 base_controller.go:67] Waiting for caches to sync for EncryptionConditionController
2024-06-11T10:49:40.131110932Z I0611 10:49:40.131100       1 certrotationcontroller.go:851] Waiting for CertRotation
2024-06-11T10:49:40.131131933Z I0611 10:49:40.131114       1 base_controller.go:67] Waiting for caches to sync for CertRotationTimeUpgradeableController
2024-06-11T10:49:40.131174234Z I0611 10:49:40.131148       1 termination_observer.go:145] Starting TerminationObserver
2024-06-11T10:49:40.131174234Z I0611 10:49:40.131156       1 base_controller.go:67] Waiting for caches to sync for BackingResourceController
2024-06-11T10:49:40.131187435Z I0611 10:49:40.131175       1 base_controller.go:67] Waiting for caches to sync for EventWatchController
2024-06-11T10:49:40.131228536Z I0611 10:49:40.130379       1 base_controller.go:67] Waiting for caches to sync for NodeController
2024-06-11T10:49:40.131277837Z I0611 10:49:40.131255       1 base_controller.go:67] Waiting for caches to sync for EncryptionKeyController
2024-06-11T10:49:40.131292738Z I0611 10:49:40.131283       1 base_controller.go:67] Waiting for caches to sync for EncryptionStateController
2024-06-11T10:49:40.131329839Z I0611 10:49:40.131320       1 base_controller.go:67] Waiting for caches to sync for EncryptionPruneController
2024-06-11T10:49:40.131348840Z I0611 10:49:40.131340       1 base_controller.go:67] Waiting for caches to sync for EncryptionMigrationController
2024-06-11T10:49:40.131362240Z I0611 10:49:40.131353       1 base_controller.go:67] Waiting for caches to sync for StatusSyncer_kube-apiserver
2024-06-11T10:49:40.131448343Z I0611 10:49:40.131424       1 base_controller.go:67] Waiting for caches to sync for InstallerStateController
2024-06-11T10:49:40.131448343Z I0611 10:49:40.130549       1 base_controller.go:67] Waiting for caches to sync for webhookSupportabilityController
2024-06-11T10:49:40.132397773Z I0611 10:49:40.132365       1 base_controller.go:67] Waiting for caches to sync for InstallerController
2024-06-11T10:49:40.187962139Z I0611 10:49:40.187899       1 shared_informer.go:318] Caches are synced for RequestHeaderAuthRequestController
2024-06-11T10:49:40.187962139Z I0611 10:49:40.187937       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-06-11T10:49:40.188004840Z I0611 10:49:40.187947       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-06-11T10:49:40.230754099Z I0611 10:49:40.230424       1 base_controller.go:73] Caches are synced for SCCReconcileController 
2024-06-11T10:49:40.230754099Z I0611 10:49:40.230667       1 base_controller.go:110] Starting #1 worker of SCCReconcileController controller ...
2024-06-11T10:49:40.230754099Z I0611 10:49:40.230676       1 base_controller.go:73] Caches are synced for RemoveStaleConditionsController 
2024-06-11T10:49:40.230754099Z I0611 10:49:40.230706       1 base_controller.go:110] Starting #1 worker of RemoveStaleConditionsController controller ...
2024-06-11T10:49:40.230927105Z I0611 10:49:40.230886       1 base_controller.go:73] Caches are synced for PruneController 
2024-06-11T10:49:40.234867930Z I0611 10:49:40.234835       1 base_controller.go:110] Starting #1 worker of PruneController controller ...
2024-06-11T10:49:40.236284975Z I0611 10:49:40.231028       1 base_controller.go:73] Caches are synced for UnsupportedConfigOverridesController 
2024-06-11T10:49:40.236360477Z I0611 10:49:40.236344       1 base_controller.go:110] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2024-06-11T10:49:40.236938096Z I0611 10:49:40.231068       1 base_controller.go:73] Caches are synced for LoggingSyncer 
2024-06-11T10:49:40.236990497Z I0611 10:49:40.236972       1 base_controller.go:110] Starting #1 worker of LoggingSyncer controller ...
2024-06-11T10:49:40.237318208Z I0611 10:49:40.231106       1 base_controller.go:73] Caches are synced for KubeletVersionSkewController 
2024-06-11T10:49:40.237384010Z I0611 10:49:40.237367       1 base_controller.go:110] Starting #1 worker of KubeletVersionSkewController controller ...
2024-06-11T10:49:40.237711820Z I0611 10:49:40.231263       1 certrotationcontroller.go:869] Finished waiting for CertRotation
2024-06-11T10:49:40.237825424Z I0611 10:49:40.231437       1 base_controller.go:73] Caches are synced for CertRotationTimeUpgradeableController 
2024-06-11T10:49:40.239685383Z I0611 10:49:40.239653       1 base_controller.go:110] Starting #1 worker of CertRotationTimeUpgradeableController controller ...
2024-06-11T10:49:40.239790086Z I0611 10:49:40.231475       1 base_controller.go:73] Caches are synced for NodeController 
2024-06-11T10:49:40.239790086Z I0611 10:49:40.237823       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2024-06-11T10:49:40.239790086Z I0611 10:49:40.237841       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2024-06-11T10:49:40.239790086Z I0611 10:49:40.237853       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2024-06-11T10:49:40.239790086Z I0611 10:49:40.237869       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2024-06-11T10:49:40.239843188Z I0611 10:49:40.237884       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2024-06-11T10:49:40.239843188Z I0611 10:49:40.237884       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2024-06-11T10:49:40.239843188Z I0611 10:49:40.237905       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2024-06-11T10:49:40.239843188Z I0611 10:49:40.237905       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2024-06-11T10:49:40.239858488Z I0611 10:49:40.237918       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2024-06-11T10:49:40.239858488Z I0611 10:49:40.237921       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2024-06-11T10:49:40.239858488Z I0611 10:49:40.237936       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2024-06-11T10:49:40.239858488Z I0611 10:49:40.237966       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2024-06-11T10:49:40.239858488Z I0611 10:49:40.238005       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com
2024-06-11T10:49:40.239870489Z I0611 10:49:40.238013       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-06-11T10:49:40.239912490Z I0611 10:49:40.239887       1 base_controller.go:110] Starting #1 worker of NodeController controller ...
2024-06-11T10:49:40.240075795Z I0611 10:49:40.240049       1 base_controller.go:73] Caches are synced for CertRotationController 
2024-06-11T10:49:40.240075795Z I0611 10:49:40.240064       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2024-06-11T10:49:40.297216211Z I0611 10:49:40.297161       1 reflector.go:351] Caches populated for *v1.Proxy from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:40.320442550Z I0611 10:49:40.320379       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:40.341284312Z I0611 10:49:40.341234       1 base_controller.go:73] Caches are synced for CertRotationController 
2024-06-11T10:49:40.341284312Z I0611 10:49:40.341257       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2024-06-11T10:49:40.341350314Z I0611 10:49:40.341273       1 base_controller.go:73] Caches are synced for CertRotationController 
2024-06-11T10:49:40.341350314Z I0611 10:49:40.341296       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2024-06-11T10:49:40.401569828Z I0611 10:49:40.401501       1 reflector.go:351] Caches populated for *v1.CustomResourceDefinition from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:40.506255755Z I0611 10:49:40.506200       1 reflector.go:351] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:40.520747816Z I0611 10:49:40.520686       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:40.531444756Z I0611 10:49:40.531395       1 base_controller.go:73] Caches are synced for StatusSyncer_kube-apiserver 
2024-06-11T10:49:40.531444756Z I0611 10:49:40.531417       1 base_controller.go:110] Starting #1 worker of StatusSyncer_kube-apiserver controller ...
2024-06-11T10:49:40.696947216Z I0611 10:49:40.696862       1 reflector.go:351] Caches populated for *v1.Image from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:40.721010781Z I0611 10:49:40.720955       1 reflector.go:351] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:40.731639319Z I0611 10:49:40.731567       1 base_controller.go:73] Caches are synced for ConnectivityCheckController 
2024-06-11T10:49:40.731639319Z I0611 10:49:40.731607       1 base_controller.go:110] Starting #1 worker of ConnectivityCheckController controller ...
2024-06-11T10:49:40.731912527Z I0611 10:49:40.731884       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:49:40.897801800Z I0611 10:49:40.897731       1 reflector.go:351] Caches populated for *v1.Authentication from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:40.925651085Z I0611 10:49:40.925591       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:40.930890151Z I0611 10:49:40.930823       1 base_controller.go:73] Caches are synced for ServiceAccountIssuerController 
2024-06-11T10:49:40.930890151Z I0611 10:49:40.930849       1 base_controller.go:110] Starting #1 worker of ServiceAccountIssuerController controller ...
2024-06-11T10:49:41.120898690Z I0611 10:49:41.120825       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:41.131294021Z I0611 10:49:41.131234       1 base_controller.go:73] Caches are synced for BackingResourceController 
2024-06-11T10:49:41.131294021Z I0611 10:49:41.131260       1 base_controller.go:110] Starting #1 worker of BackingResourceController controller ...
2024-06-11T10:49:41.318483655Z I0611 10:49:41.318407       1 request.go:697] Waited for 1.18797764s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/endpoints?limit=500&resourceVersion=0
2024-06-11T10:49:41.320218235Z I0611 10:49:41.320180       1 reflector.go:351] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:41.521995495Z I0611 10:49:41.521937       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:41.725907753Z I0611 10:49:41.725821       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:41.922604879Z I0611 10:49:41.922547       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:41.932341826Z I0611 10:49:41.932187       1 base_controller.go:73] Caches are synced for webhookSupportabilityController 
2024-06-11T10:49:41.932341826Z I0611 10:49:41.932209       1 base_controller.go:110] Starting #1 worker of webhookSupportabilityController controller ...
2024-06-11T10:49:41.936426414Z W0611 10:49:41.936379       1 degraded_webhook.go:147] failed to connect to webhook "default.machine.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:49:42.121322699Z I0611 10:49:42.121222       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:42.320719550Z I0611 10:49:42.320654       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:42.340891075Z I0611 10:49:42.340834       1 base_controller.go:73] Caches are synced for CertRotationController 
2024-06-11T10:49:42.340891075Z I0611 10:49:42.340857       1 base_controller.go:73] Caches are synced for CertRotationController 
2024-06-11T10:49:42.340891075Z I0611 10:49:42.340867       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2024-06-11T10:49:42.340891075Z I0611 10:49:42.340875       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2024-06-11T10:49:42.340891075Z I0611 10:49:42.340877       1 base_controller.go:73] Caches are synced for CertRotationController 
2024-06-11T10:49:42.340925877Z I0611 10:49:42.340894       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2024-06-11T10:49:42.340925877Z I0611 10:49:42.340907       1 base_controller.go:73] Caches are synced for CertRotationController 
2024-06-11T10:49:42.340936678Z I0611 10:49:42.340928       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2024-06-11T10:49:42.340976079Z I0611 10:49:42.340954       1 base_controller.go:73] Caches are synced for CertRotationController 
2024-06-11T10:49:42.340976079Z I0611 10:49:42.340971       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2024-06-11T10:49:42.341059383Z I0611 10:49:42.341018       1 base_controller.go:73] Caches are synced for CertRotationController 
2024-06-11T10:49:42.341128886Z I0611 10:49:42.341106       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2024-06-11T10:49:42.342371743Z I0611 10:49:42.342333       1 base_controller.go:73] Caches are synced for CertRotationController 
2024-06-11T10:49:42.342442947Z I0611 10:49:42.342422       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2024-06-11T10:49:42.342516150Z I0611 10:49:42.340841       1 base_controller.go:73] Caches are synced for CertRotationController 
2024-06-11T10:49:42.342516150Z I0611 10:49:42.342491       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2024-06-11T10:49:42.342516150Z I0611 10:49:42.342453       1 base_controller.go:73] Caches are synced for CertRotationController 
2024-06-11T10:49:42.342542651Z I0611 10:49:42.342521       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2024-06-11T10:49:42.356657299Z I0611 10:49:42.356604       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:49:42.384868894Z I0611 10:49:42.384817       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:49:42.518652833Z I0611 10:49:42.518576       1 request.go:697] Waited for 2.386345361s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?limit=500&resourceVersion=0
2024-06-11T10:49:42.520989441Z I0611 10:49:42.520942       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:42.531641529Z I0611 10:49:42.531597       1 base_controller.go:73] Caches are synced for EncryptionStateController 
2024-06-11T10:49:42.531641529Z I0611 10:49:42.531605       1 base_controller.go:73] Caches are synced for StaticPodStateController 
2024-06-11T10:49:42.531641529Z I0611 10:49:42.531622       1 base_controller.go:73] Caches are synced for GuardController 
2024-06-11T10:49:42.531676131Z I0611 10:49:42.531638       1 base_controller.go:110] Starting #1 worker of StaticPodStateController controller ...
2024-06-11T10:49:42.531676131Z I0611 10:49:42.531642       1 base_controller.go:110] Starting #1 worker of GuardController controller ...
2024-06-11T10:49:42.531676131Z I0611 10:49:42.531625       1 base_controller.go:73] Caches are synced for StartupMonitorPodCondition 
2024-06-11T10:49:42.531689232Z I0611 10:49:42.531679       1 base_controller.go:110] Starting #1 worker of StartupMonitorPodCondition controller ...
2024-06-11T10:49:42.531700832Z I0611 10:49:42.531615       1 base_controller.go:110] Starting #1 worker of EncryptionStateController controller ...
2024-06-11T10:49:42.531714433Z I0611 10:49:42.531704       1 base_controller.go:73] Caches are synced for EncryptionMigrationController 
2024-06-11T10:49:42.531759335Z I0611 10:49:42.531720       1 base_controller.go:110] Starting #1 worker of EncryptionMigrationController controller ...
2024-06-11T10:49:42.531804837Z I0611 10:49:42.531777       1 base_controller.go:73] Caches are synced for EncryptionKeyController 
2024-06-11T10:49:42.531804837Z I0611 10:49:42.531786       1 base_controller.go:73] Caches are synced for StaticPodStateFallback 
2024-06-11T10:49:42.531818537Z I0611 10:49:42.531807       1 base_controller.go:73] Caches are synced for EncryptionPruneController 
2024-06-11T10:49:42.531830338Z I0611 10:49:42.531821       1 base_controller.go:110] Starting #1 worker of EncryptionPruneController controller ...
2024-06-11T10:49:42.531853939Z I0611 10:49:42.531835       1 base_controller.go:110] Starting #1 worker of StaticPodStateFallback controller ...
2024-06-11T10:49:42.531898241Z I0611 10:49:42.531875       1 base_controller.go:73] Caches are synced for EncryptionConditionController 
2024-06-11T10:49:42.531941143Z I0611 10:49:42.531890       1 base_controller.go:110] Starting #1 worker of EncryptionConditionController controller ...
2024-06-11T10:49:42.531952544Z I0611 10:49:42.531795       1 base_controller.go:110] Starting #1 worker of EncryptionKeyController controller ...
2024-06-11T10:49:42.532209655Z I0611 10:49:42.532168       1 base_controller.go:73] Caches are synced for InstallerStateController 
2024-06-11T10:49:42.532272058Z I0611 10:49:42.532254       1 base_controller.go:110] Starting #1 worker of InstallerStateController controller ...
2024-06-11T10:49:42.532342362Z E0611 10:49:42.532225       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:42.532436066Z E0611 10:49:42.532415       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:42.532503969Z E0611 10:49:42.532486       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:42.532735280Z I0611 10:49:42.532692       1 base_controller.go:73] Caches are synced for InstallerController 
2024-06-11T10:49:42.532820883Z I0611 10:49:42.532779       1 base_controller.go:110] Starting #1 worker of InstallerController controller ...
2024-06-11T10:49:42.532885986Z E0611 10:49:42.532858       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:42.533407510Z I0611 10:49:42.533362       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:49:42.539892908Z E0611 10:49:42.538457       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:42.539892908Z E0611 10:49:42.538495       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:42.539892908Z E0611 10:49:42.538517       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:42.539892908Z E0611 10:49:42.538704       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:42.549930669Z E0611 10:49:42.549887       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:42.549930669Z E0611 10:49:42.549920       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:42.549957070Z E0611 10:49:42.549938       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:42.550204581Z E0611 10:49:42.550183       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:42.570703322Z E0611 10:49:42.570649       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:42.570703322Z E0611 10:49:42.570692       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:42.570740824Z E0611 10:49:42.570717       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:42.570971134Z E0611 10:49:42.570941       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:42.612062120Z E0611 10:49:42.611995       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:42.612062120Z E0611 10:49:42.612030       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:42.612062120Z E0611 10:49:42.612047       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:42.612290230Z E0611 10:49:42.612263       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:42.692817726Z E0611 10:49:42.692686       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:42.692817726Z E0611 10:49:42.692723       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:42.692817726Z E0611 10:49:42.692741       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:42.693012535Z E0611 10:49:42.692986       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:42.725922445Z I0611 10:49:42.725843       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:42.853816515Z E0611 10:49:42.853767       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:42.853816515Z E0611 10:49:42.853799       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:42.853879618Z E0611 10:49:42.853819       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:42.854029624Z E0611 10:49:42.854007       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:42.921598225Z I0611 10:49:42.921521       1 reflector.go:351] Caches populated for *v1.Event from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:42.931413976Z I0611 10:49:42.931356       1 base_controller.go:73] Caches are synced for EventWatchController 
2024-06-11T10:49:42.931413976Z I0611 10:49:42.931385       1 base_controller.go:110] Starting #1 worker of EventWatchController controller ...
2024-06-11T10:49:42.940022171Z W0611 10:49:42.939981       1 degraded_webhook.go:147] failed to connect to webhook "default.machine.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:49:43.121086180Z I0611 10:49:43.121017       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:43.130741323Z I0611 10:49:43.130680       1 base_controller.go:73] Caches are synced for ResourceSyncController 
2024-06-11T10:49:43.130821527Z I0611 10:49:43.130794       1 base_controller.go:110] Starting #1 worker of ResourceSyncController controller ...
2024-06-11T10:49:43.130838528Z I0611 10:49:43.130794       1 base_controller.go:73] Caches are synced for WorkerLatencyProfile 
2024-06-11T10:49:43.130838528Z I0611 10:49:43.130829       1 base_controller.go:110] Starting #1 worker of WorkerLatencyProfile controller ...
2024-06-11T10:49:43.130874429Z I0611 10:49:43.130759       1 base_controller.go:73] Caches are synced for MissingStaticPodController 
2024-06-11T10:49:43.130918531Z I0611 10:49:43.130880       1 base_controller.go:110] Starting #1 worker of MissingStaticPodController controller ...
2024-06-11T10:49:43.130979734Z I0611 10:49:43.130773       1 base_controller.go:73] Caches are synced for auditPolicyController 
2024-06-11T10:49:43.131032037Z I0611 10:49:43.131007       1 base_controller.go:110] Starting #1 worker of auditPolicyController controller ...
2024-06-11T10:49:43.131108540Z I0611 10:49:43.131087       1 base_controller.go:73] Caches are synced for RevisionController 
2024-06-11T10:49:43.131151042Z I0611 10:49:43.131135       1 base_controller.go:110] Starting #1 worker of RevisionController controller ...
2024-06-11T10:49:43.131492058Z I0611 10:49:43.131442       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'FastControllerResync' Controller "auditPolicyController" resync interval is set to 10s which might lead to client request throttling
2024-06-11T10:49:43.131572361Z I0611 10:49:43.130725       1 base_controller.go:73] Caches are synced for BoundSATokenSignerController 
2024-06-11T10:49:43.131647665Z I0611 10:49:43.131621       1 base_controller.go:110] Starting #1 worker of BoundSATokenSignerController controller ...
2024-06-11T10:49:43.131714868Z I0611 10:49:43.131679       1 base_controller.go:73] Caches are synced for KubeAPIServerStaticResources 
2024-06-11T10:49:43.131714868Z I0611 10:49:43.131708       1 base_controller.go:110] Starting #1 worker of KubeAPIServerStaticResources controller ...
2024-06-11T10:49:43.131762170Z I0611 10:49:43.131724       1 base_controller.go:73] Caches are synced for NodeKubeconfigController 
2024-06-11T10:49:43.131883476Z I0611 10:49:43.131856       1 base_controller.go:110] Starting #1 worker of NodeKubeconfigController controller ...
2024-06-11T10:49:43.131958279Z I0611 10:49:43.131743       1 base_controller.go:73] Caches are synced for ConfigObserver 
2024-06-11T10:49:43.132934324Z I0611 10:49:43.132881       1 base_controller.go:110] Starting #1 worker of ConfigObserver controller ...
2024-06-11T10:49:43.132934324Z I0611 10:49:43.131816       1 base_controller.go:73] Caches are synced for TargetConfigController 
2024-06-11T10:49:43.132967625Z I0611 10:49:43.132937       1 base_controller.go:110] Starting #1 worker of TargetConfigController controller ...
2024-06-11T10:49:43.133424446Z E0611 10:49:43.133384       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:43.133615055Z I0611 10:49:43.133567       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:43.133714160Z I0611 10:49:43.133553       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveFeatureFlagsUpdated' Updated apiServerArguments.feature-gates to AdminNetworkPolicy=true,AlibabaPlatform=true,AutomatedEtcdBackup=false,AzureWorkloadIdentity=true,BareMetalLoadBalancer=true,BuildCSIVolumes=true,CSIDriverSharedResource=false,ChunkSizeMiB=false,CloudDualStackNodeIPs=true,ClusterAPIInstall=false,ClusterAPIInstallAWS=true,ClusterAPIInstallAzure=false,ClusterAPIInstallGCP=false,ClusterAPIInstallIBMCloud=false,ClusterAPIInstallNutanix=true,ClusterAPIInstallOpenStack=true,ClusterAPIInstallPowerVS=false,ClusterAPIInstallVSphere=true,DNSNameResolver=false,DisableKubeletCloudCredentialProviders=true,DynamicResourceAllocation=false,EtcdBackendQuota=false,EventedPLEG=false,Example=false,ExternalCloudProvider=true,ExternalCloudProviderAzure=true,ExternalCloudProviderExternal=true,ExternalCloudProviderGCP=true,ExternalOIDC=false,ExternalRouteCertificate=false,GCPClusterHostedDNS=false,GCPLabelsTags=false,GatewayAPI=false,HardwareSpeed=true,ImagePolicy=false,InsightsConfig=false,InsightsConfigAPI=false,InsightsOnDemandDataGather=false,InstallAlternateInfrastructureAWS=false,KMSv1=true,MachineAPIOperatorDisableMachineHealthCheckController=false,MachineAPIProviderOpenStack=false,MachineConfigNodes=false,ManagedBootImages=false,MaxUnavailableStatefulSet=false,MetricsCollectionProfiles=false,MetricsServer=true,MixedCPUsAllocation=false,NetworkDiagnosticsConfig=true,NetworkLiveMigration=true,NewOLM=false,NodeDisruptionPolicy=false,NodeSwap=false,OnClusterBuild=false,OpenShiftPodSecurityAdmission=false,PinnedImages=false,PlatformOperators=false,PrivateHostedZoneAWS=true,RouteExternalCertificate=false,ServiceAccountTokenNodeBinding=false,ServiceAccountTokenNodeBindingValidation=false,ServiceAccountTokenPodNodeInfo=false,SignatureStores=false,SigstoreImageVerification=false,TranslateStreamCloseWebsocketRequests=false,UpgradeStatus=false,VSphereControlPlaneMachineSet=true,VSphereDriverConfiguration=true,VSphereMultiVCenters=false,VSphereStaticIPs=true,ValidatingAdmissionPolicy=false,VolumeGroupSnapshot=false
2024-06-11T10:49:43.133714160Z I0611 10:49:43.133672       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveTLSSecurityProfile' minTLSVersion changed to VersionTLS12
2024-06-11T10:49:43.133714160Z I0611 10:49:43.133693       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveTLSSecurityProfile' cipherSuites changed to ["TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256" "TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256" "TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384" "TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384" "TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256" "TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256"]
2024-06-11T10:49:43.139486325Z E0611 10:49:43.139445       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:43.139513326Z I0611 10:49:43.139482       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:43.149775197Z E0611 10:49:43.149727       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:43.149839300Z I0611 10:49:43.149801       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:43.171095075Z E0611 10:49:43.171015       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:43.171173479Z I0611 10:49:43.171110       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:43.175157962Z E0611 10:49:43.175121       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:43.175157962Z E0611 10:49:43.175151       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:43.175183863Z E0611 10:49:43.175169       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:43.175379772Z E0611 10:49:43.175354       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:43.212121858Z E0611 10:49:43.212061       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:43.212167660Z I0611 10:49:43.212132       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:43.292906065Z E0611 10:49:43.292834       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:43.292939767Z I0611 10:49:43.292906       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:43.454264470Z E0611 10:49:43.454196       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:43.454387476Z I0611 10:49:43.454343       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:43.542914939Z I0611 10:49:43.542819       1 request.go:697] Waited for 1.170730027s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:49:43.775116995Z E0611 10:49:43.775053       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:43.775201399Z I0611 10:49:43.775150       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:43.816949515Z E0611 10:49:43.816883       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:43.816949515Z E0611 10:49:43.816923       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:43.816986116Z E0611 10:49:43.816945       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:43.817195526Z E0611 10:49:43.817171       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:44.154123188Z E0611 10:49:44.154051       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:44.154320097Z I0611 10:49:44.154213       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:44.154320097Z I0611 10:49:44.154265       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:49:44.250598616Z E0611 10:49:44.250262       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:44.250598616Z E0611 10:49:44.250363       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:44.250598616Z E0611 10:49:44.250391       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:44.254080176Z E0611 10:49:44.250771       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:44.307687636Z E0611 10:49:44.307631       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:44.307844743Z E0611 10:49:44.307800       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:44.308423269Z E0611 10:49:44.308368       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:44.308866690Z E0611 10:49:44.308832       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:44.416141913Z E0611 10:49:44.416009       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:44.416179715Z I0611 10:49:44.416144       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:44.718864705Z I0611 10:49:44.718734       1 request.go:697] Waited for 1.196994832s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:44.945970628Z E0611 10:49:44.945916       1 degraded_webhook.go:68] default.machine.machine.openshift.io: dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:49:44.949246678Z W0611 10:49:44.949186       1 degraded_webhook.go:147] failed to connect to webhook "default.machineset.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:49:45.098129711Z E0611 10:49:45.098060       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:45.098129711Z E0611 10:49:45.098121       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:45.098171613Z E0611 10:49:45.098146       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:45.098477927Z E0611 10:49:45.098437       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:45.742977004Z I0611 10:49:45.742867       1 request.go:697] Waited for 2.737185515s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:49:45.953050832Z W0611 10:49:45.952926       1 degraded_webhook.go:147] failed to connect to webhook "default.machineset.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:49:46.943266906Z I0611 10:49:46.943197       1 request.go:697] Waited for 3.539783467s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:49:46.977034576Z E0611 10:49:46.976976       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:46.977099679Z I0611 10:49:46.977058       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:47.463789824Z E0611 10:49:47.462961       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:47.463789824Z E0611 10:49:47.463017       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:47.463789824Z E0611 10:49:47.463046       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:47.463789824Z E0611 10:49:47.463322       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:47.554048486Z I0611 10:49:47.553987       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:49:47.554836418Z E0611 10:49:47.554783       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:47.554935022Z I0611 10:49:47.554880       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:47.956719123Z E0611 10:49:47.956662       1 degraded_webhook.go:68] default.machineset.machine.openshift.io: dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:49:48.014590271Z W0611 10:49:48.014503       1 degraded_webhook.go:147] failed to connect to webhook "validation.machine.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:49:48.142913177Z I0611 10:49:48.142844       1 request.go:697] Waited for 3.183747844s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:49:48.546719760Z E0611 10:49:48.546654       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:48.747712014Z E0611 10:49:48.747642       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:48.891363443Z E0611 10:49:48.889571       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:48.891363443Z E0611 10:49:48.889621       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:48.891363443Z E0611 10:49:48.889650       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:48.891363443Z E0611 10:49:48.889967       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:49.017697268Z W0611 10:49:49.017631       1 degraded_webhook.go:147] failed to connect to webhook "validation.machine.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:49:49.342892562Z I0611 10:49:49.342841       1 request.go:697] Waited for 3.337739215s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:49:49.347646954Z E0611 10:49:49.347193       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:50.147005385Z E0611 10:49:50.146911       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:50.351529283Z E0611 10:49:50.351427       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:50.543345365Z I0611 10:49:50.543280       1 request.go:697] Waited for 3.143634241s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:49:50.548387570Z E0611 10:49:50.548214       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:50.754020413Z E0611 10:49:50.753951       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:50.754441030Z I0611 10:49:50.754374       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:50.754772843Z I0611 10:49:50.754693       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:49:50.809418660Z E0611 10:49:50.809364       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:50.809510864Z E0611 10:49:50.809492       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:50.809569266Z E0611 10:49:50.809554       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:50.809910380Z E0611 10:49:50.809877       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:51.020346718Z E0611 10:49:51.020281       1 degraded_webhook.go:68] validation.machine.machine.openshift.io: dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:49:51.022766616Z W0611 10:49:51.022711       1 degraded_webhook.go:147] failed to connect to webhook "validation.machineset.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:49:51.742659023Z I0611 10:49:51.742580       1 request.go:697] Waited for 3.19461681s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:49:52.026171425Z W0611 10:49:52.026099       1 degraded_webhook.go:147] failed to connect to webhook "validation.machineset.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:49:52.097600123Z E0611 10:49:52.097513       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:52.097669026Z I0611 10:49:52.097572       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:52.255239119Z I0611 10:49:52.252392       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:49:52.495559758Z E0611 10:49:52.495503       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:52.495771068Z E0611 10:49:52.495727       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:52.495771068Z E0611 10:49:52.495766       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:52.496243689Z E0611 10:49:52.496073       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:52.743227550Z I0611 10:49:52.743155       1 request.go:697] Waited for 3.141853101s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:49:53.246062573Z E0611 10:49:53.243936       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:53.246062573Z E0611 10:49:53.244974       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:53.246062573Z E0611 10:49:53.245027       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:53.246062573Z E0611 10:49:53.245494       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:53.943122697Z I0611 10:49:53.943035       1 request.go:697] Waited for 3.306595151s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:49:54.029760036Z E0611 10:49:54.029706       1 degraded_webhook.go:68] validation.machineset.machine.openshift.io: dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:49:54.041723452Z W0611 10:49:54.041670       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:49:54.154175206Z I0611 10:49:54.154097       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:49:54.154595824Z E0611 10:49:54.154539       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:54.154864336Z I0611 10:49:54.154800       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:54.348003772Z E0611 10:49:54.347929       1 base_controller.go:268] EncryptionPruneController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:54.548786238Z E0611 10:49:54.548693       1 base_controller.go:268] EncryptionKeyController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:54.943411271Z I0611 10:49:54.943356       1 request.go:697] Waited for 3.138510922s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:49:54.949273824Z E0611 10:49:54.949217       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,check-endpoints-kubeconfig,client-ca,control-plane-node-kubeconfig, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:49:54.950010755Z I0611 10:49:54.949940       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:49:54.950326669Z E0611 10:49:54.950254       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:49:54.954858365Z I0611 10:49:54.954802       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:49:54.954907867Z E0611 10:49:54.954865       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:49:54.976005277Z I0611 10:49:54.975943       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:49:54.976039279Z E0611 10:49:54.976009       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:49:55.017242757Z I0611 10:49:55.017178       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:49:55.017357562Z E0611 10:49:55.017329       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:49:55.044926252Z W0611 10:49:55.044872       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:49:55.098450962Z I0611 10:49:55.098357       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:49:55.098549567Z E0611 10:49:55.098513       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:49:55.259345007Z I0611 10:49:55.259246       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:49:55.259434611Z E0611 10:49:55.259400       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:49:55.339291157Z E0611 10:49:55.339230       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:55.339291157Z E0611 10:49:55.339272       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:55.339370261Z E0611 10:49:55.339290       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:55.339573369Z E0611 10:49:55.339543       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:55.580149253Z E0611 10:49:55.580078       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:49:55.580209456Z I0611 10:49:55.580134       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:49:55.830412655Z E0611 10:49:55.830351       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:55.830502759Z E0611 10:49:55.830485       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:55.830560861Z E0611 10:49:55.830546       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:55.833357582Z E0611 10:49:55.833179       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:55.945023602Z I0611 10:49:55.944946       1 request.go:697] Waited for 2.938174939s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:49:55.949925713Z E0611 10:49:55.949873       1 base_controller.go:266] "ResourceSyncController" controller failed to sync "", err: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:55.950183524Z I0611 10:49:55.950120       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveCloudProviderNamesChanges' CloudProvider config file changed to /etc/kubernetes/static-pod-resources/configmaps/cloud-config/cloud.conf
2024-06-11T10:49:55.957015619Z E0611 10:49:55.956951       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:55.957015619Z I0611 10:49:55.956999       1 core.go:358] ConfigMap "openshift-kube-apiserver/cloud-config" changes: {"data":{"cloud.conf":"{\n\t\"cloud\": \"AzurePublicCloud\",\n\t\"tenantId\": \"6047c7e9-b2ad-488d-a54e-dc3f6be6a7ee\",\n\t\"aadClientId\": \"\",\n\t\"aadClientSecret\": \"\",\n\t\"aadClientCertPath\": \"\",\n\t\"aadClientCertPassword\": \"\",\n\t\"useManagedIdentityExtension\": true,\n\t\"userAssignedIdentityID\": \"\",\n\t\"subscriptionId\": \"53b8f551-f0fc-4bea-8cba-6d1fefd54c8a\",\n\t\"resourceGroup\": \"ci-op-9xx71rvq-1e28e-w667k-rg\",\n\t\"location\": \"centralus\",\n\t\"vnetName\": \"ci-op-9xx71rvq-1e28e-w667k-vnet\",\n\t\"vnetResourceGroup\": \"ci-op-9xx71rvq-1e28e-w667k-rg\",\n\t\"subnetName\": \"ci-op-9xx71rvq-1e28e-w667k-worker-subnet\",\n\t\"securityGroupName\": \"ci-op-9xx71rvq-1e28e-w667k-nsg\",\n\t\"routeTableName\": \"ci-op-9xx71rvq-1e28e-w667k-node-routetable\",\n\t\"vmType\": \"standard\",\n\t\"loadBalancerSku\": \"standard\",\n\t\"cloudProviderBackoff\": true,\n\t\"useInstanceMetadata\": true,\n\t\"excludeMasterFromStandardLB\": false,\n\t\"cloudProviderBackoffDuration\": 6,\n\t\"putVMSSVMBatchSize\": 0,\n\t\"enableMigrateToIPBasedBackendPoolAPI\": false\n}\n","config":null},"metadata":{"creationTimestamp":"2024-06-11T10:48:23Z","managedFields":[{"apiVersion":"v1","fieldsType":"FieldsV1","fieldsV1":{"f:data":{".":{},"f:cloud.conf":{}}},"manager":"cluster-config-operator","operation":"Update","time":"2024-06-11T10:48:23Z"}],"resourceVersion":null,"uid":"bc689531-9115-4cef-8931-613b76732ca9"}}
2024-06-11T10:49:55.957127624Z I0611 10:49:55.957089       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:55.957178826Z E0611 10:49:55.957151       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:55.957220328Z I0611 10:49:55.957184       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:55.957263830Z I0611 10:49:55.957235       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/cloud-config -n openshift-kube-apiserver:
2024-06-11T10:49:55.957263830Z cause by changes in data.cloud.conf,data.config
2024-06-11T10:49:56.152269647Z I0611 10:49:56.152203       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 1: configmap "kube-apiserver-pod" not found
2024-06-11T10:49:56.221054315Z I0611 10:49:56.220955       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:49:56.221105718Z E0611 10:49:56.221046       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:49:56.547681213Z W0611 10:49:56.547590       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:56.547681213Z E0611 10:49:56.547650       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2024-06-11T10:49:57.142892203Z I0611 10:49:57.142832       1 request.go:697] Waited for 3.184755859s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:49:57.502720834Z I0611 10:49:57.502639       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:49:57.503009547Z E0611 10:49:57.502962       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:49:57.554026949Z I0611 10:49:57.553963       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:49:57.555511713Z E0611 10:49:57.555462       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:49:57.555660519Z E0611 10:49:57.555463       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:49:57.555660519Z I0611 10:49:57.555463       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:49:57.555660519Z I0611 10:49:57.555485       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:49:58.343039603Z I0611 10:49:58.342933       1 request.go:697] Waited for 2.795022737s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:49:58.548196858Z E0611 10:49:58.548130       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:58.914588972Z E0611 10:49:58.914532       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:58.914739379Z E0611 10:49:58.914703       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:58.914830783Z E0611 10:49:58.914811       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:58.915241301Z E0611 10:49:58.915203       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:59.543349111Z I0611 10:49:59.543230       1 request.go:697] Waited for 2.994408743s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:00.064798817Z I0611 10:50:00.064661       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:00.064990525Z E0611 10:50:00.064956       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:00.742835782Z I0611 10:50:00.742741       1 request.go:697] Waited for 2.983083754s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:00.755158914Z I0611 10:50:00.755072       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:00.755484728Z E0611 10:50:00.755433       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:50:00.759333694Z E0611 10:50:00.759268       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:00.759543403Z I0611 10:50:00.759481       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:50:00.760181531Z I0611 10:50:00.760135       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:00.837964088Z E0611 10:50:00.837583       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:00.837964088Z E0611 10:50:00.837636       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:00.837964088Z E0611 10:50:00.837665       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:00.838003990Z E0611 10:50:00.837981       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:00.947201103Z E0611 10:50:00.947109       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:01.347008159Z E0611 10:50:01.346920       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:01.942490038Z I0611 10:50:01.942422       1 request.go:697] Waited for 2.933940512s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:01.946878249Z E0611 10:50:01.946822       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:02.399437971Z E0611 10:50:02.399359       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:02.399586475Z E0611 10:50:02.399565       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:02.399651176Z E0611 10:50:02.399636       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:02.400099988Z E0611 10:50:02.400031       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:02.547776815Z E0611 10:50:02.547691       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:02.747798463Z E0611 10:50:02.747719       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:02.942596280Z I0611 10:50:02.942524       1 request.go:697] Waited for 2.782046932s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:03.147127642Z E0611 10:50:03.147050       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:03.348111815Z E0611 10:50:03.348027       1 base_controller.go:268] PodSecurityReadinessController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:03.554392821Z E0611 10:50:03.554293       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:50:03.555003637Z I0611 10:50:03.554952       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:50:03.555102739Z I0611 10:50:03.555052       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:03.556147065Z I0611 10:50:03.556098       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:03.556437473Z E0611 10:50:03.556381       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:03.943009830Z I0611 10:50:03.942913       1 request.go:697] Waited for 2.59476452s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:04.943245575Z I0611 10:50:04.943102       1 request.go:697] Waited for 2.542216164s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:05.943402818Z I0611 10:50:05.943186       1 request.go:697] Waited for 1.984068676s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:05.956146039Z E0611 10:50:05.956089       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:50:05.956146039Z I0611 10:50:05.956116       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:05.956464847Z I0611 10:50:05.956423       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:50:05.956639152Z I0611 10:50:05.956602       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:05.956860757Z E0611 10:50:05.956816       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:06.149029408Z W0611 10:50:06.148892       1 base_controller.go:232] Updating status of "WorkerLatencyProfile" failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:06.149029408Z E0611 10:50:06.148923       1 base_controller.go:268] WorkerLatencyProfile reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:06.749078030Z E0611 10:50:06.748891       1 base_controller.go:268] ResourceSyncController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:06.749620053Z I0611 10:50:06.749539       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ObserveStorageFailed' configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2024-06-11T10:50:06.749620053Z I0611 10:50:06.749589       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://localhost:2379
2024-06-11T10:50:06.950468769Z E0611 10:50:06.950389       1 base_controller.go:268] RevisionController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:07.142789410Z I0611 10:50:07.142718       1 request.go:697] Waited for 1.982610458s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:07.274431288Z I0611 10:50:07.273838       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:07.361549711Z W0611 10:50:07.361491       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:07.361549711Z E0611 10:50:07.361524       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2024-06-11T10:50:07.948443771Z E0611 10:50:07.948356       1 base_controller.go:268] webhookSupportabilityController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:07.958686320Z W0611 10:50:07.958626       1 degraded_webhook.go:147] failed to connect to webhook "default.machine.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:50:08.157800059Z E0611 10:50:08.157727       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:08.157800059Z E0611 10:50:08.157756       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:50:08.158047870Z I0611 10:50:08.157996       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:50:08.158117773Z I0611 10:50:08.158083       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:08.158224078Z I0611 10:50:08.158189       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:08.343514310Z I0611 10:50:08.343383       1 request.go:697] Waited for 1.741767848s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:08.349462571Z E0611 10:50:08.349414       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:08.962486277Z W0611 10:50:08.962397       1 degraded_webhook.go:147] failed to connect to webhook "default.machine.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:50:09.542766346Z I0611 10:50:09.542682       1 request.go:697] Waited for 1.941229702s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:09.686796168Z E0611 10:50:09.686732       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:09.686927274Z E0611 10:50:09.686908       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:09.686986476Z E0611 10:50:09.686973       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:09.687434796Z E0611 10:50:09.687390       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:10.172101076Z E0611 10:50:10.172039       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:50:10.172575707Z I0611 10:50:10.172512       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:10.172609209Z I0611 10:50:10.172529       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:50:10.173279754Z I0611 10:50:10.173221       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:10.173503369Z E0611 10:50:10.173462       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:10.305962856Z I0611 10:50:10.305883       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:10.306023760Z E0611 10:50:10.305994       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:10.542909674Z I0611 10:50:10.542815       1 request.go:697] Waited for 1.730118363s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:10.548809665Z E0611 10:50:10.548738       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:10.966250556Z E0611 10:50:10.966191       1 degraded_webhook.go:68] default.machine.machine.openshift.io: dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:50:10.968660816Z W0611 10:50:10.968587       1 degraded_webhook.go:147] failed to connect to webhook "default.machineset.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:50:11.148982878Z E0611 10:50:11.148909       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:11.349014547Z E0611 10:50:11.348951       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:11.543341038Z I0611 10:50:11.543267       1 request.go:697] Waited for 1.583590149s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:11.749718829Z E0611 10:50:11.749607       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:11.972035076Z W0611 10:50:11.971972       1 degraded_webhook.go:147] failed to connect to webhook "default.machineset.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:50:11.973850697Z I0611 10:50:11.973772       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveWebhookTokenAuthenticator' authentication-token webhook configuration status changed from false to true
2024-06-11T10:50:11.976257156Z E0611 10:50:11.976176       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:50:11.977401932Z I0611 10:50:11.977312       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:50:11.979152048Z E0611 10:50:11.979100       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:11.979721586Z I0611 10:50:11.979671       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:11.980529640Z I0611 10:50:11.980488       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:12.079011573Z I0611 10:50:12.078924       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:12.080694584Z E0611 10:50:12.080646       1 base_controller.go:268] TargetConfigController reconciliation failed: no observedConfig
2024-06-11T10:50:12.080891297Z I0611 10:50:12.080815       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMissing' no observedConfig
2024-06-11T10:50:12.081546141Z I0611 10:50:12.081489       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-06-11T10:50:12.081546141Z + 	"admission": map[string]any{
2024-06-11T10:50:12.081546141Z + 		"pluginConfig": map[string]any{
2024-06-11T10:50:12.081546141Z + 			"PodSecurity":                                       map[string]any{"configuration": map[string]any{...}},
2024-06-11T10:50:12.081546141Z + 			"network.openshift.io/ExternalIPRanger":             map[string]any{"configuration": map[string]any{...}},
2024-06-11T10:50:12.081546141Z + 			"network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{...}},
2024-06-11T10:50:12.081546141Z + 		},
2024-06-11T10:50:12.081546141Z + 	},
2024-06-11T10:50:12.081546141Z + 	"apiServerArguments": map[string]any{
2024-06-11T10:50:12.081546141Z + 		"api-audiences":                            []any{string("https://kubernetes.default.svc")},
2024-06-11T10:50:12.081546141Z + 		"authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)},
2024-06-11T10:50:12.081546141Z + 		"authentication-token-webhook-version":     []any{string("v1")},
2024-06-11T10:50:12.081546141Z + 		"cloud-config":                             []any{string("/etc/kubernetes/static-pod-resources/configmaps/cloud-config/clo"...)},
2024-06-11T10:50:12.081546141Z + 		"etcd-servers":                             []any{string("https://localhost:2379")},
2024-06-11T10:50:12.081546141Z + 		"feature-gates": []any{
2024-06-11T10:50:12.081546141Z + 			string("AdminNetworkPolicy=true"), string("AlibabaPlatform=true"),
2024-06-11T10:50:12.081546141Z + 			string("AutomatedEtcdBackup=false"), string("AzureWorkloadIdentity=true"),
2024-06-11T10:50:12.081546141Z + 			string("BareMetalLoadBalancer=true"), string("BuildCSIVolumes=true"),
2024-06-11T10:50:12.081546141Z + 			string("CSIDriverSharedResource=false"), string("ChunkSizeMiB=false"), ...,
2024-06-11T10:50:12.081546141Z + 		},
2024-06-11T10:50:12.081546141Z + 		"send-retry-after-while-not-ready-once": []any{string("false")},
2024-06-11T10:50:12.081546141Z + 		"service-account-issuer":                []any{string("https://kubernetes.default.svc")},
2024-06-11T10:50:12.081546141Z + 		"service-account-jwks-uri":              []any{string("https://api.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.c"...)},
2024-06-11T10:50:12.081546141Z + 	},
2024-06-11T10:50:12.081546141Z + 	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-06-11T10:50:12.081546141Z + 	"servicesSubnet":     string("172.30.0.0/16"),
2024-06-11T10:50:12.081546141Z + 	"servingInfo": map[string]any{
2024-06-11T10:50:12.081546141Z + 		"bindAddress": string("0.0.0.0:6443"),
2024-06-11T10:50:12.081546141Z + 		"bindNetwork": string("tcp4"),
2024-06-11T10:50:12.081546141Z + 		"cipherSuites": []any{
2024-06-11T10:50:12.081546141Z + 			string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"),
2024-06-11T10:50:12.081546141Z + 			string("TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"),
2024-06-11T10:50:12.081546141Z + 			string("TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384"),
2024-06-11T10:50:12.081546141Z + 			string("TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"),
2024-06-11T10:50:12.081546141Z + 			string("TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256"),
2024-06-11T10:50:12.081546141Z + 			string("TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256"),
2024-06-11T10:50:12.081546141Z + 		},
2024-06-11T10:50:12.081546141Z + 		"minTLSVersion": string("VersionTLS12"),
2024-06-11T10:50:12.081546141Z + 		"namedCertificates": []any{
2024-06-11T10:50:12.081546141Z + 			map[string]any{
2024-06-11T10:50:12.081546141Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2024-06-11T10:50:12.081546141Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2024-06-11T10:50:12.081546141Z + 			},
2024-06-11T10:50:12.081546141Z + 			map[string]any{
2024-06-11T10:50:12.081546141Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2024-06-11T10:50:12.081546141Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2024-06-11T10:50:12.081546141Z + 			},
2024-06-11T10:50:12.081546141Z + 			map[string]any{
2024-06-11T10:50:12.081546141Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2024-06-11T10:50:12.081546141Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2024-06-11T10:50:12.081546141Z + 			},
2024-06-11T10:50:12.081546141Z + 			map[string]any{
2024-06-11T10:50:12.081546141Z + 				"certFile": string("/etc/kubernetes/static-pod-certs"...),
2024-06-11T10:50:12.081546141Z + 				"keyFile":  string("/etc/kubernetes/static-pod-certs"...),
2024-06-11T10:50:12.081546141Z + 			},
2024-06-11T10:50:12.081546141Z + 			map[string]any{
2024-06-11T10:50:12.081546141Z + 				"certFile": string("/etc/kubernetes/static-pod-resou"...),
2024-06-11T10:50:12.081546141Z + 				"keyFile":  string("/etc/kubernetes/static-pod-resou"...),
2024-06-11T10:50:12.081546141Z + 			},
2024-06-11T10:50:12.081546141Z + 		},
2024-06-11T10:50:12.081546141Z + 	},
2024-06-11T10:50:12.081546141Z   }
2024-06-11T10:50:12.742407980Z I0611 10:50:12.742313       1 request.go:697] Waited for 1.592201821s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:13.559669694Z I0611 10:50:13.559602       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:13.560560453Z I0611 10:50:13.560500       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:13.560658059Z E0611 10:50:13.560594       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:13.579285746Z I0611 10:50:13.579209       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:13.743116770Z I0611 10:50:13.743049       1 request.go:697] Waited for 1.582091659s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:13.952093884Z I0611 10:50:13.952016       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 1: configmap "kube-apiserver-pod" not found
2024-06-11T10:50:13.974725882Z E0611 10:50:13.974659       1 degraded_webhook.go:68] default.machineset.machine.openshift.io: dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:50:13.977255294Z W0611 10:50:13.977200       1 degraded_webhook.go:147] failed to connect to webhook "validation.machine.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:50:14.183701897Z I0611 10:50:14.183629       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:14.350385847Z W0611 10:50:14.350285       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:14.350385847Z E0611 10:50:14.350351       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2024-06-11T10:50:14.779994490Z I0611 10:50:14.779915       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/client-ca -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:14.944927862Z I0611 10:50:14.944858       1 request.go:697] Waited for 1.535658749s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:14.951212639Z E0611 10:50:14.951152       1 base_controller.go:268] WorkerLatencyProfile reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:14.980520932Z W0611 10:50:14.980441       1 degraded_webhook.go:147] failed to connect to webhook "validation.machine.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:50:15.185771482Z I0611 10:50:15.185702       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-client-ca -n openshift-config-managed because it was missing
2024-06-11T10:50:15.360000064Z I0611 10:50:15.359905       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:15.360819501Z I0611 10:50:15.360764       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:15.779861078Z I0611 10:50:15.779782       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:16.143058993Z I0611 10:50:16.142994       1 request.go:697] Waited for 1.791401889s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:16.981907981Z I0611 10:50:16.981839       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca -n openshift-config-managed because it was missing
2024-06-11T10:50:16.988616476Z E0611 10:50:16.988523       1 degraded_webhook.go:68] validation.machine.machine.openshift.io: dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:50:16.992844563Z W0611 10:50:16.992781       1 degraded_webhook.go:147] failed to connect to webhook "validation.machineset.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:50:17.143335599Z I0611 10:50:17.143275       1 request.go:697] Waited for 1.781803567s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:17.158345761Z E0611 10:50:17.158265       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:17.161095582Z E0611 10:50:17.161018       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:17.161765711Z I0611 10:50:17.161693       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:17.162220331Z I0611 10:50:17.162171       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:17.163131272Z I0611 10:50:17.163019       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"InstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:17.175312709Z I0611 10:50:17.175237       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [configmaps: client-ca, secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]" to "InstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]"
2024-06-11T10:50:17.950727379Z E0611 10:50:17.950661       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:17.996173262Z W0611 10:50:17.996110       1 degraded_webhook.go:147] failed to connect to webhook "validation.machineset.machine.openshift.io" via service "machine-api-operator-webhook.openshift-machine-api.svc:443": dial tcp 172.30.215.208:443: connect: connection refused
2024-06-11T10:50:18.148698653Z E0611 10:50:18.148633       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:18.342602342Z I0611 10:50:18.342531       1 request.go:697] Waited for 1.581031077s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:18.550909490Z E0611 10:50:18.550839       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:18.957963849Z I0611 10:50:18.957903       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:18.960233954Z I0611 10:50:18.960039       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"InstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:18.960526467Z I0611 10:50:18.960473       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:18.960676474Z E0611 10:50:18.960278       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:18.975642160Z I0611 10:50:18.975581       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: EvaluationConditionsDetected changed from Unknown to False ("All is well")
2024-06-11T10:50:19.342650983Z I0611 10:50:19.342588       1 request.go:697] Waited for 1.537159962s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:20.092387950Z W0611 10:50:20.092286       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:50:20.343250950Z I0611 10:50:20.343191       1 request.go:697] Waited for 1.325070141s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:20.363946499Z E0611 10:50:20.363867       1 base_controller.go:268] ConfigObserver reconciliation failed: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found
2024-06-11T10:50:20.367784274Z I0611 10:50:20.367725       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"InstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:20.369594857Z I0611 10:50:20.368234       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:20.369594857Z E0611 10:50:20.368441       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:20.369626859Z I0611 10:50:20.368836       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:20.369646860Z I0611 10:50:20.369192       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://10.0.0.8:2379,https://localhost:2379
2024-06-11T10:50:20.370384594Z I0611 10:50:20.370291       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-06-11T10:50:20.370384594Z   	"admission": map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("privileged"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-06-11T10:50:20.370384594Z   	"apiServerArguments": map[string]any{
2024-06-11T10:50:20.370384594Z   		... // 2 identical entries
2024-06-11T10:50:20.370384594Z   		"authentication-token-webhook-version": []any{string("v1")},
2024-06-11T10:50:20.370384594Z   		"cloud-config":                         []any{string("/etc/kubernetes/static-pod-resources/configmaps/cloud-config/clo"...)},
2024-06-11T10:50:20.370384594Z   		"etcd-servers": []any{
2024-06-11T10:50:20.370384594Z + 			string("https://10.0.0.8:2379"),
2024-06-11T10:50:20.370384594Z   			string("https://localhost:2379"),
2024-06-11T10:50:20.370384594Z   		},
2024-06-11T10:50:20.370384594Z   		"feature-gates":                         []any{string("AdminNetworkPolicy=true"), string("AlibabaPlatform=true"), string("AutomatedEtcdBackup=false"), string("AzureWorkloadIdentity=true"), ...},
2024-06-11T10:50:20.370384594Z   		"send-retry-after-while-not-ready-once": []any{string("false")},
2024-06-11T10:50:20.370384594Z   		... // 2 identical entries
2024-06-11T10:50:20.370384594Z   	},
2024-06-11T10:50:20.370384594Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-06-11T10:50:20.370384594Z   	"servicesSubnet":     string("172.30.0.0/16"),
2024-06-11T10:50:20.370384594Z   	"servingInfo":        map[string]any{"bindAddress": string("0.0.0.0:6443"), "bindNetwork": string("tcp4"), "cipherSuites": []any{string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), string("TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384"), string("TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"), ...}, "minTLSVersion": string("VersionTLS12"), ...},
2024-06-11T10:50:20.370384594Z   }
2024-06-11T10:50:20.394927219Z I0611 10:50:20.394766       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "InstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]" to "InstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]\nNodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found"
2024-06-11T10:50:20.549048483Z E0611 10:50:20.548992       1 base_controller.go:268] RevisionController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:20.550040329Z I0611 10:50:20.549951       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 1 triggered by "configmap \"kube-apiserver-pod-0\" not found"
2024-06-11T10:50:21.096139562Z W0611 10:50:21.096061       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:50:21.149402403Z W0611 10:50:21.149340       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:21.149402403Z E0611 10:50:21.149383       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": configmap "kube-apiserver-server-ca" not found
2024-06-11T10:50:21.543371862Z I0611 10:50:21.543310       1 request.go:697] Waited for 1.381637033s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:21.751006980Z E0611 10:50:21.750939       1 base_controller.go:268] WorkerLatencyProfile reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:21.961481328Z I0611 10:50:21.961413       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:21.963211007Z E0611 10:50:21.962899       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:21.963440218Z I0611 10:50:21.963387       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:21.984227971Z I0611 10:50:21.984162       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:22.124776413Z I0611 10:50:22.124716       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:22Z","message":"ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]","reason":"ConfigObservation_Error::GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:22.140966656Z I0611 10:50:22.140892       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded changed from False to True ("ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]")
2024-06-11T10:50:22.248907604Z I0611 10:50:22.248829       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:22.742986952Z I0611 10:50:22.742924       1 request.go:697] Waited for 1.137848058s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:22.781818132Z I0611 10:50:22.781747       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/node-kubeconfigs -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:23.179736172Z I0611 10:50:23.179671       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:23.361234492Z I0611 10:50:23.361173       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:23.363161680Z I0611 10:50:23.363099       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:23.549685330Z E0611 10:50:23.549609       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:23.771431695Z I0611 10:50:23.771371       1 request.go:697] Waited for 1.197109375s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:23.938748464Z E0611 10:50:23.938697       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:23.939348392Z E0611 10:50:23.939284       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:23.939348392Z E0611 10:50:23.939343       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:23.939890317Z E0611 10:50:23.939834       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:23.969385769Z E0611 10:50:23.969328       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:23.981113206Z I0611 10:50:23.981033       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:24.350230926Z E0611 10:50:24.350163       1 base_controller.go:268] CertRotationController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:24.771804451Z I0611 10:50:24.771741       1 request.go:697] Waited for 1.192460961s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:50:24.957640270Z E0611 10:50:24.957572       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:24.958370203Z I0611 10:50:24.958287       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:24.960023779Z I0611 10:50:24.959944       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:22Z","message":"ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]","reason":"ConfigObservation_Error::GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:24.960332293Z I0611 10:50:24.960235       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:24.960698410Z E0611 10:50:24.960620       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:24.986086174Z I0611 10:50:24.984219       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [secrets: node-kubeconfigs, configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]" to "ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]"
2024-06-11T10:50:25.189323490Z I0611 10:50:25.189225       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cloud-config-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:25.380817968Z I0611 10:50:25.380724       1 core.go:358] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"privileged\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"cloud-config\":[\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/cloud.conf\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PersistentVolumeLabel\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.8:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AutomatedEtcdBackup=false\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"CSIDriverSharedResource=false\",\"ChunkSizeMiB=false\",\"CloudDualStackNodeIPs=true\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallAWS=true\",\"ClusterAPIInstallAzure=false\",\"ClusterAPIInstallGCP=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterAPIInstallNutanix=true\",\"ClusterAPIInstallOpenStack=true\",\"ClusterAPIInstallPowerVS=false\",\"ClusterAPIInstallVSphere=true\",\"DNSNameResolver=false\",\"DisableKubeletCloudCredentialProviders=true\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalCloudProvider=true\",\"ExternalCloudProviderAzure=true\",\"ExternalCloudProviderExternal=true\",\"ExternalCloudProviderGCP=true\",\"ExternalOIDC=false\",\"ExternalRouteCertificate=false\",\"GCPClusterHostedDNS=false\",\"GCPLabelsTags=false\",\"GatewayAPI=false\",\"HardwareSpeed=true\",\"ImagePolicy=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InstallAlternateInfrastructureAWS=false\",\"KMSv1=true\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImages=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MetricsServer=true\",\"MixedCPUsAllocation=false\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NewOLM=false\",\"NodeDisruptionPolicy=false\",\"NodeSwap=false\",\"OnClusterBuild=false\",\"OpenShiftPodSecurityAdmission=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"PrivateHostedZoneAWS=true\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"ServiceAccountTokenNodeBindingValidation=false\",\"ServiceAccountTokenPodNodeInfo=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereMultiVCenters=false\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://kubernetes.default.svc\"],\"service-account-jwks-uri\":[\"https://api.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/openid/v1/jwks\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:50:25.381087180Z I0611 10:50:25.381026       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-06-11T10:50:25.381087180Z cause by changes in data.config.yaml
2024-06-11T10:50:25.943522900Z I0611 10:50:25.943373       1 request.go:697] Waited for 1.591622097s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:26.971855562Z I0611 10:50:26.971786       1 request.go:697] Waited for 1.195554566s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:50:27.349898425Z I0611 10:50:27.349832       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:27.364338911Z I0611 10:50:27.364250       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:27.367111043Z E0611 10:50:27.367058       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:27.367402957Z I0611 10:50:27.367342       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:27.659574939Z E0611 10:50:27.659496       1 base_controller.go:268] WorkerLatencyProfile reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:27.664600278Z I0611 10:50:27.664499       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:27.795205384Z I0611 10:50:27.795122       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:27.974509003Z I0611 10:50:27.974450       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:27.975377245Z E0611 10:50:27.975330       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:27.977805160Z I0611 10:50:27.977026       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:28.350037347Z E0611 10:50:28.349971       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:28.549797039Z E0611 10:50:28.549732       1 base_controller.go:268] ConfigObserver reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:28.578719013Z I0611 10:50:28.578637       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:28.742478094Z I0611 10:50:28.742409       1 request.go:697] Waited for 1.080721751s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status
2024-06-11T10:50:28.949869548Z E0611 10:50:28.949777       1 base_controller.go:268] webhookSupportabilityController reconciliation failed: Operation cannot be fulfilled on kubeapiservers.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:50:29.052731536Z W0611 10:50:29.052656       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:50:29.361661515Z I0611 10:50:29.361593       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:29.363873820Z E0611 10:50:29.363809       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:29.363873820Z I0611 10:50:29.363800       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:29.772088916Z I0611 10:50:29.772018       1 request.go:697] Waited for 1.396637361s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-06-11T10:50:29.979088552Z I0611 10:50:29.978991       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:30.058018902Z W0611 10:50:30.057951       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:50:30.178717737Z I0611 10:50:30.178652       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:30.179155158Z I0611 10:50:30.179091       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:30.179567478Z E0611 10:50:30.179523       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:30.180006899Z I0611 10:50:30.179975       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:22Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:30.195755647Z I0611 10:50:30.195694       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "ConfigObservationDegraded: configmaps openshift-etcd/etcd-endpoints: no etcd endpoint addresses found\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]" to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]"
2024-06-11T10:50:30.761963851Z I0611 10:50:30.761902       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:30.766364160Z E0611 10:50:30.766288       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:30.766765279Z I0611 10:50:30.766703       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:30.962864396Z I0611 10:50:30.962801       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:30.963793741Z E0611 10:50:30.963738       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:30.964147857Z I0611 10:50:30.964089       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:30.971748519Z I0611 10:50:30.971708       1 request.go:697] Waited for 1.196693562s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-06-11T10:50:31.179021167Z I0611 10:50:31.178929       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:31.924442986Z I0611 10:50:31.924360       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:31.972214056Z I0611 10:50:31.972161       1 request.go:697] Waited for 1.212694521s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:50:32.089430326Z E0611 10:50:32.089363       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]
2024-06-11T10:50:32.089590233Z I0611 10:50:32.089550       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0
2024-06-11T10:50:32.090279966Z I0611 10:50:32.090219       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:32.179235293Z W0611 10:50:32.179168       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:50:32.580885277Z I0611 10:50:32.580809       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:32.875618982Z E0611 10:50:32.875559       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:32.875741188Z E0611 10:50:32.875726       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:32.875812691Z E0611 10:50:32.875799       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:32.876490823Z E0611 10:50:32.876462       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:33.172282278Z I0611 10:50:33.172223       1 request.go:697] Waited for 1.3932272s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T10:50:33.182084744Z W0611 10:50:33.182008       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:50:34.371710061Z I0611 10:50:34.371621       1 request.go:697] Waited for 1.387740631s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:34.505733815Z I0611 10:50:34.505679       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:34.511155247Z I0611 10:50:34.511096       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:35.383483200Z I0611 10:50:35.383405       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:35.571766584Z I0611 10:50:35.571687       1 request.go:697] Waited for 1.39588253s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-06-11T10:50:36.180813633Z I0611 10:50:36.180738       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:37.186194698Z I0611 10:50:37.186108       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:37.537924299Z I0611 10:50:37.537853       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:37.540666517Z I0611 10:50:37.540598       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:38.181264820Z I0611 10:50:38.181188       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 1 triggered by "configmap \"kube-apiserver-pod-0\" not found"
2024-06-11T10:50:38.196590578Z I0611 10:50:38.196455       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 1 created because configmap "kube-apiserver-pod-0" not found
2024-06-11T10:50:38.200417742Z I0611 10:50:38.200364       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:38.204422214Z I0611 10:50:38.200463       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:38.225638525Z I0611 10:50:38.225576       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 2 triggered by "required configmap/config has changed"
2024-06-11T10:50:39.372171850Z I0611 10:50:39.372062       1 request.go:697] Waited for 1.171841512s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:40.069456088Z E0611 10:50:40.069379       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:40.069456088Z E0611 10:50:40.069428       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:40.069511190Z E0611 10:50:40.069453       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:40.070098615Z E0611 10:50:40.070052       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:40.572253075Z I0611 10:50:40.572147       1 request.go:697] Waited for 1.588278991s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-06-11T10:50:41.385239979Z I0611 10:50:41.385156       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:41.475980275Z W0611 10:50:41.475918       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:50:41.772087888Z I0611 10:50:41.772029       1 request.go:697] Waited for 1.537841826s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-06-11T10:50:42.479658688Z W0611 10:50:42.479580       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:50:42.971964476Z I0611 10:50:42.971901       1 request.go:697] Waited for 1.587025409s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-06-11T10:50:42.984464034Z I0611 10:50:42.984366       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:43.590506602Z I0611 10:50:43.590450       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:43.618350546Z I0611 10:50:43.618279       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:43.974836068Z I0611 10:50:43.974778       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-0 static pod not found and needs new revision 1
2024-06-11T10:50:43.974836068Z I0611 10:50:43.974825       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:50:43.974836068Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:50:43.974836068Z  CurrentRevision: (int32) 0,
2024-06-11T10:50:43.974836068Z  TargetRevision: (int32) 1,
2024-06-11T10:50:43.974836068Z  LastFailedRevision: (int32) 0,
2024-06-11T10:50:43.974836068Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:50:43.974836068Z  LastFailedReason: (string) "",
2024-06-11T10:50:43.974836068Z  LastFailedCount: (int) 0,
2024-06-11T10:50:43.974836068Z  LastFallbackCount: (int) 0,
2024-06-11T10:50:43.974836068Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:50:43.974836068Z }
2024-06-11T10:50:43.991837927Z I0611 10:50:43.991782       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:43.995930410Z I0611 10:50:43.995861       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 0 to 1 because node ci-op-9xx71rvq-1e28e-w667k-master-0 static pod not found
2024-06-11T10:50:44.002034283Z I0611 10:50:44.001950       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:22Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: bound-sa-token-signing-certs-0,config-0,etcd-serving-ca-0,kube-apiserver-audit-policies-0,kube-apiserver-cert-syncer-kubeconfig-0,kube-apiserver-pod-0,kubelet-serving-ca-0,sa-token-signing-certs-0, secrets: etcd-client-0,localhost-recovery-client-token-0,localhost-recovery-serving-certkey-0]","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:44.002417800Z I0611 10:50:44.002369       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:44.020103090Z I0611 10:50:44.019136       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing changed from False to True ("NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1"),Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1"
2024-06-11T10:50:44.023832957Z I0611 10:50:44.023780       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:44.024013765Z I0611 10:50:44.023986       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:44Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:44.024813300Z I0611 10:50:44.024771       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:44.037926586Z I0611 10:50:44.037863       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded changed from True to False ("NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]")
2024-06-11T10:50:44.171952572Z I0611 10:50:44.171885       1 request.go:697] Waited for 1.639293417s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T10:50:44.568961304Z W0611 10:50:44.568887       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:50:44.578433027Z I0611 10:50:44.578335       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:45.172240249Z I0611 10:50:45.172184       1 request.go:697] Waited for 1.588426346s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-06-11T10:50:45.572410822Z W0611 10:50:45.572332       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:50:46.177869464Z I0611 10:50:46.177803       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cloud-config-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:46.372742768Z I0611 10:50:46.372672       1 request.go:697] Waited for 1.570216232s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:50:47.367482597Z E0611 10:50:47.367420       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:47.367623904Z E0611 10:50:47.367580       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:47.367623904Z E0611 10:50:47.367617       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:47.368330735Z E0611 10:50:47.368277       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:47.572249343Z I0611 10:50:47.572178       1 request.go:697] Waited for 1.597402846s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:47.777874527Z I0611 10:50:47.777793       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:48.771658813Z I0611 10:50:48.771591       1 request.go:697] Waited for 1.396813587s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:49.181981840Z I0611 10:50:49.181908       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:49.592988697Z I0611 10:50:49.592927       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:49.596232542Z I0611 10:50:49.596165       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:49.772040594Z I0611 10:50:49.771980       1 request.go:697] Waited for 1.396671781s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-06-11T10:50:50.585981694Z I0611 10:50:50.585903       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:50.682413142Z W0611 10:50:50.682332       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:50:50.971403472Z I0611 10:50:50.971332       1 request.go:697] Waited for 1.312423628s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-06-11T10:50:51.582286183Z I0611 10:50:51.582196       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-1-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:51.583805850Z E0611 10:50:51.583747       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:51.583805850Z E0611 10:50:51.583797       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:51.583845152Z E0611 10:50:51.583828       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:51.584318873Z E0611 10:50:51.584279       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:51.594216809Z E0611 10:50:51.594167       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:51.594216809Z E0611 10:50:51.594206       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:51.594259411Z E0611 10:50:51.594229       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:51.594918540Z E0611 10:50:51.594824       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:51.605836921Z E0611 10:50:51.605783       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:51.605836921Z E0611 10:50:51.605829       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:51.605885623Z E0611 10:50:51.605857       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:51.606507550Z E0611 10:50:51.606465       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:51.685589934Z W0611 10:50:51.685523       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:50:51.972087955Z I0611 10:50:51.972025       1 request.go:697] Waited for 1.386144163s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-06-11T10:50:51.980601630Z I0611 10:50:51.980529       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:52.247882704Z I0611 10:50:52.247797       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:50:52.278283743Z E0611 10:50:52.278214       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:52.278283743Z E0611 10:50:52.278272       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:52.278364947Z E0611 10:50:52.278321       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:52.278964573Z E0611 10:50:52.278915       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:52.389347836Z E0611 10:50:52.386329       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:52.389347836Z E0611 10:50:52.386374       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:52.389347836Z E0611 10:50:52.386399       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:52.389347836Z E0611 10:50:52.387616       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:52.976126785Z I0611 10:50:52.976067       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 1, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:50:53.171491991Z I0611 10:50:53.171414       1 request.go:697] Waited for 1.589209208s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T10:50:53.622617264Z E0611 10:50:53.622539       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:53.622617264Z E0611 10:50:53.622587       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:53.622617264Z E0611 10:50:53.622611       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:53.623323395Z E0611 10:50:53.623250       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:53.778265021Z I0611 10:50:53.778197       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:54.172040168Z I0611 10:50:54.171959       1 request.go:697] Waited for 1.743541307s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-06-11T10:50:54.358409978Z E0611 10:50:54.358353       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:54.358521483Z E0611 10:50:54.358502       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:54.358580985Z E0611 10:50:54.358567       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:54.359267615Z E0611 10:50:54.359226       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:55.372293042Z I0611 10:50:55.372226       1 request.go:697] Waited for 1.766323211s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:55.577817795Z I0611 10:50:55.577729       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:56.571486269Z I0611 10:50:56.571387       1 request.go:697] Waited for 1.795857311s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:57.382343289Z I0611 10:50:57.382212       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:50:57.391457590Z E0611 10:50:57.388080       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:57.391457590Z E0611 10:50:57.388133       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:57.391457590Z E0611 10:50:57.388163       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:57.391457590Z E0611 10:50:57.388801       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:57.571663529Z I0611 10:50:57.571592       1 request.go:697] Waited for 1.78946013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:50:58.772214606Z I0611 10:50:58.772132       1 request.go:697] Waited for 1.389972422s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-2
2024-06-11T10:51:01.444848295Z I0611 10:51:01.444785       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:51:01.508685529Z I0611 10:51:01.508616       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:51:01.509165150Z I0611 10:51:01.509076       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 1, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:01.656959881Z I0611 10:51:01.656886       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:51:01.741004681Z I0611 10:51:01.740942       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:51:01.745046054Z I0611 10:51:01.744987       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:51:01.782518960Z I0611 10:51:01.782413       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "required configmap/config has changed"
2024-06-11T10:51:01.805415141Z I0611 10:51:01.799754       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 2 created because required configmap/config has changed
2024-06-11T10:51:01.805415141Z W0611 10:51:01.801142       1 staticpod.go:38] revision 2 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T10:51:01.805415141Z E0611 10:51:01.801175       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 2
2024-06-11T10:51:01.805415141Z I0611 10:51:01.803614       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:51:01.807294421Z I0611 10:51:01.805911       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:02.972341429Z I0611 10:51:02.972247       1 request.go:697] Waited for 1.164072365s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T10:51:03.820250551Z E0611 10:51:03.820182       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:03.820250551Z E0611 10:51:03.820234       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:03.820354155Z E0611 10:51:03.820260       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:03.820935380Z E0611 10:51:03.820888       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:04.171436195Z I0611 10:51:04.171378       1 request.go:697] Waited for 1.392388446s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:51:05.774253655Z I0611 10:51:05.774186       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 1, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:05.792823950Z I0611 10:51:05.792771       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:05.793438177Z I0611 10:51:05.793392       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:44Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:51:05.793787392Z I0611 10:51:05.793408       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:51:05.805905811Z I0611 10:51:05.804028       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2"
2024-06-11T10:51:06.972275898Z I0611 10:51:06.972210       1 request.go:697] Waited for 1.17906223s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:51:08.475635620Z E0611 10:51:08.475579       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:08.475829929Z E0611 10:51:08.475758       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:08.475829929Z E0611 10:51:08.475794       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:08.476513159Z E0611 10:51:08.476410       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:08.483163954Z E0611 10:51:08.480432       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:08.483163954Z E0611 10:51:08.480473       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:08.483163954Z E0611 10:51:08.480498       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:08.483163954Z E0611 10:51:08.481044       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:09.613313737Z E0611 10:51:09.612461       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:09.613313737Z E0611 10:51:09.612515       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:09.613313737Z E0611 10:51:09.612544       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:09.613313737Z E0611 10:51:09.613146       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:09.782184321Z I0611 10:51:09.782120       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:51:09.782184321Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:51:09.782184321Z  CurrentRevision: (int32) 0,
2024-06-11T10:51:09.782184321Z  TargetRevision: (int32) 2,
2024-06-11T10:51:09.782184321Z  LastFailedRevision: (int32) 0,
2024-06-11T10:51:09.782184321Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:51:09.782184321Z  LastFailedReason: (string) "",
2024-06-11T10:51:09.782184321Z  LastFailedCount: (int) 0,
2024-06-11T10:51:09.782184321Z  LastFallbackCount: (int) 0,
2024-06-11T10:51:09.782184321Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:51:09.782184321Z }
2024-06-11T10:51:09.782184321Z  because new revision pending
2024-06-11T10:51:09.782835350Z E0611 10:51:09.782776       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:09.782835350Z E0611 10:51:09.782818       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:09.782888452Z E0611 10:51:09.782847       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:09.783354873Z E0611 10:51:09.783292       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:09.805294845Z I0611 10:51:09.805247       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:09.807805356Z I0611 10:51:09.807748       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:51:10.840042401Z E0611 10:51:10.839962       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:10.840042401Z E0611 10:51:10.840009       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:10.840042401Z E0611 10:51:10.840033       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:10.840573124Z E0611 10:51:10.840537       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:10.972015749Z I0611 10:51:10.971941       1 request.go:697] Waited for 1.16708402s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-06-11T10:51:11.495076529Z I0611 10:51:11.495017       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:51:11.508754835Z I0611 10:51:11.507084       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded changed from False to True ("GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]")
2024-06-11T10:51:12.171831720Z I0611 10:51:12.171751       1 request.go:697] Waited for 1.396947407s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:14.575199168Z I0611 10:51:14.575131       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:51:14.575199168Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:51:14.575199168Z  CurrentRevision: (int32) 0,
2024-06-11T10:51:14.575199168Z  TargetRevision: (int32) 2,
2024-06-11T10:51:14.575199168Z  LastFailedRevision: (int32) 0,
2024-06-11T10:51:14.575199168Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:51:14.575199168Z  LastFailedReason: (string) "",
2024-06-11T10:51:14.575199168Z  LastFailedCount: (int) 0,
2024-06-11T10:51:14.575199168Z  LastFallbackCount: (int) 0,
2024-06-11T10:51:14.575199168Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:51:14.575199168Z }
2024-06-11T10:51:14.575199168Z  because new revision pending
2024-06-11T10:51:15.754677883Z E0611 10:51:15.754619       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:15.755947641Z E0611 10:51:15.755898       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:15.755947641Z E0611 10:51:15.755937       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:15.756640473Z E0611 10:51:15.756583       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:15.761659501Z E0611 10:51:15.760706       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:15.761659501Z E0611 10:51:15.760759       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:15.761659501Z E0611 10:51:15.760786       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:15.761659501Z E0611 10:51:15.761421       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:15.764666038Z E0611 10:51:15.764571       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:15.764666038Z E0611 10:51:15.764620       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:15.764666038Z E0611 10:51:15.764647       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:15.765723686Z E0611 10:51:15.765321       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:16.783137521Z I0611 10:51:16.783068       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-2-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-apiserver because it was missing
2024-06-11T10:51:16.783137521Z E0611 10:51:16.783123       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:16.783181223Z E0611 10:51:16.783164       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:16.783218024Z E0611 10:51:16.783193       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:16.783852353Z E0611 10:51:16.783821       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:16.792761259Z E0611 10:51:16.792707       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:16.792889265Z E0611 10:51:16.792870       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:16.792952168Z E0611 10:51:16.792937       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:16.793643799Z E0611 10:51:16.793591       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:16.805997462Z E0611 10:51:16.805947       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:16.806106267Z E0611 10:51:16.806089       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:16.806169970Z E0611 10:51:16.806156       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:16.806927104Z E0611 10:51:16.806879       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:17.746167678Z E0611 10:51:17.746096       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:17.746167678Z E0611 10:51:17.746155       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:17.746240982Z E0611 10:51:17.746185       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:17.746880711Z E0611 10:51:17.746835       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:17.774524170Z I0611 10:51:17.774468       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:51:18.727721080Z E0611 10:51:18.727638       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:18.727721080Z E0611 10:51:18.727693       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:18.727721080Z E0611 10:51:18.727715       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:18.728200801Z E0611 10:51:18.728168       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:21.375052743Z I0611 10:51:21.374992       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:22.375206337Z I0611 10:51:22.375153       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:23.822869591Z E0611 10:51:23.822806       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:23.822869591Z E0611 10:51:23.822854       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:23.822927802Z E0611 10:51:23.822883       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:23.823558425Z E0611 10:51:23.823508       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:24.575430927Z I0611 10:51:24.575365       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:24.761859227Z E0611 10:51:24.761801       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:24.762021958Z E0611 10:51:24.761959       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:24.762021958Z E0611 10:51:24.761997       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:24.762676986Z E0611 10:51:24.762637       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:24.775014495Z E0611 10:51:24.774971       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:24.775957479Z E0611 10:51:24.775920       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:24.775997987Z E0611 10:51:24.775960       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:24.776353257Z E0611 10:51:24.776320       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:24.783847620Z E0611 10:51:24.783806       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:24.783901730Z E0611 10:51:24.783849       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:24.783901730Z E0611 10:51:24.783877       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:24.784533754Z E0611 10:51:24.784484       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:24.985258745Z W0611 10:51:24.985194       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:51:25.988689563Z W0611 10:51:25.988607       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:51:27.574910369Z I0611 10:51:27.574850       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:28.774765595Z I0611 10:51:28.774696       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:34.366513365Z E0611 10:51:34.366453       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:34.366690473Z E0611 10:51:34.366622       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:34.366690473Z E0611 10:51:34.366659       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:34.367422605Z E0611 10:51:34.367348       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:41.486734043Z E0611 10:51:41.486659       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:41.486734043Z E0611 10:51:41.486709       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:41.486802546Z E0611 10:51:41.486734       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:41.487384374Z E0611 10:51:41.487342       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:55.264629738Z E0611 10:51:55.264551       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:55.265425809Z E0611 10:51:55.265390       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:55.265518329Z E0611 10:51:55.265500       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:55.266209478Z E0611 10:51:55.266174       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:57.475493538Z I0611 10:51:57.475405       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://10.0.0.6:2379,https://10.0.0.8:2379,https://localhost:2379
2024-06-11T10:51:57.477544880Z I0611 10:51:57.477467       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-06-11T10:51:57.477544880Z   	"admission": map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("privileged"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-06-11T10:51:57.477544880Z   	"apiServerArguments": map[string]any{
2024-06-11T10:51:57.477544880Z   		... // 2 identical entries
2024-06-11T10:51:57.477544880Z   		"authentication-token-webhook-version": []any{string("v1")},
2024-06-11T10:51:57.477544880Z   		"cloud-config":                         []any{string("/etc/kubernetes/static-pod-resources/configmaps/cloud-config/clo"...)},
2024-06-11T10:51:57.477544880Z   		"etcd-servers": []any{
2024-06-11T10:51:57.477544880Z + 			string("https://10.0.0.6:2379"),
2024-06-11T10:51:57.477544880Z   			string("https://10.0.0.8:2379"),
2024-06-11T10:51:57.477544880Z   			string("https://localhost:2379"),
2024-06-11T10:51:57.477544880Z   		},
2024-06-11T10:51:57.477544880Z   		"feature-gates":                         []any{string("AdminNetworkPolicy=true"), string("AlibabaPlatform=true"), string("AutomatedEtcdBackup=false"), string("AzureWorkloadIdentity=true"), ...},
2024-06-11T10:51:57.477544880Z   		"send-retry-after-while-not-ready-once": []any{string("false")},
2024-06-11T10:51:57.477544880Z   		... // 2 identical entries
2024-06-11T10:51:57.477544880Z   	},
2024-06-11T10:51:57.477544880Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-06-11T10:51:57.477544880Z   	"servicesSubnet":     string("172.30.0.0/16"),
2024-06-11T10:51:57.477544880Z   	"servingInfo":        map[string]any{"bindAddress": string("0.0.0.0:6443"), "bindNetwork": string("tcp4"), "cipherSuites": []any{string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), string("TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384"), string("TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"), ...}, "minTLSVersion": string("VersionTLS12"), ...},
2024-06-11T10:51:57.477544880Z   }
2024-06-11T10:51:57.499482900Z I0611 10:51:57.499430       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:51:57.514637761Z I0611 10:51:57.514550       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://10.0.0.6:2379,https://10.0.0.8:2379,https://localhost:2379
2024-06-11T10:51:57.517521781Z I0611 10:51:57.517435       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-06-11T10:51:57.517521781Z   	"admission": map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("privileged"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-06-11T10:51:57.517521781Z   	"apiServerArguments": map[string]any{
2024-06-11T10:51:57.517521781Z   		... // 2 identical entries
2024-06-11T10:51:57.517521781Z   		"authentication-token-webhook-version": []any{string("v1")},
2024-06-11T10:51:57.517521781Z   		"cloud-config":                         []any{string("/etc/kubernetes/static-pod-resources/configmaps/cloud-config/clo"...)},
2024-06-11T10:51:57.517521781Z   		"etcd-servers": []any{
2024-06-11T10:51:57.517521781Z + 			string("https://10.0.0.6:2379"),
2024-06-11T10:51:57.517521781Z   			string("https://10.0.0.8:2379"),
2024-06-11T10:51:57.517521781Z   			string("https://localhost:2379"),
2024-06-11T10:51:57.517521781Z   		},
2024-06-11T10:51:57.517521781Z   		"feature-gates":                         []any{string("AdminNetworkPolicy=true"), string("AlibabaPlatform=true"), string("AutomatedEtcdBackup=false"), string("AzureWorkloadIdentity=true"), ...},
2024-06-11T10:51:57.517521781Z   		"send-retry-after-while-not-ready-once": []any{string("false")},
2024-06-11T10:51:57.517521781Z   		... // 2 identical entries
2024-06-11T10:51:57.517521781Z   	},
2024-06-11T10:51:57.517521781Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-06-11T10:51:57.517521781Z   	"servicesSubnet":     string("172.30.0.0/16"),
2024-06-11T10:51:57.517521781Z   	"servingInfo":        map[string]any{"bindAddress": string("0.0.0.0:6443"), "bindNetwork": string("tcp4"), "cipherSuites": []any{string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), string("TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384"), string("TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"), ...}, "minTLSVersion": string("VersionTLS12"), ...},
2024-06-11T10:51:57.517521781Z   }
2024-06-11T10:51:57.526827383Z I0611 10:51:57.526772       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:58.110749323Z I0611 10:51:58.110667       1 core.go:358] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"privileged\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"cloud-config\":[\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/cloud.conf\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PersistentVolumeLabel\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.6:2379\",\"https://10.0.0.8:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AutomatedEtcdBackup=false\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"CSIDriverSharedResource=false\",\"ChunkSizeMiB=false\",\"CloudDualStackNodeIPs=true\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallAWS=true\",\"ClusterAPIInstallAzure=false\",\"ClusterAPIInstallGCP=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterAPIInstallNutanix=true\",\"ClusterAPIInstallOpenStack=true\",\"ClusterAPIInstallPowerVS=false\",\"ClusterAPIInstallVSphere=true\",\"DNSNameResolver=false\",\"DisableKubeletCloudCredentialProviders=true\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalCloudProvider=true\",\"ExternalCloudProviderAzure=true\",\"ExternalCloudProviderExternal=true\",\"ExternalCloudProviderGCP=true\",\"ExternalOIDC=false\",\"ExternalRouteCertificate=false\",\"GCPClusterHostedDNS=false\",\"GCPLabelsTags=false\",\"GatewayAPI=false\",\"HardwareSpeed=true\",\"ImagePolicy=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InstallAlternateInfrastructureAWS=false\",\"KMSv1=true\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImages=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MetricsServer=true\",\"MixedCPUsAllocation=false\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NewOLM=false\",\"NodeDisruptionPolicy=false\",\"NodeSwap=false\",\"OnClusterBuild=false\",\"OpenShiftPodSecurityAdmission=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"PrivateHostedZoneAWS=true\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"ServiceAccountTokenNodeBindingValidation=false\",\"ServiceAccountTokenPodNodeInfo=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereMultiVCenters=false\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://kubernetes.default.svc\"],\"service-account-jwks-uri\":[\"https://api.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/openid/v1/jwks\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:51:58.111948781Z I0611 10:51:58.111890       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-06-11T10:51:58.111948781Z cause by changes in data.config.yaml
2024-06-11T10:51:58.114332894Z I0611 10:51:58.114259       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 3 triggered by "required configmap/config has changed"
2024-06-11T10:51:59.300583595Z I0611 10:51:59.300504       1 request.go:697] Waited for 1.185672182s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-06-11T10:51:59.703131647Z I0611 10:51:59.703056       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:59.909200851Z I0611 10:51:59.909105       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:00.300622981Z I0611 10:52:00.300559       1 request.go:697] Waited for 1.189386602s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:52:00.907794088Z I0611 10:52:00.907711       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:01.906731283Z I0611 10:52:01.906647       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:02.907556798Z I0611 10:52:02.907473       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cloud-config-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:03.908316596Z I0611 10:52:03.908228       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:04.907358572Z I0611 10:52:04.907256       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:05.907922433Z I0611 10:52:05.907849       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:06.062134579Z E0611 10:52:06.062064       1 guard_controller.go:293] Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0 on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:06.062134579Z E0611 10:52:06.062111       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:06.062208093Z E0611 10:52:06.062135       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:06.083828037Z E0611 10:52:06.083768       1 base_controller.go:268] GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0 on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:52:06.086500237Z I0611 10:52:06.086421       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:52:06.087005932Z I0611 10:52:06.086976       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:06.087551634Z I0611 10:52:06.087513       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0 on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:52:06.099893942Z I0611 10:52:06.098217       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]" to "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0 on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]"
2024-06-11T10:52:06.907642436Z I0611 10:52:06.907549       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:06.964751619Z E0611 10:52:06.964683       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:07.099980314Z I0611 10:52:07.099920       1 request.go:697] Waited for 1.038828119s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T10:52:07.251106683Z I0611 10:52:07.251041       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:52:07.275528051Z I0611 10:52:07.275455       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:52:08.100470261Z I0611 10:52:08.100415       1 request.go:697] Waited for 1.993943778s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:52:08.923387893Z I0611 10:52:08.923284       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:09.100710362Z I0611 10:52:09.100557       1 request.go:697] Waited for 2.135324124s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:09.498014480Z I0611 10:52:09.497171       1 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:00 +0000 UTC to 2034-06-09 10:19:00 +0000 UTC (now=2024-06-11 10:52:09.497120413 +0000 UTC))"
2024-06-11T10:52:09.498014480Z I0611 10:52:09.497236       1 tlsconfig.go:178] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2024-06-12 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.49721043 +0000 UTC))"
2024-06-11T10:52:09.498014480Z I0611 10:52:09.497270       1 tlsconfig.go:178] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2025-06-11 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.497247937 +0000 UTC))"
2024-06-11T10:52:09.498014480Z I0611 10:52:09.497318       1 tlsconfig.go:178] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2025-06-11 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.497282943 +0000 UTC))"
2024-06-11T10:52:09.498014480Z I0611 10:52:09.497349       1 tlsconfig.go:178] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:01 +0000 UTC to 2034-06-09 10:19:01 +0000 UTC (now=2024-06-11 10:52:09.497330552 +0000 UTC))"
2024-06-11T10:52:09.498014480Z I0611 10:52:09.497383       1 tlsconfig.go:178] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1718102903\" [] issuer=\"kubelet-signer\" (2024-06-11 10:48:22 +0000 UTC to 2024-06-12 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.497362058 +0000 UTC))"
2024-06-11T10:52:09.498014480Z I0611 10:52:09.497417       1 tlsconfig.go:178] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1718102900\" [] issuer=\"<self>\" (2024-06-11 10:48:20 +0000 UTC to 2025-06-11 10:48:21 +0000 UTC (now=2024-06-11 10:52:09.497395264 +0000 UTC))"
2024-06-11T10:52:09.498014480Z I0611 10:52:09.497449       1 tlsconfig.go:178] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:02 +0000 UTC to 2024-06-12 10:19:02 +0000 UTC (now=2024-06-11 10:52:09.497429871 +0000 UTC))"
2024-06-11T10:52:09.498175210Z I0611 10:52:09.498098       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-kube-apiserver-operator.svc\" [serving] validServingFor=[metrics.openshift-kube-apiserver-operator.svc,metrics.openshift-kube-apiserver-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1718102902\" (2024-06-11 10:48:33 +0000 UTC to 2026-06-11 10:48:34 +0000 UTC (now=2024-06-11 10:52:09.498053387 +0000 UTC))"
2024-06-11T10:52:09.498812829Z I0611 10:52:09.498766       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1718102980\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1718102979\" (2024-06-11 09:49:39 +0000 UTC to 2025-06-11 09:49:39 +0000 UTC (now=2024-06-11 10:52:09.498732114 +0000 UTC))"
2024-06-11T10:52:10.300592937Z I0611 10:52:10.300510       1 request.go:697] Waited for 1.990225014s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:52:10.911589834Z I0611 10:52:10.911502       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:11.500056723Z I0611 10:52:11.499957       1 request.go:697] Waited for 1.993708186s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:11.503448627Z I0611 10:52:11.503387       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-apiserver version "kube-apiserver" changed from "" to "1.29.5"
2024-06-11T10:52:11.503448627Z I0611 10:52:11.503423       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-apiserver version "operator" changed from "" to "4.16.0-0.nightly-2024-06-10-211334"
2024-06-11T10:52:11.503830295Z I0611 10:52:11.503800       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"versions":[{"name":"raw-internal","version":"4.16.0-0.nightly-2024-06-10-211334"},{"name":"kube-apiserver","version":"1.29.5"},{"name":"operator","version":"4.16.0-0.nightly-2024-06-10-211334"}]}}
2024-06-11T10:52:11.515859735Z I0611 10:52:11.515794       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: status.versions changed from [{"raw-internal" "4.16.0-0.nightly-2024-06-10-211334"}] to [{"raw-internal" "4.16.0-0.nightly-2024-06-10-211334"} {"kube-apiserver" "1.29.5"} {"operator" "4.16.0-0.nightly-2024-06-10-211334"}]
2024-06-11T10:52:12.500574217Z I0611 10:52:12.500507       1 request.go:697] Waited for 1.996305846s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-06-11T10:52:12.913818734Z I0611 10:52:12.913749       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:13.108577482Z E0611 10:52:13.108513       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:13.109030262Z I0611 10:52:13.108971       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:13.125172234Z E0611 10:52:13.125126       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:52:13.126941949Z I0611 10:52:13.126893       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:52:13.128127360Z I0611 10:52:13.128083       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:13.130049502Z I0611 10:52:13.130007       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:52:13.145762297Z I0611 10:52:13.143385       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0 on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]"
2024-06-11T10:52:13.500834665Z I0611 10:52:13.500757       1 request.go:697] Waited for 1.996829439s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:14.700694422Z I0611 10:52:14.700604       1 request.go:697] Waited for 1.96755043s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-06-11T10:52:15.900812925Z I0611 10:52:15.900740       1 request.go:697] Waited for 2.197062661s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T10:52:17.100757698Z I0611 10:52:17.100694       1 request.go:697] Waited for 2.194728446s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-06-11T10:52:17.109550162Z I0611 10:52:17.109458       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:17.304727884Z I0611 10:52:17.304651       1 core.go:226] Pod "openshift-kube-apiserver/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:bac0ddaf801035bf3d571daea9916b68407c1e9a58a3864616c1ca14e15e74bb","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.8","path":"readyz","port":6443,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master","operator":"Exists"},{"effect":"NoExecute","key":"node.kubernetes.io/not-ready","operator":"Exists"},{"effect":"NoExecute","key":"node.kubernetes.io/unreachable","operator":"Exists"},{"effect":"NoSchedule","key":"node-role.kubernetes.io/etcd","operator":"Exists"}],"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-06-11T10:52:18.100860903Z I0611 10:52:18.100796       1 request.go:697] Waited for 1.996426053s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:18.104045696Z I0611 10:52:18.103988       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 2, but has not made progress because static pod is pending
2024-06-11T10:52:18.708017306Z I0611 10:52:18.707950       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:19.101584492Z I0611 10:52:19.101506       1 request.go:697] Waited for 1.796674074s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:19.112335091Z E0611 10:52:19.112272       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:19.112405204Z E0611 10:52:19.112349       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:19.112940903Z E0611 10:52:19.112891       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:52:19.113646435Z I0611 10:52:19.113598       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-apiserver because it changed
2024-06-11T10:52:20.113316927Z I0611 10:52:20.113225       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-3 -n openshift-kube-apiserver because it was missing
2024-06-11T10:52:20.300291996Z I0611 10:52:20.300223       1 request.go:697] Waited for 1.377084373s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:52:21.300770538Z I0611 10:52:21.300701       1 request.go:697] Waited for 1.796957051s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:21.910011429Z I0611 10:52:21.909895       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 3 triggered by "required configmap/config has changed"
2024-06-11T10:52:21.928007975Z I0611 10:52:21.927933       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 3 created because required configmap/config has changed
2024-06-11T10:52:21.930075760Z I0611 10:52:21.930022       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:52:21.932705149Z I0611 10:52:21.932657       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:21.955485085Z W0611 10:52:21.955424       1 staticpod.go:38] revision 3 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T10:52:21.955485085Z E0611 10:52:21.955461       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 3
2024-06-11T10:52:22.303103926Z E0611 10:52:22.303048       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:22.303103926Z E0611 10:52:22.303097       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:22.303847464Z E0611 10:52:22.303810       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:52:22.500219380Z I0611 10:52:22.500144       1 request.go:697] Waited for 1.396818343s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:23.500394466Z I0611 10:52:23.500335       1 request.go:697] Waited for 1.566874266s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T10:52:24.700474625Z I0611 10:52:24.700414       1 request.go:697] Waited for 1.390002476s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:52:26.116824351Z I0611 10:52:26.116732       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 2, but has not made progress because static pod is pending
2024-06-11T10:52:26.196060839Z I0611 10:52:26.195989       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:52:26.199099991Z I0611 10:52:26.198958       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:52:26.201202273Z I0611 10:52:26.201132       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:26.271776188Z I0611 10:52:26.270688       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 2" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 2" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3"
2024-06-11T10:52:26.500686056Z I0611 10:52:26.500614       1 request.go:697] Waited for 1.11831763s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:52:27.700068952Z I0611 10:52:27.699990       1 request.go:697] Waited for 1.357551017s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-06-11T10:52:28.700545329Z I0611 10:52:28.700472       1 request.go:697] Waited for 1.972135621s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T10:52:29.703274915Z E0611 10:52:29.703219       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:29.703274915Z E0611 10:52:29.703256       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:29.703804611Z E0611 10:52:29.703776       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:52:29.900458521Z I0611 10:52:29.900394       1 request.go:697] Waited for 1.389092145s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:52:36.032093373Z E0611 10:52:36.032024       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:36.032093373Z E0611 10:52:36.032075       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:36.032641068Z E0611 10:52:36.032595       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:52:36.345099875Z E0611 10:52:36.345045       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:36.345099875Z E0611 10:52:36.345087       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:36.345795796Z E0611 10:52:36.345730       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:52:42.799687770Z E0611 10:52:42.799634       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:42.799687770Z E0611 10:52:42.799674       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:42.800147749Z E0611 10:52:42.800100       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:52:45.325441439Z I0611 10:52:45.325027       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:52:52.264110433Z I0611 10:52:52.264046       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:52:57.434350398Z I0611 10:52:57.433881       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:52:57.434350398Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:52:57.434350398Z  CurrentRevision: (int32) 0,
2024-06-11T10:52:57.434350398Z  TargetRevision: (int32) 3,
2024-06-11T10:52:57.434350398Z  LastFailedRevision: (int32) 0,
2024-06-11T10:52:57.434350398Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:52:57.434350398Z  LastFailedReason: (string) "",
2024-06-11T10:52:57.434350398Z  LastFailedCount: (int) 0,
2024-06-11T10:52:57.434350398Z  LastFallbackCount: (int) 0,
2024-06-11T10:52:57.434350398Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:52:57.434350398Z }
2024-06-11T10:52:57.434350398Z  because new revision pending
2024-06-11T10:52:57.461536682Z I0611 10:52:57.461482       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:57.464025192Z I0611 10:52:57.463970       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:52:59.816143239Z I0611 10:52:59.816003       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-3-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:00.206293087Z I0611 10:53:00.206215       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:53:01.002894110Z I0611 10:53:01.002822       1 request.go:697] Waited for 1.184342013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:53:02.007038972Z E0611 10:53:02.005626       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:53:02.007038972Z E0611 10:53:02.005666       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:02.007038972Z E0611 10:53:02.006135       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:53:02.202776680Z I0611 10:53:02.202582       1 request.go:697] Waited for 1.196048304s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:53:03.136313375Z I0611 10:53:03.136243       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:03.137006795Z I0611 10:53:03.136957       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:03.402511825Z I0611 10:53:03.402402       1 request.go:697] Waited for 1.196882348s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:04.005059213Z E0611 10:53:04.004998       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:53:04.005059213Z E0611 10:53:04.005032       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:04.005568601Z E0611 10:53:04.005538       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:53:04.358614440Z I0611 10:53:04.358549       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:04.805023100Z I0611 10:53:04.804967       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:53:06.005511876Z I0611 10:53:06.005440       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:53:06.947033028Z E0611 10:53:06.946976       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:53:06.947200751Z E0611 10:53:06.947166       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:06.948015459Z E0611 10:53:06.947971       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:53:11.970714248Z I0611 10:53:11.970647       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:20.013442508Z I0611 10:53:20.013365       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 4 triggered by "required secret/localhost-recovery-client-token has changed"
2024-06-11T10:53:20.031363278Z I0611 10:53:20.031269       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:20.041687132Z I0611 10:53:20.041631       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:20.226244988Z I0611 10:53:20.226171       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:20.525673141Z I0611 10:53:20.525599       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:20.636575601Z I0611 10:53:20.636514       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:20.639526874Z I0611 10:53:20.639482       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:21.217946906Z I0611 10:53:21.217858       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cloud-config-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:22.217181071Z I0611 10:53:22.217107       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:23.217811773Z I0611 10:53:23.217737       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:24.223325914Z I0611 10:53:24.223232       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:25.216447780Z I0611 10:53:25.216274       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:25.610225322Z I0611 10:53:25.610149       1 request.go:697] Waited for 1.176964064s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/sa-token-signing-certs
2024-06-11T10:53:25.618745610Z I0611 10:53:25.618685       1 core.go:358] ConfigMap "openshift-kube-apiserver/sa-token-signing-certs" changes: {"data":{"service-account-002.pub":"-----BEGIN RSA PUBLIC KEY-----\nMIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEA0lLI821QC67Q8wCCu+Bi\n0XYC8PIijizmrIkTu/OIeel1Oi4uwDQRTZq3dKfe+ZT6B/ZdcSPu8TeWgnj+igi2\n80OphuevFy+H9avbc0LsIlj09boksG8wnTy01/aTR3+/c7+eRfhdOypceFc/U5P6\nL2e887/YtExUHXhfxLs54G+iblGnEdGwe8ba3EGIVTb7vaF/kgHb9WRO0/YNAUS3\niyaoFjL5tfchOZN6XKrC9WE3TDbpq/fb0we0hMB8b4ukwJrrjY2mYY11vQDp/qur\niFw53Wema+X1Pf/u14xZuWMbMHbIES1FNCGRSX6Ko9xuXESp3nX9IFl+f39wj3xn\nENPpdLmxZ7MZDLIub35gd/FbDYeiyQFAYNCK/RmzQmqbkmDQ7UCticorTPi7X4OZ\nLVtCVHsjg60gcX2+iDmSLLEDafjjSPlfUSnve0MAWcPuhe2D4GoRrO5bNO07VhEH\nDpLi7Mck0h+X0FRz76ioiQBLOtOe6c8moWwyh5v6nBZIrVmVN5VoGMW74cF53bPj\nBtJdA/FCFdiYH817O6Df25I19ZxLJRl1QyDgJibf+4kXOvvx7QeLN5wd7rhttRcZ\nBfQY/BHaDKrln5lpgureRaZuomtXh1lgbWEQq2vF80PWGrnvmyQ5a+fM77kpLDHR\nroj9Xizndq8Dl79EiZXarosCAwEAAQ==\n-----END RSA PUBLIC KEY-----\n"},"metadata":{"creationTimestamp":"2024-06-11T10:41:23Z","managedFields":[{"apiVersion":"v1","fieldsType":"FieldsV1","fieldsV1":{"f:data":{".":{},"f:service-account-001.pub":{}}},"manager":"cluster-bootstrap","operation":"Update","time":"2024-06-11T10:41:23Z"},{"apiVersion":"v1","fieldsType":"FieldsV1","fieldsV1":{"f:data":{"f:service-account-002.pub":{}}},"manager":"cluster-kube-controller-manager-operator","operation":"Update","time":"2024-06-11T10:53:24Z"}],"resourceVersion":null,"uid":"7222e102-3680-460e-8389-5834b133ec0e"}}
2024-06-11T10:53:25.619220582Z I0611 10:53:25.619154       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/sa-token-signing-certs -n openshift-kube-apiserver:
2024-06-11T10:53:25.619220582Z cause by changes in data.service-account-002.pub
2024-06-11T10:53:26.418905300Z I0611 10:53:26.418844       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:27.416864698Z I0611 10:53:27.416769       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:28.421336380Z I0611 10:53:28.421239       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:28.720311987Z I0611 10:53:28.720234       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:28.737451179Z I0611 10:53:28.737401       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:28.781835890Z I0611 10:53:28.781759       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:28.821526592Z I0611 10:53:28.821471       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:28.839375990Z I0611 10:53:28.839276       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:30.224235561Z I0611 10:53:30.224122       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:30.838260929Z I0611 10:53:30.838170       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:31.622724675Z I0611 10:53:31.622547       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-4 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:32.417076973Z I0611 10:53:32.416978       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 4 triggered by "required secret/localhost-recovery-client-token has changed"
2024-06-11T10:53:32.436712855Z I0611 10:53:32.436624       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 4 created because required secret/localhost-recovery-client-token has changed
2024-06-11T10:53:32.438150051Z W0611 10:53:32.438093       1 staticpod.go:38] revision 4 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T10:53:32.438150051Z I0611 10:53:32.438124       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:32.438150051Z E0611 10:53:32.438138       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 4
2024-06-11T10:53:32.439636454Z I0611 10:53:32.439597       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:53:32.444655140Z I0611 10:53:32.444609       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required configmap/sa-token-signing-certs has changed"
2024-06-11T10:53:33.610009311Z I0611 10:53:33.609941       1 request.go:697] Waited for 1.169491137s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T10:53:34.610465860Z I0611 10:53:34.610399       1 request.go:697] Waited for 1.596571269s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-06-11T10:53:35.418829871Z I0611 10:53:35.418747       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:35.610708079Z I0611 10:53:35.610565       1 request.go:697] Waited for 1.389567596s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:53:36.081937373Z I0611 10:53:36.081585       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveStorageUpdated' Updated storage urls to https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379,https://localhost:2379
2024-06-11T10:53:36.081937373Z I0611 10:53:36.081625       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-06-11T10:53:36.081937373Z   	"admission": map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("privileged"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-06-11T10:53:36.081937373Z   	"apiServerArguments": map[string]any{
2024-06-11T10:53:36.081937373Z   		... // 2 identical entries
2024-06-11T10:53:36.081937373Z   		"authentication-token-webhook-version": []any{string("v1")},
2024-06-11T10:53:36.081937373Z   		"cloud-config":                         []any{string("/etc/kubernetes/static-pod-resources/configmaps/cloud-config/clo"...)},
2024-06-11T10:53:36.081937373Z   		"etcd-servers": []any{
2024-06-11T10:53:36.081937373Z   			string("https://10.0.0.6:2379"),
2024-06-11T10:53:36.081937373Z + 			string("https://10.0.0.7:2379"),
2024-06-11T10:53:36.081937373Z   			string("https://10.0.0.8:2379"),
2024-06-11T10:53:36.081937373Z   			string("https://localhost:2379"),
2024-06-11T10:53:36.081937373Z   		},
2024-06-11T10:53:36.081937373Z   		"feature-gates":                         []any{string("AdminNetworkPolicy=true"), string("AlibabaPlatform=true"), string("AutomatedEtcdBackup=false"), string("AzureWorkloadIdentity=true"), ...},
2024-06-11T10:53:36.081937373Z   		"send-retry-after-while-not-ready-once": []any{string("false")},
2024-06-11T10:53:36.081937373Z   		... // 2 identical entries
2024-06-11T10:53:36.081937373Z   	},
2024-06-11T10:53:36.081937373Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-06-11T10:53:36.081937373Z   	"servicesSubnet":     string("172.30.0.0/16"),
2024-06-11T10:53:36.081937373Z   	"servingInfo":        map[string]any{"bindAddress": string("0.0.0.0:6443"), "bindNetwork": string("tcp4"), "cipherSuites": []any{string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), string("TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384"), string("TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"), ...}, "minTLSVersion": string("VersionTLS12"), ...},
2024-06-11T10:53:36.081937373Z   }
2024-06-11T10:53:36.109770010Z I0611 10:53:36.109713       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:53:36.109847922Z I0611 10:53:36.109767       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:36.610705276Z I0611 10:53:36.610630       1 request.go:697] Waited for 1.397036826s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:36.819787508Z I0611 10:53:36.819712       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:37.610830042Z I0611 10:53:37.610766       1 request.go:697] Waited for 1.499080631s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T10:53:38.418121622Z I0611 10:53:38.418045       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:38.611318373Z I0611 10:53:38.611219       1 request.go:697] Waited for 1.655248921s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:53:38.821129698Z I0611 10:53:38.821018       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0" (last termination at 2024-06-11 10:52:06 +0000 UTC) at 2024-06-11 10:53:38 +0000 UTC
2024-06-11T10:53:39.459110689Z I0611 10:53:39.459047       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:39.463991769Z I0611 10:53:39.463936       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:39.810767965Z I0611 10:53:39.810705       1 request.go:697] Waited for 1.597254451s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-3-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:53:39.819041548Z I0611 10:53:39.818977       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:53:39.819041548Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:53:39.819041548Z  CurrentRevision: (int32) 0,
2024-06-11T10:53:39.819041548Z  TargetRevision: (int32) 4,
2024-06-11T10:53:39.819041548Z  LastFailedRevision: (int32) 0,
2024-06-11T10:53:39.819041548Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:53:39.819041548Z  LastFailedReason: (string) "",
2024-06-11T10:53:39.819041548Z  LastFailedCount: (int) 0,
2024-06-11T10:53:39.819041548Z  LastFallbackCount: (int) 0,
2024-06-11T10:53:39.819041548Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:53:39.819041548Z }
2024-06-11T10:53:39.819041548Z  because new revision pending
2024-06-11T10:53:39.836252792Z I0611 10:53:39.836147       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:39.836321201Z I0611 10:53:39.836251       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:53:39.836688844Z I0611 10:53:39.836643       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:53:39.848004089Z I0611 10:53:39.847946       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 3" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 3" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4"
2024-06-11T10:53:40.017484722Z I0611 10:53:40.017403       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cloud-config-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:40.214716753Z E0611 10:53:40.214650       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:53:40.214716753Z E0611 10:53:40.214685       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:40.215238315Z E0611 10:53:40.215201       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:53:41.010347172Z I0611 10:53:41.010257       1 request.go:697] Waited for 1.595256813s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:53:42.010720915Z I0611 10:53:42.010622       1 request.go:697] Waited for 2.149604868s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:53:42.217848721Z I0611 10:53:42.217754       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:43.210720188Z I0611 10:53:43.210580       1 request.go:697] Waited for 2.1960927s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:53:43.715989895Z I0611 10:53:43.715929       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:43.724809611Z I0611 10:53:43.724760       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:44.410241806Z I0611 10:53:44.410180       1 request.go:697] Waited for 2.192433186s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-06-11T10:53:44.418854791Z I0611 10:53:44.418795       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:44.613364620Z E0611 10:53:44.613273       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:53:44.613364620Z E0611 10:53:44.613352       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:44.613857693Z E0611 10:53:44.613813       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:53:45.020829830Z I0611 10:53:45.020732       1 core.go:358] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"privileged\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"cloud-config\":[\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/cloud.conf\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PersistentVolumeLabel\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.6:2379\",\"https://10.0.0.7:2379\",\"https://10.0.0.8:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AutomatedEtcdBackup=false\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"CSIDriverSharedResource=false\",\"ChunkSizeMiB=false\",\"CloudDualStackNodeIPs=true\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallAWS=true\",\"ClusterAPIInstallAzure=false\",\"ClusterAPIInstallGCP=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterAPIInstallNutanix=true\",\"ClusterAPIInstallOpenStack=true\",\"ClusterAPIInstallPowerVS=false\",\"ClusterAPIInstallVSphere=true\",\"DNSNameResolver=false\",\"DisableKubeletCloudCredentialProviders=true\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalCloudProvider=true\",\"ExternalCloudProviderAzure=true\",\"ExternalCloudProviderExternal=true\",\"ExternalCloudProviderGCP=true\",\"ExternalOIDC=false\",\"ExternalRouteCertificate=false\",\"GCPClusterHostedDNS=false\",\"GCPLabelsTags=false\",\"GatewayAPI=false\",\"HardwareSpeed=true\",\"ImagePolicy=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InstallAlternateInfrastructureAWS=false\",\"KMSv1=true\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImages=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MetricsServer=true\",\"MixedCPUsAllocation=false\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NewOLM=false\",\"NodeDisruptionPolicy=false\",\"NodeSwap=false\",\"OnClusterBuild=false\",\"OpenShiftPodSecurityAdmission=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"PrivateHostedZoneAWS=true\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"ServiceAccountTokenNodeBindingValidation=false\",\"ServiceAccountTokenPodNodeInfo=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereMultiVCenters=false\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://kubernetes.default.svc\"],\"service-account-jwks-uri\":[\"https://api.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/openid/v1/jwks\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:53:45.021459724Z I0611 10:53:45.021402       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-06-11T10:53:45.021459724Z cause by changes in data.config.yaml
2024-06-11T10:53:45.410460379Z I0611 10:53:45.410392       1 request.go:697] Waited for 2.194806355s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:53:46.420487396Z I0611 10:53:46.420415       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:46.610741370Z I0611 10:53:46.610594       1 request.go:697] Waited for 1.996124366s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:53:47.697702866Z I0611 10:53:47.697635       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:47.706655489Z I0611 10:53:47.706607       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:47.810421755Z I0611 10:53:47.810350       1 request.go:697] Waited for 1.595165078s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-4-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:53:48.023589058Z I0611 10:53:48.023493       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:48.215876109Z E0611 10:53:48.215816       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:53:48.215876109Z E0611 10:53:48.215853       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:48.216828339Z E0611 10:53:48.216777       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:53:49.010390579Z I0611 10:53:49.010295       1 request.go:697] Waited for 1.594753422s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:53:49.424737047Z I0611 10:53:49.424667       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-4-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:49.623119731Z I0611 10:53:49.623033       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:50.209811029Z I0611 10:53:50.209734       1 request.go:697] Waited for 1.396308629s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-06-11T10:53:50.814020217Z I0611 10:53:50.813942       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 4, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:53:51.210477243Z I0611 10:53:51.210409       1 request.go:697] Waited for 1.784066068s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T10:53:51.535136667Z I0611 10:53:51.535067       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:51.623943591Z I0611 10:53:51.623787       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:52.410212536Z I0611 10:53:52.410090       1 request.go:697] Waited for 1.995172188s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:53:53.413154933Z E0611 10:53:53.413094       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:53:53.413154933Z E0611 10:53:53.413131       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:53.413649406Z E0611 10:53:53.413621       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:53:53.610562033Z I0611 10:53:53.610448       1 request.go:697] Waited for 1.986643644s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-06-11T10:53:53.621604144Z I0611 10:53:53.621546       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:54.610761616Z I0611 10:53:54.610696       1 request.go:697] Waited for 1.995588703s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:53:55.810252484Z I0611 10:53:55.810182       1 request.go:697] Waited for 1.981221584s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:53:57.010390017Z I0611 10:53:57.010318       1 request.go:697] Waited for 1.996503442s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T10:53:57.413425765Z E0611 10:53:57.413368       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:53:57.413425765Z E0611 10:53:57.413403       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:57.413853209Z E0611 10:53:57.413826       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:53:57.632976427Z I0611 10:53:57.632891       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:58.210620738Z I0611 10:53:58.210524       1 request.go:697] Waited for 1.596785804s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:58.722950537Z I0611 10:53:58.722885       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:53:58.825380772Z I0611 10:53:58.825279       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:53:59.210669820Z I0611 10:53:59.210597       1 request.go:697] Waited for 1.394429224s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-06-11T10:53:59.813981018Z I0611 10:53:59.813915       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:54:00.013350303Z E0611 10:54:00.013263       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:54:00.013427014Z E0611 10:54:00.013347       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:54:00.013889380Z E0611 10:54:00.013851       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:54:00.218367595Z I0611 10:54:00.218279       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-5 -n openshift-kube-apiserver because it was missing
2024-06-11T10:54:00.411216348Z I0611 10:54:00.410957       1 request.go:697] Waited for 1.389184079s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:54:01.422715466Z I0611 10:54:01.422651       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 5 triggered by "required configmap/sa-token-signing-certs has changed"
2024-06-11T10:54:01.437795920Z I0611 10:54:01.437733       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 5 created because required configmap/sa-token-signing-certs has changed
2024-06-11T10:54:01.438167673Z I0611 10:54:01.438112       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:54:01.440750142Z I0611 10:54:01.440704       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:54:01.447780447Z I0611 10:54:01.447726       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 6 triggered by "required configmap/config has changed"
2024-06-11T10:54:01.610671620Z I0611 10:54:01.610590       1 request.go:697] Waited for 1.189151299s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:54:02.811845393Z I0611 10:54:02.811774       1 request.go:697] Waited for 1.372141302s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T10:54:04.009906863Z I0611 10:54:04.009822       1 request.go:697] Waited for 1.59549768s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:54:04.420893209Z I0611 10:54:04.420481       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-6 -n openshift-kube-apiserver because it was missing
2024-06-11T10:54:05.009993472Z I0611 10:54:05.009919       1 request.go:697] Waited for 1.395299336s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-06-11T10:54:05.819374152Z I0611 10:54:05.819261       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-6 -n openshift-kube-apiserver because it was missing
2024-06-11T10:54:06.010470631Z I0611 10:54:06.010400       1 request.go:697] Waited for 1.389070338s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:54:06.813394384Z I0611 10:54:06.813333       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:54:06.829839991Z I0611 10:54:06.829782       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:54:06.830530279Z I0611 10:54:06.830479       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:54:06.831921357Z I0611 10:54:06.831872       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:54:06.841878133Z I0611 10:54:06.841820       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5"
2024-06-11T10:54:07.210082199Z I0611 10:54:07.210007       1 request.go:697] Waited for 1.39072845s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-06-11T10:54:07.217328227Z I0611 10:54:07.217212       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-6 -n openshift-kube-apiserver because it was missing
2024-06-11T10:54:08.210152258Z I0611 10:54:08.210070       1 request.go:697] Waited for 1.378578444s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:54:08.817086659Z I0611 10:54:08.817012       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cloud-config-6 -n openshift-kube-apiserver because it was missing
2024-06-11T10:54:09.210624961Z I0611 10:54:09.210545       1 request.go:697] Waited for 1.593284451s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-06-11T10:54:10.218473863Z I0611 10:54:10.218392       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-6 -n openshift-kube-apiserver because it was missing
2024-06-11T10:54:10.410425558Z I0611 10:54:10.410353       1 request.go:697] Waited for 1.389863173s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:54:11.610180556Z I0611 10:54:11.610119       1 request.go:697] Waited for 1.392006329s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-06-11T10:54:11.617763992Z I0611 10:54:11.617698       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-6 -n openshift-kube-apiserver because it was missing
2024-06-11T10:54:12.610887383Z I0611 10:54:12.610731       1 request.go:697] Waited for 1.195244542s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:54:12.819037177Z I0611 10:54:12.818948       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-6 -n openshift-kube-apiserver because it was missing
2024-06-11T10:54:13.619185248Z I0611 10:54:13.619120       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:54:13.619185248Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:54:13.619185248Z  CurrentRevision: (int32) 0,
2024-06-11T10:54:13.619185248Z  TargetRevision: (int32) 5,
2024-06-11T10:54:13.619185248Z  LastFailedRevision: (int32) 0,
2024-06-11T10:54:13.619185248Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:54:13.619185248Z  LastFailedReason: (string) "",
2024-06-11T10:54:13.619185248Z  LastFailedCount: (int) 0,
2024-06-11T10:54:13.619185248Z  LastFallbackCount: (int) 0,
2024-06-11T10:54:13.619185248Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:54:13.619185248Z }
2024-06-11T10:54:13.619185248Z  because new revision pending
2024-06-11T10:54:13.638569441Z I0611 10:54:13.638513       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:54:13.640469675Z I0611 10:54:13.640413       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:54:13.809867686Z I0611 10:54:13.809809       1 request.go:697] Waited for 1.194871595s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:54:14.017786751Z I0611 10:54:14.017675       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-6 -n openshift-kube-apiserver because it was missing
2024-06-11T10:54:14.629001700Z E0611 10:54:14.628939       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:14.810837046Z I0611 10:54:14.810749       1 request.go:697] Waited for 1.191850622s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T10:54:14.811888475Z E0611 10:54:14.811834       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:15.211241972Z E0611 10:54:15.211181       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:15.411196154Z E0611 10:54:15.411103       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:54:15.411196154Z E0611 10:54:15.411138       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:54:15.412846758Z W0611 10:54:15.412774       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:15.412846758Z E0611 10:54:15.412821       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:54:15.814743692Z E0611 10:54:15.814685       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:16.010335644Z I0611 10:54:16.010272       1 request.go:697] Waited for 2.196459662s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:54:16.013091720Z E0611 10:54:16.013036       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.211203315Z I0611 10:54:16.211079       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ConfigMapCreateFailed' Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.212109938Z E0611 10:54:16.212054       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf01e4c990  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,LastTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:54:16.212921049Z I0611 10:54:16.212856       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RevisionCreateFailed' Failed to create revision 6: Post "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.214262332Z E0611 10:54:16.214226       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.216321012Z E0611 10:54:16.216265       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.221632436Z E0611 10:54:16.221592       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.245187046Z E0611 10:54:16.245113       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.288013681Z E0611 10:54:16.287958       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.370475718Z E0611 10:54:16.370420       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.412963207Z W0611 10:54:16.412893       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.412963207Z E0611 10:54:16.412930       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.533853980Z E0611 10:54:16.533793       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.811566222Z E0611 10:54:16.811492       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.856433536Z E0611 10:54:16.856374       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:17.012029138Z I0611 10:54:17.011236       1 request.go:697] Waited for 1.999813524s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:54:17.210854531Z E0611 10:54:17.210798       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:17.411672195Z E0611 10:54:17.411598       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:54:17.411672195Z E0611 10:54:17.411637       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:54:17.413366926Z W0611 10:54:17.413287       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:17.413410032Z E0611 10:54:17.413363       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:54:17.499811905Z E0611 10:54:17.499750       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:17.814474382Z E0611 10:54:17.814398       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:18.012107912Z E0611 10:54:18.012044       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:18.209809452Z I0611 10:54:18.209755       1 request.go:697] Waited for 1.79083923s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:54:18.212135480Z W0611 10:54:18.212070       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:18.212135480Z E0611 10:54:18.212119       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:18.611109593Z E0611 10:54:18.611044       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:18.782679512Z E0611 10:54:18.782563       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:18.813203604Z E0611 10:54:18.813120       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:19.010736369Z E0611 10:54:19.010665       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:19.210450848Z I0611 10:54:19.210389       1 request.go:697] Waited for 1.598800608s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:54:19.414712672Z E0611 10:54:19.414641       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:19.613061917Z E0611 10:54:19.613004       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:19.812808199Z W0611 10:54:19.812733       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:19.812808199Z E0611 10:54:19.812781       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:20.028910184Z E0611 10:54:20.028844       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:20.210699105Z I0611 10:54:20.210603       1 request.go:697] Waited for 1.599425997s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T10:54:20.211371971Z E0611 10:54:20.211293       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:20.610953844Z E0611 10:54:20.610888       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:20.812867238Z E0611 10:54:20.812811       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-4-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:21.012854743Z E0611 10:54:21.012787       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:21.213552118Z E0611 10:54:21.213501       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:21.345449749Z E0611 10:54:21.345394       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:21.410420918Z I0611 10:54:21.410342       1 request.go:697] Waited for 1.796569223s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:54:21.413742944Z E0611 10:54:21.413686       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:21.612174196Z W0611 10:54:21.612090       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:21.612174196Z E0611 10:54:21.612145       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:22.011727392Z E0611 10:54:22.011668       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:22.411198994Z E0611 10:54:22.411126       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:22.610015223Z I0611 10:54:22.609929       1 request.go:697] Waited for 1.796492417s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:54:23.014424285Z E0611 10:54:23.014364       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:23.212577525Z E0611 10:54:23.212483       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.412386186Z W0611 10:54:23.412314       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.412386186Z E0611 10:54:23.412359       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.610238586Z I0611 10:54:23.610180       1 request.go:697] Waited for 1.798606333s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-06-11T10:54:23.811142494Z E0611 10:54:23.810834       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.012524665Z E0611 10:54:24.012453       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.211504315Z E0611 10:54:24.211442       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.562281521Z E0611 10:54:24.562229       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf01e4c990  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,LastTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:54:24.610247021Z I0611 10:54:24.610184       1 request.go:697] Waited for 1.795978843s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-06-11T10:54:24.813247208Z E0611 10:54:24.813190       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:25.013216090Z E0611 10:54:25.013144       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.212763817Z W0611 10:54:25.212696       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.212763817Z E0611 10:54:25.212740       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.428517805Z E0611 10:54:25.428447       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:25.610447481Z I0611 10:54:25.610383       1 request.go:697] Waited for 1.799154167s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T10:54:25.611352302Z E0611 10:54:25.611266       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.011591207Z E0611 10:54:26.011532       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.468586945Z E0611 10:54:26.468531       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.610877105Z I0611 10:54:26.610777       1 request.go:697] Waited for 1.636781037s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T10:54:26.614659670Z E0611 10:54:26.614586       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:26.812900096Z E0611 10:54:26.812831       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:27.012794826Z W0611 10:54:27.012721       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:27.012794826Z E0611 10:54:27.012758       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:27.410634245Z E0611 10:54:27.410579       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:27.470680314Z E0611 10:54:27.470598       1 leaderelection.go:332] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:27.810637830Z I0611 10:54:27.810563       1 request.go:697] Waited for 1.798912607s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T10:54:27.811834377Z E0611 10:54:27.811784       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:28.010687079Z I0611 10:54:28.010600       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:28.011473175Z E0611 10:54:28.011423       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edd1c1339cf8  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,LastTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:28.012559209Z E0611 10:54:28.012503       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:28.414001070Z E0611 10:54:28.413933       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:28.614071821Z E0611 10:54:28.614014       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:29.010642885Z I0611 10:54:29.010577       1 request.go:697] Waited for 1.676162785s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T10:54:29.013341517Z W0611 10:54:29.013263       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.013341517Z E0611 10:54:29.013331       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.211492132Z E0611 10:54:29.211427       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.412411287Z E0611 10:54:29.412355       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.611139174Z E0611 10:54:29.611069       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:30.010885027Z I0611 10:54:30.010788       1 request.go:697] Waited for 1.799650639s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-06-11T10:54:30.215409825Z E0611 10:54:30.215333       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:30.427683573Z E0611 10:54:30.427618       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:30.611093780Z E0611 10:54:30.611035       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:30.814767673Z E0611 10:54:30.814690       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:31.210800771Z I0611 10:54:31.210719       1 request.go:697] Waited for 1.599505378s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T10:54:31.211834698Z E0611 10:54:31.211779       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:31.413386231Z W0611 10:54:31.413290       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:31.413386231Z E0611 10:54:31.413353       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:31.814612766Z E0611 10:54:31.814558       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:32.012833690Z E0611 10:54:32.012767       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:32.410441482Z I0611 10:54:32.410383       1 request.go:697] Waited for 1.799227387s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T10:54:32.411225078Z E0611 10:54:32.411166       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:32.811326175Z E0611 10:54:32.811245       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:33.165158994Z E0611 10:54:33.165086       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edd1c1339cf8  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,LastTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:33.412415226Z E0611 10:54:33.412344       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:33.610428852Z I0611 10:54:33.610289       1 request.go:697] Waited for 1.514011603s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T10:54:33.613569460Z E0611 10:54:33.613517       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:34.012226855Z E0611 10:54:34.012164       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:34.212818062Z W0611 10:54:34.212742       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:34.212818062Z E0611 10:54:34.212784       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:34.411639000Z I0611 10:54:34.411571       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:34.413106538Z E0611 10:54:34.413065       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:34.563411228Z E0611 10:54:34.563356       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf01e4c990  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,LastTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:54:34.610542747Z I0611 10:54:34.610474       1 request.go:697] Waited for 1.438344492s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T10:54:34.611476634Z E0611 10:54:34.611428       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:35.013186993Z E0611 10:54:35.013130       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:35.211161052Z E0611 10:54:35.211076       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:35.429750743Z E0611 10:54:35.429686       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:35.810649151Z I0611 10:54:35.810563       1 request.go:697] Waited for 1.396891251s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:54:36.213715436Z E0611 10:54:36.213645       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:36.712250871Z E0611 10:54:36.712187       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.210607890Z I0611 10:54:37.210529       1 request.go:697] Waited for 1.035537876s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T10:54:37.214432348Z E0611 10:54:37.214388       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:37.611961115Z E0611 10:54:37.611900       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.813187579Z W0611 10:54:37.813117       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.813187579Z E0611 10:54:37.813161       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:38.427526495Z E0611 10:54:38.427451       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:38.811413266Z I0611 10:54:38.811333       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:38.812871151Z E0611 10:54:38.812826       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:39.012518563Z E0611 10:54:39.012460       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:40.212402589Z E0611 10:54:40.212338       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:40.839925549Z E0611 10:54:40.839852       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:42.014334946Z E0611 10:54:42.014268       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:42.211422268Z I0611 10:54:42.211338       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:42.212805036Z E0611 10:54:42.212750       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:42.813077493Z E0611 10:54:42.813012       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:43.166175626Z E0611 10:54:43.166112       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edd1c1339cf8  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,LastTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:43.214069163Z E0611 10:54:43.214010       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:43.610435470Z I0611 10:54:43.610284       1 request.go:697] Waited for 1.075269046s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T10:54:43.611542004Z E0611 10:54:43.611492       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:43.830015130Z E0611 10:54:43.829944       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:44.212920496Z W0611 10:54:44.212853       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.212920496Z E0611 10:54:44.212890       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.565257536Z E0611 10:54:44.565196       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf01e4c990  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,LastTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:54:44.613672137Z E0611 10:54:44.613609       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.810466921Z I0611 10:54:44.810389       1 request.go:697] Waited for 1.398330118s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-06-11T10:54:44.813124645Z E0611 10:54:44.813075       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:45.413611928Z W0611 10:54:45.413538       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:45.413611928Z E0611 10:54:45.413594       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:46.009899899Z I0611 10:54:46.009845       1 request.go:697] Waited for 1.157506768s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T10:54:46.010768605Z E0611 10:54:46.010733       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:46.412990025Z E0611 10:54:46.412919       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:46.613849304Z E0611 10:54:46.613774       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:46.811987852Z E0611 10:54:46.811931       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:47.010647763Z I0611 10:54:47.010566       1 request.go:697] Waited for 1.398508941s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:54:47.012271861Z I0611 10:54:47.012133       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:47.014286907Z E0611 10:54:47.014231       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:47.427439559Z E0611 10:54:47.427374       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:49.212387896Z E0611 10:54:49.212335       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.826150097Z E0611 10:54:49.826091       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:50.211103321Z I0611 10:54:50.211034       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:50.212481877Z E0611 10:54:50.212448       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:50.412248183Z E0611 10:54:50.412185       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:51.613305394Z E0611 10:54:51.613244       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:52.226929638Z E0611 10:54:52.226869       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:53.167770474Z E0611 10:54:53.167708       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edd1c1339cf8  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,LastTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:53.410947513Z I0611 10:54:53.410867       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:53.412369275Z E0611 10:54:53.412284       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:53.472332790Z E0611 10:54:53.472246       1 leaderelection.go:332] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:54.012404974Z E0611 10:54:54.012347       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:54.212183681Z E0611 10:54:54.212116       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:54.567263439Z E0611 10:54:54.567208       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf01e4c990  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,LastTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:54:54.829676765Z E0611 10:54:54.829586       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:55.412464604Z W0611 10:54:55.412399       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:55.412464604Z E0611 10:54:55.412437       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:55.613472351Z E0611 10:54:55.613410       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:56.412437305Z E0611 10:54:56.412385       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:56.614379928Z I0611 10:54:56.614208       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:56.615950621Z E0611 10:54:56.615873       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:57.195450053Z E0611 10:54:57.195390       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:58.211337312Z I0611 10:54:58.211249       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:58.212765246Z E0611 10:54:58.212718       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:58.414104908Z E0611 10:54:58.414014       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:00.011537350Z I0611 10:55:00.011470       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:00.013172904Z E0611 10:55:00.013137       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:00.811800517Z E0611 10:55:00.811751       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:01.012414710Z E0611 10:55:01.012358       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:02.411139926Z I0611 10:55:02.411076       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:02.412624205Z E0611 10:55:02.412575       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:03.013939784Z E0611 10:55:03.013868       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:03.169584697Z E0611 10:55:03.169513       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edd1c1339cf8  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,LastTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:03.414610112Z E0611 10:55:03.414530       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:04.019369708Z E0611 10:55:04.019274       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:04.569983959Z E0611 10:55:04.569904       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf01e4c990  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,LastTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:55:04.612336378Z E0611 10:55:04.612276       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:06.229203535Z E0611 10:55:06.229137       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:06.413359699Z E0611 10:55:06.413288       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:07.610960635Z E0611 10:55:07.610903       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:07.812399929Z E0611 10:55:07.812350       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:12.658540595Z I0611 10:55:12.658464       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:12.659941552Z E0611 10:55:12.659890       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:13.160490648Z E0611 10:55:13.160429       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:13.171716401Z E0611 10:55:13.171671       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edd1c1339cf8  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,LastTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:14.571434461Z E0611 10:55:14.571376       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf01e4c990  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,LastTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:55:18.070839599Z E0611 10:55:18.070641       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:19.471751775Z E0611 10:55:19.471680       1 leaderelection.go:332] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:21.296624018Z E0611 10:55:21.296552       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:23.161648132Z E0611 10:55:23.161582       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:23.173492992Z E0611 10:55:23.173446       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edd1c1339cf8  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,LastTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:24.573539030Z E0611 10:55:24.573488       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf01e4c990  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,LastTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:55:26.737064388Z E0611 10:55:26.736995       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:26.972417825Z E0611 10:55:26.972349       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:33.144841809Z I0611 10:55:33.144776       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 5 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:33.146058231Z E0611 10:55:33.146014       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:33.159833108Z E0611 10:55:33.159792       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:33.175041429Z E0611 10:55:33.174999       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edd1c1339cf8  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,LastTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:34.575205336Z E0611 10:55:34.575142       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf01e4c990  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,LastTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:55:36.377115412Z W0611 10:55:36.377048       1 base_controller.go:232] Updating status of "NodeKubeconfigController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:36.377115412Z E0611 10:55:36.377088       1 base_controller.go:268] NodeKubeconfigController reconciliation failed: "secret/node-kubeconfigs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:38.159021867Z E0611 10:55:38.158967       1 base_controller.go:268] RevisionController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:38.569777625Z E0611 10:55:38.569686       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:41.138196477Z E0611 10:55:41.138113       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:42.536763293Z E0611 10:55:42.536703       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:42.540111956Z E0611 10:55:42.540068       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:43.155591203Z E0611 10:55:43.155518       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:43.167879735Z E0611 10:55:43.167812       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:43.176699892Z E0611 10:55:43.176650       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edd1c1339cf8  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,LastTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:43.339241019Z E0611 10:55:43.339182       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:44.577089959Z E0611 10:55:44.577034       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf01e4c990  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,LastTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:55:44.985652867Z E0611 10:55:44.985583       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:45.472148625Z E0611 10:55:45.472073       1 leaderelection.go:332] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:48.572153466Z E0611 10:55:48.572093       1 termination_observer.go:175] key failed with : unable to list pods in "openshift-kube-apiserver" namespace: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:53.161714965Z E0611 10:55:53.161638       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:53.177770327Z E0611 10:55:53.177716       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edd1c1339cf8  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,LastTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:54.579754406Z E0611 10:55:54.579668       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf01e4c990  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,LastTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:56:02.261532962Z E0611 10:56:02.261473       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:56:03.161706872Z E0611 10:56:03.161645       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:56:03.180101779Z E0611 10:56:03.180031       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edd1c1339cf8  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 5 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,LastTimestamp:2024-06-11 10:54:28.010466552 +0000 UTC m=+288.546127713,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:56:04.581803795Z E0611 10:56:04.581731       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf01e4c990  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,LastTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:56:04.581867002Z E0611 10:56:04.581822       1 event.go:294] "Unable to write event (retry limit exceeded!)" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf01e4c990  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ConfigMapCreateFailed,Message:Failed to create ConfigMap/sa-token-signing-certs-6 -n openshift-kube-apiserver: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,LastTimestamp:2024-06-11 10:54:16.210917776 +0000 UTC m=+276.746579037,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:56:04.582781496Z E0611 10:56:04.582739       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-apiserver-operator.17d7edcf0200db4f  openshift-kube-apiserver-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-apiserver-operator,Name:kube-apiserver-operator,UID:a65a24a6-1096-46dc-b349-e8787c38d7d6,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:RevisionCreateFailed,Message:Failed to create revision 6: Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-apiserver-operator-revisioncontroller,Host:,},FirstTimestamp:2024-06-11 10:54:16.212757327 +0000 UTC m=+276.748418488,LastTimestamp:2024-06-11 10:54:16.212757327 +0000 UTC m=+276.748418488,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-apiserver-operator-revisioncontroller,ReportingInstance:,}"
2024-06-11T10:56:14.153259562Z I0611 10:56:14.153172       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-apiserver because it was missing
2024-06-11T10:56:14.157417966Z I0611 10:56:14.157364       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 5, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:56:31.558549737Z I0611 10:56:31.558437       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0" (last termination at 2024-06-11 10:52:06 +0000 UTC) at 2024-06-11 10:54:50 +0000 UTC
2024-06-11T10:56:40.497729188Z I0611 10:56:40.497672       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:47.586519730Z I0611 10:56:47.586435       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:49.603525922Z I0611 10:56:49.603463       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:50.827687549Z I0611 10:56:50.827612       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:51.675490813Z I0611 10:56:51.675429       1 reflector.go:351] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:51.675652727Z I0611 10:56:51.675601       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com
2024-06-11T10:56:51.675954952Z I0611 10:56:51.675921       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:56:52.402129793Z I0611 10:56:52.402048       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:54.135978136Z I0611 10:56:54.135906       1 reflector.go:351] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:54.609517041Z I0611 10:56:54.609445       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:55.825691970Z I0611 10:56:55.825640       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:56.905822873Z I0611 10:56:56.905759       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:57.356764917Z I0611 10:56:57.356706       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:57.357162454Z I0611 10:56:57.357132       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:56:57.828091035Z I0611 10:56:57.828025       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:59.280228712Z I0611 10:56:59.280111       1 reflector.go:351] Caches populated for *v1.OAuth from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:01.053429342Z I0611 10:57:01.053362       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:01.136394324Z I0611 10:57:01.136333       1 reflector.go:351] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:01.215093589Z I0611 10:57:01.215002       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0" (last termination at 2024-06-11 10:52:06 +0000 UTC) at 2024-06-11 10:57:01 +0000 UTC
2024-06-11T10:57:03.196635544Z I0611 10:57:03.196564       1 reflector.go:351] Caches populated for *v1alpha1.StorageVersionMigration from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:03.333286895Z I0611 10:57:03.333219       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:04.373539918Z I0611 10:57:04.373444       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:04.478554710Z W0611 10:57:04.478469       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:57:05.482193923Z W0611 10:57:05.482118       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:57:06.569535871Z I0611 10:57:06.569432       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:07.187018017Z I0611 10:57:07.186942       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:07.582394402Z W0611 10:57:07.582327       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:57:07.712968525Z I0611 10:57:07.712883       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:07.974531907Z I0611 10:57:07.974469       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:08.585924225Z W0611 10:57:08.585794       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:57:08.591028167Z I0611 10:57:08.590966       1 reflector.go:351] Caches populated for *v1.Image from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:09.251566747Z I0611 10:57:09.251503       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:09.376858711Z I0611 10:57:09.376778       1 reflector.go:351] Caches populated for *v1.Authentication from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:10.579257679Z I0611 10:57:10.579186       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0" at 2024-06-11 10:56:00 +0000 UTC
2024-06-11T10:57:10.706429807Z I0611 10:57:10.706372       1 reflector.go:351] Caches populated for operator.openshift.io/v1, Resource=kubeapiservers from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:10.708166757Z I0611 10:57:10.708109       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:10.708854917Z I0611 10:57:10.708808       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:57:10.710729180Z I0611 10:57:10.710673       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "configmap \"sa-token-signing-certs-6\" not found"
2024-06-11T10:57:10.712121700Z I0611 10:57:10.712070       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:10.733950093Z E0611 10:57:10.733886       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:10.736265494Z E0611 10:57:10.736212       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:10.736448410Z I0611 10:57:10.736402       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:57:10.736878247Z I0611 10:57:10.736843       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:10.738684204Z I0611 10:57:10.738609       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:10.739422468Z I0611 10:57:10.739377       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:57:10.739863206Z I0611 10:57:10.739808       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:10.740405153Z E0611 10:57:10.740372       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:10.761863214Z I0611 10:57:10.761787       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:10.762201543Z E0611 10:57:10.762170       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:10.766158686Z I0611 10:57:10.766098       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]",Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6"
2024-06-11T10:57:10.803266904Z I0611 10:57:10.803196       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:10.803559530Z E0611 10:57:10.803517       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:10.848242904Z I0611 10:57:10.848193       1 reflector.go:351] Caches populated for *v1.Network from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:10.848419720Z I0611 10:57:10.848364       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-06-11T10:57:10.884755771Z I0611 10:57:10.884681       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:10.885029494Z E0611 10:57:10.884980       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:10.961732946Z I0611 10:57:10.961668       1 reflector.go:351] Caches populated for *v1.APIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:11.046676512Z I0611 10:57:11.046571       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:11.047037643Z E0611 10:57:11.046996       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:11.368363807Z I0611 10:57:11.368241       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:11.368569625Z E0611 10:57:11.368537       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:11.662373103Z I0611 10:57:11.662291       1 reflector.go:351] Caches populated for *v1.MutatingWebhookConfiguration from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:11.772114619Z W0611 10:57:11.772047       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:57:11.773159310Z I0611 10:57:11.773112       1 request.go:697] Waited for 1.060919899s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:57:12.010072854Z I0611 10:57:12.010005       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:12.010379080Z E0611 10:57:12.010330       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:12.175686015Z I0611 10:57:12.175622       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:12.775334815Z W0611 10:57:12.775167       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:57:12.973192072Z I0611 10:57:12.973112       1 request.go:697] Waited for 1.587448658s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-06-11T10:57:12.984897387Z I0611 10:57:12.984822       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:13.291849305Z I0611 10:57:13.291758       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:13.292010919Z E0611 10:57:13.291957       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:13.973761738Z I0611 10:57:13.973682       1 request.go:697] Waited for 1.39582004s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:14.184248690Z I0611 10:57:14.184150       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:15.185754809Z I0611 10:57:15.185685       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:15.789870510Z I0611 10:57:15.789793       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cloud-config-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:15.851956871Z I0611 10:57:15.851890       1 reflector.go:351] Caches populated for *v1.ValidatingWebhookConfiguration from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:15.852984834Z I0611 10:57:15.852907       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:15.853454362Z E0611 10:57:15.853409       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:15.938230198Z W0611 10:57:15.938125       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:57:16.383788593Z I0611 10:57:16.383721       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:16.399069818Z I0611 10:57:16.399002       1 reflector.go:351] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:16.575144686Z I0611 10:57:16.575077       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:16.942410537Z W0611 10:57:16.942337       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:57:16.976639411Z I0611 10:57:16.976580       1 reflector.go:351] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:16.982828386Z I0611 10:57:16.982747       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:17.475957662Z I0611 10:57:17.475892       1 reflector.go:351] Caches populated for *v1.SecurityContextConstraints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:17.585669809Z I0611 10:57:17.585596       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:18.141057490Z I0611 10:57:18.140974       1 reflector.go:351] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:18.176730003Z I0611 10:57:18.176683       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:18.411217469Z I0611 10:57:18.411139       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:18.776779875Z I0611 10:57:18.776712       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:19.216643767Z I0611 10:57:19.216561       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:19.579337622Z I0611 10:57:19.579251       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:19.778486204Z E0611 10:57:19.778414       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:19.778486204Z E0611 10:57:19.778449       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:19.778977047Z E0611 10:57:19.778938       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:57:19.984832114Z I0611 10:57:19.984758       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:20.842433565Z I0611 10:57:20.842356       1 reflector.go:351] Caches populated for *v1.CustomResourceDefinition from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:20.843025117Z I0611 10:57:20.842976       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:20.843484557Z I0611 10:57:20.843441       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:20.844112612Z I0611 10:57:20.844052       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:20.844534248Z I0611 10:57:20.844493       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:20.950392088Z W0611 10:57:20.950329       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:57:20.974392983Z I0611 10:57:20.974293       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:20.974824020Z E0611 10:57:20.974786       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:20.984124732Z I0611 10:57:20.984057       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:21.452951751Z I0611 10:57:21.452893       1 reflector.go:351] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:21.453640411Z I0611 10:57:21.453584       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:21.778650078Z E0611 10:57:21.778590       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:21.778650078Z E0611 10:57:21.778631       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:21.779134420Z E0611 10:57:21.779112       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:57:21.953687755Z W0611 10:57:21.953576       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:57:22.190959164Z I0611 10:57:22.190897       1 reflector.go:351] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:22.979632999Z I0611 10:57:22.979537       1 request.go:697] Waited for 1.002404191s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-06-11T10:57:22.996075639Z I0611 10:57:22.995977       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:23.578694328Z E0611 10:57:23.578626       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:23.578694328Z E0611 10:57:23.578659       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:23.579188869Z E0611 10:57:23.579126       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:57:23.788467227Z I0611 10:57:23.788398       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:24.053288012Z W0611 10:57:24.053220       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:57:24.173518912Z I0611 10:57:24.173460       1 request.go:697] Waited for 1.009256864s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:57:24.978357914Z I0611 10:57:24.978285       1 reflector.go:351] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:25.056521385Z W0611 10:57:25.056452       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T10:57:25.176494064Z I0611 10:57:25.176402       1 request.go:697] Waited for 1.388216753s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-06-11T10:57:25.190490105Z I0611 10:57:25.190415       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-7 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:25.977965392Z E0611 10:57:25.977884       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:25.977965392Z E0611 10:57:25.977920       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:25.978495335Z E0611 10:57:25.978438       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:57:26.187345158Z I0611 10:57:26.187257       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "configmap \"sa-token-signing-certs-6\" not found"
2024-06-11T10:57:26.208562988Z I0611 10:57:26.208486       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 7 created because configmap "sa-token-signing-certs-6" not found
2024-06-11T10:57:26.210408538Z I0611 10:57:26.210295       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:26.215191728Z I0611 10:57:26.215124       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:57:26.217965254Z I0611 10:57:26.217912       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: bound-sa-token-signing-certs-7,config-7,etcd-serving-ca-7,kube-apiserver-audit-policies-7,kube-apiserver-cert-syncer-kubeconfig-7,kube-apiserver-pod-7,kubelet-serving-ca-7,sa-token-signing-certs-7
2024-06-11T10:57:26.243559140Z I0611 10:57:26.243501       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:26.245817224Z I0611 10:57:26.245716       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:57:26.247141832Z I0611 10:57:26.247085       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "configmap \"sa-token-signing-certs-6\" not found"
2024-06-11T10:57:26.298293502Z E0611 10:57:26.298220       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: configmaps: bound-sa-token-signing-certs-7,config-7,etcd-serving-ca-7,kube-apiserver-audit-policies-7,kube-apiserver-cert-syncer-kubeconfig-7,kube-apiserver-pod-7,kubelet-serving-ca-7,sa-token-signing-certs-7
2024-06-11T10:57:26.299081666Z I0611 10:57:26.299007       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:26.299368789Z E0611 10:57:26.299320       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:26.301952000Z I0611 10:57:26.301905       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:57:26.303432021Z I0611 10:57:26.303369       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: configmaps: bound-sa-token-signing-certs-7,config-7,etcd-serving-ca-7,kube-apiserver-audit-policies-7,kube-apiserver-cert-syncer-kubeconfig-7,kube-apiserver-pod-7,kubelet-serving-ca-7,sa-token-signing-certs-7","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:57:26.304852536Z I0611 10:57:26.304812       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:26.305407082Z I0611 10:57:26.305361       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:26.324022599Z I0611 10:57:26.323967       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]" to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: configmaps: bound-sa-token-signing-certs-7,config-7,etcd-serving-ca-7,kube-apiserver-audit-policies-7,kube-apiserver-cert-syncer-kubeconfig-7,kube-apiserver-pod-7,kubelet-serving-ca-7,sa-token-signing-certs-7"
2024-06-11T10:57:26.362528638Z E0611 10:57:26.359560       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:26.362528638Z E0611 10:57:26.360627       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:26.362528638Z I0611 10:57:26.360929       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:26.362528638Z I0611 10:57:26.361193       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:57:26.362612344Z I0611 10:57:26.362499       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:26.363293200Z I0611 10:57:26.363222       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:57:26.381806409Z I0611 10:57:26.381740       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: configmaps: bound-sa-token-signing-certs-7,config-7,etcd-serving-ca-7,kube-apiserver-audit-policies-7,kube-apiserver-cert-syncer-kubeconfig-7,kube-apiserver-pod-7,kubelet-serving-ca-7,sa-token-signing-certs-7" to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]"
2024-06-11T10:57:27.373270723Z I0611 10:57:27.373204       1 request.go:697] Waited for 1.157209124s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:57:27.809961817Z I0611 10:57:27.809895       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "configmap \"sa-token-signing-certs-6\" not found"
2024-06-11T10:57:27.811926077Z I0611 10:57:27.811892       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:57:27.820192951Z I0611 10:57:27.820137       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:27.822486438Z I0611 10:57:27.821742       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]\nRevisionControllerDegraded: configmap \"revision-status-7\" not found","reason":"GuardController_SyncError::InstallerController_Error::RevisionController_ContentCreationError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:57:27.822884170Z E0611 10:57:27.822252       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:27.822958076Z I0611 10:57:27.822388       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:27.843700567Z I0611 10:57:27.837383       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]" to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]\nRevisionControllerDegraded: configmap \"revision-status-7\" not found"
2024-06-11T10:57:28.573219930Z I0611 10:57:28.573154       1 request.go:697] Waited for 1.595551453s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:57:28.577527581Z E0611 10:57:28.577479       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:28.577527581Z E0611 10:57:28.577511       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:28.578064725Z E0611 10:57:28.578037       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:57:29.175785619Z I0611 10:57:29.175718       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:29.177380354Z E0611 10:57:29.177276       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:29.178516851Z I0611 10:57:29.178462       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:29.178603558Z I0611 10:57:29.178576       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:29.178703367Z E0611 10:57:29.178666       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:29.180151890Z E0611 10:57:29.180076       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:29.181622915Z E0611 10:57:29.181564       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:29.181909640Z I0611 10:57:29.181856       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:29.181995447Z I0611 10:57:29.181969       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:29.183154246Z E0611 10:57:29.183095       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:29.183154246Z I0611 10:57:29.183113       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:29.184152831Z I0611 10:57:29.184102       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:29.184522862Z E0611 10:57:29.184472       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:29.573552168Z I0611 10:57:29.573453       1 request.go:697] Waited for 1.763489942s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-06-11T10:57:29.588966480Z I0611 10:57:29.588896       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "configmap \"sa-token-signing-certs-6\" not found"
2024-06-11T10:57:30.587684671Z I0611 10:57:30.587615       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:30.773697200Z I0611 10:57:30.773596       1 request.go:697] Waited for 1.994325366s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:57:31.216292624Z I0611 10:57:31.216215       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:31.216589750Z E0611 10:57:31.216550       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:31.783042947Z I0611 10:57:31.782979       1 revision_controller.go:255] down the branch indicating that our cache was out of date and we're trying to recreate a revision.
2024-06-11T10:57:31.805971686Z I0611 10:57:31.805907       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:57:31.806680346Z I0611 10:57:31.806627       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:57:31.808157071Z I0611 10:57:31.806710       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:31.809058747Z E0611 10:57:31.809011       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]
2024-06-11T10:57:31.809162556Z I0611 10:57:31.809070       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6
2024-06-11T10:57:31.826670636Z I0611 10:57:31.826611       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]\nRevisionControllerDegraded: configmap \"revision-status-7\" not found" to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]"
2024-06-11T10:57:31.841252369Z I0611 10:57:31.841210       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:31.842551279Z I0611 10:57:31.842514       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:57:31.973457048Z I0611 10:57:31.973380       1 request.go:697] Waited for 1.987862715s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-06-11T10:57:32.377947051Z E0611 10:57:32.377885       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:32.377947051Z E0611 10:57:32.377920       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:32.378400289Z E0611 10:57:32.378368       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:57:33.173367209Z I0611 10:57:33.173272       1 request.go:697] Waited for 1.994692965s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T10:57:34.173672392Z I0611 10:57:34.173576       1 request.go:697] Waited for 1.994390339s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-06-11T10:57:35.372859691Z I0611 10:57:35.372795       1 request.go:697] Waited for 1.595694127s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:35.977764140Z E0611 10:57:35.977698       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:35.977764140Z E0611 10:57:35.977737       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:35.978247581Z E0611 10:57:35.978218       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:57:36.373672817Z I0611 10:57:36.373542       1 request.go:697] Waited for 1.387447518s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:37.577993651Z I0611 10:57:37.577907       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:57:37.577993651Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:57:37.577993651Z  CurrentRevision: (int32) 0,
2024-06-11T10:57:37.577993651Z  TargetRevision: (int32) 7,
2024-06-11T10:57:37.577993651Z  LastFailedRevision: (int32) 0,
2024-06-11T10:57:37.577993651Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:57:37.577993651Z  LastFailedReason: (string) "",
2024-06-11T10:57:37.577993651Z  LastFailedCount: (int) 0,
2024-06-11T10:57:37.577993651Z  LastFallbackCount: (int) 0,
2024-06-11T10:57:37.577993651Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:57:37.577993651Z }
2024-06-11T10:57:37.577993651Z  because new revision pending
2024-06-11T10:57:37.602241701Z I0611 10:57:37.602184       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:37.605361965Z I0611 10:57:37.605296       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:57:37.622211490Z I0611 10:57:37.622138       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 6" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 6" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7"
2024-06-11T10:57:37.651995308Z I0611 10:57:37.651923       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:37.653769858Z I0611 10:57:37.653713       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:57:37.671225134Z I0611 10:57:37.669696       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: kube-apiserver-audit-policies-6,sa-token-signing-certs-6, secrets: etcd-client-6,localhost-recovery-client-token-6,localhost-recovery-serving-certkey-6]" to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]"
2024-06-11T10:57:38.177475141Z E0611 10:57:38.177410       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:38.177475141Z E0611 10:57:38.177448       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:38.177920579Z E0611 10:57:38.177887       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:57:38.758450771Z I0611 10:57:38.758379       1 reflector.go:351] Caches populated for *v1.Proxy from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:38.772695221Z I0611 10:57:38.772642       1 request.go:697] Waited for 1.168554461s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:57:39.370592100Z I0611 10:57:39.370509       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:39.772760224Z I0611 10:57:39.772705       1 request.go:697] Waited for 1.741126816s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-06-11T10:57:40.773675084Z I0611 10:57:40.773604       1 request.go:697] Waited for 1.595762235s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods
2024-06-11T10:57:40.788364864Z I0611 10:57:40.788116       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:41.972882869Z I0611 10:57:41.972810       1 request.go:697] Waited for 1.185158449s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T10:57:42.973319560Z I0611 10:57:42.973236       1 request.go:697] Waited for 1.787604092s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-06-11T10:57:43.973675029Z I0611 10:57:43.973602       1 request.go:697] Waited for 1.795652875s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:57:43.977602558Z E0611 10:57:43.977545       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:43.977661163Z E0611 10:57:43.977595       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:43.978964372Z E0611 10:57:43.978435       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:57:44.187889467Z I0611 10:57:44.187814       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:45.173601610Z I0611 10:57:45.173541       1 request.go:697] Waited for 1.795398945s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:46.183824406Z I0611 10:57:46.183732       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:46.372811131Z I0611 10:57:46.372739       1 request.go:697] Waited for 1.78565173s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-06-11T10:57:47.373528831Z I0611 10:57:47.373466       1 request.go:697] Waited for 1.58789667s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:57:47.378087598Z E0611 10:57:47.378028       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:47.378087598Z E0611 10:57:47.378065       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:47.378591639Z E0611 10:57:47.378557       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:57:47.378887863Z E0611 10:57:47.378840       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:47.585923065Z I0611 10:57:47.585749       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-apiserver because it was missing
2024-06-11T10:57:47.779512783Z I0611 10:57:47.779408       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:57:48.573544441Z I0611 10:57:48.573488       1 request.go:697] Waited for 1.594063899s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T10:57:49.573658024Z I0611 10:57:49.573584       1 request.go:697] Waited for 1.595715733s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-06-11T10:57:49.946714620Z I0611 10:57:49.946655       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:50.578386880Z E0611 10:57:50.578331       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:50.578792712Z E0611 10:57:50.578762       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:57:50.773647032Z I0611 10:57:50.773558       1 request.go:697] Waited for 1.586221267s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/revision-status-1
2024-06-11T10:57:51.972828575Z I0611 10:57:51.972731       1 request.go:697] Waited for 1.993194499s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:57:52.184449147Z I0611 10:57:52.184361       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:52.972925857Z I0611 10:57:52.972849       1 request.go:697] Waited for 2.184827759s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:57:53.642085641Z I0611 10:57:53.642009       1 reflector.go:351] Caches populated for *v1.KubeAPIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:53.973464775Z I0611 10:57:53.973398       1 request.go:697] Waited for 2.195570925s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-06-11T10:57:54.369061389Z I0611 10:57:54.368975       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:54.776802760Z E0611 10:57:54.776739       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:54.776802760Z E0611 10:57:54.776775       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:54.777291184Z E0611 10:57:54.777266       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:57:55.173641966Z I0611 10:57:55.173490       1 request.go:697] Waited for 1.793420556s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T10:57:56.373573553Z I0611 10:57:56.373506       1 request.go:697] Waited for 1.392246885s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:56.578091060Z I0611 10:57:56.578001       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:57:57.374971631Z I0611 10:57:57.374920       1 reflector.go:351] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:57.375509958Z I0611 10:57:57.375438       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:57:57.573201409Z I0611 10:57:57.573130       1 request.go:697] Waited for 1.395797643s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:57:57.580878730Z E0611 10:57:57.580820       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:57.580878730Z E0611 10:57:57.580859       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:57.581471878Z E0611 10:57:57.581404       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:57:59.579567457Z E0611 10:57:59.579497       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:59.579567457Z E0611 10:57:59.579548       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:59.580093300Z E0611 10:57:59.580064       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:58:00.778902004Z E0611 10:58:00.778840       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:58:00.778902004Z E0611 10:58:00.778880       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:58:00.779373342Z E0611 10:58:00.779347       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:58:00.980510117Z I0611 10:58:00.980451       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:58:06.635794029Z E0611 10:58:06.635725       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:58:06.701723099Z E0611 10:58:06.700031       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:58:06.702641873Z E0611 10:58:06.702568       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:58:06.743935974Z E0611 10:58:06.743876       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:58:06.743935974Z E0611 10:58:06.743926       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:58:06.744568324Z E0611 10:58:06.744508       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:58:07.189088359Z E0611 10:58:07.188879       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:58:07.189225670Z E0611 10:58:07.189205       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:58:07.190019033Z E0611 10:58:07.189958       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:58:07.256529750Z E0611 10:58:07.256472       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:58:07.256594555Z E0611 10:58:07.256545       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:58:07.257042591Z E0611 10:58:07.256991       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:58:09.368175552Z I0611 10:58:09.368101       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T10:58:10.442079998Z E0611 10:58:10.442009       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:58:10.451973189Z E0611 10:58:10.451909       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:58:10.452637842Z E0611 10:58:10.452597       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:58:13.171398842Z E0611 10:58:13.171331       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:13.179383626Z E0611 10:58:13.179333       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:13.195582112Z E0611 10:58:13.195528       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:13.208103329Z I0611 10:58:13.208008       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0" (last termination at 2024-06-11 10:56:00 +0000 UTC) at 2024-06-11 10:58:13 +0000 UTC
2024-06-11T10:58:13.247713229Z E0611 10:58:13.247656       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:13.292821632Z E0611 10:58:13.292753       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:13.377754250Z E0611 10:58:13.377702       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:13.541766858Z E0611 10:58:13.541703       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:13.865259142Z E0611 10:58:13.865179       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:14.509731427Z E0611 10:58:14.509672       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:15.793466415Z E0611 10:58:15.793411       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:18.358906468Z E0611 10:58:18.358843       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:21.548356578Z E0611 10:58:21.548237       1 leaderelection.go:332] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:23.172225246Z E0611 10:58:23.172133       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:23.484704785Z E0611 10:58:23.484617       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:28.831685284Z E0611 10:58:28.831604       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:28.840057006Z E0611 10:58:28.840002       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:28.855633763Z E0611 10:58:28.855573       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:28.881458382Z E0611 10:58:28.881392       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:28.925314041Z E0611 10:58:28.925254       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:29.009789018Z E0611 10:58:29.009727       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:29.174060324Z E0611 10:58:29.174009       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:29.499119978Z E0611 10:58:29.499059       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:30.143812782Z E0611 10:58:30.143746       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:31.430524191Z E0611 10:58:31.430454       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:33.172049396Z E0611 10:58:33.171982       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.994332396Z E0611 10:58:33.994262       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:39.119138722Z E0611 10:58:39.119080       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:41.141998997Z E0611 10:58:41.141942       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:42.538183624Z E0611 10:58:42.538037       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:42.547043840Z E0611 10:58:42.546802       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:42.548004607Z E0611 10:58:42.547967       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:42.555581434Z E0611 10:58:42.555540       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:42.560218957Z E0611 10:58:42.560173       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:42.938430074Z E0611 10:58:42.938369       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:43.144229794Z E0611 10:58:43.144155       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:43.339091853Z E0611 10:58:43.339013       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:44.139911475Z E0611 10:58:44.139854       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:44.338955025Z E0611 10:58:44.338895       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:45.139858853Z E0611 10:58:45.139803       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:45.338932405Z E0611 10:58:45.338873       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:45.556814066Z E0611 10:58:45.556746       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:45.939868120Z E0611 10:58:45.939809       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:46.338140932Z E0611 10:58:46.338088       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:47.549736237Z E0611 10:58:47.549659       1 leaderelection.go:332] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:47.556166585Z E0611 10:58:47.556102       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:47.738971805Z E0611 10:58:47.738910       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:47.940219808Z E0611 10:58:47.940149       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:48.139686087Z E0611 10:58:48.139638       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:49.558059534Z E0611 10:58:49.557988       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:49.738378386Z E0611 10:58:49.738285       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:50.139519446Z E0611 10:58:50.139464       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:50.340566611Z E0611 10:58:50.340515       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:51.757581301Z E0611 10:58:51.757501       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:51.940072358Z E0611 10:58:51.940021       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:52.140057686Z E0611 10:58:52.139995       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:52.738786881Z E0611 10:58:52.738728       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:53.758509959Z E0611 10:58:53.758433       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:53.940229260Z E0611 10:58:53.940175       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:54.340152213Z E0611 10:58:54.340083       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:55.539886268Z E0611 10:58:55.539831       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:55.758498049Z E0611 10:58:55.758422       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:56.540468956Z E0611 10:58:56.540391       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:57.560865483Z E0611 10:58:57.560794       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:57.940199340Z E0611 10:58:57.940147       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:58.339207226Z E0611 10:58:58.339139       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:59.540349655Z E0611 10:58:59.540264       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:59.756106188Z E0611 10:58:59.756039       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:00.540466005Z E0611 10:59:00.540399       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:01.553623438Z E0611 10:59:01.553556       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:02.540042267Z E0611 10:59:02.539975       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:03.140043548Z E0611 10:59:03.139989       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:03.739956622Z E0611 10:59:03.739894       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:04.355847245Z E0611 10:59:04.355779       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:04.940846346Z E0611 10:59:04.940786       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:06.140313968Z E0611 10:59:06.140245       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:07.740664021Z E0611 10:59:07.740612       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:07.955361773Z E0611 10:59:07.955284       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:08.540805463Z E0611 10:59:08.540744       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:08.738405500Z E0611 10:59:08.738325       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:09.940210776Z E0611 10:59:09.940155       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:12.515067593Z E0611 10:59:12.515004       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:13.106573914Z E0611 10:59:13.106505       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:13.174323927Z E0611 10:59:13.174224       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:13.549988514Z E0611 10:59:13.549903       1 leaderelection.go:332] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:17.650861516Z E0611 10:59:17.650795       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:18.785190241Z E0611 10:59:18.785135       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.175085541Z E0611 10:59:23.175030       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.380605630Z E0611 10:59:23.380525       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:27.906637113Z E0611 10:59:27.906581       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:29.219519233Z E0611 10:59:29.219466       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:31.305945007Z E0611 10:59:31.305871       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:00:03.608421581Z I0611 11:00:03.608353       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:13.960070379Z I0611 11:00:13.960015       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:16.630755907Z I0611 11:00:16.630675       1 reflector.go:351] Caches populated for *v1.Proxy from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:21.224518928Z I0611 11:00:21.224456       1 reflector.go:351] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:22.470483360Z I0611 11:00:22.470413       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:23.732633510Z I0611 11:00:23.732555       1 reflector.go:351] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:25.458709896Z I0611 11:00:25.458653       1 reflector.go:351] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:25.458816302Z I0611 11:00:25.458795       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com
2024-06-11T11:00:25.459365037Z I0611 11:00:25.459318       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:27.620473965Z I0611 11:00:27.620407       1 reflector.go:351] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:27.683215784Z I0611 11:00:27.683151       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:28.365525006Z I0611 11:00:28.365462       1 reflector.go:351] Caches populated for *v1.APIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:28.393927180Z I0611 11:00:28.393855       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:28.552524587Z I0611 11:00:28.552461       1 reflector.go:351] Caches populated for *v1alpha1.StorageVersionMigration from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:28.621091270Z I0611 11:00:28.621025       1 reflector.go:351] Caches populated for *v1.CustomResourceDefinition from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:28.621616703Z I0611 11:00:28.621570       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:28.622124335Z I0611 11:00:28.622082       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:28.622509159Z I0611 11:00:28.622461       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:28.622877882Z I0611 11:00:28.622835       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:28.733336382Z W0611 11:00:28.733253       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T11:00:29.430552835Z I0611 11:00:29.430479       1 reflector.go:351] Caches populated for *v1.ValidatingWebhookConfiguration from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:29.737136686Z W0611 11:00:29.737073       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T11:00:29.784578349Z I0611 11:00:29.784511       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:30.373971367Z I0611 11:00:30.373885       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:31.168748514Z I0611 11:00:31.168687       1 reflector.go:351] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:31.169121537Z I0611 11:00:31.169089       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:31.662844779Z I0611 11:00:31.662766       1 reflector.go:351] Caches populated for *v1.Authentication from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:31.846930978Z W0611 11:00:31.846864       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T11:00:32.360138436Z I0611 11:00:32.360067       1 reflector.go:351] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:32.849858028Z W0611 11:00:32.849791       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T11:00:33.171634728Z I0611 11:00:33.171560       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:33.370329040Z I0611 11:00:33.370252       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:33.571620814Z I0611 11:00:33.571554       1 reflector.go:351] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:33.572098444Z I0611 11:00:33.572059       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:34.172852771Z I0611 11:00:34.172784       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:34.173257096Z I0611 11:00:34.173210       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:34.264818416Z I0611 11:00:34.264755       1 reflector.go:351] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:34.951925005Z W0611 11:00:34.951850       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T11:00:35.927074205Z I0611 11:00:35.926992       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:35.956003380Z W0611 11:00:35.955940       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T11:00:36.232629214Z I0611 11:00:36.232559       1 reflector.go:351] Caches populated for *v1.KubeAPIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:38.421665992Z I0611 11:00:38.421614       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:39.613013530Z I0611 11:00:39.612951       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:40.741146782Z I0611 11:00:40.739993       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:41.117075493Z I0611 11:00:41.117024       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:42.345370302Z I0611 11:00:42.345276       1 reflector.go:351] Caches populated for *v1.Network from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:42.345532712Z I0611 11:00:42.345466       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-06-11T11:00:42.375942782Z I0611 11:00:42.375890       1 reflector.go:351] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:43.355525103Z I0611 11:00:43.355462       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:43.795839683Z I0611 11:00:43.795775       1 reflector.go:351] Caches populated for *v1.Image from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:47.109754023Z I0611 11:00:47.109698       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:49.092229898Z I0611 11:00:49.092150       1 reflector.go:351] Caches populated for *v1.OAuth from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:49.510591573Z I0611 11:00:49.510529       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:51.312843913Z E0611 11:00:51.312779       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:00:51.312843913Z E0611 11:00:51.312815       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:00:51.313414648Z E0611 11:00:51.313382       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:00:51.930986925Z I0611 11:00:51.930920       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:52.512189200Z I0611 11:00:52.512111       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:52.911734382Z I0611 11:00:52.911669       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:52.944345456Z I0611 11:00:52.944262       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:53.318977329Z I0611 11:00:53.318906       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0" at 2024-06-11 10:59:24 +0000 UTC
2024-06-11T11:00:53.708497604Z I0611 11:00:53.708442       1 request.go:697] Waited for 1.194533296s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:00:53.714562171Z I0611 11:00:53.714505       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:53.715446024Z I0611 11:00:53.715400       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:53.736203381Z I0611 11:00:53.736153       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:53.740559244Z I0611 11:00:53.740495       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:54.908902555Z I0611 11:00:54.908773       1 request.go:697] Waited for 1.589759116s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T11:00:55.110802074Z I0611 11:00:55.110737       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:55.317115361Z E0611 11:00:55.317043       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:00:55.317115361Z E0611 11:00:55.317079       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:00:55.317567788Z E0611 11:00:55.317524       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:00:56.039323071Z I0611 11:00:56.039240       1 reflector.go:351] Caches populated for operator.openshift.io/v1, Resource=kubeapiservers from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:56.040186523Z I0611 11:00:56.040135       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:56.308230946Z I0611 11:00:56.308155       1 request.go:697] Waited for 1.086342548s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/kube-system/secrets?resourceVersion=19675
2024-06-11T11:00:56.310646692Z I0611 11:00:56.310586       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:57.308727398Z I0611 11:00:57.308664       1 request.go:697] Waited for 1.267120389s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:00:58.309083842Z I0611 11:00:58.309018       1 request.go:697] Waited for 1.796597734s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:00:58.313008979Z E0611 11:00:58.312961       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:00:58.313008979Z E0611 11:00:58.312996       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:00:58.313479008Z E0611 11:00:58.313443       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:00:58.577003157Z I0611 11:00:58.576920       1 reflector.go:351] Caches populated for *v1.SecurityContextConstraints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:59.508037242Z I0611 11:00:59.507983       1 request.go:697] Waited for 1.193935497s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:00:59.924913634Z I0611 11:00:59.924827       1 installer_controller.go:491] Will retry "ci-op-9xx71rvq-1e28e-w667k-master-0" for revision 7 for the 1st time because installer pod failed: installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.924913634Z W0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.924913634Z W0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.924913634Z W0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.924913634Z W0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.924913634Z W0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.924913634Z W0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.924913634Z F0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition
2024-06-11T11:00:59.925006139Z I0611 11:00:59.924934       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:00:59.925006139Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:00:59.925006139Z  CurrentRevision: (int32) 0,
2024-06-11T11:00:59.925006139Z  TargetRevision: (int32) 7,
2024-06-11T11:00:59.925006139Z  LastFailedRevision: (int32) 7,
2024-06-11T11:00:59.925006139Z  LastFailedTime: (*v1.Time)(0xc002afdbf0)(2024-06-11 11:00:59.924810527 +0000 UTC m=+680.460471688),
2024-06-11T11:00:59.925006139Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:00:59.925006139Z  LastFailedCount: (int) 1,
2024-06-11T11:00:59.925006139Z  LastFallbackCount: (int) 0,
2024-06-11T11:00:59.925006139Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:00:59.925006139Z   (string) (len=2059) "installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition\n"
2024-06-11T11:00:59.925006139Z  }
2024-06-11T11:00:59.925006139Z }
2024-06-11T11:00:59.925006139Z  because installer pod failed: installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z W0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z W0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z W0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z W0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z W0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z W0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z F0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition
2024-06-11T11:00:59.925006139Z I0611 11:00:59.924928       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z W0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z W0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z W0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z W0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z W0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z W0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:59.925006139Z F0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition
2024-06-11T11:00:59.961894206Z I0611 11:00:59.961846       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:00:59.965237203Z I0611 11:00:59.965170       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"GuardController_SyncError::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:23Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 7","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:59.988818688Z I0611 11:00:59.988382       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-06-11T11:01:00.508271806Z I0611 11:01:00.508213       1 request.go:697] Waited for 1.008150928s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-06-11T11:01:00.713268349Z E0611 11:01:00.713211       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:00.713268349Z E0611 11:01:00.713246       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:01:00.713708875Z E0611 11:01:00.713679       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:01:01.508425465Z I0611 11:01:01.508364       1 request.go:697] Waited for 1.544319829s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T11:01:01.768558647Z W0611 11:01:01.768489       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T11:01:02.508983247Z I0611 11:01:02.508926       1 request.go:697] Waited for 1.794619534s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:01:02.771415565Z W0611 11:01:02.771347       1 degraded_webhook.go:147] failed to connect to webhook "alertmanagerconfigs.monitoring.coreos.com" via service "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443": dial tcp 172.30.223.182:8443: connect: connection refused
2024-06-11T11:01:03.510138665Z I0611 11:01:03.510077       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:03.709007748Z I0611 11:01:03.708948       1 request.go:697] Waited for 1.341093889s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-06-11T11:01:03.803139379Z I0611 11:01:03.803042       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:03.916342129Z E0611 11:01:03.916238       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:03.916342129Z E0611 11:01:03.916275       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:01:03.916745253Z E0611 11:01:03.916716       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:01:04.709060101Z I0611 11:01:04.708994       1 request.go:697] Waited for 1.531811793s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:01:05.909044400Z I0611 11:01:05.908980       1 request.go:697] Waited for 1.395783302s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-06-11T11:01:06.313623769Z E0611 11:01:06.313561       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:06.313623769Z E0611 11:01:06.313600       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:01:06.314292308Z E0611 11:01:06.314242       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:01:06.512861174Z I0611 11:01:06.512807       1 installer_controller.go:491] Will retry "ci-op-9xx71rvq-1e28e-w667k-master-0" for revision 7 for the 1st time because installer pod failed: installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512861174Z W0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512861174Z W0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512861174Z W0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512861174Z W0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512861174Z W0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512861174Z W0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512861174Z F0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition
2024-06-11T11:01:06.512951379Z I0611 11:01:06.512908       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512951379Z W0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512951379Z W0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512951379Z W0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512951379Z W0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512951379Z W0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512951379Z W0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512951379Z F0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition
2024-06-11T11:01:06.512976781Z I0611 11:01:06.512924       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:01:06.512976781Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:01:06.512976781Z  CurrentRevision: (int32) 0,
2024-06-11T11:01:06.512976781Z  TargetRevision: (int32) 7,
2024-06-11T11:01:06.512976781Z  LastFailedRevision: (int32) 7,
2024-06-11T11:01:06.512976781Z  LastFailedTime: (*v1.Time)(0xc003109248)(2024-06-11 11:01:06.51278957 +0000 UTC m=+687.048450731),
2024-06-11T11:01:06.512976781Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:01:06.512976781Z  LastFailedCount: (int) 1,
2024-06-11T11:01:06.512976781Z  LastFallbackCount: (int) 0,
2024-06-11T11:01:06.512976781Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:01:06.512976781Z   (string) (len=2059) "installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition\n"
2024-06-11T11:01:06.512976781Z  }
2024-06-11T11:01:06.512976781Z }
2024-06-11T11:01:06.512976781Z  because installer pod failed: installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512976781Z W0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512976781Z W0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512976781Z W0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512976781Z W0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512976781Z W0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512976781Z W0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:01:06.512976781Z F0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition
2024-06-11T11:01:06.535349695Z I0611 11:01:06.535275       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:01:07.708714688Z I0611 11:01:07.708656       1 request.go:697] Waited for 1.172349633s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:01:08.709041095Z I0611 11:01:08.708802       1 request.go:697] Waited for 1.727227812s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-06-11T11:01:08.914114497Z E0611 11:01:08.914014       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:08.914114497Z E0611 11:01:08.914056       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:01:08.914585425Z E0611 11:01:08.914550       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:01:09.397160973Z I0611 11:01:09.397098       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:01:09.411006904Z I0611 11:01:09.410951       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:01:09.908201329Z I0611 11:01:09.908136       1 request.go:697] Waited for 1.191207557s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-06-11T11:01:10.908836954Z I0611 11:01:10.908744       1 request.go:697] Waited for 1.192830754s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-apiserver/configmaps?resourceVersion=20287
2024-06-11T11:01:10.918273120Z I0611 11:01:10.918234       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:15.137239673Z E0611 11:01:15.137171       1 degraded_webhook.go:68] alertmanagerconfigs.openshift.io: skipping checking the webhook "alertmanagerconfigs.openshift.io" via "prometheus-operator-admission-webhook.openshift-monitoring.svc:8443" service because the caBundle (provided by the service-ca-operator) is empty. Please check the service-ca's logs if the issue persists
2024-06-11T11:01:15.271523853Z I0611 11:01:15.271437       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:01:16.309097957Z I0611 11:01:16.309020       1 request.go:697] Waited for 1.020783557s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:16.690904159Z I0611 11:01:16.690843       1 reflector.go:351] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:17.708484872Z I0611 11:01:17.708412       1 request.go:697] Waited for 1.016891183s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T11:01:19.880674284Z E0611 11:01:19.880598       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:01:19.891447930Z E0611 11:01:19.891392       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:19.891820053Z E0611 11:01:19.891787       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:01:20.002659907Z I0611 11:01:20.002607       1 reflector.go:351] Caches populated for *v1.MutatingWebhookConfiguration from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:20.320991720Z E0611 11:01:20.320896       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:01:20.330617497Z E0611 11:01:20.330561       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:20.331008421Z E0611 11:01:20.330981       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:01:21.127783758Z I0611 11:01:21.127686       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-retry-1-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-apiserver because it was missing
2024-06-11T11:01:21.129157640Z E0611 11:01:21.129101       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:21.129272547Z E0611 11:01:21.129254       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:01:21.319489668Z I0611 11:01:21.319430       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:01:22.508913779Z I0611 11:01:22.508851       1 request.go:697] Waited for 1.121720246s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-06-11T11:01:23.514837915Z E0611 11:01:23.514766       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:01:23.708948733Z I0611 11:01:23.708884       1 request.go:697] Waited for 1.348239453s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:24.909093747Z I0611 11:01:24.909023       1 request.go:697] Waited for 1.593699167s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:01:26.115237917Z E0611 11:01:26.115172       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:26.115237917Z E0611 11:01:26.115208       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:01:26.115770948Z E0611 11:01:26.115726       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:01:26.912328814Z I0611 11:01:26.912235       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:01:28.512845486Z I0611 11:01:28.512706       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:01:33.932343537Z E0611 11:01:33.932266       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:33.932408840Z E0611 11:01:33.932349       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:01:33.932908169Z E0611 11:01:33.932871       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:01:36.528487220Z E0611 11:01:36.528429       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:36.528487220Z E0611 11:01:36.528465       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:01:36.528997149Z E0611 11:01:36.528965       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:01:50.559117417Z E0611 11:01:50.559050       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:50.559117417Z E0611 11:01:50.559096       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:01:50.559717351Z E0611 11:01:50.559677       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:01:50.665540479Z E0611 11:01:50.665461       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:50.665540479Z E0611 11:01:50.665521       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:01:50.666291022Z E0611 11:01:50.666235       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:01:54.051435360Z E0611 11:01:54.051281       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:54.051435360Z E0611 11:01:54.051426       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:01:54.052320510Z E0611 11:01:54.052248       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:02:00.722450080Z I0611 11:02:00.722256       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0" (last termination at 2024-06-11 10:59:24 +0000 UTC) at 2024-06-11 11:02:00 +0000 UTC
2024-06-11T11:02:01.240378084Z E0611 11:02:01.240318       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:02:01.240465389Z E0611 11:02:01.240374       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:02:01.240884313Z E0611 11:02:01.240855       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:02:01.623036035Z I0611 11:02:01.622976       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:02:02.824064483Z E0611 11:02:02.823993       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:02:02.824064483Z E0611 11:02:02.824037       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:02:02.824598313Z E0611 11:02:02.824555       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:02:04.419457880Z I0611 11:02:04.419401       1 request.go:697] Waited for 1.176085617s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:02:05.023188475Z E0611 11:02:05.023118       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:02:05.023188475Z E0611 11:02:05.023157       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:02:05.023654701Z E0611 11:02:05.023626       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:02:05.823667380Z I0611 11:02:05.823609       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 5
2024-06-11T11:02:07.023665848Z I0611 11:02:07.023594       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 5
2024-06-11T11:02:13.485584607Z E0611 11:02:13.485479       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:02:13.485584607Z E0611 11:02:13.485522       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:02:13.486061933Z E0611 11:02:13.486026       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:02:14.077043010Z I0611 11:02:14.076981       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 5
2024-06-11T11:02:24.364553416Z I0611 11:02:24.364499       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:03:12.680683096Z I0611 11:03:12.680561       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0" (last termination at 2024-06-11 10:59:24 +0000 UTC) at 2024-06-11 11:03:12 +0000 UTC
2024-06-11T11:03:13.191630942Z E0611 11:03:13.191576       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:13.199714371Z E0611 11:03:13.199654       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:13.212675260Z E0611 11:03:13.212611       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:13.235788388Z E0611 11:03:13.235735       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:13.278815574Z E0611 11:03:13.278759       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:13.362890241Z E0611 11:03:13.362800       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:13.526452730Z E0611 11:03:13.526388       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:13.850564750Z E0611 11:03:13.850503       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:14.495854833Z E0611 11:03:14.495782       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:15.780293154Z E0611 11:03:15.780221       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:18.344255624Z E0611 11:03:18.344194       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:23.191909024Z E0611 11:03:23.191840       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:23.468886632Z E0611 11:03:23.468825       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:33.193176644Z E0611 11:03:33.193106       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:33.708431244Z E0611 11:03:33.708366       1 leaderelection.go:332] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:41.143589606Z E0611 11:03:41.143531       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:41.153101481Z E0611 11:03:41.153027       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:41.169967122Z E0611 11:03:41.169907       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:41.194251733Z E0611 11:03:41.194202       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:41.237953113Z E0611 11:03:41.237898       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:41.322748942Z E0611 11:03:41.322681       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:41.487273548Z E0611 11:03:41.487217       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:41.811801334Z E0611 11:03:41.811750       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:42.455441736Z E0611 11:03:42.455384       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:42.541826045Z E0611 11:03:42.541751       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:42.544443275Z E0611 11:03:42.544394       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:42.548152560Z E0611 11:03:42.548113       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:42.553839244Z E0611 11:03:42.553779       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:42.742386148Z E0611 11:03:42.742285       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:43.141731666Z E0611 11:03:43.141669       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:43.942102385Z E0611 11:03:43.942042       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:44.143291019Z E0611 11:03:44.143224       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:44.343255593Z E0611 11:03:44.343199       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:44.741442953Z I0611 11:03:44.741384       1 request.go:697] Waited for 1.004720412s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T11:03:44.745826871Z E0611 11:03:44.745775       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:45.142235543Z E0611 11:03:45.142176       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:45.343738293Z E0611 11:03:45.343681       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:45.759413025Z E0611 11:03:45.759343       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:46.142362225Z E0611 11:03:46.142279       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:46.944258427Z E0611 11:03:46.944202       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:47.141631466Z E0611 11:03:47.141571       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:47.944686232Z E0611 11:03:47.944621       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:48.169405903Z E0611 11:03:48.169329       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:48.344038651Z E0611 11:03:48.343971       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:48.742192107Z E0611 11:03:48.742130       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.342756166Z E0611 11:03:49.342703       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:50.167714079Z E0611 11:03:50.167643       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:50.741779750Z E0611 11:03:50.741704       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:51.343190153Z E0611 11:03:51.343138       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:52.160169549Z E0611 11:03:52.160072       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:52.343445649Z E0611 11:03:52.343388       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:53.143372651Z E0611 11:03:53.143265       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:53.744687149Z E0611 11:03:53.744621       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:53.943439660Z E0611 11:03:53.943377       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:54.141227221Z E0611 11:03:54.141168       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:54.741442161Z I0611 11:03:54.741390       1 request.go:697] Waited for 1.197305918s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-06-11T11:03:54.761494012Z E0611 11:03:54.761437       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:55.543864602Z E0611 11:03:55.543786       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:56.144145890Z E0611 11:03:56.144078       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:56.359183639Z E0611 11:03:56.359116       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:57.943845699Z E0611 11:03:57.943786       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:58.360289540Z E0611 11:03:58.360212       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:58.744727240Z E0611 11:03:58.744434       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:59.710130799Z E0611 11:03:59.710068       1 leaderelection.go:332] error retrieving resource lock openshift-kube-apiserver-operator/kube-apiserver-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-apiserver-operator/leases/kube-apiserver-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:59.942275171Z E0611 11:03:59.942192       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:00.559380269Z E0611 11:04:00.559317       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:00.943784168Z E0611 11:04:00.943716       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:01.343410099Z E0611 11:04:01.343346       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:02.360248394Z E0611 11:04:02.360181       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:03.144881987Z E0611 11:04:03.144817       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:03.344344544Z E0611 11:04:03.344276       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:04.745106272Z E0611 11:04:04.745045       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-apiserver-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:05.144974334Z E0611 11:04:05.144892       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:05.558634291Z E0611 11:04:05.558567       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:05.944649855Z E0611 11:04:05.944567       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:07.144495052Z E0611 11:04:07.144434       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:08.544352235Z E0611 11:04:08.544268       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:08.958558619Z E0611 11:04:08.958486       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:10.143850283Z E0611 11:04:10.143792       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:10.342574903Z E0611 11:04:10.342493       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:10.944828916Z E0611 11:04:10.944762       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:12.726775824Z E0611 11:04:12.726717       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:13.196875138Z E0611 11:04:13.196819       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:14.108123228Z E0611 11:04:14.108053       1 base_controller.go:268] KubeAPIServerStaticResources reconciliation failed: ["assets/kube-apiserver/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrole-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-auth-delegator.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-auth-delegator": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-node-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-node-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-clusterrolebinding-crd-reader.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:kube-apiserver-check-endpoints-crd-reader": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding-kube-system.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:controller:kube-apiserver-check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/check-endpoints-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-apiserver/rolebindings/system:openshift:controller:check-endpoints": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/delegated-incluster-authentication-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/authentication-reader-for-authenticated-users": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-apiserver-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/apiserver.openshift.io_apirequestcount.yaml" (string): Get "https://172.30.0.1:443/apis/apiextensions.k8s.io/v1/customresourcedefinitions/apirequestcounts.apiserver.openshift.io": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-flowschema-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-flowschema-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-apiserver/storage-version-migration-prioritylevelconfiguration-v1beta3.yaml" (string): Get "https://172.30.0.1:443/apis/migration.k8s.io/v1alpha1/storageversionmigrations/flowcontrol-prioritylevel-storage-version-migration-v1beta3": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/api-usage.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/api-usage": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/audit-errors.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/audit-errors": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/cpu-utilization.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/cpu-utilization": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-requests.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-requests": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-basic.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-basic": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/podsecurity-violations.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/podsecurity": dial tcp 172.30.0.1:443: connect: connection refused, "assets/alerts/kube-apiserver-slos-extended.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-kube-apiserver/prometheusrules/kube-apiserver-slos-extended": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:17.862549551Z E0611 11:04:17.862478       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:21.190119071Z E0611 11:04:21.190054       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubeapiservers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:23.198014063Z E0611 11:04:23.197945       1 base_controller.go:268] auditPolicyController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:59.651290114Z I0611 11:04:59.651224       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:00.052484997Z I0611 11:05:00.052412       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:03.369589313Z I0611 11:05:03.369513       1 reflector.go:351] Caches populated for *v1.Proxy from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:03.652015869Z I0611 11:05:03.651951       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:05.780271108Z I0611 11:05:05.780202       1 reflector.go:351] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:05.780764332Z I0611 11:05:05.780724       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:05:07.524182453Z I0611 11:05:07.524105       1 reflector.go:351] Caches populated for *v1.Image from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:10.157539382Z I0611 11:05:10.157480       1 reflector.go:351] Caches populated for *v1.CustomResourceDefinition from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:10.158270018Z I0611 11:05:10.158198       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:05:10.158662337Z I0611 11:05:10.158633       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:05:10.159097758Z I0611 11:05:10.159058       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:05:10.334012555Z I0611 11:05:10.333956       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:10.653898796Z I0611 11:05:10.653852       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:13.554769921Z I0611 11:05:13.554702       1 reflector.go:351] Caches populated for operator.openshift.io/v1, Resource=kubeapiservers from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:13.560088580Z I0611 11:05:13.560032       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:05:14.649155787Z I0611 11:05:14.649092       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:14.732815251Z I0611 11:05:14.732689       1 request.go:697] Waited for 1.172438057s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:05:15.065406250Z I0611 11:05:15.065341       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:17.345710500Z I0611 11:05:17.345630       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:17.413013778Z I0611 11:05:17.412955       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:18.337771123Z I0611 11:05:18.337707       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:05:18.337771123Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:05:18.337771123Z  CurrentRevision: (int32) 7,
2024-06-11T11:05:18.337771123Z  TargetRevision: (int32) 0,
2024-06-11T11:05:18.337771123Z  LastFailedRevision: (int32) 7,
2024-06-11T11:05:18.337771123Z  LastFailedTime: (*v1.Time)(0xc002b54450)(2024-06-11 11:01:06 +0000 UTC),
2024-06-11T11:05:18.337771123Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:05:18.337771123Z  LastFailedCount: (int) 1,
2024-06-11T11:05:18.337771123Z  LastFallbackCount: (int) 0,
2024-06-11T11:05:18.337771123Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:05:18.337771123Z   (string) (len=2059) "installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition\n"
2024-06-11T11:05:18.337771123Z  }
2024-06-11T11:05:18.337771123Z }
2024-06-11T11:05:18.337771123Z  because static pod is ready
2024-06-11T11:05:18.359390519Z I0611 11:05:18.359315       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 0 to 7 because static pod is ready
2024-06-11T11:05:18.362759243Z I0611 11:05:18.362671       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:05:18.363238161Z I0611 11:05:18.363192       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T11:05:18Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:05:18.382230660Z I0611 11:05:18.382173       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition\nNodeInstallerDegraded: " to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]",Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 7" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 7",Available changed from False to True ("StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 7")
2024-06-11T11:05:18.594222465Z I0611 11:05:18.594155       1 reflector.go:351] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:18.951891584Z I0611 11:05:18.951823       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:19.532710004Z I0611 11:05:19.532588       1 request.go:697] Waited for 1.16891122s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:05:19.709035141Z I0611 11:05:19.708959       1 reflector.go:351] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:19.709474262Z I0611 11:05:19.709442       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:05:20.022020794Z I0611 11:05:20.021946       1 reflector.go:351] Caches populated for *v1.KubeAPIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:20.523009949Z I0611 11:05:20.522944       1 reflector.go:351] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:20.733093820Z I0611 11:05:20.733028       1 request.go:697] Waited for 1.583872382s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:05:21.241992257Z I0611 11:05:21.241931       1 reflector.go:351] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:21.242117064Z I0611 11:05:21.242063       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com
2024-06-11T11:05:21.242657190Z I0611 11:05:21.242618       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:05:21.932315679Z I0611 11:05:21.932248       1 request.go:697] Waited for 1.395501062s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-06-11T11:05:22.143999427Z I0611 11:05:22.143929       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:22.243435241Z I0611 11:05:22.243373       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:22.611015438Z I0611 11:05:22.610943       1 reflector.go:351] Caches populated for *v1.ValidatingWebhookConfiguration from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:22.920707431Z I0611 11:05:22.920650       1 reflector.go:351] Caches populated for *v1alpha1.StorageVersionMigration from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:22.933083730Z I0611 11:05:22.932981       1 request.go:697] Waited for 1.597313132s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:05:23.933120072Z I0611 11:05:23.933064       1 request.go:697] Waited for 1.593045752s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:05:24.309199310Z I0611 11:05:24.309134       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:24.535676830Z I0611 11:05:24.535622       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:24.735079916Z I0611 11:05:24.735021       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:24.933343851Z I0611 11:05:24.933072       1 request.go:697] Waited for 1.332767632s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-06-11T11:05:25.113287651Z I0611 11:05:25.113224       1 reflector.go:351] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:25.336127605Z I0611 11:05:25.336060       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:25.337156552Z E0611 11:05:25.336581       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:05:25.337156552Z E0611 11:05:25.336632       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:05:25.536559239Z I0611 11:05:25.536485       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-1 static pod not found and needs new revision 7
2024-06-11T11:05:25.536559239Z I0611 11:05:25.536546       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:05:25.536559239Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:05:25.536559239Z  CurrentRevision: (int32) 0,
2024-06-11T11:05:25.536559239Z  TargetRevision: (int32) 7,
2024-06-11T11:05:25.536559239Z  LastFailedRevision: (int32) 0,
2024-06-11T11:05:25.536559239Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:05:25.536559239Z  LastFailedReason: (string) "",
2024-06-11T11:05:25.536559239Z  LastFailedCount: (int) 0,
2024-06-11T11:05:25.536559239Z  LastFallbackCount: (int) 0,
2024-06-11T11:05:25.536559239Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:05:25.536559239Z }
2024-06-11T11:05:25.560335722Z I0611 11:05:25.560225       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 0 to 7 because node ci-op-9xx71rvq-1e28e-w667k-master-1 static pod not found
2024-06-11T11:05:25.564697121Z I0611 11:05:25.564643       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:05:25.987929707Z I0611 11:05:25.987832       1 reflector.go:351] Caches populated for *v1.Authentication from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:26.132419191Z I0611 11:05:26.132291       1 request.go:697] Waited for 1.194849547s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-06-11T11:05:27.133171494Z I0611 11:05:27.133113       1 request.go:697] Waited for 1.567623735s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:05:27.534711792Z I0611 11:05:27.534632       1 reflector.go:351] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:28.332519447Z I0611 11:05:28.332428       1 request.go:697] Waited for 1.991196136s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:05:28.337281564Z E0611 11:05:28.337245       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:05:28.337604479Z E0611 11:05:28.337565       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:05:28.548139372Z I0611 11:05:28.548071       1 reflector.go:351] Caches populated for *v1.APIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:29.050569967Z I0611 11:05:29.050490       1 reflector.go:351] Caches populated for *v1.OAuth from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:29.136055363Z I0611 11:05:29.135972       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:29.332927834Z I0611 11:05:29.332872       1 request.go:697] Waited for 1.621408386s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets?resourceVersion=23406
2024-06-11T11:05:29.344165346Z I0611 11:05:29.344115       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:30.533091224Z I0611 11:05:30.533030       1 request.go:697] Waited for 1.78940584s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:05:30.934957436Z I0611 11:05:30.934884       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:31.138828541Z I0611 11:05:31.138761       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:31.732861951Z I0611 11:05:31.732789       1 request.go:697] Waited for 1.793085264s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:05:31.740057435Z E0611 11:05:31.739995       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:05:31.741425089Z E0611 11:05:31.741374       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:05:32.135218774Z I0611 11:05:32.135150       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:32.734459190Z I0611 11:05:32.734386       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:32.959481795Z I0611 11:05:32.959405       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-apiserver because it was missing
2024-06-11T11:05:33.139209108Z I0611 11:05:33.139054       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0" at 2024-06-11 11:04:22 +0000 UTC
2024-06-11T11:05:33.332465757Z I0611 11:05:33.332401       1 request.go:697] Waited for 1.196516854s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:05:34.141524676Z I0611 11:05:34.141462       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:05:34.533192477Z I0611 11:05:34.533119       1 request.go:697] Waited for 1.331940213s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:05:35.136793687Z E0611 11:05:35.136739       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:05:35.136793687Z E0611 11:05:35.136774       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:05:35.137366714Z E0611 11:05:35.137330       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:05:35.732632274Z I0611 11:05:35.732574       1 request.go:697] Waited for 1.394521718s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T11:05:36.400214831Z I0611 11:05:36.400154       1 reflector.go:351] Caches populated for *v1.Network from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:36.400982168Z I0611 11:05:36.400418       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-06-11T11:05:36.733051265Z I0611 11:05:36.732989       1 request.go:697] Waited for 1.195983677s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:05:36.992575755Z I0611 11:05:36.992513       1 reflector.go:351] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:37.337641964Z E0611 11:05:37.337579       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:05:37.337641964Z E0611 11:05:37.337617       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:05:37.338106585Z E0611 11:05:37.338078       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:05:38.167704253Z I0611 11:05:38.167648       1 reflector.go:351] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:38.651740088Z I0611 11:05:38.651665       1 reflector.go:351] Caches populated for *v1.MutatingWebhookConfiguration from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:39.339013888Z I0611 11:05:39.338939       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:05:39.357993874Z I0611 11:05:39.357935       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:05:42.337086648Z I0611 11:05:42.337008       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:05:46.212682374Z I0611 11:05:46.212616       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:48.293430350Z I0611 11:05:48.293365       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:50.313821733Z I0611 11:05:50.313746       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:51.715631062Z I0611 11:05:51.715544       1 reflector.go:351] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:58.891201592Z I0611 11:05:58.891142       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:58.891680114Z I0611 11:05:58.891641       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:06:01.076189754Z I0611 11:06:01.076133       1 reflector.go:351] Caches populated for *v1.SecurityContextConstraints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:06:04.413751958Z I0611 11:06:04.413680       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:06:11.930197315Z E0611 11:06:11.930102       1 guard_controller.go:293] Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:06:11.930197315Z E0611 11:06:11.930163       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:11.952334648Z E0611 11:06:11.952234       1 base_controller.go:268] GuardController reconciliation failed: [Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:06:11.953996626Z I0611 11:06:11.953945       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:06:11.957571892Z I0611 11:06:11.957528       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T11:05:18Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:06:11.974356175Z I0611 11:06:11.973156       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]" to "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]"
2024-06-11T11:06:13.120582157Z I0611 11:06:13.120519       1 request.go:697] Waited for 1.163802501s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:06:13.724024013Z I0611 11:06:13.723961       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:06:14.319022074Z I0611 11:06:14.318946       1 request.go:697] Waited for 1.494440829s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:06:15.319639262Z I0611 11:06:15.319586       1 request.go:697] Waited for 1.789417692s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-06-11T11:06:16.518842815Z I0611 11:06:16.518722       1 request.go:697] Waited for 1.789746307s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T11:06:17.518861174Z I0611 11:06:17.518782       1 request.go:697] Waited for 1.392651979s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:06:18.519206249Z I0611 11:06:18.519100       1 request.go:697] Waited for 1.19443593s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:06:19.519259188Z I0611 11:06:19.519141       1 request.go:697] Waited for 1.194374207s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:06:20.133771781Z E0611 11:06:20.133698       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:20.133969991Z I0611 11:06:20.133907       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-apiserver because it was missing
2024-06-11T11:06:20.157505670Z E0611 11:06:20.157431       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:20.157904989Z E0611 11:06:20.157854       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:20.160954229Z I0611 11:06:20.160909       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T11:05:18Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:06:20.170786280Z I0611 11:06:20.170715       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:06:20.173669012Z I0611 11:06:20.173601       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]" to "GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2"
2024-06-11T11:06:21.319062661Z I0611 11:06:21.319004       1 request.go:697] Waited for 1.160528543s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:06:22.319689869Z I0611 11:06:22.319636       1 request.go:697] Waited for 2.146643085s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:06:23.519039994Z I0611 11:06:23.518979       1 request.go:697] Waited for 2.19556933s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:06:25.732585949Z I0611 11:06:25.732509       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:06:25.923745219Z I0611 11:06:25.923673       1 core.go:226] Pod "openshift-kube-apiserver/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-1" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:bac0ddaf801035bf3d571daea9916b68407c1e9a58a3864616c1ca14e15e74bb","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.6","path":"readyz","port":6443,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master","operator":"Exists"},{"effect":"NoExecute","key":"node.kubernetes.io/not-ready","operator":"Exists"},{"effect":"NoExecute","key":"node.kubernetes.io/unreachable","operator":"Exists"},{"effect":"NoSchedule","key":"node-role.kubernetes.io/etcd","operator":"Exists"}],"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-06-11T11:06:26.919451501Z I0611 11:06:26.919393       1 request.go:697] Waited for 1.095642466s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-06-11T11:06:27.334666973Z I0611 11:06:27.334475       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-apiserver because it changed
2024-06-11T11:06:27.334847582Z E0611 11:06:27.334803       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:28.519043148Z I0611 11:06:28.518975       1 request.go:697] Waited for 1.183282925s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:06:30.325339750Z I0611 11:06:30.325261       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:06:30.923332599Z E0611 11:06:30.923244       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:30.923856422Z E0611 11:06:30.923822       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:32.323284489Z I0611 11:06:32.323225       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:06:32.323284489Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:06:32.323284489Z  CurrentRevision: (int32) 7,
2024-06-11T11:06:32.323284489Z  TargetRevision: (int32) 0,
2024-06-11T11:06:32.323284489Z  LastFailedRevision: (int32) 0,
2024-06-11T11:06:32.323284489Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:06:32.323284489Z  LastFailedReason: (string) "",
2024-06-11T11:06:32.323284489Z  LastFailedCount: (int) 0,
2024-06-11T11:06:32.323284489Z  LastFallbackCount: (int) 0,
2024-06-11T11:06:32.323284489Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:06:32.323284489Z }
2024-06-11T11:06:32.323284489Z  because static pod is ready
2024-06-11T11:06:32.342372549Z I0611 11:06:32.342284       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 0 to 7 because static pod is ready
2024-06-11T11:06:32.345849005Z I0611 11:06:32.345789       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T11:05:18Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:06:32.348451723Z I0611 11:06:32.348388       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:06:32.359364515Z I0611 11:06:32.359276       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 7" to "NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 7",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 7" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 7"
2024-06-11T11:06:33.518904470Z I0611 11:06:33.518824       1 request.go:697] Waited for 1.173734995s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T11:06:34.519374857Z I0611 11:06:34.519290       1 request.go:697] Waited for 2.166225322s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-06-11T11:06:35.719295397Z I0611 11:06:35.719224       1 request.go:697] Waited for 1.395043733s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:06:36.919125094Z I0611 11:06:36.919065       1 request.go:697] Waited for 1.196066329s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:37.523376387Z E0611 11:06:37.523292       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:37.523829907Z E0611 11:06:37.523792       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:40.326496672Z E0611 11:06:40.326429       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:40.326890989Z E0611 11:06:40.326847       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:41.723157894Z E0611 11:06:41.723096       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:41.723550912Z E0611 11:06:41.723520       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:45.523092200Z E0611 11:06:45.523017       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:45.523601217Z E0611 11:06:45.523570       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:54.156641743Z I0611 11:06:54.156561       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:06:54.291170485Z I0611 11:06:54.291104       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:06:54.307372500Z I0611 11:06:54.305549       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:06:54.466234017Z I0611 11:06:54.466158       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:06:54.484223712Z I0611 11:06:54.484153       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:06:54.520993536Z I0611 11:06:54.520935       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:06:54.594932002Z W0611 11:06:54.594869       1 degraded_webhook.go:147] failed to connect to webhook "consoleplugins.console.openshift.io" via service "webhook.openshift-console-operator.svc:9443": dial tcp 172.30.8.209:9443: connect: connection refused
2024-06-11T11:06:55.598034308Z W0611 11:06:55.597968       1 degraded_webhook.go:147] failed to connect to webhook "consoleplugins.console.openshift.io" via service "webhook.openshift-console-operator.svc:9443": dial tcp 172.30.8.209:9443: connect: connection refused
2024-06-11T11:06:57.652706961Z I0611 11:06:57.652642       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:06:57.753058693Z W0611 11:06:57.752973       1 degraded_webhook.go:147] failed to connect to webhook "consoleplugins.console.openshift.io" via service "webhook.openshift-console-operator.svc:9443": dial tcp 172.30.8.209:9443: connect: connection refused
2024-06-11T11:06:58.661444216Z I0611 11:06:58.661280       1 request.go:697] Waited for 1.009382083s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:06:58.756339607Z W0611 11:06:58.756259       1 degraded_webhook.go:147] failed to connect to webhook "consoleplugins.console.openshift.io" via service "webhook.openshift-console-operator.svc:9443": dial tcp 172.30.8.209:9443: connect: connection refused
2024-06-11T11:06:59.661657154Z I0611 11:06:59.661602       1 request.go:697] Waited for 1.196641614s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:07:00.408818435Z I0611 11:07:00.408758       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObserveInternalRegistryHostnameChanged' Internal registry hostname changed to "image-registry.openshift-image-registry.svc:5000"
2024-06-11T11:07:00.422031930Z I0611 11:07:00.421951       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-06-11T11:07:00.422031930Z   	"admission":          map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("privileged"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-06-11T11:07:00.422031930Z   	"apiServerArguments": map[string]any{"api-audiences": []any{string("https://kubernetes.default.svc")}, "authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)}, "authentication-token-webhook-version": []any{string("v1")}, "cloud-config": []any{string("/etc/kubernetes/static-pod-resources/configmaps/cloud-config/clo"...)}, ...},
2024-06-11T11:07:00.422031930Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-06-11T11:07:00.422031930Z + 	"imagePolicyConfig": map[string]any{
2024-06-11T11:07:00.422031930Z + 		"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000"),
2024-06-11T11:07:00.422031930Z + 	},
2024-06-11T11:07:00.422031930Z   	"servicesSubnet": string("172.30.0.0/16"),
2024-06-11T11:07:00.422031930Z   	"servingInfo":    map[string]any{"bindAddress": string("0.0.0.0:6443"), "bindNetwork": string("tcp4"), "cipherSuites": []any{string("TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256"), string("TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256"), string("TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384"), string("TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384"), ...}, "minTLSVersion": string("VersionTLS12"), ...},
2024-06-11T11:07:00.422031930Z   }
2024-06-11T11:07:00.461709219Z I0611 11:07:00.461650       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:07:01.289042713Z I0611 11:07:01.288886       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:07:01.460767054Z I0611 11:07:01.460699       1 request.go:697] Waited for 1.164400789s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T11:07:02.461120548Z I0611 11:07:02.461066       1 request.go:697] Waited for 1.548124086s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:07:03.461255733Z I0611 11:07:03.461142       1 request.go:697] Waited for 1.785649394s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:07:04.105965695Z I0611 11:07:04.105640       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:07:04.115999547Z I0611 11:07:04.115938       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:07:04.461561524Z I0611 11:07:04.461500       1 request.go:697] Waited for 1.775848752s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:07:05.661231203Z I0611 11:07:05.661164       1 request.go:697] Waited for 1.376379544s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:05.687962908Z I0611 11:07:05.687904       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-2 static pod not found and needs new revision 7
2024-06-11T11:07:05.688097414Z I0611 11:07:05.688074       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:07:05.688097414Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:07:05.688097414Z  CurrentRevision: (int32) 0,
2024-06-11T11:07:05.688097414Z  TargetRevision: (int32) 7,
2024-06-11T11:07:05.688097414Z  LastFailedRevision: (int32) 0,
2024-06-11T11:07:05.688097414Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:07:05.688097414Z  LastFailedReason: (string) "",
2024-06-11T11:07:05.688097414Z  LastFailedCount: (int) 0,
2024-06-11T11:07:05.688097414Z  LastFallbackCount: (int) 0,
2024-06-11T11:07:05.688097414Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:07:05.688097414Z }
2024-06-11T11:07:05.726264035Z I0611 11:07:05.726191       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-2" from revision 0 to 7 because node ci-op-9xx71rvq-1e28e-w667k-master-2 static pod not found
2024-06-11T11:07:05.733329553Z I0611 11:07:05.733258       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:07:06.465654565Z E0611 11:07:06.465536       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:06.466115586Z E0611 11:07:06.466074       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:06.860885281Z I0611 11:07:06.860819       1 request.go:697] Waited for 1.282534014s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:07:07.861179821Z I0611 11:07:07.861126       1 request.go:697] Waited for 1.791004483s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-06-11T11:07:09.061596878Z I0611 11:07:09.061535       1 request.go:697] Waited for 1.734947573s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T11:07:10.260947084Z I0611 11:07:10.260889       1 request.go:697] Waited for 1.587334692s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:07:11.087453811Z I0611 11:07:11.087366       1 core.go:358] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"privileged\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"cloud-config\":[\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/cloud.conf\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PersistentVolumeLabel\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.6:2379\",\"https://10.0.0.7:2379\",\"https://10.0.0.8:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AutomatedEtcdBackup=false\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"CSIDriverSharedResource=false\",\"ChunkSizeMiB=false\",\"CloudDualStackNodeIPs=true\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallAWS=true\",\"ClusterAPIInstallAzure=false\",\"ClusterAPIInstallGCP=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterAPIInstallNutanix=true\",\"ClusterAPIInstallOpenStack=true\",\"ClusterAPIInstallPowerVS=false\",\"ClusterAPIInstallVSphere=true\",\"DNSNameResolver=false\",\"DisableKubeletCloudCredentialProviders=true\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalCloudProvider=true\",\"ExternalCloudProviderAzure=true\",\"ExternalCloudProviderExternal=true\",\"ExternalCloudProviderGCP=true\",\"ExternalOIDC=false\",\"ExternalRouteCertificate=false\",\"GCPClusterHostedDNS=false\",\"GCPLabelsTags=false\",\"GatewayAPI=false\",\"HardwareSpeed=true\",\"ImagePolicy=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InstallAlternateInfrastructureAWS=false\",\"KMSv1=true\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImages=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MetricsServer=true\",\"MixedCPUsAllocation=false\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NewOLM=false\",\"NodeDisruptionPolicy=false\",\"NodeSwap=false\",\"OnClusterBuild=false\",\"OpenShiftPodSecurityAdmission=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"PrivateHostedZoneAWS=true\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"ServiceAccountTokenNodeBindingValidation=false\",\"ServiceAccountTokenPodNodeInfo=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereMultiVCenters=false\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://kubernetes.default.svc\"],\"service-account-jwks-uri\":[\"https://api.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/openid/v1/jwks\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"imagePolicyConfig\":{\"internalRegistryHostname\":\"image-registry.openshift-image-registry.svc:5000\"},\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T11:07:11.087567116Z I0611 11:07:11.087515       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-06-11T11:07:11.087567116Z cause by changes in data.config.yaml
2024-06-11T11:07:11.093223380Z I0611 11:07:11.093159       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required configmap/config has changed"
2024-06-11T11:07:11.261499724Z I0611 11:07:11.261438       1 request.go:697] Waited for 1.104775398s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:07:12.461363054Z I0611 11:07:12.461259       1 request.go:697] Waited for 1.369743549s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-06-11T11:07:12.867256674Z E0611 11:07:12.867151       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:12.867991808Z E0611 11:07:12.867924       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:13.660762563Z I0611 11:07:13.660701       1 request.go:697] Waited for 1.192674395s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-06-11T11:07:13.872171417Z I0611 11:07:13.870934       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:14.660932884Z I0611 11:07:14.660867       1 request.go:697] Waited for 1.391552866s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:14.691010787Z I0611 11:07:14.690944       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-2 static pod not found and needs new revision 7
2024-06-11T11:07:14.691061889Z I0611 11:07:14.691011       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:07:14.691061889Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:07:14.691061889Z  CurrentRevision: (int32) 0,
2024-06-11T11:07:14.691061889Z  TargetRevision: (int32) 7,
2024-06-11T11:07:14.691061889Z  LastFailedRevision: (int32) 0,
2024-06-11T11:07:14.691061889Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:07:14.691061889Z  LastFailedReason: (string) "",
2024-06-11T11:07:14.691061889Z  LastFailedCount: (int) 0,
2024-06-11T11:07:14.691061889Z  LastFallbackCount: (int) 0,
2024-06-11T11:07:14.691061889Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:07:14.691061889Z }
2024-06-11T11:07:15.472237549Z I0611 11:07:15.472162       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:15.661719647Z I0611 11:07:15.661642       1 request.go:697] Waited for 1.585463916s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:07:16.465712178Z E0611 11:07:16.465649       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:16.861345911Z I0611 11:07:16.861242       1 request.go:697] Waited for 1.38929827s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-06-11T11:07:16.870056897Z I0611 11:07:16.869990       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:18.061747010Z I0611 11:07:18.061678       1 request.go:697] Waited for 1.385074083s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-06-11T11:07:18.277663979Z I0611 11:07:18.277586       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cloud-config-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:18.741331327Z I0611 11:07:18.741234       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ObservedConfigChanged' Writing updated observed config:   map[string]any{
2024-06-11T11:07:18.741331327Z   	"admission":          map[string]any{"pluginConfig": map[string]any{"PodSecurity": map[string]any{"configuration": map[string]any{"defaults": map[string]any{"audit": string("restricted"), "audit-version": string("latest"), "enforce": string("privileged"), "enforce-version": string("latest"), ...}}}, "network.openshift.io/ExternalIPRanger": map[string]any{"configuration": map[string]any{"allowIngressIP": bool(false), "apiVersion": string("network.openshift.io/v1"), "kind": string("ExternalIPRangerAdmissionConfig")}}, "network.openshift.io/RestrictedEndpointsAdmission": map[string]any{"configuration": map[string]any{"apiVersion": string("network.openshift.io/v1"), "kind": string("RestrictedEndpointsAdmissionConfig"), "restrictedCIDRs": []any{string("10.128.0.0/14"), string("172.30.0.0/16")}}}}},
2024-06-11T11:07:18.741331327Z   	"apiServerArguments": map[string]any{"api-audiences": []any{string("https://kubernetes.default.svc")}, "authentication-token-webhook-config-file": []any{string("/etc/kubernetes/static-pod-resources/secrets/webhook-authenticat"...)}, "authentication-token-webhook-version": []any{string("v1")}, "cloud-config": []any{string("/etc/kubernetes/static-pod-resources/configmaps/cloud-config/clo"...)}, ...},
2024-06-11T11:07:18.741331327Z + 	"authConfig": map[string]any{
2024-06-11T11:07:18.741331327Z + 		"oauthMetadataFile": string("/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata"),
2024-06-11T11:07:18.741331327Z + 	},
2024-06-11T11:07:18.741331327Z   	"corsAllowedOrigins": []any{string(`//127\.0\.0\.1(:|$)`), string("//localhost(:|$)")},
2024-06-11T11:07:18.741331327Z   	"imagePolicyConfig":  map[string]any{"internalRegistryHostname": string("image-registry.openshift-image-registry.svc:5000")},
2024-06-11T11:07:18.741331327Z   	... // 2 identical entries
2024-06-11T11:07:18.741331327Z   }
2024-06-11T11:07:18.763747321Z I0611 11:07:18.763685       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:07:19.260735746Z I0611 11:07:19.260671       1 request.go:697] Waited for 1.337498174s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:07:19.265852673Z E0611 11:07:19.265759       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:19.670707315Z I0611 11:07:19.670612       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:20.260923472Z I0611 11:07:20.260843       1 request.go:697] Waited for 1.495629283s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:07:21.460857850Z I0611 11:07:21.460799       1 request.go:697] Waited for 1.985765604s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-06-11T11:07:21.678191882Z I0611 11:07:21.678114       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:22.461181182Z I0611 11:07:22.461120       1 request.go:697] Waited for 2.125650204s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-06-11T11:07:22.471163724Z I0611 11:07:22.471101       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:22.876141072Z I0611 11:07:22.876056       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:23.488174632Z I0611 11:07:23.488023       1 core.go:358] ConfigMap "openshift-kube-apiserver/config" changes: {"apiVersion":"v1","data":{"config.yaml":"{\"admission\":{\"pluginConfig\":{\"PodSecurity\":{\"configuration\":{\"apiVersion\":\"pod-security.admission.config.k8s.io/v1\",\"defaults\":{\"audit\":\"restricted\",\"audit-version\":\"latest\",\"enforce\":\"privileged\",\"enforce-version\":\"latest\",\"warn\":\"restricted\",\"warn-version\":\"latest\"},\"exemptions\":{\"usernames\":[\"system:serviceaccount:openshift-infra:build-controller\"]},\"kind\":\"PodSecurityConfiguration\"}},\"network.openshift.io/ExternalIPRanger\":{\"configuration\":{\"allowIngressIP\":false,\"apiVersion\":\"network.openshift.io/v1\",\"externalIPNetworkCIDRs\":null,\"kind\":\"ExternalIPRangerAdmissionConfig\"},\"location\":\"\"},\"network.openshift.io/RestrictedEndpointsAdmission\":{\"configuration\":{\"apiVersion\":\"network.openshift.io/v1\",\"kind\":\"RestrictedEndpointsAdmissionConfig\",\"restrictedCIDRs\":[\"10.128.0.0/14\",\"172.30.0.0/16\"]}}}},\"apiServerArguments\":{\"allow-privileged\":[\"true\"],\"anonymous-auth\":[\"true\"],\"api-audiences\":[\"https://kubernetes.default.svc\"],\"audit-log-format\":[\"json\"],\"audit-log-maxbackup\":[\"10\"],\"audit-log-maxsize\":[\"200\"],\"audit-log-path\":[\"/var/log/kube-apiserver/audit.log\"],\"audit-policy-file\":[\"/etc/kubernetes/static-pod-resources/configmaps/kube-apiserver-audit-policies/policy.yaml\"],\"authentication-token-webhook-config-file\":[\"/etc/kubernetes/static-pod-resources/secrets/webhook-authenticator/kubeConfig\"],\"authentication-token-webhook-version\":[\"v1\"],\"authorization-mode\":[\"Scope\",\"SystemMasters\",\"RBAC\",\"Node\"],\"client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/client-ca/ca-bundle.crt\"],\"cloud-config\":[\"/etc/kubernetes/static-pod-resources/configmaps/cloud-config/cloud.conf\"],\"enable-admission-plugins\":[\"CertificateApproval\",\"CertificateSigning\",\"CertificateSubjectRestriction\",\"DefaultIngressClass\",\"DefaultStorageClass\",\"DefaultTolerationSeconds\",\"LimitRanger\",\"MutatingAdmissionWebhook\",\"NamespaceLifecycle\",\"NodeRestriction\",\"OwnerReferencesPermissionEnforcement\",\"PersistentVolumeClaimResize\",\"PersistentVolumeLabel\",\"PodNodeSelector\",\"PodTolerationRestriction\",\"Priority\",\"ResourceQuota\",\"RuntimeClass\",\"ServiceAccount\",\"StorageObjectInUseProtection\",\"TaintNodesByCondition\",\"ValidatingAdmissionWebhook\",\"ValidatingAdmissionPolicy\",\"authorization.openshift.io/RestrictSubjectBindings\",\"authorization.openshift.io/ValidateRoleBindingRestriction\",\"config.openshift.io/DenyDeleteClusterConfiguration\",\"config.openshift.io/ValidateAPIServer\",\"config.openshift.io/ValidateAuthentication\",\"config.openshift.io/ValidateConsole\",\"config.openshift.io/ValidateFeatureGate\",\"config.openshift.io/ValidateImage\",\"config.openshift.io/ValidateOAuth\",\"config.openshift.io/ValidateProject\",\"config.openshift.io/ValidateScheduler\",\"image.openshift.io/ImagePolicy\",\"network.openshift.io/ExternalIPRanger\",\"network.openshift.io/RestrictedEndpointsAdmission\",\"quota.openshift.io/ClusterResourceQuota\",\"quota.openshift.io/ValidateClusterResourceQuota\",\"route.openshift.io/IngressAdmission\",\"scheduling.openshift.io/OriginPodNodeEnvironment\",\"security.openshift.io/DefaultSecurityContextConstraints\",\"security.openshift.io/SCCExecRestrictions\",\"security.openshift.io/SecurityContextConstraint\",\"security.openshift.io/ValidateSecurityContextConstraints\",\"storage.openshift.io/CSIInlineVolumeSecurity\"],\"enable-aggregator-routing\":[\"true\"],\"enable-logs-handler\":[\"false\"],\"endpoint-reconciler-type\":[\"lease\"],\"etcd-cafile\":[\"/etc/kubernetes/static-pod-resources/configmaps/etcd-serving-ca/ca-bundle.crt\"],\"etcd-certfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.crt\"],\"etcd-healthcheck-timeout\":[\"9s\"],\"etcd-keyfile\":[\"/etc/kubernetes/static-pod-resources/secrets/etcd-client/tls.key\"],\"etcd-prefix\":[\"kubernetes.io\"],\"etcd-readycheck-timeout\":[\"9s\"],\"etcd-servers\":[\"https://10.0.0.6:2379\",\"https://10.0.0.7:2379\",\"https://10.0.0.8:2379\",\"https://localhost:2379\"],\"event-ttl\":[\"3h\"],\"feature-gates\":[\"AdminNetworkPolicy=true\",\"AlibabaPlatform=true\",\"AutomatedEtcdBackup=false\",\"AzureWorkloadIdentity=true\",\"BareMetalLoadBalancer=true\",\"BuildCSIVolumes=true\",\"CSIDriverSharedResource=false\",\"ChunkSizeMiB=false\",\"CloudDualStackNodeIPs=true\",\"ClusterAPIInstall=false\",\"ClusterAPIInstallAWS=true\",\"ClusterAPIInstallAzure=false\",\"ClusterAPIInstallGCP=false\",\"ClusterAPIInstallIBMCloud=false\",\"ClusterAPIInstallNutanix=true\",\"ClusterAPIInstallOpenStack=true\",\"ClusterAPIInstallPowerVS=false\",\"ClusterAPIInstallVSphere=true\",\"DNSNameResolver=false\",\"DisableKubeletCloudCredentialProviders=true\",\"DynamicResourceAllocation=false\",\"EtcdBackendQuota=false\",\"EventedPLEG=false\",\"Example=false\",\"ExternalCloudProvider=true\",\"ExternalCloudProviderAzure=true\",\"ExternalCloudProviderExternal=true\",\"ExternalCloudProviderGCP=true\",\"ExternalOIDC=false\",\"ExternalRouteCertificate=false\",\"GCPClusterHostedDNS=false\",\"GCPLabelsTags=false\",\"GatewayAPI=false\",\"HardwareSpeed=true\",\"ImagePolicy=false\",\"InsightsConfig=false\",\"InsightsConfigAPI=false\",\"InsightsOnDemandDataGather=false\",\"InstallAlternateInfrastructureAWS=false\",\"KMSv1=true\",\"MachineAPIOperatorDisableMachineHealthCheckController=false\",\"MachineAPIProviderOpenStack=false\",\"MachineConfigNodes=false\",\"ManagedBootImages=false\",\"MaxUnavailableStatefulSet=false\",\"MetricsCollectionProfiles=false\",\"MetricsServer=true\",\"MixedCPUsAllocation=false\",\"NetworkDiagnosticsConfig=true\",\"NetworkLiveMigration=true\",\"NewOLM=false\",\"NodeDisruptionPolicy=false\",\"NodeSwap=false\",\"OnClusterBuild=false\",\"OpenShiftPodSecurityAdmission=false\",\"PinnedImages=false\",\"PlatformOperators=false\",\"PrivateHostedZoneAWS=true\",\"RouteExternalCertificate=false\",\"ServiceAccountTokenNodeBinding=false\",\"ServiceAccountTokenNodeBindingValidation=false\",\"ServiceAccountTokenPodNodeInfo=false\",\"SignatureStores=false\",\"SigstoreImageVerification=false\",\"TranslateStreamCloseWebsocketRequests=false\",\"UpgradeStatus=false\",\"VSphereControlPlaneMachineSet=true\",\"VSphereDriverConfiguration=true\",\"VSphereMultiVCenters=false\",\"VSphereStaticIPs=true\",\"ValidatingAdmissionPolicy=false\",\"VolumeGroupSnapshot=false\"],\"goaway-chance\":[\"0\"],\"http2-max-streams-per-connection\":[\"2000\"],\"kubelet-certificate-authority\":[\"/etc/kubernetes/static-pod-resources/configmaps/kubelet-serving-ca/ca-bundle.crt\"],\"kubelet-client-certificate\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.crt\"],\"kubelet-client-key\":[\"/etc/kubernetes/static-pod-certs/secrets/kubelet-client/tls.key\"],\"kubelet-preferred-address-types\":[\"InternalIP\"],\"kubelet-read-only-port\":[\"0\"],\"kubernetes-service-node-port\":[\"0\"],\"max-mutating-requests-inflight\":[\"1000\"],\"max-requests-inflight\":[\"3000\"],\"min-request-timeout\":[\"3600\"],\"proxy-client-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.crt\"],\"proxy-client-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/aggregator-client/tls.key\"],\"requestheader-allowed-names\":[\"kube-apiserver-proxy\",\"system:kube-apiserver-proxy\",\"system:openshift-aggregator\"],\"requestheader-client-ca-file\":[\"/etc/kubernetes/static-pod-certs/configmaps/aggregator-client-ca/ca-bundle.crt\"],\"requestheader-extra-headers-prefix\":[\"X-Remote-Extra-\"],\"requestheader-group-headers\":[\"X-Remote-Group\"],\"requestheader-username-headers\":[\"X-Remote-User\"],\"send-retry-after-while-not-ready-once\":[\"false\"],\"service-account-issuer\":[\"https://kubernetes.default.svc\"],\"service-account-jwks-uri\":[\"https://api.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com:6443/openid/v1/jwks\"],\"service-account-lookup\":[\"true\"],\"service-account-signing-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/bound-service-account-signing-key/service-account.key\"],\"service-node-port-range\":[\"30000-32767\"],\"shutdown-delay-duration\":[\"70s\"],\"shutdown-send-retry-after\":[\"true\"],\"storage-backend\":[\"etcd3\"],\"storage-media-type\":[\"application/vnd.kubernetes.protobuf\"],\"strict-transport-security-directives\":[\"max-age=31536000,includeSubDomains,preload\"],\"tls-cert-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\"],\"tls-private-key-file\":[\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"]},\"apiVersion\":\"kubecontrolplane.config.openshift.io/v1\",\"authConfig\":{\"oauthMetadataFile\":\"/etc/kubernetes/static-pod-resources/configmaps/oauth-metadata/oauthMetadata\"},\"consolePublicURL\":\"\",\"corsAllowedOrigins\":[\"//127\\\\.0\\\\.0\\\\.1(:|$)\",\"//localhost(:|$)\"],\"imagePolicyConfig\":{\"internalRegistryHostname\":\"image-registry.openshift-image-registry.svc:5000\"},\"kind\":\"KubeAPIServerConfig\",\"projectConfig\":{\"defaultNodeSelector\":\"\"},\"serviceAccountPublicKeyFiles\":[\"/etc/kubernetes/static-pod-resources/configmaps/sa-token-signing-certs\",\"/etc/kubernetes/static-pod-resources/configmaps/bound-sa-token-signing-certs\"],\"servicesSubnet\":\"172.30.0.0/16\",\"servingInfo\":{\"bindAddress\":\"0.0.0.0:6443\",\"bindNetwork\":\"tcp4\",\"cipherSuites\":[\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\",\"TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\",\"TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256\",\"TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"],\"minTLSVersion\":\"VersionTLS12\",\"namedCertificates\":[{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/localhost-serving-cert-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/service-network-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/external-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-certs/secrets/internal-loadbalancer-serving-certkey/tls.key\"},{\"certFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.crt\",\"keyFile\":\"/etc/kubernetes/static-pod-resources/secrets/localhost-recovery-serving-certkey/tls.key\"}]}}"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T11:07:23.493186160Z I0611 11:07:23.493106       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/config -n openshift-kube-apiserver:
2024-06-11T11:07:23.493186160Z cause by changes in data.config.yaml
2024-06-11T11:07:23.661354208Z I0611 11:07:23.661242       1 request.go:697] Waited for 1.983154626s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-06-11T11:07:23.673555763Z I0611 11:07:23.673482       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:24.359626463Z I0611 11:07:24.359570       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:07:24.661747402Z I0611 11:07:24.661686       1 request.go:697] Waited for 1.786873486s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T11:07:25.074148656Z I0611 11:07:25.074086       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:07:25.861731373Z I0611 11:07:25.861674       1 request.go:697] Waited for 2.18970848s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-06-11T11:07:25.875948719Z I0611 11:07:25.875865       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:27.060929007Z I0611 11:07:27.060864       1 request.go:697] Waited for 1.985080774s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:07:27.465845121Z E0611 11:07:27.465781       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:27.466353445Z E0611 11:07:27.466250       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:27.466666459Z E0611 11:07:27.466633       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:27.876968218Z I0611 11:07:27.876889       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:28.061563212Z I0611 11:07:28.061509       1 request.go:697] Waited for 1.98653104s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:07:29.261650888Z I0611 11:07:29.261517       1 request.go:697] Waited for 1.906309991s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-06-11T11:07:29.871446119Z I0611 11:07:29.871346       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:30.460951527Z I0611 11:07:30.460893       1 request.go:697] Waited for 1.98675025s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:31.461511178Z I0611 11:07:31.461452       1 request.go:697] Waited for 1.590419275s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-06-11T11:07:31.475429208Z I0611 11:07:31.475357       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:32.461719364Z I0611 11:07:32.461647       1 request.go:697] Waited for 1.555040367s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-06-11T11:07:33.661554388Z I0611 11:07:33.661488       1 request.go:697] Waited for 1.395972304s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:33.676535466Z I0611 11:07:33.676452       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:07:34.072243983Z E0611 11:07:34.072182       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:34.470776827Z I0611 11:07:34.470680       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:34.860806286Z I0611 11:07:34.860743       1 request.go:697] Waited for 1.386830691s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:35.861163379Z I0611 11:07:35.861086       1 request.go:697] Waited for 1.390320548s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-06-11T11:07:35.870566204Z I0611 11:07:35.870500       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:36.861402666Z I0611 11:07:36.861294       1 request.go:697] Waited for 1.19311912s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-pod
2024-06-11T11:07:37.083184407Z I0611 11:07:37.083102       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-8 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:37.861719957Z I0611 11:07:37.861622       1 request.go:697] Waited for 1.194731693s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:07:38.272563758Z I0611 11:07:38.272496       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 8 triggered by "required configmap/config has changed"
2024-06-11T11:07:38.295175982Z I0611 11:07:38.295094       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 8 created because required configmap/config has changed
2024-06-11T11:07:38.305879367Z I0611 11:07:38.305816       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:07:38.322580523Z W0611 11:07:38.322534       1 staticpod.go:38] revision 8 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T11:07:38.322630125Z E0611 11:07:38.322577       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 8
2024-06-11T11:07:38.327214733Z I0611 11:07:38.327159       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 9 triggered by "required configmap/config has changed,optional configmap/oauth-metadata has been created"
2024-06-11T11:07:38.861805437Z I0611 11:07:38.861731       1 request.go:697] Waited for 1.176054348s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-06-11T11:07:39.064577618Z E0611 11:07:39.064510       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:39.064975836Z E0611 11:07:39.064948       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:39.351453148Z I0611 11:07:39.351390       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:07:40.061268073Z I0611 11:07:40.061210       1 request.go:697] Waited for 1.75414495s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T11:07:40.664392514Z I0611 11:07:40.664331       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:07:40.687648256Z I0611 11:07:40.687564       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:07:40.688194781Z I0611 11:07:40.688138       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T11:05:18Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:07:40.704965933Z I0611 11:07:40.703684       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 7" to "NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 8",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 7" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 8"
2024-06-11T11:07:41.260769652Z I0611 11:07:41.260694       1 request.go:697] Waited for 1.995252657s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-06-11T11:07:41.947527843Z I0611 11:07:41.947455       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:42.074077017Z I0611 11:07:42.073980       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-pod-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:42.261685928Z I0611 11:07:42.261610       1 request.go:697] Waited for 1.789406628s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:07:43.461222509Z I0611 11:07:43.461139       1 request.go:697] Waited for 1.511370762s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:07:44.473233983Z I0611 11:07:44.473163       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:44.661350917Z I0611 11:07:44.661267       1 request.go:697] Waited for 2.386467797s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:07:45.677241664Z I0611 11:07:45.677167       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:45.861760537Z I0611 11:07:45.861698       1 request.go:697] Waited for 2.194592995s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T11:07:46.870433761Z I0611 11:07:46.870034       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-cert-syncer-kubeconfig-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:47.061330720Z I0611 11:07:47.061244       1 request.go:697] Waited for 2.388217775s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:07:47.665881829Z E0611 11:07:47.665823       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:47.666438853Z E0611 11:07:47.666391       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:47.666715566Z E0611 11:07:47.666687       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:48.261512294Z I0611 11:07:48.261415       1 request.go:697] Waited for 2.196524545s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:07:49.082125643Z I0611 11:07:49.082051       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/oauth-metadata-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:49.261546125Z I0611 11:07:49.261481       1 request.go:697] Waited for 2.188006558s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:07:50.074827852Z I0611 11:07:50.074757       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:50.461287328Z I0611 11:07:50.461234       1 request.go:697] Waited for 2.195838761s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:07:51.270762488Z I0611 11:07:51.270667       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cloud-config-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:51.461507167Z I0611 11:07:51.461452       1 request.go:697] Waited for 2.189579486s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:07:51.672778048Z I0611 11:07:51.672696       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:07:51.672778048Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:07:51.672778048Z  CurrentRevision: (int32) 0,
2024-06-11T11:07:51.672778048Z  TargetRevision: (int32) 8,
2024-06-11T11:07:51.672778048Z  LastFailedRevision: (int32) 0,
2024-06-11T11:07:51.672778048Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:07:51.672778048Z  LastFailedReason: (string) "",
2024-06-11T11:07:51.672778048Z  LastFailedCount: (int) 0,
2024-06-11T11:07:51.672778048Z  LastFallbackCount: (int) 0,
2024-06-11T11:07:51.672778048Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:07:51.672778048Z }
2024-06-11T11:07:51.672778048Z  because new revision pending
2024-06-11T11:07:51.700188352Z I0611 11:07:51.700133       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:07:52.661780894Z I0611 11:07:52.661693       1 request.go:697] Waited for 2.195898864s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:07:53.475626746Z I0611 11:07:53.475560       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/bound-sa-token-signing-certs-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:53.861339490Z I0611 11:07:53.861267       1 request.go:697] Waited for 2.163684749s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:07:55.061258801Z I0611 11:07:55.061194       1 request.go:697] Waited for 2.395167117s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:07:55.871706887Z I0611 11:07:55.871641       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:56.261905836Z I0611 11:07:56.261837       1 request.go:697] Waited for 2.396061551s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:07:56.665870621Z E0611 11:07:56.665801       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:57.461711096Z I0611 11:07:57.461597       1 request.go:697] Waited for 2.197185768s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:58.071906929Z I0611 11:07:58.071806       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-server-ca-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:07:58.661355007Z I0611 11:07:58.661244       1 request.go:697] Waited for 2.193382625s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-06-11T11:07:59.861452915Z I0611 11:07:59.861386       1 request.go:697] Waited for 2.194388091s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:08:00.271721645Z I0611 11:08:00.271631       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:08:01.060841792Z I0611 11:08:01.060775       1 request.go:697] Waited for 2.195941742s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:08:02.061115224Z I0611 11:08:02.061048       1 request.go:697] Waited for 1.789399479s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps
2024-06-11T11:08:02.071771603Z I0611 11:08:02.071700       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/sa-token-signing-certs-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:08:02.469211756Z I0611 11:08:02.465151       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:08:02.469211756Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:08:02.469211756Z  CurrentRevision: (int32) 0,
2024-06-11T11:08:02.469211756Z  TargetRevision: (int32) 8,
2024-06-11T11:08:02.469211756Z  LastFailedRevision: (int32) 0,
2024-06-11T11:08:02.469211756Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:08:02.469211756Z  LastFailedReason: (string) "",
2024-06-11T11:08:02.469211756Z  LastFailedCount: (int) 0,
2024-06-11T11:08:02.469211756Z  LastFallbackCount: (int) 0,
2024-06-11T11:08:02.469211756Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:08:02.469211756Z }
2024-06-11T11:08:02.469211756Z  because new revision pending
2024-06-11T11:08:03.061415657Z I0611 11:08:03.061354       1 request.go:697] Waited for 1.795276344s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-8-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:03.868575703Z I0611 11:08:03.868495       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-apiserver-audit-policies-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:08:04.261156650Z I0611 11:08:04.261088       1 request.go:697] Waited for 1.794427006s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:08:04.667042082Z E0611 11:08:04.666978       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:04.667507102Z E0611 11:08:04.667452       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:05.261565301Z I0611 11:08:05.261463       1 request.go:697] Waited for 1.392991198s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets
2024-06-11T11:08:05.273856741Z I0611 11:08:05.273790       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-client-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:08:06.461655124Z I0611 11:08:06.461589       1 request.go:697] Waited for 1.188027294s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/encryption-config-9
2024-06-11T11:08:07.471456688Z I0611 11:08:07.471377       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-serving-certkey-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:08:08.272598884Z I0611 11:08:08.272511       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:08:08.673135181Z I0611 11:08:08.673031       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-apiserver because it was missing
2024-06-11T11:08:08.674869557Z E0611 11:08:08.674813       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:09.277004611Z I0611 11:08:09.276935       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/webhook-authenticator-9 -n openshift-kube-apiserver because it was missing
2024-06-11T11:08:09.669114437Z I0611 11:08:09.669059       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:08:09.861149374Z I0611 11:08:09.861080       1 request.go:697] Waited for 1.18771838s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T11:08:10.861499322Z I0611 11:08:10.861438       1 request.go:697] Waited for 1.796295617s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/localhost-recovery-client-token
2024-06-11T11:08:11.076007946Z I0611 11:08:11.075918       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 9 triggered by "required configmap/config has changed,optional configmap/oauth-metadata has been created"
2024-06-11T11:08:11.098512435Z I0611 11:08:11.098430       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 9 created because required configmap/config has changed,optional configmap/oauth-metadata has been created
2024-06-11T11:08:11.099757489Z W0611 11:08:11.099709       1 staticpod.go:38] revision 9 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T11:08:11.099857994Z E0611 11:08:11.099838       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 9
2024-06-11T11:08:11.103211841Z I0611 11:08:11.103158       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:08:12.061799717Z I0611 11:08:12.061727       1 request.go:697] Waited for 1.797148111s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:08:13.261471459Z I0611 11:08:13.261370       1 request.go:697] Waited for 2.158634827s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-9-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:08:14.261602779Z I0611 11:08:14.261531       1 request.go:697] Waited for 2.190750976s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:15.273220880Z I0611 11:08:15.273081       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-9-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-apiserver because it was missing
2024-06-11T11:08:15.460841535Z I0611 11:08:15.460766       1 request.go:697] Waited for 1.796300191s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:15.865413449Z E0611 11:08:15.865344       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:16.461187078Z I0611 11:08:16.461103       1 request.go:697] Waited for 1.395032918s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:08:17.461686027Z I0611 11:08:17.461621       1 request.go:697] Waited for 1.796292085s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:08:18.661523053Z I0611 11:08:18.661463       1 request.go:697] Waited for 1.596644995s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods
2024-06-11T11:08:18.670595557Z I0611 11:08:18.670448       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-9-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-apiserver because it was missing
2024-06-11T11:08:18.865695844Z I0611 11:08:18.865626       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:08:18.886570874Z I0611 11:08:18.886499       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:08:18.888766872Z I0611 11:08:18.888709       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T11:05:18Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:08:18.904073253Z I0611 11:08:18.901864       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 8" to "NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 9",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 8" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 9"
2024-06-11T11:08:19.661565228Z I0611 11:08:19.661510       1 request.go:697] Waited for 1.597128762s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-06-11T11:08:20.861188519Z I0611 11:08:20.861117       1 request.go:697] Waited for 1.972310742s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:08:22.061221331Z I0611 11:08:22.061150       1 request.go:697] Waited for 2.193384938s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:08:22.474376188Z I0611 11:08:22.474263       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-9-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-apiserver because it was missing
2024-06-11T11:08:23.061339395Z I0611 11:08:23.061263       1 request.go:697] Waited for 1.596616844s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:08:23.065786816Z E0611 11:08:23.065724       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:23.066269440Z E0611 11:08:23.066236       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:24.261617918Z I0611 11:08:24.261550       1 request.go:697] Waited for 1.594849757s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:25.461167105Z I0611 11:08:25.461103       1 request.go:697] Waited for 1.793305332s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:08:26.461709390Z I0611 11:08:26.461630       1 request.go:697] Waited for 1.796374284s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:08:27.461708453Z I0611 11:08:27.461649       1 request.go:697] Waited for 1.394771005s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:27.472348423Z I0611 11:08:27.472241       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:08:27.472348423Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:08:27.472348423Z  CurrentRevision: (int32) 0,
2024-06-11T11:08:27.472348423Z  TargetRevision: (int32) 9,
2024-06-11T11:08:27.472348423Z  LastFailedRevision: (int32) 0,
2024-06-11T11:08:27.472348423Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:08:27.472348423Z  LastFailedReason: (string) "",
2024-06-11T11:08:27.472348423Z  LastFailedCount: (int) 0,
2024-06-11T11:08:27.472348423Z  LastFallbackCount: (int) 0,
2024-06-11T11:08:27.472348423Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:08:27.472348423Z }
2024-06-11T11:08:27.472348423Z  because new revision pending
2024-06-11T11:08:27.502101697Z I0611 11:08:27.502025       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:08:28.661788022Z I0611 11:08:28.661728       1 request.go:697] Waited for 1.163056538s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:08:29.861147747Z I0611 11:08:29.861070       1 request.go:697] Waited for 2.193909051s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:30.065448111Z E0611 11:08:30.065364       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:30.065967844Z E0611 11:08:30.065911       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:30.861763356Z I0611 11:08:30.861512       1 request.go:697] Waited for 2.193674737s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:08:30.900087669Z I0611 11:08:30.899939       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:08:31.863283822Z I0611 11:08:31.863227       1 request.go:697] Waited for 1.597360986s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-06-11T11:08:32.864624377Z E0611 11:08:32.864566       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:33.061006543Z I0611 11:08:33.060947       1 request.go:697] Waited for 1.170618115s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/localhost-recovery-client
2024-06-11T11:08:34.265111366Z I0611 11:08:34.265041       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:08:34.265111366Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:08:34.265111366Z  CurrentRevision: (int32) 0,
2024-06-11T11:08:34.265111366Z  TargetRevision: (int32) 9,
2024-06-11T11:08:34.265111366Z  LastFailedRevision: (int32) 0,
2024-06-11T11:08:34.265111366Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:08:34.265111366Z  LastFailedReason: (string) "",
2024-06-11T11:08:34.265111366Z  LastFailedCount: (int) 0,
2024-06-11T11:08:34.265111366Z  LastFallbackCount: (int) 0,
2024-06-11T11:08:34.265111366Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:08:34.265111366Z }
2024-06-11T11:08:34.265111366Z  because new revision pending
2024-06-11T11:08:34.466526249Z E0611 11:08:34.466456       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:35.750499168Z I0611 11:08:35.750443       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:08:35.760158529Z I0611 11:08:35.760104       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:08:35.831499361Z I0611 11:08:35.831355       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:08:35.848771757Z I0611 11:08:35.848716       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:08:36.471193688Z I0611 11:08:36.471121       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-9-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-apiserver because it was missing
2024-06-11T11:08:36.865420967Z I0611 11:08:36.865363       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 9, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:08:37.661551667Z I0611 11:08:37.661476       1 request.go:697] Waited for 1.188850614s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:08:38.661670562Z I0611 11:08:38.661618       1 request.go:697] Waited for 1.19427961s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:08:40.469190695Z E0611 11:08:40.469108       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:40.469835265Z E0611 11:08:40.469794       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:41.666580046Z I0611 11:08:41.666518       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:08:42.261350641Z I0611 11:08:42.261204       1 request.go:697] Waited for 1.117728706s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T11:08:44.261226134Z I0611 11:08:44.261142       1 request.go:697] Waited for 1.119741176s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver
2024-06-11T11:08:44.865014120Z E0611 11:08:44.864937       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:44.865534307Z E0611 11:08:44.865500       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:45.461541526Z I0611 11:08:45.461462       1 request.go:697] Waited for 1.195088487s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/services/apiserver
2024-06-11T11:08:47.066949406Z I0611 11:08:47.066870       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:08:48.265137767Z E0611 11:08:48.265074       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:48.265706294Z E0611 11:08:48.265653       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:09:25.837743438Z E0611 11:09:25.837685       1 guard_controller.go:293] Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:09:25.855987035Z E0611 11:09:25.855916       1 base_controller.go:268] GuardController reconciliation failed: Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:09:25.858443092Z I0611 11:09:25.858385       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:11Z","message":"GuardControllerDegraded: Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T11:05:18Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:09:25.860156712Z I0611 11:09:25.860115       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:09:25.877117570Z I0611 11:09:25.877029       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2" to "GuardControllerDegraded: Missing PodIP in operand kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2"
2024-06-11T11:09:26.638961325Z I0611 11:09:26.638893       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:09:27.033898362Z I0611 11:09:27.033831       1 request.go:697] Waited for 1.1756202s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:09:28.233906103Z I0611 11:09:28.233843       1 request.go:697] Waited for 2.193104555s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T11:09:29.234009621Z I0611 11:09:29.233940       1 request.go:697] Waited for 1.993074209s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-9-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:09:30.234346984Z I0611 11:09:30.234241       1 request.go:697] Waited for 1.595182922s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:09:31.234458804Z I0611 11:09:31.234385       1 request.go:697] Waited for 1.596422353s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/client-ca
2024-06-11T11:09:32.434448651Z I0611 11:09:32.434383       1 request.go:697] Waited for 1.195397292s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-server-ca
2024-06-11T11:09:33.445892836Z I0611 11:09:33.445795       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-apiserver because it was missing
2024-06-11T11:09:33.633853872Z I0611 11:09:33.633778       1 request.go:697] Waited for 1.19522788s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/trusted-ca-bundle
2024-06-11T11:09:34.834562324Z I0611 11:09:34.834500       1 request.go:697] Waited for 1.388399741s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:09:35.639686917Z I0611 11:09:35.639585       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 9, but has not made progress because static pod is pending
2024-06-11T11:09:35.863075236Z I0611 11:09:35.862991       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:09:35.863818768Z I0611 11:09:35.863763       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:09:35Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T11:05:18Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:09:35.878560982Z I0611 11:09:35.878496       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Degraded changed from True to False ("NodeControllerDegraded: All master nodes are ready")
2024-06-11T11:09:36.033506263Z I0611 11:09:36.033420       1 request.go:697] Waited for 1.191990706s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:09:37.034030811Z I0611 11:09:37.033965       1 request.go:697] Waited for 1.17346562s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:09:38.234216571Z I0611 11:09:38.234162       1 request.go:697] Waited for 1.988076196s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-06-11T11:09:39.234443466Z I0611 11:09:39.234381       1 request.go:697] Waited for 1.390493911s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-9-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:09:40.433772192Z I0611 11:09:40.433680       1 request.go:697] Waited for 1.194677102s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/revision-pruner-9-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:09:42.637400601Z I0611 11:09:42.637293       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 9, but has not made progress because static pod is pending
2024-06-11T11:09:42.838201911Z I0611 11:09:42.838121       1 core.go:226] Pod "openshift-kube-apiserver/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-2" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:bac0ddaf801035bf3d571daea9916b68407c1e9a58a3864616c1ca14e15e74bb","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.7","path":"readyz","port":6443,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"imagePullSecrets":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"tolerations":[{"effect":"NoSchedule","key":"node-role.kubernetes.io/master","operator":"Exists"},{"effect":"NoExecute","key":"node.kubernetes.io/not-ready","operator":"Exists"},{"effect":"NoExecute","key":"node.kubernetes.io/unreachable","operator":"Exists"},{"effect":"NoSchedule","key":"node-role.kubernetes.io/etcd","operator":"Exists"}],"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-06-11T11:09:43.847925247Z I0611 11:09:43.847853       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-apiserver because it changed
2024-06-11T11:09:44.233825953Z I0611 11:09:44.233756       1 request.go:697] Waited for 1.098482879s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:09:45.234595041Z I0611 11:09:45.234510       1 request.go:697] Waited for 1.388011526s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T11:09:46.433896647Z I0611 11:09:46.433829       1 request.go:697] Waited for 1.39556113s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:09:47.634243818Z I0611 11:09:47.634172       1 request.go:697] Waited for 1.206389915s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:09:52.908430609Z I0611 11:09:52.908371       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:09:52.908992906Z I0611 11:09:52.908934       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:09:56.661986836Z I0611 11:09:56.661923       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:09:56.662563529Z I0611 11:09:56.662522       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:09:56.733977577Z I0611 11:09:56.733880       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:09:56.746631606Z I0611 11:09:56.746556       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:10:09.363388235Z I0611 11:10:09.363283       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:10:15.029001379Z I0611 11:10:15.028921       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:10:15.029001379Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:10:15.029001379Z  CurrentRevision: (int32) 9,
2024-06-11T11:10:15.029001379Z  TargetRevision: (int32) 0,
2024-06-11T11:10:15.029001379Z  LastFailedRevision: (int32) 0,
2024-06-11T11:10:15.029001379Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:10:15.029001379Z  LastFailedReason: (string) "",
2024-06-11T11:10:15.029001379Z  LastFailedCount: (int) 0,
2024-06-11T11:10:15.029001379Z  LastFallbackCount: (int) 0,
2024-06-11T11:10:15.029001379Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:10:15.029001379Z }
2024-06-11T11:10:15.029001379Z  because static pod is ready
2024-06-11T11:10:15.049974115Z I0611 11:10:15.049893       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-2" from revision 0 to 9 because static pod is ready
2024-06-11T11:10:15.057169559Z I0611 11:10:15.057074       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:09:35Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7; 1 node is at revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T11:05:18Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 7; 1 node is at revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:10:15.057267975Z I0611 11:10:15.057096       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:10:15.075011797Z I0611 11:10:15.071531       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 9" to "NodeInstallerProgressing: 2 nodes are at revision 7; 1 node is at revision 9",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 7; 0 nodes have achieved new revision 9" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 7; 1 node is at revision 9"
2024-06-11T11:10:16.201976437Z I0611 11:10:16.201907       1 request.go:697] Waited for 1.132102958s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:10:19.810647079Z I0611 11:10:19.810564       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-0 with revision 7 is the oldest and needs new revision 9
2024-06-11T11:10:19.810724261Z I0611 11:10:19.810698       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:10:19.810724261Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:10:19.810724261Z  CurrentRevision: (int32) 7,
2024-06-11T11:10:19.810724261Z  TargetRevision: (int32) 9,
2024-06-11T11:10:19.810724261Z  LastFailedRevision: (int32) 7,
2024-06-11T11:10:19.810724261Z  LastFailedTime: (*v1.Time)(0xc002336240)(2024-06-11 11:01:06 +0000 UTC),
2024-06-11T11:10:19.810724261Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:10:19.810724261Z  LastFailedCount: (int) 1,
2024-06-11T11:10:19.810724261Z  LastFallbackCount: (int) 0,
2024-06-11T11:10:19.810724261Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:10:19.810724261Z   (string) (len=2059) "installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition\n"
2024-06-11T11:10:19.810724261Z  }
2024-06-11T11:10:19.810724261Z }
2024-06-11T11:10:19.828472431Z I0611 11:10:19.828402       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 7 to 9 because node ci-op-9xx71rvq-1e28e-w667k-master-0 with revision 7 is the oldest
2024-06-11T11:10:19.832182567Z I0611 11:10:19.832063       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:10:21.002269055Z I0611 11:10:21.002187       1 request.go:697] Waited for 1.168925193s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/secrets/node-kubeconfigs
2024-06-11T11:10:24.226731397Z I0611 11:10:24.226650       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-9-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-apiserver because it was missing
2024-06-11T11:10:24.606780880Z I0611 11:10:24.606709       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 9, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:10:25.401976510Z I0611 11:10:25.401895       1 request.go:697] Waited for 1.173704051s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:10:26.402055556Z I0611 11:10:26.401987       1 request.go:697] Waited for 1.192566657s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:10:27.601553442Z I0611 11:10:27.601489       1 request.go:697] Waited for 1.191627159s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:10:29.406126342Z I0611 11:10:29.406059       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:10:31.605897620Z I0611 11:10:31.605829       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:11:03.303982777Z I0611 11:11:03.303840       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0" (last termination at 2024-06-11 11:04:22 +0000 UTC) at 2024-06-11 11:11:03 +0000 UTC
2024-06-11T11:11:05.132250271Z I0611 11:11:05.132185       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:11:09.933757426Z I0611 11:11:09.933674       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 9, but has not made progress because waiting for static pod of revision 9, found 7
2024-06-11T11:11:12.331825795Z I0611 11:11:12.331765       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 9, but has not made progress because waiting for static pod of revision 9, found 7
2024-06-11T11:11:15.932883175Z I0611 11:11:15.932809       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 9, but has not made progress because waiting for static pod of revision 9, found 7
2024-06-11T11:11:18.451279871Z I0611 11:11:18.451208       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:11:22.464194200Z I0611 11:11:22.464012       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:12:15.318172734Z I0611 11:12:15.318044       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0" (last termination at 2024-06-11 11:04:22 +0000 UTC) at 2024-06-11 11:12:15 +0000 UTC
2024-06-11T11:12:16.472460521Z I0611 11:12:16.472392       1 reflector.go:351] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:16.847955200Z I0611 11:12:16.847876       1 reflector.go:351] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:16.848590874Z I0611 11:12:16.848523       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:12:17.148355404Z I0611 11:12:17.148283       1 reflector.go:351] Caches populated for *v1.OAuth from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:17.319978859Z I0611 11:12:17.319919       1 reflector.go:351] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:17.407709911Z I0611 11:12:17.407649       1 reflector.go:351] Caches populated for *v1alpha1.StorageVersionMigration from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:17.439439319Z I0611 11:12:17.439383       1 reflector.go:351] Caches populated for *v1.APIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:17.457047176Z I0611 11:12:17.456995       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:17.477589977Z I0611 11:12:17.477535       1 reflector.go:351] Caches populated for *v1.Authentication from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:18.364600730Z I0611 11:12:18.364542       1 reflector.go:351] Caches populated for *v1.Image from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:18.518851856Z I0611 11:12:18.518784       1 reflector.go:351] Caches populated for *v1.Proxy from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:18.662235211Z I0611 11:12:18.662155       1 reflector.go:351] Caches populated for *v1.Scheduler from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:23.572519321Z I0611 11:12:23.572432       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0" at 2024-06-11 11:12:23 +0000 UTC
2024-06-11T11:12:24.353052002Z I0611 11:12:24.352951       1 request.go:697] Waited for 1.129699502s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:12:27.362947403Z I0611 11:12:27.362874       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 9, but has not made progress because static pod is pending
2024-06-11T11:12:30.505198756Z I0611 11:12:30.505112       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 9, but has not made progress because static pod is pending
2024-06-11T11:12:36.231265549Z I0611 11:12:36.231184       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 9, but has not made progress because static pod is pending
2024-06-11T11:12:39.229039785Z I0611 11:12:39.228972       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 9, but has not made progress because static pod is pending
2024-06-11T11:12:44.336906020Z I0611 11:12:44.336794       1 request.go:697] Waited for 1.107684582s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:13:14.825074845Z I0611 11:13:14.824994       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:13:14.825074845Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:13:14.825074845Z  CurrentRevision: (int32) 9,
2024-06-11T11:13:14.825074845Z  TargetRevision: (int32) 0,
2024-06-11T11:13:14.825074845Z  LastFailedRevision: (int32) 7,
2024-06-11T11:13:14.825074845Z  LastFailedTime: (*v1.Time)(0xc0068ab830)(2024-06-11 11:01:06 +0000 UTC),
2024-06-11T11:13:14.825074845Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:13:14.825074845Z  LastFailedCount: (int) 1,
2024-06-11T11:13:14.825074845Z  LastFallbackCount: (int) 0,
2024-06-11T11:13:14.825074845Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:13:14.825074845Z   (string) (len=2059) "installer:    1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:08.460733       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:18.460770       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:28.461125       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:38.461572       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:48.460760       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:48.461504       1 cmd.go:467] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:48.461542       1 cmd.go:106] timed out waiting for the condition\n"
2024-06-11T11:13:14.825074845Z  }
2024-06-11T11:13:14.825074845Z }
2024-06-11T11:13:14.825074845Z  because static pod is ready
2024-06-11T11:13:14.843926547Z I0611 11:13:14.843838       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 7 to 9 because static pod is ready
2024-06-11T11:13:14.849937153Z I0611 11:13:14.849875       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:09:35Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:50:43Z","message":"NodeInstallerProgressing: 1 node is at revision 7; 2 nodes are at revision 9","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T11:05:18Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 7; 2 nodes are at revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:13:14.850497309Z I0611 11:13:14.850447       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:13:14.865471520Z I0611 11:13:14.865404       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 7; 1 node is at revision 9" to "NodeInstallerProgressing: 1 node is at revision 7; 2 nodes are at revision 9",Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 7; 1 node is at revision 9" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 7; 2 nodes are at revision 9"
2024-06-11T11:13:15.997347041Z I0611 11:13:15.997218       1 request.go:697] Waited for 1.139075952s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/config
2024-06-11T11:13:19.603394264Z I0611 11:13:19.603257       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-1 with revision 7 is the oldest and needs new revision 9
2024-06-11T11:13:19.603394264Z I0611 11:13:19.603370       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:13:19.603394264Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:13:19.603394264Z  CurrentRevision: (int32) 7,
2024-06-11T11:13:19.603394264Z  TargetRevision: (int32) 9,
2024-06-11T11:13:19.603394264Z  LastFailedRevision: (int32) 0,
2024-06-11T11:13:19.603394264Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:13:19.603394264Z  LastFailedReason: (string) "",
2024-06-11T11:13:19.603394264Z  LastFailedCount: (int) 0,
2024-06-11T11:13:19.603394264Z  LastFallbackCount: (int) 0,
2024-06-11T11:13:19.603394264Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:13:19.603394264Z }
2024-06-11T11:13:19.620779507Z I0611 11:13:19.620709       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 7 to 9 because node ci-op-9xx71rvq-1e28e-w667k-master-1 with revision 7 is the oldest
2024-06-11T11:13:19.625194048Z I0611 11:13:19.625142       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:13:20.798289663Z I0611 11:13:20.797189       1 request.go:697] Waited for 1.169442605s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/serviceaccounts/installer-sa
2024-06-11T11:13:21.797651883Z I0611 11:13:21.797592       1 request.go:697] Waited for 1.394376393s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:13:24.017072235Z I0611 11:13:24.016989       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-9-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-apiserver because it was missing
2024-06-11T11:13:24.376570709Z I0611 11:13:24.374908       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:13:24.410336750Z I0611 11:13:24.410257       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 9, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:13:25.197809965Z I0611 11:13:25.197709       1 request.go:697] Waited for 1.177985782s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T11:13:26.197862423Z I0611 11:13:26.197806       1 request.go:697] Waited for 1.195136426s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:13:27.397536558Z I0611 11:13:27.397468       1 request.go:697] Waited for 1.19440236s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:13:29.002337123Z I0611 11:13:29.002273       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:13:31.201593458Z I0611 11:13:31.201446       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:14:03.163346408Z I0611 11:14:03.163209       1 termination_observer.go:236] Observed event "TerminationPreShutdownHooksFinished" for API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1" (last termination at 2024-06-11 11:06:11 +0000 UTC) at 2024-06-11 11:14:03 +0000 UTC
2024-06-11T11:14:04.595573311Z I0611 11:14:04.595505       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 9, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:14:08.997370555Z I0611 11:14:08.997268       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 9, but has not made progress because waiting for static pod of revision 9, found 7
2024-06-11T11:14:11.397179221Z I0611 11:14:11.397102       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 9, but has not made progress because waiting for static pod of revision 9, found 7
2024-06-11T11:14:16.685086866Z I0611 11:14:16.685009       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 9, but has not made progress because waiting for static pod of revision 9, found 7
2024-06-11T11:15:05.785734955Z I0611 11:15:05.785679       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:15:10.159103439Z I0611 11:15:10.159024       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:15:10.159464667Z I0611 11:15:10.159410       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:15:10.159738789Z I0611 11:15:10.159706       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:15:10.160021512Z I0611 11:15:10.159986       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:15:15.119592377Z I0611 11:15:15.119490       1 termination_observer.go:236] Observed event "TerminationGracefulTerminationFinished" for API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1" (last termination at 2024-06-11 11:06:11 +0000 UTC) at 2024-06-11 11:15:15 +0000 UTC
2024-06-11T11:15:21.243154767Z I0611 11:15:21.243008       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com
2024-06-11T11:15:21.243517995Z I0611 11:15:21.243479       1 connectivity_check_controller.go:166] ConnectivityCheckController is waiting for transition to desired version (4.16.0-0.nightly-2024-06-10-211334) to be completed.
2024-06-11T11:15:26.971905270Z I0611 11:15:26.971822       1 termination_observer.go:130] Observed termination of API server pod "kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1" at 2024-06-11 11:15:26 +0000 UTC
2024-06-11T11:15:27.564348445Z I0611 11:15:27.564141       1 request.go:697] Waited for 1.186495473s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:15:28.564627824Z I0611 11:15:28.564572       1 request.go:697] Waited for 1.190638091s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:15:29.566394618Z I0611 11:15:29.566332       1 request.go:697] Waited for 1.194357077s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:15:30.569373704Z I0611 11:15:30.568419       1 request.go:697] Waited for 1.19752772s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T11:15:32.564064046Z I0611 11:15:32.563990       1 request.go:697] Waited for 1.101527286s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T11:15:32.970038463Z I0611 11:15:32.969966       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 9, but has not made progress because static pod is pending
2024-06-11T11:15:33.564248011Z I0611 11:15:33.564194       1 request.go:697] Waited for 1.193303436s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dinstaller
2024-06-11T11:15:34.564809702Z I0611 11:15:34.564718       1 request.go:697] Waited for 1.32555506s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:15:36.401793436Z I0611 11:15:36.401689       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-06-11T11:15:36.564338874Z I0611 11:15:36.564270       1 request.go:697] Waited for 1.077840582s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T11:15:39.168747016Z I0611 11:15:39.168677       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 9, but has not made progress because static pod is pending
2024-06-11T11:15:44.364511850Z I0611 11:15:44.364444       1 request.go:697] Waited for 1.1244932s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/configmaps/kube-apiserver-audit-policies
2024-06-11T11:15:44.569626094Z I0611 11:15:44.569557       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 9, but has not made progress because static pod is pending
2024-06-11T11:15:54.394271549Z I0611 11:15:54.394175       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'CustomResourceDefinitionCreated' Created CustomResourceDefinition.apiextensions.k8s.io/podnetworkconnectivitychecks.controlplane.operator.openshift.io because it was missing
2024-06-11T11:15:54.395523742Z E0611 11:15:54.395461       1 base_controller.go:268] ConnectivityCheckController reconciliation failed: the server could not find the requested resource (get podnetworkconnectivitychecks.controlplane.operator.openshift.io)
2024-06-11T11:15:54.448618467Z I0611 11:15:54.448531       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
2024-06-11T11:16:16.622200384Z I0611 11:16:16.622138       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:16:16.622200384Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:16:16.622200384Z  CurrentRevision: (int32) 9,
2024-06-11T11:16:16.622200384Z  TargetRevision: (int32) 0,
2024-06-11T11:16:16.622200384Z  LastFailedRevision: (int32) 0,
2024-06-11T11:16:16.622200384Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:16:16.622200384Z  LastFailedReason: (string) "",
2024-06-11T11:16:16.622200384Z  LastFailedCount: (int) 0,
2024-06-11T11:16:16.622200384Z  LastFallbackCount: (int) 0,
2024-06-11T11:16:16.622200384Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:16:16.622200384Z }
2024-06-11T11:16:16.622200384Z  because static pod is ready
2024-06-11T11:16:16.640264371Z I0611 11:16:16.640186       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 7 to 9 because static pod is ready
2024-06-11T11:16:16.642144694Z I0611 11:16:16.642096       1 status_controller.go:218] clusteroperator/kube-apiserver diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:09:35Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:16:16Z","message":"NodeInstallerProgressing: 3 nodes are at revision 9","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T11:05:18Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 9","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:22Z","message":"KubeletMinorVersionUpgradeable: Kubelet and API server minor versions are synced.","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:50:18Z","message":"All is well","reason":"AsExpected","status":"False","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:16:16.656494837Z I0611 11:16:16.656439       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-apiserver-operator", Name:"kube-apiserver-operator", UID:"a65a24a6-1096-46dc-b349-e8787c38d7d6", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-apiserver changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 9"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 7; 2 nodes are at revision 9" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 9"
2024-06-11T11:16:17.797002347Z I0611 11:16:17.796902       1 request.go:697] Waited for 1.129366877s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods/kube-apiserver-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:24:30.318635282Z I0611 11:24:30.318560       1 reflector.go:351] Caches populated for *v1.Event from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:25:21.243514118Z I0611 11:25:21.243435       1 externalloadbalancer.go:27] syncing external loadbalancer hostnames: api.ci-op-9xx71rvq-1e28e.qe.azure.devcluster.openshift.com
2024-06-11T11:25:36.402565971Z I0611 11:25:36.402454       1 servicehostname.go:40] syncing servicenetwork hostnames: [172.30.0.1 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local openshift openshift.default openshift.default.svc openshift.default.svc.cluster.local]
