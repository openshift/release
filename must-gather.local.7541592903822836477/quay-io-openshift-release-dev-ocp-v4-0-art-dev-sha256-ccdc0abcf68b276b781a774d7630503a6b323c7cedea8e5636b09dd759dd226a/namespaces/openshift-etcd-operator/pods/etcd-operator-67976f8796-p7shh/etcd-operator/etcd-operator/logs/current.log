2024-06-11T10:49:36.909693204Z I0611 10:49:36.909478       1 profiler.go:21] Starting profiling endpoint at http://127.0.0.1:6060/debug/pprof/
2024-06-11T10:49:36.909693204Z I0611 10:49:36.909661       1 observer_polling.go:159] Starting file observer
2024-06-11T10:49:36.909932115Z I0611 10:49:36.909903       1 cmd.go:240] Using service-serving-cert provided certificates
2024-06-11T10:49:36.910003919Z I0611 10:49:36.909949       1 leaderelection.go:121] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2024-06-11T10:49:36.910408237Z I0611 10:49:36.910371       1 observer_polling.go:159] Starting file observer
2024-06-11T10:49:36.927195607Z I0611 10:49:36.927141       1 builder.go:298] openshift-cluster-etcd-operator version 4.16.0-202406061206.p0.gdc4f4e8.assembly.stream.el9-dc4f4e8-dc4f4e858ba8395dce6883242c7d12009685d145
2024-06-11T10:49:37.242600062Z I0611 10:49:37.242542       1 secure_serving.go:57] Forcing use of http/1.1 only
2024-06-11T10:49:37.242680866Z W0611 10:49:37.242662       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2024-06-11T10:49:37.242720268Z W0611 10:49:37.242707       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2024-06-11T10:49:37.250278514Z I0611 10:49:37.250151       1 leaderelection.go:250] attempting to acquire leader lease openshift-etcd-operator/openshift-cluster-etcd-operator-lock...
2024-06-11T10:49:37.250587628Z I0611 10:49:37.250515       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2024-06-11T10:49:37.250587628Z I0611 10:49:37.250552       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
2024-06-11T10:49:37.250673132Z I0611 10:49:37.250613       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2024-06-11T10:49:37.250673132Z I0611 10:49:37.250661       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-06-11T10:49:37.250734335Z I0611 10:49:37.250701       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2024-06-11T10:49:37.250734335Z I0611 10:49:37.250717       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-06-11T10:49:37.250874142Z I0611 10:49:37.250832       1 secure_serving.go:213] Serving securely on [::]:8443
2024-06-11T10:49:37.250942445Z I0611 10:49:37.250896       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2024-06-11T10:49:37.251583174Z I0611 10:49:37.251541       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2024-06-11T10:49:37.288148250Z I0611 10:49:37.288093       1 leaderelection.go:260] successfully acquired lease openshift-etcd-operator/openshift-cluster-etcd-operator-lock
2024-06-11T10:49:37.288819981Z I0611 10:49:37.288745       1 event.go:364] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-etcd-operator", Name:"openshift-cluster-etcd-operator-lock", UID:"cc52bf49-b43c-4de4-ae3e-b7cc5a740716", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"11367", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' etcd-operator-67976f8796-p7shh_c6a8cd57-3785-47ae-945b-5cdbb5ad4ec7 became leader
2024-06-11T10:49:37.294158125Z I0611 10:49:37.294097       1 starter.go:166] recorded cluster versions: map[raw-internal:4.16.0-0.nightly-2024-06-10-211334]
2024-06-11T10:49:37.301165346Z I0611 10:49:37.301112       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2024-06-11T10:49:37.306960712Z I0611 10:49:37.306897       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AdminNetworkPolicy", "AlibabaPlatform", "AzureWorkloadIdentity", "BareMetalLoadBalancer", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ClusterAPIInstallAWS", "ClusterAPIInstallNutanix", "ClusterAPIInstallOpenStack", "ClusterAPIInstallVSphere", "DisableKubeletCloudCredentialProviders", "ExternalCloudProvider", "ExternalCloudProviderAzure", "ExternalCloudProviderExternal", "ExternalCloudProviderGCP", "HardwareSpeed", "KMSv1", "MetricsServer", "NetworkDiagnosticsConfig", "NetworkLiveMigration", "PrivateHostedZoneAWS", "VSphereControlPlaneMachineSet", "VSphereDriverConfiguration", "VSphereStaticIPs"}, Disabled:[]v1.FeatureGateName{"AutomatedEtcdBackup", "CSIDriverSharedResource", "ChunkSizeMiB", "ClusterAPIInstall", "ClusterAPIInstallAzure", "ClusterAPIInstallGCP", "ClusterAPIInstallIBMCloud", "ClusterAPIInstallPowerVS", "DNSNameResolver", "DynamicResourceAllocation", "EtcdBackendQuota", "EventedPLEG", "Example", "ExternalOIDC", "ExternalRouteCertificate", "GCPClusterHostedDNS", "GCPLabelsTags", "GatewayAPI", "ImagePolicy", "InsightsConfig", "InsightsConfigAPI", "InsightsOnDemandDataGather", "InstallAlternateInfrastructureAWS", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MachineConfigNodes", "ManagedBootImages", "MaxUnavailableStatefulSet", "MetricsCollectionProfiles", "MixedCPUsAllocation", "NewOLM", "NodeDisruptionPolicy", "NodeSwap", "OnClusterBuild", "OpenShiftPodSecurityAdmission", "PinnedImages", "PlatformOperators", "RouteExternalCertificate", "ServiceAccountTokenNodeBinding", "ServiceAccountTokenNodeBindingValidation", "ServiceAccountTokenPodNodeInfo", "SignatureStores", "SigstoreImageVerification", "TranslateStreamCloseWebsocketRequests", "UpgradeStatus", "VSphereMultiVCenters", "ValidatingAdmissionPolicy", "VolumeGroupSnapshot"}}
2024-06-11T10:49:37.307034015Z I0611 10:49:37.306969       1 starter.go:445] FeatureGates initializedenabled[AdminNetworkPolicy AlibabaPlatform AzureWorkloadIdentity BareMetalLoadBalancer BuildCSIVolumes CloudDualStackNodeIPs ClusterAPIInstallAWS ClusterAPIInstallNutanix ClusterAPIInstallOpenStack ClusterAPIInstallVSphere DisableKubeletCloudCredentialProviders ExternalCloudProvider ExternalCloudProviderAzure ExternalCloudProviderExternal ExternalCloudProviderGCP HardwareSpeed KMSv1 MetricsServer NetworkDiagnosticsConfig NetworkLiveMigration PrivateHostedZoneAWS VSphereControlPlaneMachineSet VSphereDriverConfiguration VSphereStaticIPs]disabled[AutomatedEtcdBackup CSIDriverSharedResource ChunkSizeMiB ClusterAPIInstall ClusterAPIInstallAzure ClusterAPIInstallGCP ClusterAPIInstallIBMCloud ClusterAPIInstallPowerVS DNSNameResolver DynamicResourceAllocation EtcdBackendQuota EventedPLEG Example ExternalOIDC ExternalRouteCertificate GCPClusterHostedDNS GCPLabelsTags GatewayAPI ImagePolicy InsightsConfig InsightsConfigAPI InsightsOnDemandDataGather InstallAlternateInfrastructureAWS MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MachineConfigNodes ManagedBootImages MaxUnavailableStatefulSet MetricsCollectionProfiles MixedCPUsAllocation NewOLM NodeDisruptionPolicy NodeSwap OnClusterBuild OpenShiftPodSecurityAdmission PinnedImages PlatformOperators RouteExternalCertificate ServiceAccountTokenNodeBinding ServiceAccountTokenNodeBindingValidation ServiceAccountTokenPodNodeInfo SignatureStores SigstoreImageVerification TranslateStreamCloseWebsocketRequests UpgradeStatus VSphereMultiVCenters ValidatingAdmissionPolicy VolumeGroupSnapshot]
2024-06-11T10:49:37.307106519Z I0611 10:49:37.307074       1 starter.go:499] waiting for cluster version informer sync...
2024-06-11T10:49:37.351907472Z I0611 10:49:37.351845       1 shared_informer.go:318] Caches are synced for RequestHeaderAuthRequestController
2024-06-11T10:49:37.351953074Z I0611 10:49:37.351850       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-06-11T10:49:37.351987576Z I0611 10:49:37.351850       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-06-11T10:49:37.417441376Z I0611 10:49:37.417388       1 starter.go:522] Detected available machine API, starting vertical scaling related controllers and informers...
2024-06-11T10:49:37.418463122Z I0611 10:49:37.418410       1 base_controller.go:67] Waiting for caches to sync for MachineDeletionHooksController
2024-06-11T10:49:37.418463122Z I0611 10:49:37.418413       1 base_controller.go:67] Waiting for caches to sync for ClusterMemberRemovalController
2024-06-11T10:49:37.418667132Z I0611 10:49:37.418629       1 base_controller.go:67] Waiting for caches to sync for MissingStaticPodController
2024-06-11T10:49:37.418825139Z I0611 10:49:37.418779       1 base_controller.go:67] Waiting for caches to sync for TargetConfigController
2024-06-11T10:49:37.418926544Z I0611 10:49:37.418836       1 base_controller.go:67] Waiting for caches to sync for DefragController
2024-06-11T10:49:37.418952745Z I0611 10:49:37.418925       1 envvarcontroller.go:193] Starting EnvVarController
2024-06-11T10:49:37.418985346Z I0611 10:49:37.418974       1 base_controller.go:67] Waiting for caches to sync for RevisionController
2024-06-11T10:49:37.419240658Z I0611 10:49:37.419194       1 base_controller.go:67] Waiting for caches to sync for ResourceSyncController
2024-06-11T10:49:37.419378564Z I0611 10:49:37.419345       1 base_controller.go:67] Waiting for caches to sync for EtcdCertSignerController
2024-06-11T10:49:37.419409866Z I0611 10:49:37.419396       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateController
2024-06-11T10:49:37.419452968Z I0611 10:49:37.419417       1 base_controller.go:67] Waiting for caches to sync for EtcdCertCleanerController
2024-06-11T10:49:37.419452968Z I0611 10:49:37.419430       1 base_controller.go:67] Waiting for caches to sync for PruneController
2024-06-11T10:49:37.419452968Z I0611 10:49:37.419436       1 base_controller.go:73] Caches are synced for EtcdCertCleanerController 
2024-06-11T10:49:37.419468369Z I0611 10:49:37.419449       1 base_controller.go:110] Starting #1 worker of EtcdCertCleanerController controller ...
2024-06-11T10:49:37.419479869Z I0611 10:49:37.419462       1 base_controller.go:67] Waiting for caches to sync for NodeController
2024-06-11T10:49:37.419491770Z I0611 10:49:37.419449       1 base_controller.go:67] Waiting for caches to sync for BootstrapTeardownController
2024-06-11T10:49:37.419539772Z I0611 10:49:37.419515       1 base_controller.go:67] Waiting for caches to sync for EtcdEndpointsController
2024-06-11T10:49:37.419597775Z I0611 10:49:37.419353       1 base_controller.go:67] Waiting for caches to sync for InstallerController
2024-06-11T10:49:37.419691679Z I0611 10:49:37.419660       1 base_controller.go:67] Waiting for caches to sync for ClusterMemberController
2024-06-11T10:49:37.419898888Z I0611 10:49:37.419832       1 base_controller.go:67] Waiting for caches to sync for ConfigObserver
2024-06-11T10:49:37.419898888Z I0611 10:49:37.419861       1 base_controller.go:67] Waiting for caches to sync for BackingResourceController
2024-06-11T10:49:37.419937190Z I0611 10:49:37.419904       1 base_controller.go:67] Waiting for caches to sync for UnsupportedConfigOverridesController
2024-06-11T10:49:37.420039595Z I0611 10:49:37.419981       1 base_controller.go:67] Waiting for caches to sync for LoggingSyncer
2024-06-11T10:49:37.420118098Z I0611 10:49:37.420080       1 base_controller.go:67] Waiting for caches to sync for GuardController
2024-06-11T10:49:37.420179701Z I0611 10:49:37.418814       1 base_controller.go:67] Waiting for caches to sync for ScriptController
2024-06-11T10:49:37.420714026Z I0611 10:49:37.420644       1 base_controller.go:67] Waiting for caches to sync for FSyncController
2024-06-11T10:49:37.420714026Z I0611 10:49:37.419375       1 base_controller.go:67] Waiting for caches to sync for InstallerStateController
2024-06-11T10:49:37.420714026Z I0611 10:49:37.420678       1 base_controller.go:67] Waiting for caches to sync for EtcdMembersController
2024-06-11T10:49:37.420714026Z I0611 10:49:37.420698       1 base_controller.go:73] Caches are synced for EtcdMembersController 
2024-06-11T10:49:37.420745127Z I0611 10:49:37.420715       1 base_controller.go:110] Starting #1 worker of EtcdMembersController controller ...
2024-06-11T10:49:37.420816530Z I0611 10:49:37.420774       1 base_controller.go:73] Caches are synced for FSyncController 
2024-06-11T10:49:37.421173447Z I0611 10:49:37.418796       1 base_controller.go:67] Waiting for caches to sync for UnsupportedConfigOverridesController
2024-06-11T10:49:37.421206248Z E0611 10:49:37.420920       1 base_controller.go:268] EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2024-06-11T10:49:37.421216749Z I0611 10:49:37.421199       1 base_controller.go:110] Starting #1 worker of FSyncController controller ...
2024-06-11T10:49:37.421272551Z I0611 10:49:37.420959       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' etcds.operator.openshift.io "cluster" not found
2024-06-11T10:49:37.421272551Z I0611 10:49:37.421118       1 base_controller.go:67] Waiting for caches to sync for EtcdStaticResources
2024-06-11T10:49:37.422435105Z I0611 10:49:37.422394       1 base_controller.go:67] Waiting for caches to sync for StatusSyncer_etcd
2024-06-11T10:49:37.426423187Z E0611 10:49:37.426380       1 base_controller.go:268] EtcdMembersController reconciliation failed: getting cache client could not retrieve endpoints: node lister not synced
2024-06-11T10:49:37.426453189Z I0611 10:49:37.426430       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' etcds.operator.openshift.io "cluster" not found
2024-06-11T10:49:37.436518350Z I0611 10:49:37.436458       1 etcdcli_pool.go:70] creating a new cached client
2024-06-11T10:49:37.506140541Z E0611 10:49:37.506080       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:49:37.514648031Z E0611 10:49:37.514607       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:49:37.518628813Z I0611 10:49:37.518571       1 base_controller.go:73] Caches are synced for ClusterMemberRemovalController 
2024-06-11T10:49:37.518628813Z I0611 10:49:37.518597       1 base_controller.go:110] Starting #1 worker of ClusterMemberRemovalController controller ...
2024-06-11T10:49:37.518982330Z I0611 10:49:37.518956       1 base_controller.go:73] Caches are synced for DefragController 
2024-06-11T10:49:37.518993230Z I0611 10:49:37.518979       1 base_controller.go:110] Starting #1 worker of DefragController controller ...
2024-06-11T10:49:37.519026632Z I0611 10:49:37.519002       1 base_controller.go:73] Caches are synced for TargetConfigController 
2024-06-11T10:49:37.519035632Z I0611 10:49:37.519024       1 base_controller.go:110] Starting #1 worker of TargetConfigController controller ...
2024-06-11T10:49:37.519097735Z I0611 10:49:37.519074       1 base_controller.go:73] Caches are synced for RevisionController 
2024-06-11T10:49:37.519097735Z I0611 10:49:37.519087       1 base_controller.go:110] Starting #1 worker of RevisionController controller ...
2024-06-11T10:49:37.519136337Z E0611 10:49:37.519109       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController missing env var values
2024-06-11T10:49:37.519499753Z I0611 10:49:37.519473       1 base_controller.go:73] Caches are synced for PruneController 
2024-06-11T10:49:37.519499753Z I0611 10:49:37.519491       1 base_controller.go:110] Starting #1 worker of PruneController controller ...
2024-06-11T10:49:37.519568956Z I0611 10:49:37.519544       1 base_controller.go:73] Caches are synced for NodeController 
2024-06-11T10:49:37.519578157Z I0611 10:49:37.519565       1 base_controller.go:110] Starting #1 worker of NodeController controller ...
2024-06-11T10:49:37.519725664Z I0611 10:49:37.519685       1 base_controller.go:73] Caches are synced for EtcdEndpointsController 
2024-06-11T10:49:37.519794567Z I0611 10:49:37.519766       1 base_controller.go:110] Starting #1 worker of EtcdEndpointsController controller ...
2024-06-11T10:49:37.519843869Z I0611 10:49:37.519744       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:49:37.519903772Z I0611 10:49:37.519880       1 etcdcli_pool.go:70] creating a new cached client
2024-06-11T10:49:37.519994576Z I0611 10:49:37.519952       1 base_controller.go:73] Caches are synced for BackingResourceController 
2024-06-11T10:49:37.520061579Z I0611 10:49:37.520040       1 base_controller.go:110] Starting #1 worker of BackingResourceController controller ...
2024-06-11T10:49:37.520163184Z I0611 10:49:37.520041       1 base_controller.go:73] Caches are synced for UnsupportedConfigOverridesController 
2024-06-11T10:49:37.520163184Z I0611 10:49:37.520136       1 base_controller.go:110] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2024-06-11T10:49:37.520557002Z I0611 10:49:37.520510       1 base_controller.go:73] Caches are synced for ScriptController 
2024-06-11T10:49:37.520557002Z I0611 10:49:37.520529       1 base_controller.go:110] Starting #1 worker of ScriptController controller ...
2024-06-11T10:49:37.520587403Z I0611 10:49:37.520558       1 base_controller.go:73] Caches are synced for LoggingSyncer 
2024-06-11T10:49:37.520587403Z I0611 10:49:37.520567       1 base_controller.go:110] Starting #1 worker of LoggingSyncer controller ...
2024-06-11T10:49:37.521628551Z I0611 10:49:37.521591       1 base_controller.go:73] Caches are synced for EtcdStaticResources 
2024-06-11T10:49:37.521628551Z I0611 10:49:37.521609       1 base_controller.go:110] Starting #1 worker of EtcdStaticResources controller ...
2024-06-11T10:49:37.521987467Z I0611 10:49:37.521966       1 base_controller.go:73] Caches are synced for UnsupportedConfigOverridesController 
2024-06-11T10:49:37.521987467Z I0611 10:49:37.521979       1 base_controller.go:110] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2024-06-11T10:49:37.522513491Z I0611 10:49:37.522471       1 base_controller.go:73] Caches are synced for StatusSyncer_etcd 
2024-06-11T10:49:37.522513491Z I0611 10:49:37.522493       1 base_controller.go:110] Starting #1 worker of StatusSyncer_etcd controller ...
2024-06-11T10:49:37.523171922Z I0611 10:49:37.523138       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"EtcdMembersControllerDegraded: giving up getting a cached client after 3 tries\nNodeControllerDegraded: All master nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: giving up getting a cached client after 3 tries\nEtcdEndpointsDegraded: failed to get member list: giving up getting a cached client after 3 tries\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:59Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:49:37.528210552Z E0611 10:49:37.528171       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:49:37.534169426Z I0611 10:49:37.533084       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "EtcdMembersControllerDegraded: giving up getting a cached client after 3 tries\nNodeControllerDegraded: All master nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: giving up getting a cached client after 3 tries\nEtcdEndpointsDegraded: failed to get member list: giving up getting a cached client after 3 tries" to "EtcdMembersControllerDegraded: giving up getting a cached client after 3 tries\nNodeControllerDegraded: All master nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: giving up getting a cached client after 3 tries\nEtcdEndpointsDegraded: failed to get member list: giving up getting a cached client after 3 tries\nEtcdMembersDegraded: No unhealthy members found"
2024-06-11T10:49:37.534794354Z I0611 10:49:37.534752       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 7.67 %, dbSize: 52621312
2024-06-11T10:49:37.551909239Z E0611 10:49:37.551868       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:49:37.553084993Z I0611 10:49:37.552847       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:49:37.568464297Z I0611 10:49:37.568425       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 7.67 %, dbSize: 52621312
2024-06-11T10:49:37.595915056Z E0611 10:49:37.595850       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:49:37.614404103Z I0611 10:49:37.614341       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:49:37.614953228Z I0611 10:49:37.614889       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"EtcdMembersControllerDegraded: giving up getting a cached client after 3 tries\nNodeControllerDegraded: All master nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: giving up getting a cached client after 3 tries\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:59Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:49:37.615138937Z E0611 10:49:37.615054       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:37.621605533Z E0611 10:49:37.621570       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:37.628671357Z I0611 10:49:37.628633       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:37.636064096Z I0611 10:49:37.636024       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 7.54 %, dbSize: 52621312
2024-06-11T10:49:37.652923868Z E0611 10:49:37.652669       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:37.653275884Z I0611 10:49:37.653219       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "EtcdMembersControllerDegraded: giving up getting a cached client after 3 tries\nNodeControllerDegraded: All master nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: giving up getting a cached client after 3 tries\nEtcdEndpointsDegraded: failed to get member list: giving up getting a cached client after 3 tries\nEtcdMembersDegraded: No unhealthy members found" to "EtcdMembersControllerDegraded: giving up getting a cached client after 3 tries\nNodeControllerDegraded: All master nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: giving up getting a cached client after 3 tries\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found"
2024-06-11T10:49:37.664355592Z E0611 10:49:37.664314       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:37.680494132Z E0611 10:49:37.680453       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:49:37.682861440Z E0611 10:49:37.682818       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:37.766673284Z E0611 10:49:37.766621       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:37.820909408Z I0611 10:49:37.820846       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:37.844780167Z E0611 10:49:37.844720       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:49:37.919019826Z I0611 10:49:37.918953       1 base_controller.go:73] Caches are synced for MachineDeletionHooksController 
2024-06-11T10:49:37.919019826Z I0611 10:49:37.918977       1 base_controller.go:110] Starting #1 worker of MachineDeletionHooksController controller ...
2024-06-11T10:49:37.920127961Z I0611 10:49:37.920094       1 base_controller.go:73] Caches are synced for BootstrapTeardownController 
2024-06-11T10:49:37.920127961Z I0611 10:49:37.920110       1 base_controller.go:110] Starting #1 worker of BootstrapTeardownController controller ...
2024-06-11T10:49:37.929986775Z E0611 10:49:37.929945       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:37.939168266Z I0611 10:49:37.938757       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:49:37.940999325Z E0611 10:49:37.940953       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:37.951128247Z I0611 10:49:37.951084       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 7.49 %, dbSize: 52621312
2024-06-11T10:49:37.951222450Z I0611 10:49:37.951182       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Operation cannot be fulfilled on etcds.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:38.021529484Z I0611 10:49:38.021468       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:38.168640460Z E0611 10:49:38.168580       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:49:38.221944954Z I0611 10:49:38.221880       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:38.237123236Z E0611 10:49:38.237066       1 base_controller.go:268] EtcdMembersController reconciliation failed: Operation cannot be fulfilled on etcds.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:38.237880260Z I0611 10:49:38.237836       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:49:38.238435478Z I0611 10:49:38.238396       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"EtcdMembersControllerDegraded: Operation cannot be fulfilled on etcds.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again\nNodeControllerDegraded: All master nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: giving up getting a cached client after 3 tries\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:59Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:49:38.240231335Z E0611 10:49:38.240196       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:38.250751169Z I0611 10:49:38.250705       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "EtcdMembersControllerDegraded: giving up getting a cached client after 3 tries\nNodeControllerDegraded: All master nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: giving up getting a cached client after 3 tries\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found" to "EtcdMembersControllerDegraded: Operation cannot be fulfilled on etcds.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again\nNodeControllerDegraded: All master nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: giving up getting a cached client after 3 tries\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found"
2024-06-11T10:49:38.252255317Z I0611 10:49:38.252217       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 7.41 %, dbSize: 52621312
2024-06-11T10:49:38.252369821Z E0611 10:49:38.252339       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:38.319806264Z I0611 10:49:38.319699       1 base_controller.go:73] Caches are synced for EtcdCertSignerController 
2024-06-11T10:49:38.319806264Z I0611 10:49:38.319748       1 base_controller.go:110] Starting #1 worker of EtcdCertSignerController controller ...
2024-06-11T10:49:38.436654578Z I0611 10:49:38.436585       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:38.619834700Z I0611 10:49:38.619755       1 request.go:697] Waited for 1.198957668s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/kube-system/secrets?limit=500&resourceVersion=0
2024-06-11T10:49:38.621719260Z I0611 10:49:38.621664       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:38.638167583Z I0611 10:49:38.638127       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:49:38.640531258Z E0611 10:49:38.640489       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:38.652223829Z I0611 10:49:38.652179       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 7.35 %, dbSize: 52621312
2024-06-11T10:49:38.813259847Z E0611 10:49:38.813200       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:49:38.821195900Z I0611 10:49:38.821155       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:38.919613128Z I0611 10:49:38.919512       1 base_controller.go:73] Caches are synced for ResourceSyncController 
2024-06-11T10:49:38.919613128Z I0611 10:49:38.919579       1 base_controller.go:110] Starting #1 worker of ResourceSyncController controller ...
2024-06-11T10:49:39.022198888Z I0611 10:49:39.022111       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:39.119746588Z I0611 10:49:39.119663       1 base_controller.go:73] Caches are synced for InstallerController 
2024-06-11T10:49:39.119746588Z I0611 10:49:39.119711       1 base_controller.go:110] Starting #1 worker of InstallerController controller ...
2024-06-11T10:49:39.119798390Z I0611 10:49:39.119765       1 base_controller.go:73] Caches are synced for StaticPodStateController 
2024-06-11T10:49:39.119798390Z I0611 10:49:39.119792       1 base_controller.go:110] Starting #1 worker of StaticPodStateController controller ...
2024-06-11T10:49:39.119815091Z I0611 10:49:39.119797       1 base_controller.go:73] Caches are synced for MissingStaticPodController 
2024-06-11T10:49:39.119829491Z I0611 10:49:39.119813       1 base_controller.go:110] Starting #1 worker of MissingStaticPodController controller ...
2024-06-11T10:49:39.119843491Z I0611 10:49:39.119824       1 base_controller.go:73] Caches are synced for ClusterMemberController 
2024-06-11T10:49:39.119857292Z I0611 10:49:39.119840       1 base_controller.go:110] Starting #1 worker of ClusterMemberController controller ...
2024-06-11T10:49:39.119897093Z I0611 10:49:39.119874       1 base_controller.go:73] Caches are synced for ConfigObserver 
2024-06-11T10:49:39.119897093Z I0611 10:49:39.119882       1 base_controller.go:110] Starting #1 worker of ConfigObserver controller ...
2024-06-11T10:49:39.120219903Z I0611 10:49:39.120163       1 base_controller.go:73] Caches are synced for GuardController 
2024-06-11T10:49:39.120219903Z I0611 10:49:39.120182       1 base_controller.go:110] Starting #1 worker of GuardController controller ...
2024-06-11T10:49:39.121115432Z I0611 10:49:39.120771       1 base_controller.go:73] Caches are synced for InstallerStateController 
2024-06-11T10:49:39.121115432Z I0611 10:49:39.120790       1 base_controller.go:110] Starting #1 worker of InstallerStateController controller ...
2024-06-11T10:49:39.242263482Z I0611 10:49:39.242202       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:49:39.243479221Z I0611 10:49:39.243438       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"NodeControllerDegraded: All master nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: giving up getting a cached client after 3 tries\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:59Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:49:39.251468175Z I0611 10:49:39.251414       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "EtcdMembersControllerDegraded: Operation cannot be fulfilled on etcds.operator.openshift.io \"cluster\": the object has been modified; please apply your changes to the latest version and try again\nNodeControllerDegraded: All master nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: giving up getting a cached client after 3 tries\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: giving up getting a cached client after 3 tries\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found"
2024-06-11T10:49:39.253836250Z E0611 10:49:39.253785       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:39.261151083Z I0611 10:49:39.261108       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 7.22 %, dbSize: 52621312
2024-06-11T10:49:39.428348897Z E0611 10:49:39.428283       1 base_controller.go:268] BootstrapTeardownController reconciliation failed: Operation cannot be fulfilled on etcds.operator.openshift.io "cluster": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:49:39.819143717Z I0611 10:49:39.819076       1 request.go:697] Waited for 2.297095148s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T10:49:39.837558102Z I0611 10:49:39.837451       1 etcdcli_pool.go:70] creating a new cached client
2024-06-11T10:49:39.838767441Z I0611 10:49:39.838698       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:49:39.850677919Z I0611 10:49:39.850628       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 7.18 %, dbSize: 52621312
2024-06-11T10:49:39.850863525Z E0611 10:49:39.850835       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:40.098798705Z E0611 10:49:40.098742       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:49:40.241843152Z I0611 10:49:40.241773       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:49:40.247822942Z E0611 10:49:40.247767       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:40.250678932Z I0611 10:49:40.250637       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:59Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:49:40.263830750Z I0611 10:49:40.263761       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nClusterMemberControllerDegraded: could not get list of unhealthy members: giving up getting a cached client after 3 tries\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found"
2024-06-11T10:49:40.271534695Z I0611 10:49:40.271466       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 7.03 %, dbSize: 52621312
2024-06-11T10:49:40.815980599Z E0611 10:49:40.815924       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:40.819428109Z I0611 10:49:40.819384       1 request.go:697] Waited for 1.397132505s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:49:41.621845377Z I0611 10:49:41.621778       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 1, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:49:41.819681056Z I0611 10:49:41.819607       1 request.go:697] Waited for 1.194877031s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T10:49:42.662788048Z E0611 10:49:42.662733       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:49:43.822607374Z I0611 10:49:43.822544       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 1, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:49:44.906454114Z I0611 10:49:44.906384       1 clustermembercontroller.go:224] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-1) for scale-up since its machine (ci-op-9xx71rvq-1e28e-w667k-master-1) is missing the PreDrain deletion hook (name: EtcdQuorumOperator, owner: clusteroperator/etcd)
2024-06-11T10:49:44.906454114Z I0611 10:49:44.906413       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-2) for scale-up: no Machine found referencing this node's internal IP (10.0.0.7)
2024-06-11T10:49:44.906506917Z I0611 10:49:44.906459       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-0) for scale-up: no Machine found referencing this node's internal IP (10.0.0.8)
2024-06-11T10:49:44.941706432Z I0611 10:49:44.941641       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-0) for scale-up: no Machine found referencing this node's internal IP (10.0.0.8)
2024-06-11T10:49:44.941706432Z I0611 10:49:44.941689       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-2) for scale-up: no Machine found referencing this node's internal IP (10.0.0.7)
2024-06-11T10:49:44.977674083Z I0611 10:49:44.977614       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-0) for scale-up: no Machine found referencing this node's internal IP (10.0.0.8)
2024-06-11T10:49:44.977674083Z I0611 10:49:44.977655       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-2) for scale-up: no Machine found referencing this node's internal IP (10.0.0.7)
2024-06-11T10:49:45.027010247Z I0611 10:49:45.026932       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-0) for scale-up: no Machine found referencing this node's internal IP (10.0.0.8)
2024-06-11T10:49:45.055242742Z I0611 10:49:45.055186       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-0) for scale-up: no Machine found referencing this node's internal IP (10.0.0.8)
2024-06-11T10:49:45.654393539Z I0611 10:49:45.654320       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-0) for scale-up: no Machine found referencing this node's internal IP (10.0.0.8)
2024-06-11T10:49:45.840184353Z I0611 10:49:45.840134       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-0) for scale-up: no Machine found referencing this node's internal IP (10.0.0.8)
2024-06-11T10:49:46.309118078Z I0611 10:49:46.309058       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-0) for scale-up: no Machine found referencing this node's internal IP (10.0.0.8)
2024-06-11T10:49:47.470345390Z I0611 10:49:47.470239       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-0) for scale-up: no Machine found referencing this node's internal IP (10.0.0.8)
2024-06-11T10:49:47.497709400Z I0611 10:49:47.497654       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-0) for scale-up: no Machine found referencing this node's internal IP (10.0.0.8)
2024-06-11T10:49:47.548854875Z I0611 10:49:47.548796       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-0) for scale-up: no Machine found referencing this node's internal IP (10.0.0.8)
2024-06-11T10:49:47.576688505Z I0611 10:49:47.576627       1 clustermembercontroller.go:213] Ignoring node (ci-op-9xx71rvq-1e28e-w667k-master-0) for scale-up: no Machine found referencing this node's internal IP (10.0.0.8)
2024-06-11T10:49:47.801202414Z E0611 10:49:47.801150       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:49:49.945986930Z I0611 10:49:49.945930       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 1, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:49:49.948076115Z I0611 10:49:49.948010       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/etcd version "etcd" changed from "" to "4.16.0-0.nightly-2024-06-10-211334"
2024-06-11T10:49:49.948076115Z I0611 10:49:49.948039       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/etcd version "operator" changed from "" to "4.16.0-0.nightly-2024-06-10-211334"
2024-06-11T10:49:49.948415628Z I0611 10:49:49.948375       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"versions":[{"name":"raw-internal","version":"4.16.0-0.nightly-2024-06-10-211334"},{"name":"etcd","version":"4.16.0-0.nightly-2024-06-10-211334"},{"name":"operator","version":"4.16.0-0.nightly-2024-06-10-211334"}]}}
2024-06-11T10:49:49.961144945Z I0611 10:49:49.960015       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: status.versions changed from [{"raw-internal" "4.16.0-0.nightly-2024-06-10-211334"}] to [{"raw-internal" "4.16.0-0.nightly-2024-06-10-211334"} {"etcd" "4.16.0-0.nightly-2024-06-10-211334"} {"operator" "4.16.0-0.nightly-2024-06-10-211334"}]
2024-06-11T10:49:49.961144945Z I0611 10:49:49.960177       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:50.325235416Z I0611 10:49:50.325164       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodDisruptionBudgetCreated' Created PodDisruptionBudget.policy/etcd-guard-pdb -n openshift-etcd because it was missing
2024-06-11T10:49:50.414784749Z I0611 10:49:50.414721       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:50.462670992Z I0611 10:49:50.462601       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:50.835673325Z I0611 10:49:50.835595       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:51.419121096Z I0611 10:49:51.419067       1 request.go:697] Waited for 1.079557199s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:49:51.475816397Z I0611 10:49:51.475760       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:52.311683709Z I0611 10:49:52.311628       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:52.420046246Z I0611 10:49:52.419905       1 request.go:697] Waited for 1.198296956s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:52.516479403Z I0611 10:49:52.516432       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:52.822612837Z I0611 10:49:52.822557       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 1, but has not made progress because static pod is pending
2024-06-11T10:49:53.267017320Z I0611 10:49:53.266967       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:53.425623587Z E0611 10:49:53.425543       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:53.425665089Z E0611 10:49:53.425622       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:53.425752393Z I0611 10:49:53.425706       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-etcd because it was missing
2024-06-11T10:49:53.443884713Z E0611 10:49:53.443820       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:53.446000608Z I0611 10:49:53.445957       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:49:53.446356324Z I0611 10:49:53.446254       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:59Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 1","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:49:53.446710440Z I0611 10:49:53.446654       1 etcdcli_pool.go:70] creating a new cached client
2024-06-11T10:49:53.449284757Z E0611 10:49:53.449236       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: no etcd members are present
2024-06-11T10:49:53.450822726Z I0611 10:49:53.450779       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:53.460191449Z I0611 10:49:53.460131       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found"
2024-06-11T10:49:53.488170514Z I0611 10:49:53.488117       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:53.491611969Z I0611 10:49:53.491550       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 3.18 %, dbSize: 52621312
2024-06-11T10:49:53.619199935Z I0611 10:49:53.619133       1 request.go:697] Waited for 1.123558673s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:49:54.472532547Z I0611 10:49:54.472463       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:54.619668297Z I0611 10:49:54.619602       1 request.go:697] Waited for 1.175022551s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:55.328350885Z I0611 10:49:55.328278       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:55.355938176Z I0611 10:49:55.355874       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:55.619826066Z I0611 10:49:55.619749       1 request.go:697] Waited for 1.598301485s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-1-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:55.853849466Z I0611 10:49:55.853790       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:56.227357988Z I0611 10:49:56.227170       1 core.go:227] Pod "openshift-etcd/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c7cd88272ec1d0a6e1a9814448acb1744650cc1315124b44a8e7b6e711e96ed","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.8","path":"readyz","port":9980,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-06-11T10:49:56.338496684Z I0611 10:49:56.338434       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:56.619993034Z I0611 10:49:56.619901       1 request.go:697] Waited for 1.397683326s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:49:57.023055131Z I0611 10:49:57.022994       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 1, but has not made progress because static pod is pending
2024-06-11T10:49:57.344547007Z I0611 10:49:57.344497       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:57.628753174Z E0611 10:49:57.628671       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:57.628981184Z E0611 10:49:57.628842       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:57.628981184Z I0611 10:49:57.628857       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-etcd because it changed
2024-06-11T10:49:57.629403302Z E0611 10:49:57.629348       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:57.629808519Z E0611 10:49:57.629744       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:57.653255831Z I0611 10:49:57.653196       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-0 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:49:57.819570310Z I0611 10:49:57.819395       1 request.go:697] Waited for 1.396692384s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-06-11T10:49:58.054168435Z E0611 10:49:58.054102       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:49:58.359824328Z I0611 10:49:58.359749       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MemberAddAsLearner' successfully added new member https://10.0.0.8:2380
2024-06-11T10:49:58.367262149Z I0611 10:49:58.367214       1 clustermembercontroller.go:293] Not ready for promotion: etcd learner member (https://10.0.0.8:2380) is not yet in sync with leader's log 
2024-06-11T10:49:58.819534470Z I0611 10:49:58.819474       1 request.go:697] Waited for 1.396447473s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:49:58.933528490Z W0611 10:49:58.933467       1 etcdcli.go:346] UnstartedEtcdMember found: [NAME-PENDING-10.0.0.8]
2024-06-11T10:49:58.933528490Z W0611 10:49:58.933491       1 etcdcli.go:351] UnhealthyEtcdMember found: [NAME-PENDING-10.0.0.8]
2024-06-11T10:50:00.019977883Z I0611 10:50:00.019872       1 request.go:697] Waited for 1.197480885s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:50:00.421857828Z E0611 10:50:00.421631       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:00.421943532Z E0611 10:50:00.421916       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:00.822743631Z I0611 10:50:00.822679       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 1, but has not made progress because static pod is pending
2024-06-11T10:50:00.855446443Z W0611 10:50:00.855389       1 etcdcli.go:346] UnstartedEtcdMember found: [NAME-PENDING-10.0.0.8]
2024-06-11T10:50:00.855446443Z W0611 10:50:00.855412       1 etcdcli.go:351] UnhealthyEtcdMember found: [NAME-PENDING-10.0.0.8]
2024-06-11T10:50:01.219533157Z I0611 10:50:01.219454       1 request.go:697] Waited for 1.196411739s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:50:02.416919612Z W0611 10:50:02.416864       1 etcdcli.go:346] UnstartedEtcdMember found: [NAME-PENDING-10.0.0.8]
2024-06-11T10:50:02.416919612Z W0611 10:50:02.416884       1 etcdcli.go:351] UnhealthyEtcdMember found: [NAME-PENDING-10.0.0.8]
2024-06-11T10:50:02.421281422Z E0611 10:50:02.421241       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:02.421281422Z E0611 10:50:02.421272       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:02.421529529Z E0611 10:50:02.421505       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:03.622864849Z I0611 10:50:03.622812       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 1, but has not made progress because static pod is pending
2024-06-11T10:50:04.021807218Z E0611 10:50:04.021722       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:04.021807218Z E0611 10:50:04.021758       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:04.022045824Z E0611 10:50:04.022024       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:04.022288930Z E0611 10:50:04.022267       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:04.609105541Z I0611 10:50:04.608996       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MemberPromote' successfully promoted learner member https://10.0.0.8:2380
2024-06-11T10:50:04.825172695Z E0611 10:50:04.825114       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:04.825508203Z E0611 10:50:04.825475       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:06.623260807Z E0611 10:50:06.623190       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:06.623260807Z E0611 10:50:06.623230       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:06.623577421Z E0611 10:50:06.623547       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:07.023038454Z I0611 10:50:07.022978       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 1, but has not made progress because static pod is pending
2024-06-11T10:50:07.422392982Z E0611 10:50:07.422325       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:07.422392982Z E0611 10:50:07.422357       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:07.422701095Z E0611 10:50:07.422678       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:07.823081568Z E0611 10:50:07.823018       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:07.823081568Z E0611 10:50:07.823065       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:07.823445684Z E0611 10:50:07.823408       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:08.063550323Z E0611 10:50:08.063470       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:08.063550323Z E0611 10:50:08.063530       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:08.223803856Z E0611 10:50:08.223730       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:09.695607555Z E0611 10:50:09.695544       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:09.695607555Z E0611 10:50:09.695594       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:09.696050374Z E0611 10:50:09.696002       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:10.623194499Z E0611 10:50:10.623131       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:10.623194499Z E0611 10:50:10.623170       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:10.623526721Z E0611 10:50:10.623501       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:11.419223905Z I0611 10:50:11.419155       1 request.go:697] Waited for 1.09547737s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:50:12.622947555Z I0611 10:50:12.622787       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:50:12.622947555Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:50:12.622947555Z  CurrentRevision: (int32) 1,
2024-06-11T10:50:12.622947555Z  TargetRevision: (int32) 0,
2024-06-11T10:50:12.622947555Z  LastFailedRevision: (int32) 0,
2024-06-11T10:50:12.622947555Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:50:12.622947555Z  LastFailedReason: (string) "",
2024-06-11T10:50:12.622947555Z  LastFailedCount: (int) 0,
2024-06-11T10:50:12.622947555Z  LastFallbackCount: (int) 0,
2024-06-11T10:50:12.622947555Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:50:12.622947555Z }
2024-06-11T10:50:12.622947555Z  because static pod is ready
2024-06-11T10:50:12.644061056Z I0611 10:50:12.643946       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 0 to 1 because static pod is ready
2024-06-11T10:50:12.645674263Z I0611 10:50:12.645610       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:12.645879776Z I0611 10:50:12.645849       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1\nEtcdMembersAvailable: 1 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:12.660196526Z I0611 10:50:12.658886       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 1" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1",Available changed from False to True ("StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1\nEtcdMembersAvailable: 1 members are available")
2024-06-11T10:50:12.662334568Z I0611 10:50:12.662284       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.80 %, dbSize: 52621312
2024-06-11T10:50:12.822949222Z E0611 10:50:12.822889       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:12.822985525Z E0611 10:50:12.822949       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:12.823408553Z E0611 10:50:12.823377       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:12.823766577Z E0611 10:50:12.823740       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:13.328056829Z I0611 10:50:13.327967       1 core.go:359] ConfigMap "openshift-etcd/etcd-endpoints" changes: {"data":{"3213203613138f0c":"10.0.0.8"},"metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:50:13.328444755Z W0611 10:50:13.328392       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.8:2379]]
2024-06-11T10:50:13.329974757Z I0611 10:50:13.329894       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-endpoints -n openshift-etcd:
2024-06-11T10:50:13.329974757Z cause by changes in data.3213203613138f0c
2024-06-11T10:50:13.336186669Z I0611 10:50:13.336080       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 2 triggered by "required configmap/etcd-endpoints has been created"
2024-06-11T10:50:13.352730166Z W0611 10:50:13.352675       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.8:2379]]
2024-06-11T10:50:13.355202130Z I0611 10:50:13.355155       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:13.355832472Z W0611 10:50:13.355790       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.8:2379]]
2024-06-11T10:50:13.357224864Z I0611 10:50:13.357183       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1\nEtcdMembersAvailable: 1 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:13.357867607Z W0611 10:50:13.357825       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.8:2379]]
2024-06-11T10:50:13.373295830Z I0611 10:50:13.373240       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nEtcdEndpointsDegraded: no etcd members are present\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nEtcdMembersDegraded: No unhealthy members found"
2024-06-11T10:50:13.376694256Z I0611 10:50:13.376648       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.68 %, dbSize: 52621312
2024-06-11T10:50:13.819325030Z I0611 10:50:13.819250       1 request.go:697] Waited for 1.173307146s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T10:50:14.820720286Z I0611 10:50:14.819803       1 request.go:697] Waited for 1.483749386s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps
2024-06-11T10:50:15.822651565Z E0611 10:50:15.822590       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:15.823053482Z E0611 10:50:15.823029       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:16.020402484Z I0611 10:50:16.020340       1 request.go:697] Waited for 1.59773065s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:16.431279301Z I0611 10:50:16.431198       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-2 -n openshift-etcd because it was missing
2024-06-11T10:50:16.623804791Z I0611 10:50:16.623720       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:50:16.623804791Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:50:16.623804791Z  CurrentRevision: (int32) 1,
2024-06-11T10:50:16.623804791Z  TargetRevision: (int32) 0,
2024-06-11T10:50:16.623804791Z  LastFailedRevision: (int32) 0,
2024-06-11T10:50:16.623804791Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:50:16.623804791Z  LastFailedReason: (string) "",
2024-06-11T10:50:16.623804791Z  LastFailedCount: (int) 0,
2024-06-11T10:50:16.623804791Z  LastFallbackCount: (int) 0,
2024-06-11T10:50:16.623804791Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:50:16.623804791Z }
2024-06-11T10:50:16.623804791Z  because static pod is ready
2024-06-11T10:50:17.029080761Z I0611 10:50:17.028997       1 core.go:359] ConfigMap "openshift-etcd/etcd-scripts" changes: {"apiVersion":"v1","data":{"etcd.env":"export ALL_ETCD_ENDPOINTS=\"https://10.0.0.5:2379,https://10.0.0.8:2379\"\nexport ETCDCTL_API=\"3\"\nexport ETCDCTL_CACERT=\"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\nexport ETCDCTL_CERT=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\nexport ETCDCTL_ENDPOINTS=\"https://10.0.0.8:2379\"\nexport ETCDCTL_KEY=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\nexport ETCD_CIPHER_SUITES=\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\nexport ETCD_DATA_DIR=\"/var/lib/etcd\"\nexport ETCD_ELECTION_TIMEOUT=\"2500\"\nexport ETCD_ENABLE_PPROF=\"true\"\nexport ETCD_EXPERIMENTAL_MAX_LEARNERS=\"3\"\nexport ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION=\"200ms\"\nexport ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL=\"5s\"\nexport ETCD_HEARTBEAT_INTERVAL=\"500\"\nexport ETCD_IMAGE=\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\nexport ETCD_INITIAL_CLUSTER_STATE=\"existing\"\nexport ETCD_QUOTA_BACKEND_BYTES=\"8589934592\"\nexport ETCD_SOCKET_REUSE_ADDRESS=\"true\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME=\"ci-op-9xx71rvq-1e28e-w667k-master-0\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST=\"10.0.0.8\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP=\"10.0.0.8\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME=\"ci-op-9xx71rvq-1e28e-w667k-master-1\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST=\"10.0.0.6\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP=\"10.0.0.6\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME=\"ci-op-9xx71rvq-1e28e-w667k-master-2\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST=\"10.0.0.7\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP=\"10.0.0.7\"\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:50:17.029820093Z I0611 10:50:17.029760       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-scripts -n openshift-etcd:
2024-06-11T10:50:17.029820093Z cause by changes in data.etcd.env
2024-06-11T10:50:17.219532658Z I0611 10:50:17.219469       1 request.go:697] Waited for 1.195831028s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:17.430061842Z I0611 10:50:17.429964       1 core.go:359] ConfigMap "openshift-etcd/etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  annotations:\n    kubectl.kubernetes.io/default-container: etcd\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  initContainers:\n    - name: setup\n      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          echo -n \"Fixing etcd log permissions.\"\n          mkdir -p /var/log/etcd \u0026\u0026 chmod 0700 /var/log/etcd\n      securityContext:\n        privileged: true\n      resources:\n        requests:\n          memory: 50Mi\n          cpu: 5m\n      volumeMounts:\n        - mountPath: /var/log/etcd\n          name: log-dir\n    - name: etcd-ensure-env-vars\n      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_NAME?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_IP?not set}\"\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected node IP to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_IP}\" \u003e\u00262\n            exit 1\n          fi\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected etcd url host to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" \u003e\u00262\n            exit 1\n          fi\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: NODE_IP\n        valueFrom:\n          fieldRef:\n            fieldPath: status.podIP\n    - name: etcd-resources-copy\n      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          rm -f $(grep -l '^### Created by cluster-etcd-operator' /usr/local/bin/*)\n          cp -p /etc/kubernetes/static-pod-certs/configmaps/etcd-scripts/*.sh /usr/local/bin\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      volumeMounts:\n        - mountPath: /etc/kubernetes/static-pod-resources\n          name: resource-dir\n        - mountPath: /etc/kubernetes/static-pod-certs\n          name: cert-dir\n        - mountPath: /usr/local/bin\n          name: usr-local-bin\n  containers:\n  # The etcdctl container should always be first. It is intended to be used\n  # to open a remote shell via `oc rsh` that is ready to run `etcdctl`.\n  - name: etcdctl\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - \"/bin/bash\"\n      - \"-c\"\n      - \"trap TERM INT; sleep infinity \u0026 wait\"\n    resources:\n      requests:\n        memory: 60Mi\n        cpu: 10m\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_VERSION\"\n        value: \"REVISION\"\n  - name: etcd\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        etcdctl member list || true\n\n        # this has a non-zero return code if the command is non-zero.  If you use an export first, it doesn't and you\n        # will succeed when you should fail.\n        ETCD_INITIAL_CLUSTER=$(discover-etcd-initial-cluster \\\n          --cacert=/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt \\\n          --cert=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --key=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --endpoints=${ALL_ETCD_ENDPOINTS} \\\n          --data-dir=/var/lib/etcd \\\n          --target-peer-url-host=${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST} \\\n          --target-name=NODE_NAME)\n        export ETCD_INITIAL_CLUSTER\n\n        # we cannot use the \"normal\" port conflict initcontainer because when we upgrade, the existing static pod will never yield,\n        # so we do the detection in etcd container itself.\n        echo -n \"Waiting for ports 2379, 2380 and 9978 to be released.\"\n        time while [ -n \"$(ss -Htan '( sport = 2379 or sport = 2380 or sport = 9978 )')\" ]; do\n          echo -n \".\"\n          sleep 1\n        done\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        env | grep ETCD | grep -v NODE\n\n        set -x\n        # See https://etcd.io/docs/v3.4.0/tuning/ for why we use ionice\n        exec nice -n -19 ionice -c2 -n0 etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --experimental-initial-corrupt-check=true \\\n          --snapshot-count=10000 \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-peer-client-ca/ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379,unixs://${NODE_NODE_ENVVAR_NAME_IP}:0 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978 ||  mv /etc/kubernetes/etcd-backup-dir/etcd-member.yaml /etc/kubernetes/manifests\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_VERSION\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      timeoutSeconds: 30\n      failureThreshold: 5\n      periodSeconds: 5\n      successThreshold: 1\n    livenessProbe:\n      httpGet:\n        path: healthz\n        port: 9980\n        scheme: HTTPS\n      timeoutSeconds: 30\n      periodSeconds: 5\n      successThreshold: 1\n      failureThreshold: 5\n    startupProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      initialDelaySeconds: 10\n      timeoutSeconds: 1\n      periodSeconds: 10\n      successThreshold: 1\n      failureThreshold: 18\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-metrics\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n\n        exec nice -n -18 etcd grpc-proxy start \\\n          --endpoints https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:9978 \\\n          --metrics-addr https://0.0.0.0:9979 \\\n          --listen-addr 127.0.0.1:9977 \\\n          --advertise-client-url \"\"  \\\n          --key /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --key-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.key \\\n          --cert /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --cert-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.crt \\\n          --cacert /etc/kubernetes/static-pod-certs/configmaps/etcd-peer-client-ca/ca-bundle.crt \\\n          --trusted-ca-file /etc/kubernetes/static-pod-certs/configmaps/etcd-metrics-proxy-serving-ca/ca-bundle.crt \\\n          --listen-cipher-suites TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_256_GCM_SHA384,TLS_CHACHA20_POLY1305_SHA256\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_VERSION\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 200Mi\n        cpu: 40m\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-readyz\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c7cd88272ec1d0a6e1a9814448acb1744650cc1315124b44a8e7b6e711e96ed\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        exec nice -n -18 cluster-etcd-operator readyz \\\n          --target=https://localhost:2379 \\\n          --listen-port=9980 \\\n          --serving-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --serving-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --client-cert-file=$(ETCDCTL_CERT) \\\n          --client-key-file=$(ETCDCTL_KEY) \\\n          --client-cacert-file=$(ETCDCTL_CACERT)\n    securityContext:\n      privileged: true\n    ports:\n    - containerPort: 9980\n      name: readyz\n      protocol: TCP\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n    volumeMounts:\n      - mountPath: /var/log/etcd/\n        name: log-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-pod-REVISION\n      name: resource-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /usr/local/bin\n      name: usr-local-bin\n    - hostPath:\n        path: /var/log/etcd\n      name: log-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:50:17.430656768Z I0611 10:50:17.430584       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-pod -n openshift-etcd:
2024-06-11T10:50:17.430656768Z cause by changes in data.pod.yaml
2024-06-11T10:50:17.634901174Z I0611 10:50:17.634844       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-2 -n openshift-etcd because it was missing
2024-06-11T10:50:18.219803113Z I0611 10:50:18.219743       1 request.go:697] Waited for 1.189989419s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:50:18.585718086Z E0611 10:50:18.585625       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:50:18.831166237Z I0611 10:50:18.831083       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-peer-client-ca-2 -n openshift-etcd because it was missing
2024-06-11T10:50:19.022377602Z I0611 10:50:19.022294       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-1 static pod not found and needs new revision 1
2024-06-11T10:50:19.022411304Z I0611 10:50:19.022376       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T10:50:19.022411304Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T10:50:19.022411304Z  CurrentRevision: (int32) 0,
2024-06-11T10:50:19.022411304Z  TargetRevision: (int32) 1,
2024-06-11T10:50:19.022411304Z  LastFailedRevision: (int32) 0,
2024-06-11T10:50:19.022411304Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:50:19.022411304Z  LastFailedReason: (string) "",
2024-06-11T10:50:19.022411304Z  LastFailedCount: (int) 0,
2024-06-11T10:50:19.022411304Z  LastFallbackCount: (int) 0,
2024-06-11T10:50:19.022411304Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:50:19.022411304Z }
2024-06-11T10:50:19.039933407Z I0611 10:50:19.039854       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 0 to 1 because node ci-op-9xx71rvq-1e28e-w667k-master-1 static pod not found
2024-06-11T10:50:19.040953354Z I0611 10:50:19.040903       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:19.062217428Z I0611 10:50:19.062160       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.29 %, dbSize: 53727232
2024-06-11T10:50:19.633421912Z I0611 10:50:19.633342       1 core.go:359] ConfigMap "openshift-etcd/restore-etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  containers:\n  - name: etcd\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        # this can be controlled by cluster-restore.sh, which will replace this line entirely when enabled at runtime\n        export ETCD_ETCDCTL_RESTORE_ENABLE_BUMP=\"false\"\n        \n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        export ETCD_INITIAL_CLUSTER=\"${ETCD_NAME}=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\"\n        env | grep ETCD | grep -v NODE\n        export ETCD_NODE_PEER_URL=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\n\n        # checking if there are any fio perf file left behind that could be deleted without problems\n        if [ ! -z $(ls -A \"/var/lib/etcd/etcd_perf*\") ]; then\n          rm -f /var/lib/etcd/etcd_perf*\n        fi\n\n        # checking if data directory is empty, if not etcdctl restore will fail\n        if [ ! -z $(ls -A \"/var/lib/etcd\") ]; then\n          echo \"please delete the contents of data directory before restoring, running the restore script will do this for you\"\n          exit 1\n        fi\n        \n        ETCD_ETCDCTL_BIN=\"etcdctl\"\n        if [ -x \"$(command -v etcdutl)\" ]; then\n          echo \"found newer etcdutl, using that instead of etcdctl\"\n          ETCD_ETCDCTL_BIN=\"etcdutl\"\n        fi      \n\n        # check if we have backup file to be restored\n        # if the file exist, check if it has not changed size in last 5 seconds\n        if [ ! -f /var/lib/etcd-backup/snapshot.db ]; then\n          echo \"please make a copy of the snapshot db file, then move that copy to /var/lib/etcd-backup/snapshot.db\"\n          exit 1\n        else\n          filesize=$(stat --format=%s \"/var/lib/etcd-backup/snapshot.db\")\n          sleep 5\n          newfilesize=$(stat --format=%s \"/var/lib/etcd-backup/snapshot.db\")\n          if [ \"$filesize\" != \"$newfilesize\" ]; then\n            echo \"file size has changed since last 5 seconds, retry sometime after copying is complete\"\n            exit 1\n          fi\n        fi\n        \n        BUMP_ARGS=\"\"\n        if [[ \"${ETCD_ETCDCTL_RESTORE_ENABLE_BUMP}\" == \"true\" ]]; then\n          echo \"enabling restore bump\"\n          BUMP_ARGS=\"--bump-revision 1000000000 --mark-compacted\"\n        fi\n                \n        UUID=$(uuidgen)\n        echo \"restoring to a single node cluster\"\n        ${ETCD_ETCDCTL_BIN} snapshot restore /var/lib/etcd-backup/snapshot.db \\\n         --name  $ETCD_NAME \\\n         --initial-cluster=$ETCD_INITIAL_CLUSTER \\\n         --initial-cluster-token \"openshift-etcd-${UUID}\" \\\n         --initial-advertise-peer-urls $ETCD_NODE_PEER_URL \\\n         --data-dir=\"/var/lib/etcd/restore-${UUID}\" \\\n         ${BUMP_ARGS}\n\n        mv /var/lib/etcd/restore-${UUID}/* /var/lib/etcd/\n\n        rmdir /var/lib/etcd/restore-${UUID}\n        rm /var/lib/etcd-backup/snapshot.db\n\n        set -x\n        exec etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-peer-client-ca/ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_REV\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      tcpSocket:\n        port: 2380\n      failureThreshold: 3\n      initialDelaySeconds: 3\n      periodSeconds: 5\n      successThreshold: 1\n      timeoutSeconds: 5\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n      - mountPath: /var/lib/etcd-backup/\n        name: backup-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /var/lib/etcd-backup\n        type: \"\"\n      name: backup-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:50:19.634566964Z I0611 10:50:19.634490       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/restore-etcd-pod -n openshift-etcd:
2024-06-11T10:50:19.634566964Z cause by changes in data.pod.yaml
2024-06-11T10:50:19.834020907Z I0611 10:50:19.833940       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-serving-ca-2 -n openshift-etcd because it was missing
2024-06-11T10:50:20.219368871Z I0611 10:50:20.219293       1 request.go:697] Waited for 1.174269128s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-1-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:21.219442714Z I0611 10:50:21.219357       1 request.go:697] Waited for 1.391931005s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps
2024-06-11T10:50:21.293568912Z I0611 10:50:21.293482       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-client-ca-2 -n openshift-etcd because it was missing
2024-06-11T10:50:21.435694027Z E0611 10:50:21.435635       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:21.435694027Z E0611 10:50:21.435687       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:21.435728828Z I0611 10:50:21.435703       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-1-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-etcd because it was missing
2024-06-11T10:50:22.219493155Z I0611 10:50:22.219421       1 request.go:697] Waited for 1.195763113s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:50:22.429718792Z I0611 10:50:22.429628       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-2 -n openshift-etcd because it was missing
2024-06-11T10:50:22.622481828Z I0611 10:50:22.622424       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 1, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:50:23.219856511Z I0611 10:50:23.219796       1 request.go:697] Waited for 1.596342775s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:50:24.034493153Z I0611 10:50:24.034420       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-2 -n openshift-etcd because it was missing
2024-06-11T10:50:24.419849018Z I0611 10:50:24.419716       1 request.go:697] Waited for 1.596443779s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:50:24.622278397Z E0611 10:50:24.622201       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:25.619602813Z I0611 10:50:25.619520       1 request.go:697] Waited for 1.585274767s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/revision-status-2
2024-06-11T10:50:25.634928816Z I0611 10:50:25.634785       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 2 triggered by "required configmap/etcd-endpoints has been created"
2024-06-11T10:50:25.660289478Z I0611 10:50:25.660184       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 2 created because required configmap/etcd-endpoints has been created
2024-06-11T10:50:25.662751191Z I0611 10:50:25.662685       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:25.678750825Z I0611 10:50:25.678693       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.03 %, dbSize: 54513664
2024-06-11T10:50:25.680707314Z W0611 10:50:25.680655       1 staticpod.go:38] revision 2 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T10:50:25.680808219Z E0611 10:50:25.680789       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 2
2024-06-11T10:50:25.689761629Z I0611 10:50:25.689690       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 3 triggered by "required configmap/etcd-pod has changed"
2024-06-11T10:50:25.822969672Z I0611 10:50:25.822899       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 1, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:50:25.841772166Z I0611 10:50:25.841712       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:25.842643107Z I0611 10:50:25.842598       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 2","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 2\nEtcdMembersAvailable: 1 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:25.856653173Z I0611 10:50:25.856599       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.02 %, dbSize: 54542336
2024-06-11T10:50:25.860437052Z I0611 10:50:25.857964       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 2",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1\nEtcdMembersAvailable: 1 members are available" to "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 2\nEtcdMembersAvailable: 1 members are available"
2024-06-11T10:50:26.619659527Z I0611 10:50:26.619583       1 request.go:697] Waited for 1.596281144s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:27.818977513Z I0611 10:50:27.818918       1 request.go:697] Waited for 1.795915533s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:50:28.039511292Z E0611 10:50:28.039449       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:28.039640198Z E0611 10:50:28.039606       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:28.039923212Z E0611 10:50:28.039893       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:28.228190157Z I0611 10:50:28.228136       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T10:50:28.228190157Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T10:50:28.228190157Z  CurrentRevision: (int32) 0,
2024-06-11T10:50:28.228190157Z  TargetRevision: (int32) 2,
2024-06-11T10:50:28.228190157Z  LastFailedRevision: (int32) 0,
2024-06-11T10:50:28.228190157Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:50:28.228190157Z  LastFailedReason: (string) "",
2024-06-11T10:50:28.228190157Z  LastFailedCount: (int) 0,
2024-06-11T10:50:28.228190157Z  LastFallbackCount: (int) 0,
2024-06-11T10:50:28.228190157Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:50:28.228190157Z }
2024-06-11T10:50:28.228190157Z  because new revision pending
2024-06-11T10:50:28.258881216Z I0611 10:50:28.258827       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:28.279948717Z I0611 10:50:28.279876       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 55042048
2024-06-11T10:50:28.629916245Z I0611 10:50:28.629828       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-3 -n openshift-etcd because it was missing
2024-06-11T10:50:28.819258342Z I0611 10:50:28.819191       1 request.go:697] Waited for 1.149253007s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:50:29.819407665Z I0611 10:50:29.819348       1 request.go:697] Waited for 1.590381367s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:30.427258847Z I0611 10:50:30.427186       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-3 -n openshift-etcd because it was missing
2024-06-11T10:50:30.819423381Z I0611 10:50:30.819365       1 request.go:697] Waited for 1.795279903s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:50:31.422879754Z E0611 10:50:31.422799       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:31.422879754Z E0611 10:50:31.422845       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:31.423291674Z E0611 10:50:31.423243       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:31.631028545Z I0611 10:50:31.630957       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-2-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-etcd because it was missing
2024-06-11T10:50:31.819486099Z I0611 10:50:31.819411       1 request.go:697] Waited for 1.590386968s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T10:50:32.033350561Z I0611 10:50:32.031377       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-peer-client-ca-3 -n openshift-etcd because it was missing
2024-06-11T10:50:32.822343650Z I0611 10:50:32.822247       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 2, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:50:33.019809133Z I0611 10:50:33.019748       1 request.go:697] Waited for 1.388415971s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:50:33.628601960Z I0611 10:50:33.628533       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-serving-ca-3 -n openshift-etcd because it was missing
2024-06-11T10:50:34.219551628Z I0611 10:50:34.219477       1 request.go:697] Waited for 1.395912216s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-2-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:34.823501958Z E0611 10:50:34.823442       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:34.823501958Z E0611 10:50:34.823482       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:34.823767069Z E0611 10:50:34.823742       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:35.227932722Z I0611 10:50:35.227862       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-client-ca-3 -n openshift-etcd because it was missing
2024-06-11T10:50:35.419047427Z I0611 10:50:35.418991       1 request.go:697] Waited for 1.595843921s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:50:35.822576152Z I0611 10:50:35.822480       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 2, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:50:36.419449378Z I0611 10:50:36.419393       1 request.go:697] Waited for 1.19182747s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps
2024-06-11T10:50:36.432369933Z I0611 10:50:36.432285       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-3 -n openshift-etcd because it was missing
2024-06-11T10:50:37.419639620Z I0611 10:50:37.419529       1 request.go:697] Waited for 1.396876573s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:37.431312722Z E0611 10:50:37.431245       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:37.431312722Z E0611 10:50:37.431286       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:37.431640536Z E0611 10:50:37.431612       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:37.447566619Z E0611 10:50:37.447518       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:50:37.653633767Z I0611 10:50:37.653539       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-3 -n openshift-etcd because it was missing
2024-06-11T10:50:38.419616853Z I0611 10:50:38.419556       1 request.go:697] Waited for 1.195925046s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-2-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:38.423045001Z I0611 10:50:38.422984       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:50:39.428702277Z I0611 10:50:39.428617       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 3 triggered by "required configmap/etcd-pod has changed"
2024-06-11T10:50:39.451196543Z I0611 10:50:39.451123       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:39.451869872Z I0611 10:50:39.451827       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 3 created because required configmap/etcd-pod has changed
2024-06-11T10:50:39.619725379Z I0611 10:50:39.619635       1 request.go:697] Waited for 1.794029224s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:50:40.422431142Z E0611 10:50:40.422371       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:40.422431142Z E0611 10:50:40.422406       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:40.422747956Z E0611 10:50:40.422718       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:40.819902907Z I0611 10:50:40.819818       1 request.go:697] Waited for 1.797146258s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:50:41.822739763Z I0611 10:50:41.822655       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 2, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:50:41.842080611Z I0611 10:50:41.842017       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:41.842492629Z I0611 10:50:41.842457       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 1 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:41.852911695Z I0611 10:50:41.852819       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 2" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 2\nEtcdMembersAvailable: 1 members are available" to "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 1 members are available"
2024-06-11T10:50:41.877192079Z I0611 10:50:41.877132       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.02 %, dbSize: 56721408
2024-06-11T10:50:42.019343328Z I0611 10:50:42.019272       1 request.go:697] Waited for 1.595973945s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:43.219885249Z I0611 10:50:43.219801       1 request.go:697] Waited for 1.37873668s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-2-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:43.422615604Z E0611 10:50:43.422540       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:43.422615604Z E0611 10:50:43.422574       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:43.422890416Z E0611 10:50:43.422851       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:44.219972717Z I0611 10:50:44.219820       1 request.go:697] Waited for 1.384233426s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:44.642200475Z I0611 10:50:44.642123       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T10:50:44.642200475Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T10:50:44.642200475Z  CurrentRevision: (int32) 0,
2024-06-11T10:50:44.642200475Z  TargetRevision: (int32) 3,
2024-06-11T10:50:44.642200475Z  LastFailedRevision: (int32) 0,
2024-06-11T10:50:44.642200475Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:50:44.642200475Z  LastFailedReason: (string) "",
2024-06-11T10:50:44.642200475Z  LastFailedCount: (int) 0,
2024-06-11T10:50:44.642200475Z  LastFallbackCount: (int) 0,
2024-06-11T10:50:44.642200475Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:50:44.642200475Z }
2024-06-11T10:50:44.642200475Z  because new revision pending
2024-06-11T10:50:44.663708636Z I0611 10:50:44.663660       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:45.819471257Z I0611 10:50:45.819386       1 request.go:697] Waited for 1.176155032s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:47.020043179Z I0611 10:50:47.019969       1 request.go:697] Waited for 1.597387246s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-06-11T10:50:47.421421206Z E0611 10:50:47.421355       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:47.421421206Z E0611 10:50:47.421398       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:47.421758621Z E0611 10:50:47.421706       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:47.622758399Z I0611 10:50:47.622693       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T10:50:47.622758399Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T10:50:47.622758399Z  CurrentRevision: (int32) 0,
2024-06-11T10:50:47.622758399Z  TargetRevision: (int32) 3,
2024-06-11T10:50:47.622758399Z  LastFailedRevision: (int32) 0,
2024-06-11T10:50:47.622758399Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:50:47.622758399Z  LastFailedReason: (string) "",
2024-06-11T10:50:47.622758399Z  LastFailedCount: (int) 0,
2024-06-11T10:50:47.622758399Z  LastFallbackCount: (int) 0,
2024-06-11T10:50:47.622758399Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:50:47.622758399Z }
2024-06-11T10:50:47.622758399Z  because new revision pending
2024-06-11T10:50:48.224599679Z I0611 10:50:48.224539       1 request.go:697] Waited for 1.398068543s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:49.418893921Z I0611 10:50:49.418829       1 request.go:697] Waited for 1.188136067s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:49.823858509Z E0611 10:50:49.823798       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:49.823858509Z E0611 10:50:49.823833       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:49.824146122Z E0611 10:50:49.824100       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:50.040665671Z I0611 10:50:50.040600       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-3-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-etcd because it was missing
2024-06-11T10:50:50.822168098Z I0611 10:50:50.822098       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:50:51.219705611Z I0611 10:50:51.219633       1 request.go:697] Waited for 1.178504016s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:52.419328157Z I0611 10:50:52.419241       1 request.go:697] Waited for 1.196175595s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:52.422105579Z E0611 10:50:52.422054       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:52.422105579Z E0611 10:50:52.422091       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:52.422468995Z E0611 10:50:52.422432       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:53.222044118Z I0611 10:50:53.221979       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:50:53.619624533Z I0611 10:50:53.619557       1 request.go:697] Waited for 1.234110065s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:50:54.622233500Z E0611 10:50:54.622176       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:54.622233500Z E0611 10:50:54.622212       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:54.622542213Z E0611 10:50:54.622503       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:54.622790824Z E0611 10:50:54.622760       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:54.622790824Z E0611 10:50:54.622786       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:55.422944173Z I0611 10:50:55.422882       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:50:56.019149137Z I0611 10:50:56.019080       1 request.go:697] Waited for 1.07575959s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:50:56.623102943Z E0611 10:50:56.623047       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:57.422586062Z I0611 10:50:57.422525       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:50:59.676497743Z E0611 10:50:59.676432       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:51:00.024955370Z I0611 10:51:00.024871       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:00.025410390Z E0611 10:51:00.025358       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:00.025457792Z E0611 10:51:00.025410       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:00.025768305Z E0611 10:51:00.025737       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:01.662087701Z E0611 10:51:01.662024       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:01.662087701Z E0611 10:51:01.662069       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:01.662389514Z E0611 10:51:01.662357       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:03.827064643Z E0611 10:51:03.826990       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:03.827064643Z E0611 10:51:03.827054       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:03.831242822Z E0611 10:51:03.831189       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:08.482088806Z E0611 10:51:08.481984       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:08.492506168Z E0611 10:51:08.492454       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:08.492772280Z E0611 10:51:08.492729       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:08.503017534Z E0611 10:51:08.502970       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:08.503017534Z E0611 10:51:08.503002       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:08.503436952Z E0611 10:51:08.503391       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:09.608217212Z E0611 10:51:09.608152       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:09.613624751Z E0611 10:51:09.613558       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:09.691063983Z E0611 10:51:09.691000       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:11.086535724Z E0611 10:51:11.086461       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:11.086535724Z E0611 10:51:11.086499       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:11.086804636Z E0611 10:51:11.086778       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:15.769438356Z E0611 10:51:15.769382       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:15.769541760Z E0611 10:51:15.769524       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:15.769954179Z E0611 10:51:15.769902       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:15.781552507Z E0611 10:51:15.781501       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:15.781710715Z E0611 10:51:15.781649       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:15.781995027Z E0611 10:51:15.781953       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:33.592277541Z E0611 10:51:33.592195       1 guard_controller.go:293] Missing PodIP in operand etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:33.592277541Z E0611 10:51:33.592254       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:33.606731388Z I0611 10:51:33.606647       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 3, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:33.648945853Z E0611 10:51:33.648876       1 base_controller.go:268] GuardController reconciliation failed: [Missing PodIP in operand etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:33.650224595Z I0611 10:51:33.650176       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:33.651334151Z I0611 10:51:33.651273       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing PodIP in operand etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 1 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:51:33.687264565Z I0611 10:51:33.687205       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:51:33.691140309Z I0611 10:51:33.690079       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing PodIP in operand etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nEtcdMembersDegraded: No unhealthy members found"
2024-06-11T10:51:33.691663771Z I0611 10:51:33.691606       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.01 %, dbSize: 59641856
2024-06-11T10:51:33.691663771Z I0611 10:51:33.691635       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 60108800
2024-06-11T10:51:33.764161019Z I0611 10:51:33.764106       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:51:33.860566897Z I0611 10:51:33.860498       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:51:33.914648610Z I0611 10:51:33.914582       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:51:34.412176201Z I0611 10:51:34.412107       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:51:34.792848381Z I0611 10:51:34.792782       1 request.go:697] Waited for 1.132071042s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:51:35.063695362Z I0611 10:51:35.063600       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:51:35.869094086Z I0611 10:51:35.869016       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:51:35.992906408Z I0611 10:51:35.992846       1 request.go:697] Waited for 1.396706999s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:36.595202473Z E0611 10:51:36.595145       1 guard_controller.go:293] Missing PodIP in operand etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:36.595202473Z E0611 10:51:36.595181       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:36.595534188Z E0611 10:51:36.595505       1 base_controller.go:268] GuardController reconciliation failed: [Missing PodIP in operand etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:36.595804400Z E0611 10:51:36.595777       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:37.192699424Z I0611 10:51:37.192628       1 request.go:697] Waited for 1.396991111s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:37.198410679Z I0611 10:51:37.198350       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 3, but has not made progress because static pod is pending
2024-06-11T10:51:37.442689975Z I0611 10:51:37.442626       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:37.444125139Z I0611 10:51:37.444062       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing PodIP in operand etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:51:37.461641720Z I0611 10:51:37.461569       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 1 members are available" to "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available"
2024-06-11T10:51:37.475204725Z E0611 10:51:37.475149       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:51:37.477226315Z I0611 10:51:37.477177       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.02 %, dbSize: 59834368
2024-06-11T10:51:37.477226315Z I0611 10:51:37.477203       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 60301312
2024-06-11T10:51:37.497272809Z I0611 10:51:37.497222       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:51:38.392550554Z I0611 10:51:38.392488       1 request.go:697] Waited for 1.192885635s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-3-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:38.903593341Z I0611 10:51:38.903529       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:51:39.168888201Z I0611 10:51:39.168821       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:51:39.592072029Z I0611 10:51:39.592012       1 request.go:697] Waited for 1.389026912s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T10:51:39.907116606Z I0611 10:51:39.907054       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:51:40.592928567Z I0611 10:51:40.592864       1 request.go:697] Waited for 1.597001427s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:51:40.912495546Z I0611 10:51:40.912431       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:51:41.397432729Z I0611 10:51:41.397350       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 3, but has not made progress because static pod is pending
2024-06-11T10:51:41.534510797Z I0611 10:51:41.534444       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:51:41.792165955Z I0611 10:51:41.792102       1 request.go:697] Waited for 1.395005826s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:51:42.792746569Z I0611 10:51:42.792682       1 request.go:697] Waited for 1.393506455s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-3-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:42.949821981Z I0611 10:51:42.949740       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MemberAddAsLearner' successfully added new member https://10.0.0.6:2380
2024-06-11T10:51:42.964015651Z I0611 10:51:42.963958       1 clustermembercontroller.go:293] Not ready for promotion: etcd learner member (https://10.0.0.6:2380) is not yet in sync with leader's log 
2024-06-11T10:51:43.792983367Z I0611 10:51:43.792918       1 request.go:697] Waited for 1.397511044s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods
2024-06-11T10:51:43.803337056Z I0611 10:51:43.803236       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-etcd because it was missing
2024-06-11T10:51:43.831669693Z E0611 10:51:43.831592       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:43.832882250Z I0611 10:51:43.832831       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:43.834030904Z I0611 10:51:43.833971       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:51:43.844098479Z I0611 10:51:43.844039       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing PodIP in operand etcd-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2\nEtcdMembersDegraded: No unhealthy members found"
2024-06-11T10:51:44.993465014Z I0611 10:51:44.993397       1 request.go:697] Waited for 1.168187123s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:51:45.266286988Z I0611 10:51:45.266209       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MemberPromote' successfully promoted learner member https://10.0.0.6:2380
2024-06-11T10:51:45.795988483Z I0611 10:51:45.795905       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 3, but has not made progress because static pod is pending
2024-06-11T10:51:46.192089531Z I0611 10:51:46.191997       1 request.go:697] Waited for 1.594750829s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:51:47.192361784Z I0611 10:51:47.192257       1 request.go:697] Waited for 1.395095228s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-3-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:48.192553458Z I0611 10:51:48.192425       1 request.go:697] Waited for 1.395859401s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:49.196030694Z I0611 10:51:49.195951       1 core.go:227] Pod "openshift-etcd/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c7cd88272ec1d0a6e1a9814448acb1744650cc1315124b44a8e7b6e711e96ed","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.6","path":"readyz","port":9980,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-06-11T10:51:49.602822968Z I0611 10:51:49.602755       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 3, but has not made progress because static pod is pending
2024-06-11T10:51:50.202920510Z E0611 10:51:50.202840       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:50.203345370Z I0611 10:51:50.203231       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-etcd because it changed
2024-06-11T10:51:50.203406478Z E0611 10:51:50.203253       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:51.996380976Z I0611 10:51:51.996290       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 3, but has not made progress because static pod is pending
2024-06-11T10:51:52.995773738Z E0611 10:51:52.995716       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:52.996017772Z E0611 10:51:52.995992       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:53.396772497Z I0611 10:51:53.396710       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:53Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:51:53.408037680Z I0611 10:51:53.406321       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded changed from False to True ("GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2")
2024-06-11T10:51:53.408037680Z I0611 10:51:53.407431       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:53Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:51:53.413242512Z E0611 10:51:53.413190       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:51:53.600130278Z I0611 10:51:53.596848       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 3, but has not made progress because static pod is pending
2024-06-11T10:51:54.992556497Z I0611 10:51:54.992462       1 request.go:697] Waited for 1.019716907s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:51:56.192348550Z I0611 10:51:56.192260       1 request.go:697] Waited for 1.196116962s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:51:56.797202294Z I0611 10:51:56.797079       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T10:51:56.797202294Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T10:51:56.797202294Z  CurrentRevision: (int32) 3,
2024-06-11T10:51:56.797202294Z  TargetRevision: (int32) 0,
2024-06-11T10:51:56.797202294Z  LastFailedRevision: (int32) 0,
2024-06-11T10:51:56.797202294Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:51:56.797202294Z  LastFailedReason: (string) "",
2024-06-11T10:51:56.797202294Z  LastFailedCount: (int) 0,
2024-06-11T10:51:56.797202294Z  LastFallbackCount: (int) 0,
2024-06-11T10:51:56.797202294Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:51:56.797202294Z }
2024-06-11T10:51:56.797202294Z  because static pod is ready
2024-06-11T10:51:56.814834888Z I0611 10:51:56.814751       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 0 to 3 because static pod is ready
2024-06-11T10:51:56.817509663Z I0611 10:51:56.816351       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:56.817509663Z I0611 10:51:56.817154       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:53Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:51:56.832164616Z I0611 10:51:56.832107       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3" to "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 1; 0 nodes have achieved new revision 3\nEtcdMembersAvailable: 2 members are available" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3\nEtcdMembersAvailable: 2 members are available"
2024-06-11T10:51:56.873171940Z I0611 10:51:56.873103       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.01 %, dbSize: 60497920
2024-06-11T10:51:56.873171940Z I0611 10:51:56.873131       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.07 %, dbSize: 60989440
2024-06-11T10:51:57.396329505Z E0611 10:51:57.396266       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:57.396718689Z E0611 10:51:57.396690       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:57.473687050Z I0611 10:51:57.473623       1 core.go:359] ConfigMap "openshift-etcd/etcd-endpoints" changes: {"data":{"7d736d9464ec5c19":"10.0.0.6"},"metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:51:57.474361395Z W0611 10:51:57.474267       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.8:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.8:2379]]
2024-06-11T10:51:57.474534832Z I0611 10:51:57.474480       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-endpoints -n openshift-etcd:
2024-06-11T10:51:57.474534832Z cause by changes in data.7d736d9464ec5c19
2024-06-11T10:51:57.477866849Z W0611 10:51:57.474978       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.8:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.8:2379]]
2024-06-11T10:51:57.483800626Z I0611 10:51:57.483743       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 4 triggered by "required configmap/etcd-endpoints has changed"
2024-06-11T10:51:57.591853575Z W0611 10:51:57.590967       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.8:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.8:2379]]
2024-06-11T10:51:57.603337246Z W0611 10:51:57.603272       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.8:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.8:2379]]
2024-06-11T10:51:57.992329943Z I0611 10:51:57.992238       1 request.go:697] Waited for 1.176064648s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-3-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:58.992344737Z I0611 10:51:58.992280       1 request.go:697] Waited for 1.508633335s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps
2024-06-11T10:52:00.192949377Z I0611 10:52:00.192883       1 request.go:697] Waited for 1.397152999s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:00.402282746Z I0611 10:52:00.402189       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-4 -n openshift-etcd because it was missing
2024-06-11T10:52:00.796340231Z I0611 10:52:00.796241       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T10:52:00.796340231Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T10:52:00.796340231Z  CurrentRevision: (int32) 3,
2024-06-11T10:52:00.796340231Z  TargetRevision: (int32) 0,
2024-06-11T10:52:00.796340231Z  LastFailedRevision: (int32) 0,
2024-06-11T10:52:00.796340231Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:52:00.796340231Z  LastFailedReason: (string) "",
2024-06-11T10:52:00.796340231Z  LastFailedCount: (int) 0,
2024-06-11T10:52:00.796340231Z  LastFallbackCount: (int) 0,
2024-06-11T10:52:00.796340231Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:52:00.796340231Z }
2024-06-11T10:52:00.796340231Z  because static pod is ready
2024-06-11T10:52:01.392920007Z I0611 10:52:01.392845       1 request.go:697] Waited for 1.190723733s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:01.600446764Z I0611 10:52:01.600375       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-4 -n openshift-etcd because it was missing
2024-06-11T10:52:02.592543673Z I0611 10:52:02.592483       1 request.go:697] Waited for 1.196197172s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:02.595867595Z E0611 10:52:02.595816       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:02.596199757Z E0611 10:52:02.596166       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:02.801210705Z I0611 10:52:02.801137       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-peer-client-ca-4 -n openshift-etcd because it was missing
2024-06-11T10:52:03.603389457Z I0611 10:52:03.603282       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-serving-ca-4 -n openshift-etcd because it was missing
2024-06-11T10:52:03.796035193Z I0611 10:52:03.795968       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-2 static pod not found and needs new revision 3
2024-06-11T10:52:03.796085402Z I0611 10:52:03.796027       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T10:52:03.796085402Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T10:52:03.796085402Z  CurrentRevision: (int32) 0,
2024-06-11T10:52:03.796085402Z  TargetRevision: (int32) 3,
2024-06-11T10:52:03.796085402Z  LastFailedRevision: (int32) 0,
2024-06-11T10:52:03.796085402Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:52:03.796085402Z  LastFailedReason: (string) "",
2024-06-11T10:52:03.796085402Z  LastFailedCount: (int) 0,
2024-06-11T10:52:03.796085402Z  LastFallbackCount: (int) 0,
2024-06-11T10:52:03.796085402Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:52:03.796085402Z }
2024-06-11T10:52:03.813632084Z I0611 10:52:03.813567       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-2" from revision 0 to 3 because node ci-op-9xx71rvq-1e28e-w667k-master-2 static pod not found
2024-06-11T10:52:03.814974235Z I0611 10:52:03.814927       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:04.200697687Z I0611 10:52:04.200614       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-client-ca-4 -n openshift-etcd because it was missing
2024-06-11T10:52:04.992711338Z I0611 10:52:04.992619       1 request.go:697] Waited for 1.176397352s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-3-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:05.602537609Z I0611 10:52:05.602455       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-4 -n openshift-etcd because it was missing
2024-06-11T10:52:06.192819725Z I0611 10:52:06.192763       1 request.go:697] Waited for 1.397342981s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-06-11T10:52:06.405638034Z I0611 10:52:06.405476       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-3-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-etcd because it was missing
2024-06-11T10:52:06.803427942Z I0611 10:52:06.803336       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-4 -n openshift-etcd because it was missing
2024-06-11T10:52:07.001013802Z I0611 10:52:07.000930       1 core.go:359] ConfigMap "openshift-etcd/etcd-scripts" changes: {"apiVersion":"v1","data":{"etcd.env":"export ALL_ETCD_ENDPOINTS=\"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.8:2379\"\nexport ETCDCTL_API=\"3\"\nexport ETCDCTL_CACERT=\"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\nexport ETCDCTL_CERT=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\nexport ETCDCTL_ENDPOINTS=\"https://10.0.0.6:2379,https://10.0.0.8:2379\"\nexport ETCDCTL_KEY=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\nexport ETCD_CIPHER_SUITES=\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\nexport ETCD_DATA_DIR=\"/var/lib/etcd\"\nexport ETCD_ELECTION_TIMEOUT=\"2500\"\nexport ETCD_ENABLE_PPROF=\"true\"\nexport ETCD_EXPERIMENTAL_MAX_LEARNERS=\"3\"\nexport ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION=\"200ms\"\nexport ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL=\"5s\"\nexport ETCD_HEARTBEAT_INTERVAL=\"500\"\nexport ETCD_IMAGE=\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\nexport ETCD_INITIAL_CLUSTER_STATE=\"existing\"\nexport ETCD_QUOTA_BACKEND_BYTES=\"8589934592\"\nexport ETCD_SOCKET_REUSE_ADDRESS=\"true\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME=\"ci-op-9xx71rvq-1e28e-w667k-master-0\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST=\"10.0.0.8\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP=\"10.0.0.8\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME=\"ci-op-9xx71rvq-1e28e-w667k-master-1\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST=\"10.0.0.6\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP=\"10.0.0.6\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME=\"ci-op-9xx71rvq-1e28e-w667k-master-2\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST=\"10.0.0.7\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP=\"10.0.0.7\"\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:52:07.002046995Z I0611 10:52:07.001969       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-scripts -n openshift-etcd:
2024-06-11T10:52:07.002046995Z cause by changes in data.etcd.env
2024-06-11T10:52:07.392274489Z I0611 10:52:07.392180       1 request.go:697] Waited for 1.195932006s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-06-11T10:52:07.796466096Z I0611 10:52:07.796277       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:52:08.212247170Z I0611 10:52:08.212129       1 core.go:359] ConfigMap "openshift-etcd/etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  annotations:\n    kubectl.kubernetes.io/default-container: etcd\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  initContainers:\n    - name: setup\n      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          echo -n \"Fixing etcd log permissions.\"\n          mkdir -p /var/log/etcd \u0026\u0026 chmod 0700 /var/log/etcd\n      securityContext:\n        privileged: true\n      resources:\n        requests:\n          memory: 50Mi\n          cpu: 5m\n      volumeMounts:\n        - mountPath: /var/log/etcd\n          name: log-dir\n    - name: etcd-ensure-env-vars\n      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_NAME?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_IP?not set}\"\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected node IP to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_IP}\" \u003e\u00262\n            exit 1\n          fi\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected etcd url host to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" \u003e\u00262\n            exit 1\n          fi\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: NODE_IP\n        valueFrom:\n          fieldRef:\n            fieldPath: status.podIP\n    - name: etcd-resources-copy\n      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          rm -f $(grep -l '^### Created by cluster-etcd-operator' /usr/local/bin/*)\n          cp -p /etc/kubernetes/static-pod-certs/configmaps/etcd-scripts/*.sh /usr/local/bin\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      volumeMounts:\n        - mountPath: /etc/kubernetes/static-pod-resources\n          name: resource-dir\n        - mountPath: /etc/kubernetes/static-pod-certs\n          name: cert-dir\n        - mountPath: /usr/local/bin\n          name: usr-local-bin\n  containers:\n  # The etcdctl container should always be first. It is intended to be used\n  # to open a remote shell via `oc rsh` that is ready to run `etcdctl`.\n  - name: etcdctl\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - \"/bin/bash\"\n      - \"-c\"\n      - \"trap TERM INT; sleep infinity \u0026 wait\"\n    resources:\n      requests:\n        memory: 60Mi\n        cpu: 10m\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_VERSION\"\n        value: \"REVISION\"\n  - name: etcd\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        etcdctl member list || true\n\n        # this has a non-zero return code if the command is non-zero.  If you use an export first, it doesn't and you\n        # will succeed when you should fail.\n        ETCD_INITIAL_CLUSTER=$(discover-etcd-initial-cluster \\\n          --cacert=/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt \\\n          --cert=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --key=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --endpoints=${ALL_ETCD_ENDPOINTS} \\\n          --data-dir=/var/lib/etcd \\\n          --target-peer-url-host=${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST} \\\n          --target-name=NODE_NAME)\n        export ETCD_INITIAL_CLUSTER\n\n        # we cannot use the \"normal\" port conflict initcontainer because when we upgrade, the existing static pod will never yield,\n        # so we do the detection in etcd container itself.\n        echo -n \"Waiting for ports 2379, 2380 and 9978 to be released.\"\n        time while [ -n \"$(ss -Htan '( sport = 2379 or sport = 2380 or sport = 9978 )')\" ]; do\n          echo -n \".\"\n          sleep 1\n        done\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        env | grep ETCD | grep -v NODE\n\n        set -x\n        # See https://etcd.io/docs/v3.4.0/tuning/ for why we use ionice\n        exec nice -n -19 ionice -c2 -n0 etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --experimental-initial-corrupt-check=true \\\n          --snapshot-count=10000 \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-peer-client-ca/ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379,unixs://${NODE_NODE_ENVVAR_NAME_IP}:0 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978 ||  mv /etc/kubernetes/etcd-backup-dir/etcd-member.yaml /etc/kubernetes/manifests\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_VERSION\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      timeoutSeconds: 30\n      failureThreshold: 5\n      periodSeconds: 5\n      successThreshold: 1\n    livenessProbe:\n      httpGet:\n        path: healthz\n        port: 9980\n        scheme: HTTPS\n      timeoutSeconds: 30\n      periodSeconds: 5\n      successThreshold: 1\n      failureThreshold: 5\n    startupProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      initialDelaySeconds: 10\n      timeoutSeconds: 1\n      periodSeconds: 10\n      successThreshold: 1\n      failureThreshold: 18\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-metrics\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n\n        exec nice -n -18 etcd grpc-proxy start \\\n          --endpoints https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:9978 \\\n          --metrics-addr https://0.0.0.0:9979 \\\n          --listen-addr 127.0.0.1:9977 \\\n          --advertise-client-url \"\"  \\\n          --key /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --key-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.key \\\n          --cert /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --cert-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.crt \\\n          --cacert /etc/kubernetes/static-pod-certs/configmaps/etcd-peer-client-ca/ca-bundle.crt \\\n          --trusted-ca-file /etc/kubernetes/static-pod-certs/configmaps/etcd-metrics-proxy-serving-ca/ca-bundle.crt \\\n          --listen-cipher-suites TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_256_GCM_SHA384,TLS_CHACHA20_POLY1305_SHA256\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_VERSION\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 200Mi\n        cpu: 40m\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-readyz\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c7cd88272ec1d0a6e1a9814448acb1744650cc1315124b44a8e7b6e711e96ed\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        exec nice -n -18 cluster-etcd-operator readyz \\\n          --target=https://localhost:2379 \\\n          --listen-port=9980 \\\n          --serving-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --serving-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --client-cert-file=$(ETCDCTL_CERT) \\\n          --client-key-file=$(ETCDCTL_KEY) \\\n          --client-cacert-file=$(ETCDCTL_CACERT)\n    securityContext:\n      privileged: true\n    ports:\n    - containerPort: 9980\n      name: readyz\n      protocol: TCP\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n    volumeMounts:\n      - mountPath: /var/log/etcd/\n        name: log-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-pod-REVISION\n      name: resource-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /usr/local/bin\n      name: usr-local-bin\n    - hostPath:\n        path: /var/log/etcd\n      name: log-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:52:08.213209550Z I0611 10:52:08.213121       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-pod -n openshift-etcd:
2024-06-11T10:52:08.213209550Z cause by changes in data.pod.yaml
2024-06-11T10:52:08.392278846Z I0611 10:52:08.392198       1 request.go:697] Waited for 1.588905114s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/revision-status-4
2024-06-11T10:52:08.401138803Z I0611 10:52:08.401051       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 4 triggered by "required configmap/etcd-endpoints has changed"
2024-06-11T10:52:08.420184166Z I0611 10:52:08.420109       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 4 created because required configmap/etcd-endpoints has changed
2024-06-11T10:52:08.420984015Z W0611 10:52:08.420923       1 staticpod.go:38] revision 4 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T10:52:08.420984015Z E0611 10:52:08.420966       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 4
2024-06-11T10:52:08.421229261Z I0611 10:52:08.421183       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:08.432989261Z I0611 10:52:08.432936       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required configmap/etcd-pod has changed"
2024-06-11T10:52:08.457922025Z I0611 10:52:08.457873       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.01 %, dbSize: 61399040
2024-06-11T10:52:08.457922025Z I0611 10:52:08.457898       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.04 %, dbSize: 61878272
2024-06-11T10:52:09.392705981Z I0611 10:52:09.392642       1 request.go:697] Waited for 1.397431698s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:09.498223619Z I0611 10:52:09.498148       1 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:00 +0000 UTC to 2034-06-09 10:19:00 +0000 UTC (now=2024-06-11 10:52:09.498093995 +0000 UTC))"
2024-06-11T10:52:09.498276429Z I0611 10:52:09.498226       1 tlsconfig.go:178] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2024-06-12 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.498198314 +0000 UTC))"
2024-06-11T10:52:09.498276429Z I0611 10:52:09.498261       1 tlsconfig.go:178] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2025-06-11 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.498239422 +0000 UTC))"
2024-06-11T10:52:09.499406140Z I0611 10:52:09.498322       1 tlsconfig.go:178] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2025-06-11 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.498278429 +0000 UTC))"
2024-06-11T10:52:09.499406140Z I0611 10:52:09.498365       1 tlsconfig.go:178] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:01 +0000 UTC to 2034-06-09 10:19:01 +0000 UTC (now=2024-06-11 10:52:09.498343441 +0000 UTC))"
2024-06-11T10:52:09.499406140Z I0611 10:52:09.498400       1 tlsconfig.go:178] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1718102903\" [] issuer=\"kubelet-signer\" (2024-06-11 10:48:22 +0000 UTC to 2024-06-12 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.498378348 +0000 UTC))"
2024-06-11T10:52:09.499406140Z I0611 10:52:09.498435       1 tlsconfig.go:178] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1718102900\" [] issuer=\"<self>\" (2024-06-11 10:48:20 +0000 UTC to 2025-06-11 10:48:21 +0000 UTC (now=2024-06-11 10:52:09.498412854 +0000 UTC))"
2024-06-11T10:52:09.499406140Z I0611 10:52:09.498470       1 tlsconfig.go:178] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:02 +0000 UTC to 2024-06-12 10:19:02 +0000 UTC (now=2024-06-11 10:52:09.498449561 +0000 UTC))"
2024-06-11T10:52:09.499406140Z I0611 10:52:09.499202       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-etcd-operator.svc\" [serving] validServingFor=[metrics.openshift-etcd-operator.svc,metrics.openshift-etcd-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1718102902\" (2024-06-11 10:48:31 +0000 UTC to 2026-06-11 10:48:32 +0000 UTC (now=2024-06-11 10:52:09.499163895 +0000 UTC))"
2024-06-11T10:52:09.501525037Z I0611 10:52:09.499807       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1718102977\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1718102977\" (2024-06-11 09:49:36 +0000 UTC to 2025-06-11 09:49:36 +0000 UTC (now=2024-06-11 10:52:09.499769208 +0000 UTC))"
2024-06-11T10:52:10.592949547Z I0611 10:52:10.592879       1 request.go:697] Waited for 1.790557889s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T10:52:10.795521985Z I0611 10:52:10.795445       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 3, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:52:10.814857325Z I0611 10:52:10.814796       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:10.815773588Z I0611 10:52:10.815718       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:53Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 4\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:52:10.835417783Z I0611 10:52:10.833050       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3" to "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 4",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3\nEtcdMembersAvailable: 2 members are available" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 4\nEtcdMembersAvailable: 2 members are available"
2024-06-11T10:52:10.849329458Z I0611 10:52:10.849250       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.07 %, dbSize: 61968384
2024-06-11T10:52:11.202130922Z I0611 10:52:11.202044       1 core.go:359] ConfigMap "openshift-etcd/restore-etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  containers:\n  - name: etcd\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        # this can be controlled by cluster-restore.sh, which will replace this line entirely when enabled at runtime\n        export ETCD_ETCDCTL_RESTORE_ENABLE_BUMP=\"false\"\n        \n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        export ETCD_INITIAL_CLUSTER=\"${ETCD_NAME}=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\"\n        env | grep ETCD | grep -v NODE\n        export ETCD_NODE_PEER_URL=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\n\n        # checking if there are any fio perf file left behind that could be deleted without problems\n        if [ ! -z $(ls -A \"/var/lib/etcd/etcd_perf*\") ]; then\n          rm -f /var/lib/etcd/etcd_perf*\n        fi\n\n        # checking if data directory is empty, if not etcdctl restore will fail\n        if [ ! -z $(ls -A \"/var/lib/etcd\") ]; then\n          echo \"please delete the contents of data directory before restoring, running the restore script will do this for you\"\n          exit 1\n        fi\n        \n        ETCD_ETCDCTL_BIN=\"etcdctl\"\n        if [ -x \"$(command -v etcdutl)\" ]; then\n          echo \"found newer etcdutl, using that instead of etcdctl\"\n          ETCD_ETCDCTL_BIN=\"etcdutl\"\n        fi      \n\n        # check if we have backup file to be restored\n        # if the file exist, check if it has not changed size in last 5 seconds\n        if [ ! -f /var/lib/etcd-backup/snapshot.db ]; then\n          echo \"please make a copy of the snapshot db file, then move that copy to /var/lib/etcd-backup/snapshot.db\"\n          exit 1\n        else\n          filesize=$(stat --format=%s \"/var/lib/etcd-backup/snapshot.db\")\n          sleep 5\n          newfilesize=$(stat --format=%s \"/var/lib/etcd-backup/snapshot.db\")\n          if [ \"$filesize\" != \"$newfilesize\" ]; then\n            echo \"file size has changed since last 5 seconds, retry sometime after copying is complete\"\n            exit 1\n          fi\n        fi\n        \n        BUMP_ARGS=\"\"\n        if [[ \"${ETCD_ETCDCTL_RESTORE_ENABLE_BUMP}\" == \"true\" ]]; then\n          echo \"enabling restore bump\"\n          BUMP_ARGS=\"--bump-revision 1000000000 --mark-compacted\"\n        fi\n                \n        UUID=$(uuidgen)\n        echo \"restoring to a single node cluster\"\n        ${ETCD_ETCDCTL_BIN} snapshot restore /var/lib/etcd-backup/snapshot.db \\\n         --name  $ETCD_NAME \\\n         --initial-cluster=$ETCD_INITIAL_CLUSTER \\\n         --initial-cluster-token \"openshift-etcd-${UUID}\" \\\n         --initial-advertise-peer-urls $ETCD_NODE_PEER_URL \\\n         --data-dir=\"/var/lib/etcd/restore-${UUID}\" \\\n         ${BUMP_ARGS}\n\n        mv /var/lib/etcd/restore-${UUID}/* /var/lib/etcd/\n\n        rmdir /var/lib/etcd/restore-${UUID}\n        rm /var/lib/etcd-backup/snapshot.db\n\n        set -x\n        exec etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-peer-client-ca/ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_REV\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      tcpSocket:\n        port: 2380\n      failureThreshold: 3\n      initialDelaySeconds: 3\n      periodSeconds: 5\n      successThreshold: 1\n      timeoutSeconds: 5\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n      - mountPath: /var/lib/etcd-backup/\n        name: backup-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /var/lib/etcd-backup\n        type: \"\"\n      name: backup-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:52:11.204469438Z I0611 10:52:11.203531       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/restore-etcd-pod -n openshift-etcd:
2024-06-11T10:52:11.204469438Z cause by changes in data.pod.yaml
2024-06-11T10:52:11.603324995Z I0611 10:52:11.602365       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-5 -n openshift-etcd because it was missing
2024-06-11T10:52:11.792508851Z I0611 10:52:11.792437       1 request.go:697] Waited for 1.396267398s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:12.796107993Z E0611 10:52:12.795842       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:12.796440552Z E0611 10:52:12.796119       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:12.992421417Z I0611 10:52:12.992355       1 request.go:697] Waited for 1.789180198s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:52:13.400153054Z I0611 10:52:13.399933       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-5 -n openshift-etcd because it was missing
2024-06-11T10:52:13.992653460Z I0611 10:52:13.992584       1 request.go:697] Waited for 1.596558231s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-3-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:14.001213883Z I0611 10:52:14.001135       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T10:52:14.001213883Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T10:52:14.001213883Z  CurrentRevision: (int32) 0,
2024-06-11T10:52:14.001213883Z  TargetRevision: (int32) 4,
2024-06-11T10:52:14.001213883Z  LastFailedRevision: (int32) 0,
2024-06-11T10:52:14.001213883Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:52:14.001213883Z  LastFailedReason: (string) "",
2024-06-11T10:52:14.001213883Z  LastFailedCount: (int) 0,
2024-06-11T10:52:14.001213883Z  LastFallbackCount: (int) 0,
2024-06-11T10:52:14.001213883Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:52:14.001213883Z }
2024-06-11T10:52:14.001213883Z  because new revision pending
2024-06-11T10:52:14.028590854Z I0611 10:52:14.028530       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:14.085502178Z I0611 10:52:14.085416       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.01 %, dbSize: 61702144
2024-06-11T10:52:14.085502178Z I0611 10:52:14.085447       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 62173184
2024-06-11T10:52:14.801335826Z I0611 10:52:14.801214       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-peer-client-ca-5 -n openshift-etcd because it was missing
2024-06-11T10:52:14.992925211Z I0611 10:52:14.992860       1 request.go:697] Waited for 1.396263497s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:15.995197917Z E0611 10:52:15.995137       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:16.192659245Z I0611 10:52:16.192594       1 request.go:697] Waited for 1.795886991s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:52:16.600777450Z I0611 10:52:16.600692       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-serving-ca-5 -n openshift-etcd because it was missing
2024-06-11T10:52:17.193084123Z I0611 10:52:17.193018       1 request.go:697] Waited for 1.59632909s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-3-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:17.197811464Z I0611 10:52:17.197762       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T10:52:17.197811464Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T10:52:17.197811464Z  CurrentRevision: (int32) 0,
2024-06-11T10:52:17.197811464Z  TargetRevision: (int32) 4,
2024-06-11T10:52:17.197811464Z  LastFailedRevision: (int32) 0,
2024-06-11T10:52:17.197811464Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:52:17.197811464Z  LastFailedReason: (string) "",
2024-06-11T10:52:17.197811464Z  LastFailedCount: (int) 0,
2024-06-11T10:52:17.197811464Z  LastFallbackCount: (int) 0,
2024-06-11T10:52:17.197811464Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:52:17.197811464Z }
2024-06-11T10:52:17.197811464Z  because new revision pending
2024-06-11T10:52:18.004579200Z I0611 10:52:18.004484       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-client-ca-5 -n openshift-etcd because it was missing
2024-06-11T10:52:18.392552745Z I0611 10:52:18.392484       1 request.go:697] Waited for 1.38562844s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-06-11T10:52:18.796024172Z E0611 10:52:18.795964       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:19.204115458Z I0611 10:52:19.204031       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-5 -n openshift-etcd because it was missing
2024-06-11T10:52:19.592824239Z I0611 10:52:19.592745       1 request.go:697] Waited for 1.196824454s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-06-11T10:52:19.801532649Z I0611 10:52:19.801402       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-4-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-etcd because it was missing
2024-06-11T10:52:20.401997208Z I0611 10:52:20.401912       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-5 -n openshift-etcd because it was missing
2024-06-11T10:52:20.592996025Z I0611 10:52:20.592927       1 request.go:697] Waited for 1.196613615s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:20.995819231Z I0611 10:52:20.995748       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 4, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:52:21.792451768Z I0611 10:52:21.792390       1 request.go:697] Waited for 1.390486166s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/revision-status-5
2024-06-11T10:52:21.806462773Z I0611 10:52:21.806361       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 5 triggered by "required configmap/etcd-pod has changed"
2024-06-11T10:52:21.822683690Z I0611 10:52:21.822609       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 5 created because required configmap/etcd-pod has changed
2024-06-11T10:52:21.827856852Z I0611 10:52:21.827755       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:21.841779241Z W0611 10:52:21.841705       1 staticpod.go:38] revision 5 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T10:52:21.841779241Z E0611 10:52:21.841748       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 5
2024-06-11T10:52:22.992076543Z I0611 10:52:22.992005       1 request.go:697] Waited for 1.169935054s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T10:52:23.796269685Z I0611 10:52:23.796199       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 4, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:52:23.822199007Z I0611 10:52:23.822091       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:23.826516010Z I0611 10:52:23.826469       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:53Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 2 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:52:23.842768432Z I0611 10:52:23.840437       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 4" to "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 4\nEtcdMembersAvailable: 2 members are available" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 2 members are available"
2024-06-11T10:52:23.864240425Z I0611 10:52:23.864162       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.01 %, dbSize: 63725568
2024-06-11T10:52:23.992653503Z I0611 10:52:23.992587       1 request.go:697] Waited for 1.595194332s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:52:24.209868795Z E0611 10:52:24.209808       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:24.210237464Z E0611 10:52:24.210186       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:25.192433707Z I0611 10:52:25.192368       1 request.go:697] Waited for 1.374504494s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-4-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:26.192518096Z I0611 10:52:26.192437       1 request.go:697] Waited for 1.392268318s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-06-11T10:52:26.622477672Z I0611 10:52:26.622408       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T10:52:26.622477672Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T10:52:26.622477672Z  CurrentRevision: (int32) 0,
2024-06-11T10:52:26.622477672Z  TargetRevision: (int32) 5,
2024-06-11T10:52:26.622477672Z  LastFailedRevision: (int32) 0,
2024-06-11T10:52:26.622477672Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:52:26.622477672Z  LastFailedReason: (string) "",
2024-06-11T10:52:26.622477672Z  LastFailedCount: (int) 0,
2024-06-11T10:52:26.622477672Z  LastFallbackCount: (int) 0,
2024-06-11T10:52:26.622477672Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:52:26.622477672Z }
2024-06-11T10:52:26.622477672Z  because new revision pending
2024-06-11T10:52:26.667209495Z I0611 10:52:26.667146       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:27.192808339Z I0611 10:52:27.192744       1 request.go:697] Waited for 1.391774661s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:52:28.392413875Z I0611 10:52:28.392353       1 request.go:697] Waited for 1.578968125s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T10:52:29.592637024Z I0611 10:52:29.592569       1 request.go:697] Waited for 1.595711266s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:52:29.801813408Z I0611 10:52:29.801744       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-etcd because it was missing
2024-06-11T10:52:29.995433568Z E0611 10:52:29.995367       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:29.995741524Z E0611 10:52:29.995711       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:30.792188651Z I0611 10:52:30.792127       1 request.go:697] Waited for 1.395225959s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-06-11T10:52:30.995756217Z I0611 10:52:30.995690       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:52:31.792442887Z I0611 10:52:31.792374       1 request.go:697] Waited for 1.195790044s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:32.993019600Z I0611 10:52:32.992952       1 request.go:697] Waited for 1.196847536s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:33.395686421Z I0611 10:52:33.395611       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:52:34.395886690Z E0611 10:52:34.395820       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:34.396234651Z E0611 10:52:34.396201       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:34.795859908Z I0611 10:52:34.795785       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:52:35.796861388Z E0611 10:52:35.796804       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:35.797145437Z E0611 10:52:35.797118       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:37.446742847Z I0611 10:52:37.446660       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:37.447696313Z I0611 10:52:37.447647       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:53Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:52:37.453875287Z E0611 10:52:37.453666       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:52:37.460930113Z I0611 10:52:37.460861       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 2 members are available" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 3 members are available"
2024-06-11T10:52:37.483223288Z I0611 10:52:37.483161       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.02 %, dbSize: 66191360
2024-06-11T10:52:37.483223288Z I0611 10:52:37.483183       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.04 %, dbSize: 66678784
2024-06-11T10:52:37.595934677Z E0611 10:52:37.595873       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:37.596192022Z E0611 10:52:37.596160       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:38.592136123Z I0611 10:52:38.592071       1 request.go:697] Waited for 1.145791245s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:39.592579806Z I0611 10:52:39.592482       1 request.go:697] Waited for 1.395896815s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:52:40.195970579Z I0611 10:52:40.195899       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:52:40.592736539Z I0611 10:52:40.592664       1 request.go:697] Waited for 1.470886448s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:52:42.192723442Z I0611 10:52:42.192648       1 request.go:697] Waited for 1.018142575s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:42.795852009Z E0611 10:52:42.795772       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:42.796170364Z E0611 10:52:42.796137       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:43.392700995Z I0611 10:52:43.392597       1 request.go:697] Waited for 1.196878019s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:43.396239004Z I0611 10:52:43.396176       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:52:44.592461710Z I0611 10:52:44.592394       1 request.go:697] Waited for 1.395344397s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:52:45.796346235Z I0611 10:52:45.796219       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:52:47.198088734Z E0611 10:52:47.198027       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:47.198465199Z E0611 10:52:47.198428       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:06.955260419Z E0611 10:53:06.955195       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:06.955608765Z E0611 10:53:06.955554       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:13.027961639Z E0611 10:53:13.027903       1 guard_controller.go:293] Missing PodIP in operand etcd-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:13.028879391Z I0611 10:53:13.028841       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:53:13.054101878Z E0611 10:53:13.054000       1 base_controller.go:268] GuardController reconciliation failed: Missing PodIP in operand etcd-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:13.055136549Z I0611 10:53:13.055075       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:53:13.059295740Z I0611 10:53:13.059237       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:51:53Z","message":"GuardControllerDegraded: Missing PodIP in operand etcd-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:53:13.074580577Z I0611 10:53:13.074516       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2" to "GuardControllerDegraded: Missing PodIP in operand etcd-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2"
2024-06-11T10:53:13.095258009Z I0611 10:53:13.095185       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-2 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:53:13.159772718Z I0611 10:53:13.159709       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.02 %, dbSize: 68558848
2024-06-11T10:53:13.159772718Z I0611 10:53:13.159732       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.03 %, dbSize: 69033984
2024-06-11T10:53:13.186343928Z I0611 10:53:13.186278       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-2 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:53:13.256762517Z I0611 10:53:13.256704       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-2 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:53:14.218935517Z I0611 10:53:14.218876       1 request.go:697] Waited for 1.161190643s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T10:53:14.220155603Z I0611 10:53:14.220107       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-2 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:53:15.222014081Z I0611 10:53:15.221942       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:53:15.374967341Z I0611 10:53:15.374903       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-2 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:53:15.418451000Z I0611 10:53:15.418389       1 request.go:697] Waited for 1.594902413s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:53:16.248470389Z I0611 10:53:16.248417       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-2 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:53:16.418731866Z I0611 10:53:16.418637       1 request.go:697] Waited for 1.39494873s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:53:17.242933519Z I0611 10:53:17.242880       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-2 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:53:17.621709379Z I0611 10:53:17.621433       1 request.go:697] Waited for 1.191431872s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:53:18.249562928Z I0611 10:53:18.249508       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-2 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:53:18.822608000Z I0611 10:53:18.822497       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:53:19.257926015Z I0611 10:53:19.257866       1 clustermembercontroller.go:374] Skipping etcd-ci-op-9xx71rvq-1e28e-w667k-master-2 as the etcd container is in incorrect state, isEtcdContainerRunning = false, isEtcdContainerReady = false
2024-06-11T10:53:20.324091758Z I0611 10:53:20.323977       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MemberAddAsLearner' successfully added new member https://10.0.0.7:2380
2024-06-11T10:53:20.343666793Z I0611 10:53:20.343612       1 clustermembercontroller.go:293] Not ready for promotion: etcd learner member (https://10.0.0.7:2380) is not yet in sync with leader's log 
2024-06-11T10:53:20.641801638Z I0611 10:53:20.641713       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-etcd because it was missing
2024-06-11T10:53:20.672374034Z I0611 10:53:20.666552       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:53:20.672374034Z I0611 10:53:20.669017       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:53:20Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:53:20.676790342Z W0611 10:53:20.676740       1 etcdcli.go:346] UnstartedEtcdMember found: [NAME-PENDING-10.0.0.7]
2024-06-11T10:53:20.676870854Z W0611 10:53:20.676854       1 etcdcli.go:351] UnhealthyEtcdMember found: [NAME-PENDING-10.0.0.7]
2024-06-11T10:53:20.694478174Z I0611 10:53:20.694404       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded changed from True to False ("NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found")
2024-06-11T10:53:20.799510695Z W0611 10:53:20.799449       1 etcdcli.go:346] UnstartedEtcdMember found: [NAME-PENDING-10.0.0.7]
2024-06-11T10:53:20.799510695Z W0611 10:53:20.799479       1 etcdcli.go:351] UnhealthyEtcdMember found: [NAME-PENDING-10.0.0.7]
2024-06-11T10:53:20.803563844Z W0611 10:53:20.803514       1 etcdcli.go:346] UnstartedEtcdMember found: [NAME-PENDING-10.0.0.7]
2024-06-11T10:53:20.803563844Z W0611 10:53:20.803534       1 etcdcli.go:351] UnhealthyEtcdMember found: [NAME-PENDING-10.0.0.7]
2024-06-11T10:53:21.224539962Z I0611 10:53:21.224466       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:53:21.618867112Z I0611 10:53:21.618787       1 request.go:697] Waited for 1.096974377s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:53:22.354185987Z I0611 10:53:22.354100       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MemberPromote' successfully promoted learner member https://10.0.0.7:2380
2024-06-11T10:53:22.819337421Z I0611 10:53:22.819229       1 request.go:697] Waited for 1.592826445s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:24.018957012Z I0611 10:53:24.018890       1 request.go:697] Waited for 1.396288928s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:53:25.019179352Z I0611 10:53:25.019115       1 request.go:697] Waited for 1.39716466s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-06-11T10:53:25.422482834Z I0611 10:53:25.422408       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:53:27.423640922Z I0611 10:53:27.423574       1 core.go:227] Pod "openshift-etcd/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c7cd88272ec1d0a6e1a9814448acb1744650cc1315124b44a8e7b6e711e96ed","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.7","path":"readyz","port":9980,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-06-11T10:53:27.622081828Z I0611 10:53:27.622015       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:53:27.830142088Z I0611 10:53:27.830069       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-etcd because it changed
2024-06-11T10:53:29.822973717Z I0611 10:53:29.822900       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:53:33.371197793Z I0611 10:53:33.371056       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:53:34.418358720Z I0611 10:53:34.418284       1 request.go:697] Waited for 1.022111506s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:53:36.024668754Z I0611 10:53:36.024602       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T10:53:36.024668754Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T10:53:36.024668754Z  CurrentRevision: (int32) 5,
2024-06-11T10:53:36.024668754Z  TargetRevision: (int32) 0,
2024-06-11T10:53:36.024668754Z  LastFailedRevision: (int32) 0,
2024-06-11T10:53:36.024668754Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:53:36.024668754Z  LastFailedReason: (string) "",
2024-06-11T10:53:36.024668754Z  LastFailedCount: (int) 0,
2024-06-11T10:53:36.024668754Z  LastFallbackCount: (int) 0,
2024-06-11T10:53:36.024668754Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:53:36.024668754Z }
2024-06-11T10:53:36.024668754Z  because static pod is ready
2024-06-11T10:53:36.041940884Z I0611 10:53:36.041822       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-2" from revision 0 to 5 because static pod is ready
2024-06-11T10:53:36.043635042Z I0611 10:53:36.043580       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:53:36.045387408Z I0611 10:53:36.045335       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:53:20Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:53:36.061222819Z I0611 10:53:36.061160       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5" to "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 1 node is at revision 1; 1 node is at revision 3; 0 nodes have achieved new revision 5\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5\nEtcdMembersAvailable: 3 members are available"
2024-06-11T10:53:36.078221507Z I0611 10:53:36.078152       1 core.go:359] ConfigMap "openshift-etcd/etcd-endpoints" changes: {"data":{"a4a1160c07133b06":"10.0.0.7"},"metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:53:36.078868606Z W0611 10:53:36.078820       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.8:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.7:2379 https://10.0.0.8:2379]]
2024-06-11T10:53:36.079521705Z I0611 10:53:36.079432       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-endpoints -n openshift-etcd:
2024-06-11T10:53:36.079521705Z cause by changes in data.a4a1160c07133b06
2024-06-11T10:53:36.082077394Z W0611 10:53:36.082017       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.8:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.7:2379 https://10.0.0.8:2379]]
2024-06-11T10:53:36.087242181Z I0611 10:53:36.087176       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 6 triggered by "required configmap/etcd-endpoints has changed"
2024-06-11T10:53:36.114433720Z I0611 10:53:36.114380       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.08 %, dbSize: 70840320
2024-06-11T10:53:36.114679558Z I0611 10:53:36.114654       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 0.08 %, dbSize: 70631424
2024-06-11T10:53:36.177135967Z W0611 10:53:36.177066       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.8:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.7:2379 https://10.0.0.8:2379]]
2024-06-11T10:53:36.178279741Z W0611 10:53:36.178197       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.8:2379]] vs. [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.7:2379 https://10.0.0.8:2379]]
2024-06-11T10:53:36.178279741Z I0611 10:53:36.178245       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:53:36.251146835Z I0611 10:53:36.251069       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 0.01 %, dbSize: 70651904
2024-06-11T10:53:37.219099202Z I0611 10:53:37.219028       1 request.go:697] Waited for 1.174962184s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:53:37.461755746Z E0611 10:53:37.461675       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:53:38.418537771Z I0611 10:53:38.418465       1 request.go:697] Waited for 1.590180062s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T10:53:39.228233961Z I0611 10:53:39.228160       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-6 -n openshift-etcd because it was missing
2024-06-11T10:53:39.418887110Z I0611 10:53:39.418809       1 request.go:697] Waited for 1.595212267s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:53:40.419357064Z I0611 10:53:40.419248       1 request.go:697] Waited for 1.595826181s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:40.630644264Z I0611 10:53:40.630568       1 core.go:359] ConfigMap "openshift-etcd/etcd-scripts" changes: {"apiVersion":"v1","data":{"etcd.env":"export ALL_ETCD_ENDPOINTS=\"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\nexport ETCDCTL_API=\"3\"\nexport ETCDCTL_CACERT=\"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\nexport ETCDCTL_CERT=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\nexport ETCDCTL_ENDPOINTS=\"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\nexport ETCDCTL_KEY=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\nexport ETCD_CIPHER_SUITES=\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\nexport ETCD_DATA_DIR=\"/var/lib/etcd\"\nexport ETCD_ELECTION_TIMEOUT=\"2500\"\nexport ETCD_ENABLE_PPROF=\"true\"\nexport ETCD_EXPERIMENTAL_MAX_LEARNERS=\"3\"\nexport ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION=\"200ms\"\nexport ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL=\"5s\"\nexport ETCD_HEARTBEAT_INTERVAL=\"500\"\nexport ETCD_IMAGE=\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\nexport ETCD_INITIAL_CLUSTER_STATE=\"existing\"\nexport ETCD_QUOTA_BACKEND_BYTES=\"8589934592\"\nexport ETCD_SOCKET_REUSE_ADDRESS=\"true\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME=\"ci-op-9xx71rvq-1e28e-w667k-master-0\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST=\"10.0.0.8\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP=\"10.0.0.8\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME=\"ci-op-9xx71rvq-1e28e-w667k-master-1\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST=\"10.0.0.6\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP=\"10.0.0.6\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME=\"ci-op-9xx71rvq-1e28e-w667k-master-2\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST=\"10.0.0.7\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP=\"10.0.0.7\"\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:53:40.631779699Z I0611 10:53:40.631714       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-scripts -n openshift-etcd:
2024-06-11T10:53:40.631779699Z cause by changes in data.etcd.env
2024-06-11T10:53:41.042210958Z I0611 10:53:41.041923       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-6 -n openshift-etcd because it was missing
2024-06-11T10:53:41.230606239Z I0611 10:53:41.230462       1 core.go:359] ConfigMap "openshift-etcd/etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  annotations:\n    kubectl.kubernetes.io/default-container: etcd\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  initContainers:\n    - name: setup\n      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          echo -n \"Fixing etcd log permissions.\"\n          mkdir -p /var/log/etcd \u0026\u0026 chmod 0700 /var/log/etcd\n      securityContext:\n        privileged: true\n      resources:\n        requests:\n          memory: 50Mi\n          cpu: 5m\n      volumeMounts:\n        - mountPath: /var/log/etcd\n          name: log-dir\n    - name: etcd-ensure-env-vars\n      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_NAME?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_IP?not set}\"\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected node IP to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_IP}\" \u003e\u00262\n            exit 1\n          fi\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected etcd url host to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" \u003e\u00262\n            exit 1\n          fi\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: NODE_IP\n        valueFrom:\n          fieldRef:\n            fieldPath: status.podIP\n    - name: etcd-resources-copy\n      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          rm -f $(grep -l '^### Created by cluster-etcd-operator' /usr/local/bin/*)\n          cp -p /etc/kubernetes/static-pod-certs/configmaps/etcd-scripts/*.sh /usr/local/bin\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      volumeMounts:\n        - mountPath: /etc/kubernetes/static-pod-resources\n          name: resource-dir\n        - mountPath: /etc/kubernetes/static-pod-certs\n          name: cert-dir\n        - mountPath: /usr/local/bin\n          name: usr-local-bin\n  containers:\n  # The etcdctl container should always be first. It is intended to be used\n  # to open a remote shell via `oc rsh` that is ready to run `etcdctl`.\n  - name: etcdctl\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - \"/bin/bash\"\n      - \"-c\"\n      - \"trap TERM INT; sleep infinity \u0026 wait\"\n    resources:\n      requests:\n        memory: 60Mi\n        cpu: 10m\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_VERSION\"\n        value: \"REVISION\"\n  - name: etcd\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        etcdctl member list || true\n\n        # this has a non-zero return code if the command is non-zero.  If you use an export first, it doesn't and you\n        # will succeed when you should fail.\n        ETCD_INITIAL_CLUSTER=$(discover-etcd-initial-cluster \\\n          --cacert=/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt \\\n          --cert=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --key=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --endpoints=${ALL_ETCD_ENDPOINTS} \\\n          --data-dir=/var/lib/etcd \\\n          --target-peer-url-host=${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST} \\\n          --target-name=NODE_NAME)\n        export ETCD_INITIAL_CLUSTER\n\n        # we cannot use the \"normal\" port conflict initcontainer because when we upgrade, the existing static pod will never yield,\n        # so we do the detection in etcd container itself.\n        echo -n \"Waiting for ports 2379, 2380 and 9978 to be released.\"\n        time while [ -n \"$(ss -Htan '( sport = 2379 or sport = 2380 or sport = 9978 )')\" ]; do\n          echo -n \".\"\n          sleep 1\n        done\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        env | grep ETCD | grep -v NODE\n\n        set -x\n        # See https://etcd.io/docs/v3.4.0/tuning/ for why we use ionice\n        exec nice -n -19 ionice -c2 -n0 etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --experimental-initial-corrupt-check=true \\\n          --snapshot-count=10000 \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-peer-client-ca/ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379,unixs://${NODE_NODE_ENVVAR_NAME_IP}:0 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978 ||  mv /etc/kubernetes/etcd-backup-dir/etcd-member.yaml /etc/kubernetes/manifests\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_VERSION\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      timeoutSeconds: 30\n      failureThreshold: 5\n      periodSeconds: 5\n      successThreshold: 1\n    livenessProbe:\n      httpGet:\n        path: healthz\n        port: 9980\n        scheme: HTTPS\n      timeoutSeconds: 30\n      periodSeconds: 5\n      successThreshold: 1\n      failureThreshold: 5\n    startupProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      initialDelaySeconds: 10\n      timeoutSeconds: 1\n      periodSeconds: 10\n      successThreshold: 1\n      failureThreshold: 18\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-metrics\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n\n        exec nice -n -18 etcd grpc-proxy start \\\n          --endpoints https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:9978 \\\n          --metrics-addr https://0.0.0.0:9979 \\\n          --listen-addr 127.0.0.1:9977 \\\n          --advertise-client-url \"\"  \\\n          --key /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --key-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.key \\\n          --cert /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --cert-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.crt \\\n          --cacert /etc/kubernetes/static-pod-certs/configmaps/etcd-peer-client-ca/ca-bundle.crt \\\n          --trusted-ca-file /etc/kubernetes/static-pod-certs/configmaps/etcd-metrics-proxy-serving-ca/ca-bundle.crt \\\n          --listen-cipher-suites TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_256_GCM_SHA384,TLS_CHACHA20_POLY1305_SHA256\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_VERSION\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 200Mi\n        cpu: 40m\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-readyz\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c7cd88272ec1d0a6e1a9814448acb1744650cc1315124b44a8e7b6e711e96ed\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        exec nice -n -18 cluster-etcd-operator readyz \\\n          --target=https://localhost:2379 \\\n          --listen-port=9980 \\\n          --serving-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --serving-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --client-cert-file=$(ETCDCTL_CERT) \\\n          --client-key-file=$(ETCDCTL_KEY) \\\n          --client-cacert-file=$(ETCDCTL_CACERT)\n    securityContext:\n      privileged: true\n    ports:\n    - containerPort: 9980\n      name: readyz\n      protocol: TCP\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n    volumeMounts:\n      - mountPath: /var/log/etcd/\n        name: log-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-pod-REVISION\n      name: resource-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /usr/local/bin\n      name: usr-local-bin\n    - hostPath:\n        path: /var/log/etcd\n      name: log-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:53:41.231227713Z I0611 10:53:41.231152       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-pod -n openshift-etcd:
2024-06-11T10:53:41.231227713Z cause by changes in data.pod.yaml
2024-06-11T10:53:41.618395607Z I0611 10:53:41.618327       1 request.go:697] Waited for 1.792098297s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:53:42.427420588Z I0611 10:53:42.427338       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-peer-client-ca-6 -n openshift-etcd because it was missing
2024-06-11T10:53:42.618693434Z I0611 10:53:42.618620       1 request.go:697] Waited for 1.387835161s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:53:43.521777511Z E0611 10:53:43.521718       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:53:43.619049027Z I0611 10:53:43.618970       1 request.go:697] Waited for 1.394532311s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:53:43.828676612Z I0611 10:53:43.828583       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-serving-ca-6 -n openshift-etcd because it was missing
2024-06-11T10:53:44.027719818Z I0611 10:53:44.027615       1 core.go:359] ConfigMap "openshift-etcd/restore-etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  containers:\n  - name: etcd\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        # this can be controlled by cluster-restore.sh, which will replace this line entirely when enabled at runtime\n        export ETCD_ETCDCTL_RESTORE_ENABLE_BUMP=\"false\"\n        \n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        export ETCD_INITIAL_CLUSTER=\"${ETCD_NAME}=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\"\n        env | grep ETCD | grep -v NODE\n        export ETCD_NODE_PEER_URL=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\n\n        # checking if there are any fio perf file left behind that could be deleted without problems\n        if [ ! -z $(ls -A \"/var/lib/etcd/etcd_perf*\") ]; then\n          rm -f /var/lib/etcd/etcd_perf*\n        fi\n\n        # checking if data directory is empty, if not etcdctl restore will fail\n        if [ ! -z $(ls -A \"/var/lib/etcd\") ]; then\n          echo \"please delete the contents of data directory before restoring, running the restore script will do this for you\"\n          exit 1\n        fi\n        \n        ETCD_ETCDCTL_BIN=\"etcdctl\"\n        if [ -x \"$(command -v etcdutl)\" ]; then\n          echo \"found newer etcdutl, using that instead of etcdctl\"\n          ETCD_ETCDCTL_BIN=\"etcdutl\"\n        fi      \n\n        # check if we have backup file to be restored\n        # if the file exist, check if it has not changed size in last 5 seconds\n        if [ ! -f /var/lib/etcd-backup/snapshot.db ]; then\n          echo \"please make a copy of the snapshot db file, then move that copy to /var/lib/etcd-backup/snapshot.db\"\n          exit 1\n        else\n          filesize=$(stat --format=%s \"/var/lib/etcd-backup/snapshot.db\")\n          sleep 5\n          newfilesize=$(stat --format=%s \"/var/lib/etcd-backup/snapshot.db\")\n          if [ \"$filesize\" != \"$newfilesize\" ]; then\n            echo \"file size has changed since last 5 seconds, retry sometime after copying is complete\"\n            exit 1\n          fi\n        fi\n        \n        BUMP_ARGS=\"\"\n        if [[ \"${ETCD_ETCDCTL_RESTORE_ENABLE_BUMP}\" == \"true\" ]]; then\n          echo \"enabling restore bump\"\n          BUMP_ARGS=\"--bump-revision 1000000000 --mark-compacted\"\n        fi\n                \n        UUID=$(uuidgen)\n        echo \"restoring to a single node cluster\"\n        ${ETCD_ETCDCTL_BIN} snapshot restore /var/lib/etcd-backup/snapshot.db \\\n         --name  $ETCD_NAME \\\n         --initial-cluster=$ETCD_INITIAL_CLUSTER \\\n         --initial-cluster-token \"openshift-etcd-${UUID}\" \\\n         --initial-advertise-peer-urls $ETCD_NODE_PEER_URL \\\n         --data-dir=\"/var/lib/etcd/restore-${UUID}\" \\\n         ${BUMP_ARGS}\n\n        mv /var/lib/etcd/restore-${UUID}/* /var/lib/etcd/\n\n        rmdir /var/lib/etcd/restore-${UUID}\n        rm /var/lib/etcd-backup/snapshot.db\n\n        set -x\n        exec etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-peer-client-ca/ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.5:2379,https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_REV\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      tcpSocket:\n        port: 2380\n      failureThreshold: 3\n      initialDelaySeconds: 3\n      periodSeconds: 5\n      successThreshold: 1\n      timeoutSeconds: 5\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n      - mountPath: /var/lib/etcd-backup/\n        name: backup-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /var/lib/etcd-backup\n        type: \"\"\n      name: backup-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:53:44.028851287Z I0611 10:53:44.028715       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/restore-etcd-pod -n openshift-etcd:
2024-06-11T10:53:44.028851287Z cause by changes in data.pod.yaml
2024-06-11T10:53:44.819072420Z I0611 10:53:44.818983       1 request.go:697] Waited for 1.396380497s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:44.822880788Z I0611 10:53:44.822835       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-0 with revision 1 is the oldest and needs new revision 5
2024-06-11T10:53:44.822922594Z I0611 10:53:44.822890       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:53:44.822922594Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:53:44.822922594Z  CurrentRevision: (int32) 1,
2024-06-11T10:53:44.822922594Z  TargetRevision: (int32) 5,
2024-06-11T10:53:44.822922594Z  LastFailedRevision: (int32) 0,
2024-06-11T10:53:44.822922594Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:53:44.822922594Z  LastFailedReason: (string) "",
2024-06-11T10:53:44.822922594Z  LastFailedCount: (int) 0,
2024-06-11T10:53:44.822922594Z  LastFallbackCount: (int) 0,
2024-06-11T10:53:44.822922594Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:53:44.822922594Z }
2024-06-11T10:53:44.840196172Z I0611 10:53:44.840123       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 1 to 5 because node ci-op-9xx71rvq-1e28e-w667k-master-0 with revision 1 is the oldest
2024-06-11T10:53:44.841090206Z I0611 10:53:44.841041       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:53:44.903269685Z I0611 10:53:44.903197       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.01 %, dbSize: 71872512
2024-06-11T10:53:44.903269685Z I0611 10:53:44.903226       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 72339456
2024-06-11T10:53:45.027680453Z I0611 10:53:45.027606       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-client-ca-6 -n openshift-etcd because it was missing
2024-06-11T10:53:46.019070408Z I0611 10:53:46.018998       1 request.go:697] Waited for 1.178186134s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:53:46.625991152Z I0611 10:53:46.625894       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-6 -n openshift-etcd because it was missing
2024-06-11T10:53:47.218949305Z I0611 10:53:47.218888       1 request.go:697] Waited for 1.59610223s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:48.031015671Z I0611 10:53:48.030935       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-6 -n openshift-etcd because it was missing
2024-06-11T10:53:48.219295676Z I0611 10:53:48.219234       1 request.go:697] Waited for 1.396762591s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:53:49.418521899Z I0611 10:53:49.418427       1 request.go:697] Waited for 1.387755061s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/revision-status-6
2024-06-11T10:53:49.429163052Z I0611 10:53:49.429095       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 6 triggered by "required configmap/etcd-endpoints has changed"
2024-06-11T10:53:49.448699219Z I0611 10:53:49.448629       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 6 created because required configmap/etcd-endpoints has changed
2024-06-11T10:53:49.450930023Z I0611 10:53:49.450875       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:53:49.478389572Z W0611 10:53:49.478335       1 staticpod.go:38] revision 6 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T10:53:49.478389572Z E0611 10:53:49.478374       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 6
2024-06-11T10:53:49.486657201Z I0611 10:53:49.486579       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "required configmap/etcd-pod has changed"
2024-06-11T10:53:49.499268323Z I0611 10:53:49.499176       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.03 %, dbSize: 72368128
2024-06-11T10:53:49.499268323Z I0611 10:53:49.499205       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 72847360
2024-06-11T10:53:50.618918281Z I0611 10:53:50.618835       1 request.go:697] Waited for 1.167243357s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:53:51.618943209Z I0611 10:53:51.618875       1 request.go:697] Waited for 1.596119409s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:53:52.432194637Z I0611 10:53:52.432113       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-7 -n openshift-etcd because it was missing
2024-06-11T10:53:52.619206668Z I0611 10:53:52.619133       1 request.go:697] Waited for 1.396274425s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:53:53.422781238Z I0611 10:53:53.422717       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-0 with revision 1 is the oldest and needs new revision 5
2024-06-11T10:53:53.422847248Z I0611 10:53:53.422777       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:53:53.422847248Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:53:53.422847248Z  CurrentRevision: (int32) 1,
2024-06-11T10:53:53.422847248Z  TargetRevision: (int32) 5,
2024-06-11T10:53:53.422847248Z  LastFailedRevision: (int32) 0,
2024-06-11T10:53:53.422847248Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:53:53.422847248Z  LastFailedReason: (string) "",
2024-06-11T10:53:53.422847248Z  LastFailedCount: (int) 0,
2024-06-11T10:53:53.422847248Z  LastFallbackCount: (int) 0,
2024-06-11T10:53:53.422847248Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:53:53.422847248Z }
2024-06-11T10:53:53.441450562Z I0611 10:53:53.441375       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 1 to 5 because node ci-op-9xx71rvq-1e28e-w667k-master-0 with revision 1 is the oldest
2024-06-11T10:53:53.443088701Z I0611 10:53:53.443020       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:53:53.444131453Z I0611 10:53:53.444070       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:53:20Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:53:53.460986712Z I0611 10:53:53.458381       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5" to "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 3 members are available"
2024-06-11T10:53:53.508997916Z I0611 10:53:53.508915       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.07 %, dbSize: 72708096
2024-06-11T10:53:53.508997916Z I0611 10:53:53.508951       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 0.05 %, dbSize: 72507392
2024-06-11T10:53:53.508997916Z I0611 10:53:53.508957       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.05 %, dbSize: 73179136
2024-06-11T10:53:53.619266003Z I0611 10:53:53.619200       1 request.go:697] Waited for 1.187067965s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps
2024-06-11T10:53:53.628007378Z I0611 10:53:53.627935       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-7 -n openshift-etcd because it was missing
2024-06-11T10:53:54.819593786Z I0611 10:53:54.819462       1 request.go:697] Waited for 1.376353971s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T10:53:55.234086202Z I0611 10:53:55.234011       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-peer-client-ca-7 -n openshift-etcd because it was missing
2024-06-11T10:53:56.019000144Z I0611 10:53:56.018935       1 request.go:697] Waited for 1.396935176s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:53:56.221344753Z I0611 10:53:56.221270       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:53:56.221344753Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:53:56.221344753Z  CurrentRevision: (int32) 1,
2024-06-11T10:53:56.221344753Z  TargetRevision: (int32) 6,
2024-06-11T10:53:56.221344753Z  LastFailedRevision: (int32) 0,
2024-06-11T10:53:56.221344753Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:53:56.221344753Z  LastFailedReason: (string) "",
2024-06-11T10:53:56.221344753Z  LastFailedCount: (int) 0,
2024-06-11T10:53:56.221344753Z  LastFallbackCount: (int) 0,
2024-06-11T10:53:56.221344753Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:53:56.221344753Z }
2024-06-11T10:53:56.221344753Z  because new revision pending
2024-06-11T10:53:56.241597416Z I0611 10:53:56.241518       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:53:56.287284869Z I0611 10:53:56.287200       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.01 %, dbSize: 72863744
2024-06-11T10:53:56.287284869Z I0611 10:53:56.287230       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 0.01 %, dbSize: 72650752
2024-06-11T10:53:56.287284869Z I0611 10:53:56.287239       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.04 %, dbSize: 73355264
2024-06-11T10:53:56.427627663Z I0611 10:53:56.427530       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-serving-ca-7 -n openshift-etcd because it was missing
2024-06-11T10:53:57.219340198Z I0611 10:53:57.219246       1 request.go:697] Waited for 1.192108515s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:53:57.829387931Z I0611 10:53:57.829278       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-client-ca-7 -n openshift-etcd because it was missing
2024-06-11T10:53:58.418950403Z I0611 10:53:58.418891       1 request.go:697] Waited for 1.382353114s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-06-11T10:53:58.835546324Z I0611 10:53:58.835469       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-etcd because it was missing
2024-06-11T10:53:59.026412094Z I0611 10:53:59.026337       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-7 -n openshift-etcd because it was missing
2024-06-11T10:53:59.619088573Z I0611 10:53:59.619012       1 request.go:697] Waited for 1.190127739s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T10:54:00.022118256Z I0611 10:54:00.022061       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:54:00.630600192Z I0611 10:54:00.630511       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-7 -n openshift-etcd because it was missing
2024-06-11T10:54:00.818637158Z I0611 10:54:00.818537       1 request.go:697] Waited for 1.596440491s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:54:02.018557097Z I0611 10:54:02.018485       1 request.go:697] Waited for 1.387980307s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/revision-status-7
2024-06-11T10:54:02.042429107Z I0611 10:54:02.042353       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "required configmap/etcd-pod has changed"
2024-06-11T10:54:02.059094188Z I0611 10:54:02.059033       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 7 created because required configmap/etcd-pod has changed
2024-06-11T10:54:02.060017720Z W0611 10:54:02.059963       1 staticpod.go:38] revision 7 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T10:54:02.060141038Z I0611 10:54:02.060087       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:54:02.060230851Z E0611 10:54:02.060110       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 7
2024-06-11T10:54:02.111621893Z I0611 10:54:02.111563       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 0.02 %, dbSize: 73109504
2024-06-11T10:54:02.111621893Z I0611 10:54:02.111585       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 73781248
2024-06-11T10:54:02.822323335Z I0611 10:54:02.822248       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:54:02.840961523Z I0611 10:54:02.840901       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:53:20Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:54:02.841227157Z I0611 10:54:02.840971       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:54:02.856466709Z I0611 10:54:02.856374       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6" to "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 6\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 3 members are available"
2024-06-11T10:54:02.899259691Z I0611 10:54:02.899196       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.01 %, dbSize: 73338880
2024-06-11T10:54:02.899391608Z I0611 10:54:02.899336       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 0.01 %, dbSize: 73138176
2024-06-11T10:54:02.899391608Z I0611 10:54:02.899354       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 73809920
2024-06-11T10:54:03.018799204Z I0611 10:54:03.018715       1 request.go:697] Waited for 1.39506522s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:54:04.019135445Z I0611 10:54:04.019077       1 request.go:697] Waited for 1.595975241s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:54:05.218991744Z I0611 10:54:05.218927       1 request.go:697] Waited for 1.396159245s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:54:05.831177264Z I0611 10:54:05.831111       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:54:05.831177264Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:54:05.831177264Z  CurrentRevision: (int32) 1,
2024-06-11T10:54:05.831177264Z  TargetRevision: (int32) 7,
2024-06-11T10:54:05.831177264Z  LastFailedRevision: (int32) 0,
2024-06-11T10:54:05.831177264Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:54:05.831177264Z  LastFailedReason: (string) "",
2024-06-11T10:54:05.831177264Z  LastFailedCount: (int) 0,
2024-06-11T10:54:05.831177264Z  LastFallbackCount: (int) 0,
2024-06-11T10:54:05.831177264Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:54:05.831177264Z }
2024-06-11T10:54:05.831177264Z  because new revision pending
2024-06-11T10:54:05.853434215Z I0611 10:54:05.853375       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:54:05.896968492Z I0611 10:54:05.896875       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 29.15 %, dbSize: 75337728
2024-06-11T10:54:05.896968492Z I0611 10:54:05.896915       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 28.51 %, dbSize: 74452992
2024-06-11T10:54:05.896968492Z I0611 10:54:05.896924       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 28.57 %, dbSize: 75104256
2024-06-11T10:54:06.419355208Z I0611 10:54:06.419277       1 request.go:697] Waited for 1.197086944s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:54:07.619251774Z I0611 10:54:07.619176       1 request.go:697] Waited for 1.596544574s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:54:08.619380029Z I0611 10:54:08.619291       1 request.go:697] Waited for 1.595596792s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:54:08.822843655Z I0611 10:54:08.822759       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:54:08.822843655Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:54:08.822843655Z  CurrentRevision: (int32) 1,
2024-06-11T10:54:08.822843655Z  TargetRevision: (int32) 7,
2024-06-11T10:54:08.822843655Z  LastFailedRevision: (int32) 0,
2024-06-11T10:54:08.822843655Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:54:08.822843655Z  LastFailedReason: (string) "",
2024-06-11T10:54:08.822843655Z  LastFailedCount: (int) 0,
2024-06-11T10:54:08.822843655Z  LastFallbackCount: (int) 0,
2024-06-11T10:54:08.822843655Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:54:08.822843655Z }
2024-06-11T10:54:08.822843655Z  because new revision pending
2024-06-11T10:54:09.619541788Z I0611 10:54:09.619469       1 request.go:697] Waited for 1.396490647s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:54:11.027602342Z I0611 10:54:11.027531       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-etcd because it was missing
2024-06-11T10:54:12.030057186Z I0611 10:54:12.029995       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:54:12.218944702Z I0611 10:54:12.218731       1 request.go:697] Waited for 1.191083228s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:54:14.025653622Z I0611 10:54:14.025599       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:54:14.820158796Z I0611 10:54:14.820092       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:14.821025903Z E0611 10:54:14.820970       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:14.821744092Z E0611 10:54:14.821708       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:15.220183275Z I0611 10:54:15.220098       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:15.221687761Z E0611 10:54:15.221589       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:15.349176698Z E0611 10:54:15.349083       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:15.421519628Z E0611 10:54:15.421466       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:15.620182551Z I0611 10:54:15.620097       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:15.622248106Z E0611 10:54:15.622203       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.020063770Z I0611 10:54:16.019996       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.021491164Z E0611 10:54:16.021448       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.419569608Z I0611 10:54:16.419492       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.420922392Z E0611 10:54:16.420873       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.621455717Z E0611 10:54:16.621398       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.820061580Z I0611 10:54:16.819990       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.821592889Z E0611 10:54:16.821555       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:17.219392494Z I0611 10:54:17.219290       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:17.220892599Z E0611 10:54:17.220833       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:17.622748457Z E0611 10:54:17.622691       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:17.820141154Z I0611 10:54:17.820044       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:17.821950001Z E0611 10:54:17.821888       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:18.421166772Z E0611 10:54:18.421099       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:18.819577029Z I0611 10:54:18.819500       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:18.820897859Z E0611 10:54:18.820851       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:19.221576739Z E0611 10:54:19.221520       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:19.619759074Z E0611 10:54:19.619693       1 guard_controller.go:359] Unable to apply pod etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2 changes: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:19.621569451Z W0611 10:54:19.621500       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:19.621569451Z E0611 10:54:19.621548       1 base_controller.go:268] GuardController reconciliation failed: Unable to apply pod etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2 changes: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:20.221168532Z E0611 10:54:20.221116       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:20.619815412Z I0611 10:54:20.619745       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:20.621278656Z E0611 10:54:20.621222       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:21.021021144Z W0611 10:54:21.020959       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:21.021071949Z E0611 10:54:21.021014       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:21.621560317Z E0611 10:54:21.621499       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:22.021020932Z W0611 10:54:22.020955       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:22.021020932Z E0611 10:54:22.021011       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:23.022370945Z E0611 10:54:23.022315       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.220928739Z W0611 10:54:23.220855       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.220980646Z E0611 10:54:23.220924       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:23.419412124Z I0611 10:54:23.419344       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.420794708Z E0611 10:54:23.420757       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.428728267Z E0611 10:54:23.428667       1 leaderelection.go:332] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.221857997Z W0611 10:54:24.221789       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.221923405Z E0611 10:54:24.221851       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:24.821588821Z E0611 10:54:24.821525       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.221257550Z W0611 10:54:25.221182       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.221257550Z E0611 10:54:25.221246       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:25.351409717Z E0611 10:54:25.351343       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:25.820565118Z W0611 10:54:25.820495       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.820565118Z E0611 10:54:25.820547       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:26.620963943Z W0611 10:54:26.620896       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.621009049Z E0611 10:54:26.620967       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:27.221646054Z E0611 10:54:27.221576       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:27.622436636Z W0611 10:54:27.622344       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:27.622516246Z E0611 10:54:27.622456       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:28.221656667Z W0611 10:54:28.221590       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:28.221656667Z E0611 10:54:28.221643       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:28.543237529Z I0611 10:54:28.543161       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:28.544575293Z E0611 10:54:28.544523       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.021163376Z W0611 10:54:29.021102       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.021163376Z E0611 10:54:29.021154       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:29.787392502Z E0611 10:54:29.787341       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:34.146689524Z W0611 10:54:34.146593       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:34.146689524Z E0611 10:54:34.146665       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:34.912374242Z E0611 10:54:34.912289       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:35.353233870Z E0611 10:54:35.353161       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:37.456157609Z E0611 10:54:37.456094       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:54:37.504079401Z I0611 10:54:37.503994       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.504929481Z E0611 10:54:37.504872       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f70c8314  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,LastTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-06-11T10:54:37.505266612Z E0611 10:54:37.505226       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.505332019Z I0611 10:54:37.505277       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.513798312Z I0611 10:54:37.513727       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.515137238Z E0611 10:54:37.515096       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.515172041Z I0611 10:54:37.515141       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.526358390Z E0611 10:54:37.526286       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.526517205Z I0611 10:54:37.526475       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.527590605Z E0611 10:54:37.527542       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:37.527637710Z E0611 10:54:37.527587       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,LastTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:54:37.528880826Z E0611 10:54:37.528708       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.529871019Z E0611 10:54:37.529820       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.529913823Z I0611 10:54:37.529887       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.529954227Z I0611 10:54:37.529926       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.531293952Z E0611 10:54:37.531246       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.531379360Z I0611 10:54:37.531326       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.704205662Z E0611 10:54:37.704143       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.704281369Z I0611 10:54:37.704246       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.705284363Z E0611 10:54:37.705236       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,LastTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:54:37.904648603Z E0611 10:54:37.904538       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:38.104248409Z I0611 10:54:38.104171       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:38.305221889Z E0611 10:54:38.305160       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:38.305278896Z I0611 10:54:38.305249       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:38.504530258Z E0611 10:54:38.504461       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:38.504656774Z I0611 10:54:38.504603       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:38.705048881Z E0611 10:54:38.704974       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:38.904502068Z E0611 10:54:38.904439       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:38.904556975Z I0611 10:54:38.904515       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:39.105232118Z E0611 10:54:39.105154       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:39.124693885Z I0611 10:54:39.124617       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:39.304684905Z E0611 10:54:39.304618       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:39.304739612Z I0611 10:54:39.304683       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:39.503473008Z I0611 10:54:39.503389       1 request.go:697] Waited for 1.179392628s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status
2024-06-11T10:54:39.504929093Z E0611 10:54:39.504861       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:39.505010503Z I0611 10:54:39.504968       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:39.506367375Z E0611 10:54:39.506231       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,LastTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:54:39.524697099Z E0611 10:54:39.524656       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:39.704564103Z E0611 10:54:39.704486       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:39.904617367Z E0611 10:54:39.904540       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:39.904692476Z I0611 10:54:39.904627       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:39.999851441Z E0611 10:54:39.999785       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f70c8314  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,LastTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-06-11T10:54:40.105113187Z E0611 10:54:40.105048       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:40.124914697Z E0611 10:54:40.124863       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:40.305018631Z I0611 10:54:40.304943       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:40.504714950Z E0611 10:54:40.504619       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:40.703766886Z I0611 10:54:40.703700       1 request.go:697] Waited for 1.371751717s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status
2024-06-11T10:54:40.705192467Z E0611 10:54:40.705131       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:40.705238473Z I0611 10:54:40.705199       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:40.904345116Z E0611 10:54:40.904262       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:40.904428727Z I0611 10:54:40.904366       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:41.104676515Z E0611 10:54:41.104620       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:41.104736923Z I0611 10:54:41.104692       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:41.304601463Z E0611 10:54:41.304538       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:41.304741880Z I0611 10:54:41.304677       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:41.325578622Z E0611 10:54:41.325504       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:41.504802845Z E0611 10:54:41.504742       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:41.504871254Z I0611 10:54:41.504836       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:41.704614878Z E0611 10:54:41.704545       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:41.704687787Z I0611 10:54:41.704619       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:41.724023239Z I0611 10:54:41.723854       1 request.go:697] Waited for 1.198393437s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:54:41.905287720Z E0611 10:54:41.905219       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:42.105592415Z I0611 10:54:42.105479       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:42.112565000Z E0611 10:54:42.112517       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,LastTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:54:42.305282207Z E0611 10:54:42.305205       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:42.325544176Z E0611 10:54:42.325482       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:42.505153466Z E0611 10:54:42.505076       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:42.505225374Z I0611 10:54:42.505173       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:42.705251152Z E0611 10:54:42.705175       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:42.903288287Z I0611 10:54:42.903149       1 request.go:697] Waited for 1.110773566s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status
2024-06-11T10:54:42.904429527Z E0611 10:54:42.904386       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:42.904508736Z I0611 10:54:42.904459       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:42.925084744Z E0611 10:54:42.925030       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:43.105261202Z E0611 10:54:43.105199       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:43.304436177Z E0611 10:54:43.304374       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:43.304478482Z I0611 10:54:43.304434       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:43.325252313Z E0611 10:54:43.325199       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:43.505186943Z E0611 10:54:43.505111       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:43.505260552Z I0611 10:54:43.505220       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:43.704633750Z E0611 10:54:43.704546       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:43.724472768Z E0611 10:54:43.724414       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:43.904338388Z I0611 10:54:43.904264       1 request.go:697] Waited for 1.356650339s due to client-side throttling, not priority and fairness, request: PUT:https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status
2024-06-11T10:54:43.905271402Z E0611 10:54:43.905189       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:43.905373414Z I0611 10:54:43.905295       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.105037248Z E0611 10:54:44.104974       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.105108657Z I0611 10:54:44.105049       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.304732686Z E0611 10:54:44.304666       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.504733460Z I0611 10:54:44.504656       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.525290966Z E0611 10:54:44.525225       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.704633823Z E0611 10:54:44.704569       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.704696630Z I0611 10:54:44.704662       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.904476578Z E0611 10:54:44.904428       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.904517383Z I0611 10:54:44.904495       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:45.104949710Z E0611 10:54:45.104892       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:45.304501630Z E0611 10:54:45.304437       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:45.304570939Z I0611 10:54:45.304517       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:45.355208010Z E0611 10:54:45.355154       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:45.504408794Z E0611 10:54:45.504338       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:45.504462700Z I0611 10:54:45.504394       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:45.649244645Z E0611 10:54:45.649185       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,LastTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:54:45.705314979Z E0611 10:54:45.705233       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:45.705358484Z I0611 10:54:45.705294       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:45.904681976Z E0611 10:54:45.904627       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:45.904767086Z I0611 10:54:45.904716       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:46.104185590Z E0611 10:54:46.104126       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:46.304700827Z E0611 10:54:46.304619       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:46.323758150Z I0611 10:54:46.323696       1 request.go:697] Waited for 1.157421559s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:54:46.324675862Z E0611 10:54:46.324633       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:46.505037843Z I0611 10:54:46.504949       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:46.704512454Z E0611 10:54:46.704432       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:46.704604765Z I0611 10:54:46.704547       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:46.904904976Z E0611 10:54:46.904840       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:46.904956182Z I0611 10:54:46.904897       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:47.014547839Z E0611 10:54:47.014455       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,LastTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:54:47.104876647Z E0611 10:54:47.104791       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:47.104935354Z I0611 10:54:47.104875       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:47.304501176Z E0611 10:54:47.304429       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:47.324601526Z I0611 10:54:47.324514       1 request.go:697] Waited for 1.199461482s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:54:47.504833491Z E0611 10:54:47.504722       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:47.504929703Z I0611 10:54:47.504881       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:47.704444418Z W0611 10:54:47.704364       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:47.704511426Z E0611 10:54:47.704460       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:47.905343902Z E0611 10:54:47.905248       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:47.905407610Z I0611 10:54:47.905351       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.104346155Z I0611 10:54:48.104232       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.304994209Z E0611 10:54:48.304932       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.504885270Z E0611 10:54:48.504824       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.504932976Z I0611 10:54:48.504884       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.524792897Z E0611 10:54:48.524745       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.704777432Z E0611 10:54:48.704722       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.704864142Z I0611 10:54:48.704815       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.723994774Z I0611 10:54:48.723944       1 request.go:697] Waited for 1.098584388s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T10:54:48.904182634Z E0611 10:54:48.904114       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.904287947Z I0611 10:54:48.904231       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.104861891Z E0611 10:54:49.104809       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.304345703Z E0611 10:54:49.304238       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:49.430812116Z E0611 10:54:49.430732       1 leaderelection.go:332] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.505442311Z E0611 10:54:49.505355       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.505509619Z I0611 10:54:49.505442       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.704348152Z E0611 10:54:49.704265       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.704438163Z I0611 10:54:49.704366       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.904542251Z E0611 10:54:49.904465       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:50.000938299Z E0611 10:54:50.000875       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f70c8314  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,LastTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-06-11T10:54:50.105222208Z E0611 10:54:50.105155       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:50.105357225Z I0611 10:54:50.105269       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:50.314416363Z E0611 10:54:50.314344       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:50.504584978Z I0611 10:54:50.504479       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:50.704701123Z E0611 10:54:50.704644       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:50.904355215Z E0611 10:54:50.904251       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:50.904425423Z I0611 10:54:50.904356       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:51.105025523Z E0611 10:54:51.104963       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:51.105113933Z I0611 10:54:51.105063       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:51.305133268Z E0611 10:54:51.305060       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:51.305193174Z I0611 10:54:51.305119       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:51.505137200Z E0611 10:54:51.505077       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:51.525069965Z E0611 10:54:51.524978       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:51.727327154Z E0611 10:54:51.727252       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:51.727441367Z I0611 10:54:51.727366       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:51.927777837Z E0611 10:54:51.927717       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:52.114464256Z E0611 10:54:52.114389       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,LastTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:54:52.267175413Z E0611 10:54:52.267114       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:52.267236720Z I0611 10:54:52.267168       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:52.326551861Z E0611 10:54:52.326498       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:52.326612968Z I0611 10:54:52.326582       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:52.527234071Z E0611 10:54:52.527177       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:52.926731777Z E0611 10:54:52.926675       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:53.126756512Z E0611 10:54:53.126689       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:53.126847723Z I0611 10:54:53.126798       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:53.467731467Z I0611 10:54:53.467660       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:53.469134127Z E0611 10:54:53.469078       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:53.469191133Z I0611 10:54:53.469156       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:53.726445172Z E0611 10:54:53.726383       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:53.726498378Z I0611 10:54:53.726455       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:54.126822279Z E0611 10:54:54.126712       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:54.326395062Z E0611 10:54:54.326331       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:54.326458070Z I0611 10:54:54.326389       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:54.528918181Z E0611 10:54:54.528822       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:55.127366900Z E0611 10:54:55.127270       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:55.362474023Z E0611 10:54:55.362384       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:55.526605078Z E0611 10:54:55.526545       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:55.526650783Z I0611 10:54:55.526609       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:55.651254345Z E0611 10:54:55.651201       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,LastTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:54:55.729564146Z E0611 10:54:55.729491       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:56.327013905Z E0611 10:54:56.326948       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:56.327073312Z I0611 10:54:56.327015       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:56.435058185Z E0611 10:54:56.434995       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:56.435102191Z I0611 10:54:56.435057       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:56.526605538Z E0611 10:54:56.526547       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:56.730372685Z E0611 10:54:56.730254       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:57.015899082Z E0611 10:54:57.015844       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,LastTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:54:57.125745385Z E0611 10:54:57.125680       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:57.326952017Z E0611 10:54:57.326875       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:57.390416618Z E0611 10:54:57.390357       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:57.390474825Z I0611 10:54:57.390412       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:58.126989957Z E0611 10:54:58.126930       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:58.526984539Z E0611 10:54:58.526933       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:58.527068947Z I0611 10:54:58.526995       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:58.592148276Z I0611 10:54:58.592082       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:58.593422996Z E0611 10:54:58.593378       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:58.593460299Z I0611 10:54:58.593434       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:58.928622964Z E0611 10:54:58.928568       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:59.126909038Z E0611 10:54:59.126842       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:59.327414821Z E0611 10:54:59.327357       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:59.327473627Z I0611 10:54:59.327413       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:59.725934953Z E0611 10:54:59.725869       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:00.003003946Z E0611 10:55:00.002949       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f70c8314  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,LastTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-06-11T10:55:00.527464739Z E0611 10:55:00.527370       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:00.928913946Z E0611 10:55:00.928755       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:01.128538246Z E0611 10:55:01.128472       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:01.327599193Z I0611 10:55:01.327497       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:01.329210245Z E0611 10:55:01.329120       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:01.726787488Z E0611 10:55:01.726725       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:02.116755014Z E0611 10:55:02.116664       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,LastTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:55:02.127657741Z E0611 10:55:02.127604       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:02.928911507Z E0611 10:55:02.928853       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:03.657259440Z E0611 10:55:03.657202       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:03.657349351Z I0611 10:55:03.657266       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:04.291143956Z E0611 10:55:04.291078       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:04.451203902Z E0611 10:55:04.451141       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:04.451256009Z I0611 10:55:04.451197       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:04.691759378Z E0611 10:55:04.691698       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:05.363789904Z E0611 10:55:05.363725       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:05.504620426Z E0611 10:55:05.504555       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:05.657236272Z E0611 10:55:05.657153       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,LastTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:55:06.685354473Z E0611 10:55:06.685256       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:06.685354473Z I0611 10:55:06.685322       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:07.017947813Z E0611 10:55:07.017898       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,LastTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:55:07.367796881Z E0611 10:55:07.367739       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:07.633825288Z E0611 10:55:07.633771       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:07.633879794Z I0611 10:55:07.633826       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:08.190246523Z W0611 10:55:08.190179       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:08.190246523Z E0611 10:55:08.190235       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:08.836012536Z I0611 10:55:08.835950       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:08.837521704Z E0611 10:55:08.837456       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:08.837563809Z I0611 10:55:08.837519       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:09.417883813Z E0611 10:55:09.417810       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:09.815702237Z E0611 10:55:09.815639       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:10.004914666Z E0611 10:55:10.004853       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f70c8314  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,LastTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-06-11T10:55:10.636917342Z E0611 10:55:10.636846       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:11.373048845Z E0611 10:55:11.372992       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:12.118576798Z E0611 10:55:12.118512       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,LastTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:55:13.901036724Z E0611 10:55:13.900986       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:13.901095431Z I0611 10:55:13.901039       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:14.696389126Z E0611 10:55:14.696292       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:14.696500934Z I0611 10:55:14.696387       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:15.364926933Z E0611 10:55:15.364869       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:15.430633257Z E0611 10:55:15.430572       1 leaderelection.go:332] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:15.659262793Z E0611 10:55:15.659201       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,LastTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:55:17.020106188Z E0611 10:55:17.020044       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,LastTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:55:19.662407751Z E0611 10:55:19.662349       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:20.006896558Z E0611 10:55:20.006839       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f70c8314  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,LastTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-06-11T10:55:20.059647738Z E0611 10:55:20.059596       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:20.895326163Z E0611 10:55:20.895235       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:22.120754412Z E0611 10:55:22.120699       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,LastTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:55:25.366901229Z E0611 10:55:25.366841       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:25.661144031Z E0611 10:55:25.661080       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,LastTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:55:27.021758274Z E0611 10:55:27.021692       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,LastTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:55:27.173227587Z E0611 10:55:27.173173       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:27.173283793Z I0611 10:55:27.173224       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:27.853467852Z E0611 10:55:27.853359       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:28.117272916Z E0611 10:55:28.117208       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:28.117376527Z I0611 10:55:28.117283       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:29.269212575Z E0611 10:55:29.269151       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:29.321016787Z I0611 10:55:29.320950       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:29.322361437Z E0611 10:55:29.322323       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:29.322397841Z I0611 10:55:29.322326       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:30.008243375Z E0611 10:55:30.008186       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f70c8314  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,LastTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-06-11T10:55:31.857278161Z E0611 10:55:31.857215       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:32.122926125Z E0611 10:55:32.122872       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,LastTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:55:34.384737291Z E0611 10:55:34.384676       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:34.384808398Z I0611 10:55:34.384735       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:35.180712983Z E0611 10:55:35.180638       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:35.180712983Z I0611 10:55:35.180695       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:35.368453956Z E0611 10:55:35.368393       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:35.663148376Z E0611 10:55:35.663094       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,LastTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:55:37.023889309Z E0611 10:55:37.023812       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,LastTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:55:37.427016735Z I0611 10:55:37.426917       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:37.428673318Z E0611 10:55:37.428620       1 base_controller.go:268] EtcdMembersController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:37.428720123Z I0611 10:55:37.428674       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ReportEtcdMembersErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:37.489582861Z E0611 10:55:37.489513       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:55:37.526927895Z E0611 10:55:37.526864       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:37.526986001Z I0611 10:55:37.526953       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:37.527861098Z E0611 10:55:37.527809       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:37.528291846Z E0611 10:55:37.528256       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:37.529546285Z E0611 10:55:37.529501       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:37.529592090Z I0611 10:55:37.529547       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:37.532276487Z E0611 10:55:37.532238       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:37.535704366Z E0611 10:55:37.535663       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:37.535744671Z I0611 10:55:37.535713       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:37.729401709Z E0611 10:55:37.729351       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:38.326027148Z E0611 10:55:38.325963       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:38.326086853Z I0611 10:55:38.326021       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:39.124876186Z E0611 10:55:39.124790       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:39.127996126Z E0611 10:55:39.127956       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:40.011049150Z E0611 10:55:40.010971       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f70c8314  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,LastTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-06-11T10:55:40.146870412Z E0611 10:55:40.146817       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:40.544489542Z E0611 10:55:40.544426       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:41.389768256Z E0611 10:55:41.389704       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:41.430401986Z E0611 10:55:41.430322       1 leaderelection.go:332] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:42.124595995Z E0611 10:55:42.124540       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,LastTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:55:42.292410894Z I0611 10:55:42.292336       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-0": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:42.293877953Z E0611 10:55:42.293828       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:45.370437095Z E0611 10:55:45.370383       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:45.665714717Z E0611 10:55:45.665645       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,LastTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:55:47.025661378Z E0611 10:55:47.025579       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,LastTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:55:49.157206429Z W0611 10:55:49.157139       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:49.157206429Z E0611 10:55:49.157194       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:50.013172336Z E0611 10:55:50.013098       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f70c8314  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,LastTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-06-11T10:55:52.126068657Z E0611 10:55:52.126007       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,LastTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:55:55.372411815Z E0611 10:55:55.372343       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:55.372476420Z E0611 10:55:55.372431       1 event.go:294] "Unable to write event (retry limit exceeded!)" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:55.373440991Z E0611 10:55:55.373395       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edceaefc4d92\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:15.219973549 +0000 UTC m=+278.375964656,Count:2,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:55.667960493Z E0611 10:55:55.667878       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,LastTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:55:56.163288493Z E0611 10:55:56.163227       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edceaefc4d92\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:15.219973549 +0000 UTC m=+278.375964656,Count:2,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:57.027185651Z E0611 10:55:57.027127       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,LastTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:56:00.015595260Z E0611 10:56:00.015526       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f70c8314  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdMembersErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,LastTimestamp:2024-06-11 10:54:37.503808276 +0000 UTC m=+300.659799483,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-member-observer-controller-etcdmemberscontroller,ReportingInstance:,}"
2024-06-11T10:56:02.127714445Z E0611 10:56:02.127596       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,LastTimestamp:2024-06-11 10:54:39.504823179 +0000 UTC m=+302.660814386,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:56:05.670639476Z E0611 10:56:05.670562       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,LastTimestamp:2024-06-11 10:54:37.526261681 +0000 UTC m=+300.682252888,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:56:06.165276455Z E0611 10:56:06.165211       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edceaefc4d92\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edceaefc4d92  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-0\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:14.81994997 +0000 UTC m=+277.975941177,LastTimestamp:2024-06-11 10:54:15.219973549 +0000 UTC m=+278.375964656,Count:2,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:56:07.028569153Z E0611 10:56:07.028513       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,LastTimestamp:2024-06-11 10:54:37.704110553 +0000 UTC m=+300.860101760,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:56:37.451877686Z E0611 10:56:37.451798       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:56:37.454607745Z I0611 10:56:37.454540       1 helpers.go:184] lister was stale at resourceVersion=17632, live get showed resourceVersion=18134
2024-06-11T10:56:45.431755295Z I0611 10:56:45.431685       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:54.957507492Z I0611 10:56:54.957448       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:56.048945720Z I0611 10:56:56.048877       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:57.773983463Z I0611 10:56:57.773906       1 reflector.go:351] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:58.289707761Z I0611 10:56:58.289615       1 reflector.go:351] Caches populated for *v1.APIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:58.442755907Z I0611 10:56:58.442694       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:01.259737315Z I0611 10:57:01.259662       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:01.317777440Z I0611 10:57:01.317718       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:02.305336828Z I0611 10:57:02.305236       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:02.588124100Z I0611 10:57:02.588061       1 reflector.go:351] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:03.210249175Z I0611 10:57:03.210185       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:03.545429370Z I0611 10:57:03.545375       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:03.882747058Z I0611 10:57:03.882688       1 reflector.go:351] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:04.122552933Z I0611 10:57:04.122477       1 reflector.go:351] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:04.873291387Z I0611 10:57:04.873226       1 installer_controller.go:491] Will retry "ci-op-9xx71rvq-1e28e-w667k-master-0" for revision 7 for the 1st time because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873291387Z W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873291387Z W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873291387Z W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873291387Z W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873291387Z W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873291387Z W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873291387Z W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873291387Z F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition
2024-06-11T10:57:04.873408998Z I0611 10:57:04.873372       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:  172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873408998Z W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873408998Z W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873408998Z W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873408998Z W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873408998Z W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873408998Z W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873408998Z W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873408998Z F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition
2024-06-11T10:57:04.873435100Z I0611 10:57:04.873403       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:57:04.873435100Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:57:04.873435100Z  CurrentRevision: (int32) 1,
2024-06-11T10:57:04.873435100Z  TargetRevision: (int32) 7,
2024-06-11T10:57:04.873435100Z  LastFailedRevision: (int32) 7,
2024-06-11T10:57:04.873435100Z  LastFailedTime: (*v1.Time)(0xc000ae32a8)(2024-06-11 10:57:04.87320968 +0000 UTC m=+448.029200787),
2024-06-11T10:57:04.873435100Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T10:57:04.873435100Z  LastFailedCount: (int) 1,
2024-06-11T10:57:04.873435100Z  LastFallbackCount: (int) 0,
2024-06-11T10:57:04.873435100Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T10:57:04.873435100Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T10:57:04.873435100Z  }
2024-06-11T10:57:04.873435100Z }
2024-06-11T10:57:04.873435100Z  because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873435100Z W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873435100Z W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873435100Z W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873435100Z W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873435100Z W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873435100Z W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873435100Z W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:04.873435100Z F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition
2024-06-11T10:57:04.907602189Z I0611 10:57:04.907532       1 helpers.go:260] lister was stale at resourceVersion=17632, live get showed resourceVersion=18134
2024-06-11T10:57:05.676007340Z I0611 10:57:05.675942       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:08.253893332Z I0611 10:57:08.253774       1 reflector.go:351] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:09.411228692Z I0611 10:57:09.411162       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:10.841182592Z I0611 10:57:10.841096       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:11.157200996Z I0611 10:57:11.157139       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:14.650636489Z I0611 10:57:14.650573       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:15.714920069Z I0611 10:57:15.714812       1 reflector.go:351] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:17.792126035Z I0611 10:57:17.792069       1 reflector.go:351] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:18.464784945Z I0611 10:57:18.464717       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:18.886399743Z I0611 10:57:18.886338       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:20.268035132Z I0611 10:57:20.267965       1 installer_controller.go:491] Will retry "ci-op-9xx71rvq-1e28e-w667k-master-0" for revision 7 for the 1st time because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268035132Z W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268035132Z W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268035132Z W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268035132Z W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268035132Z W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268035132Z W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268035132Z W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268035132Z F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition
2024-06-11T10:57:20.268113239Z I0611 10:57:20.268073       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:57:20.268113239Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:57:20.268113239Z  CurrentRevision: (int32) 1,
2024-06-11T10:57:20.268113239Z  TargetRevision: (int32) 7,
2024-06-11T10:57:20.268113239Z  LastFailedRevision: (int32) 7,
2024-06-11T10:57:20.268113239Z  LastFailedTime: (*v1.Time)(0xc00320c030)(2024-06-11 10:57:20.267950624 +0000 UTC m=+463.423941831),
2024-06-11T10:57:20.268113239Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T10:57:20.268113239Z  LastFailedCount: (int) 1,
2024-06-11T10:57:20.268113239Z  LastFallbackCount: (int) 0,
2024-06-11T10:57:20.268113239Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T10:57:20.268113239Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T10:57:20.268113239Z  }
2024-06-11T10:57:20.268113239Z }
2024-06-11T10:57:20.268113239Z  because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268113239Z W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268113239Z W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268113239Z W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268113239Z W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268113239Z W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268113239Z W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268113239Z W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268113239Z F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition
2024-06-11T10:57:20.268161643Z I0611 10:57:20.268110       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:  172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268161643Z W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268161643Z W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268161643Z W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268161643Z W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268161643Z W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268161643Z W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268161643Z W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:20.268161643Z F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition
2024-06-11T10:57:20.309453147Z I0611 10:57:20.309386       1 helpers.go:260] lister was stale at resourceVersion=17632, live get showed resourceVersion=19395
2024-06-11T10:57:21.470179355Z I0611 10:57:21.470114       1 installer_controller.go:491] Will retry "ci-op-9xx71rvq-1e28e-w667k-master-0" for revision 7 for the 1st time because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470179355Z W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470179355Z W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470179355Z W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470179355Z W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470179355Z W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470179355Z W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470179355Z W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470179355Z F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition
2024-06-11T10:57:21.470320567Z I0611 10:57:21.470248       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:57:21.470320567Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:57:21.470320567Z  CurrentRevision: (int32) 1,
2024-06-11T10:57:21.470320567Z  TargetRevision: (int32) 7,
2024-06-11T10:57:21.470320567Z  LastFailedRevision: (int32) 7,
2024-06-11T10:57:21.470320567Z  LastFailedTime: (*v1.Time)(0xc002ec05d0)(2024-06-11 10:57:21.470092947 +0000 UTC m=+464.626084154),
2024-06-11T10:57:21.470320567Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T10:57:21.470320567Z  LastFailedCount: (int) 1,
2024-06-11T10:57:21.470320567Z  LastFallbackCount: (int) 0,
2024-06-11T10:57:21.470320567Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T10:57:21.470320567Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T10:57:21.470320567Z  }
2024-06-11T10:57:21.470320567Z }
2024-06-11T10:57:21.470320567Z  because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470320567Z W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470320567Z W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470320567Z W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470320567Z W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470320567Z W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470320567Z W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470320567Z W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470320567Z F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition
2024-06-11T10:57:21.470372071Z I0611 10:57:21.470229       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:  172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470372071Z W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470372071Z W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470372071Z W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470372071Z W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470372071Z W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470372071Z W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470372071Z W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:57:21.470372071Z F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition
2024-06-11T10:57:21.506869257Z I0611 10:57:21.506809       1 helpers.go:260] lister was stale at resourceVersion=17632, live get showed resourceVersion=19714
2024-06-11T10:57:21.874718263Z I0611 10:57:21.874624       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:22.465242071Z I0611 10:57:22.465171       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:22.865156668Z I0611 10:57:22.865098       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:23.457273432Z I0611 10:57:23.457203       1 reflector.go:351] Caches populated for *v1.Job from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:23.663385132Z I0611 10:57:23.663208       1 request.go:697] Waited for 1.197372197s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T10:57:30.455490493Z I0611 10:57:30.455422       1 reflector.go:351] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:31.465628408Z I0611 10:57:31.465564       1 reflector.go:351] Caches populated for *v1.Role from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:37.465823566Z E0611 10:57:37.465761       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:57:37.499569220Z I0611 10:57:37.499509       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:37.550451122Z I0611 10:57:37.550388       1 helpers.go:184] lister was stale at resourceVersion=17632, live get showed resourceVersion=19733
2024-06-11T10:57:37.677427759Z I0611 10:57:37.677352       1 reflector.go:351] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:37.677868796Z I0611 10:57:37.677820       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:57:37.680041880Z I0611 10:57:37.679986       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:53:20Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:57:37.700220986Z I0611 10:57:37.700128       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nEtcdMembersDegraded: No unhealthy members found",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available"
2024-06-11T10:57:37.740796917Z I0611 10:57:37.740708       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 14.94 %, dbSize: 75337728
2024-06-11T10:57:37.740796917Z I0611 10:57:37.740743       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 14.09 %, dbSize: 74452992
2024-06-11T10:57:37.740796917Z I0611 10:57:37.740751       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 14.08 %, dbSize: 74416128
2024-06-11T10:57:37.740796917Z I0611 10:57:37.740759       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 14.30 %, dbSize: 75104256
2024-06-11T10:57:38.700633315Z I0611 10:57:38.700552       1 request.go:697] Waited for 1.021527316s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:57:39.519721847Z I0611 10:57:39.519649       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-retry-1-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-etcd because it was missing
2024-06-11T10:57:40.300552327Z I0611 10:57:40.300477       1 request.go:697] Waited for 1.175412999s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:57:40.504707644Z I0611 10:57:40.504646       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:57:41.300745139Z I0611 10:57:41.300674       1 request.go:697] Waited for 1.175912432s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-06-11T10:57:42.300920249Z I0611 10:57:42.300848       1 request.go:697] Waited for 1.194870196s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:57:42.705751653Z I0611 10:57:42.705667       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:57:44.102733936Z I0611 10:57:44.102666       1 reflector.go:351] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:44.213567717Z I0611 10:57:44.213497       1 reflector.go:351] Caches populated for *v1.Network from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:44.705267092Z I0611 10:57:44.705201       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:57:45.300747457Z I0611 10:57:45.300693       1 request.go:697] Waited for 1.197132147s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:57:45.355169515Z I0611 10:57:45.355103       1 reflector.go:351] Caches populated for *v1.Etcd from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:47.100954841Z I0611 10:57:47.100887       1 request.go:697] Waited for 1.039008042s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces?resourceVersion=17136
2024-06-11T10:57:47.104643139Z I0611 10:57:47.104590       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:48.101200235Z I0611 10:57:48.101142       1 request.go:697] Waited for 1.192496104s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:58:11.384434210Z E0611 10:58:11.384356       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error on peer cert sync for node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/secrets/etcd-peer-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:11.384507015Z I0611 10:58:11.384437       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:11.385567192Z E0611 10:58:11.385523       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   18415 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 10:58:11.384293199 +0000 UTC m=+514.540284306,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:58:11.584422452Z E0611 10:58:11.584369       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:11.584483656Z I0611 10:58:11.584445       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:11.637890466Z W0611 10:58:11.637824       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:11.637890466Z E0611 10:58:11.637881       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:11.784513101Z E0611 10:58:11.784463       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:11.784552404Z I0611 10:58:11.784520       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:11.984899572Z E0611 10:58:11.984832       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:11.984958777Z I0611 10:58:11.984912       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:12.184223066Z E0611 10:58:12.184168       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:12.184266369Z I0611 10:58:12.184233       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:12.237864393Z W0611 10:58:12.237791       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:12.237864393Z E0611 10:58:12.237845       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:12.383928987Z E0611 10:58:12.383865       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:12.383987492Z I0611 10:58:12.383936       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:12.584765491Z E0611 10:58:12.584708       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:12.584820395Z I0611 10:58:12.584791       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:12.837117667Z W0611 10:58:12.837048       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:12.837117667Z E0611 10:58:12.837100       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:12.909282751Z E0611 10:58:12.909203       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:12.909282751Z I0611 10:58:12.909258       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:13.437001088Z W0611 10:58:13.436927       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:13.437001088Z E0611 10:58:13.436987       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:13.552119616Z E0611 10:58:13.552060       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:13.552169020Z I0611 10:58:13.552114       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:14.036630889Z W0611 10:58:14.036558       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:14.036696894Z E0611 10:58:14.036621       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:14.636280592Z W0611 10:58:14.636213       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:14.636280592Z E0611 10:58:14.636270       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:14.835653689Z E0611 10:58:14.835595       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:14.835712594Z I0611 10:58:14.835651       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:15.030891784Z E0611 10:58:15.030830       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   18415 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 10:58:11.384293199 +0000 UTC m=+514.540284306,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:58:15.237557415Z W0611 10:58:15.237455       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:15.237557415Z E0611 10:58:15.237532       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:15.836308952Z W0611 10:58:15.836232       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:15.836308952Z E0611 10:58:15.836284       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:16.482258245Z W0611 10:58:16.482196       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:16.482341851Z E0611 10:58:16.482250       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:17.399421935Z E0611 10:58:17.399356       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:17.399481740Z I0611 10:58:17.399417       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:17.512461881Z E0611 10:58:17.512391       1 leaderelection.go:332] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:17.768020906Z W0611 10:58:17.767941       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:17.768020906Z E0611 10:58:17.768010       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:20.333671758Z W0611 10:58:20.333597       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:20.333671758Z E0611 10:58:20.333655       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:22.523848949Z E0611 10:58:22.523781       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:22.523904054Z I0611 10:58:22.523844       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:25.032839178Z E0611 10:58:25.032750       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   18415 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 10:58:11.384293199 +0000 UTC m=+514.540284306,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:58:25.461213508Z W0611 10:58:25.461140       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:25.461213508Z E0611 10:58:25.461204       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:32.766913392Z E0611 10:58:32.766851       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:32.766975697Z I0611 10:58:32.766908       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:35.034723158Z E0611 10:58:35.034650       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   18415 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 10:58:11.384293199 +0000 UTC m=+514.540284306,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:58:35.708363614Z W0611 10:58:35.708265       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:35.708363614Z E0611 10:58:35.708351       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:37.490683671Z E0611 10:58:37.490595       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:58:37.529946996Z E0611 10:58:37.529874       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.530094504Z I0611 10:58:37.530010       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.530843944Z E0611 10:58:37.530796       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:37.530913348Z E0611 10:58:37.530887       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.531124059Z E0611 10:58:37.531075       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd3f8631fb1\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator   18789 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 10:58:37.52984099 +0000 UTC m=+540.685832197,Count:31,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:58:37.532779849Z E0611 10:58:37.532743       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.532839852Z I0611 10:58:37.532805       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.534980768Z E0611 10:58:37.534938       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.535078173Z I0611 10:58:37.535037       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.536023024Z E0611 10:58:37.535978       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.536204234Z E0611 10:58:37.536172       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd402fce1d9\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator   18716 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 10:58:37.534897964 +0000 UTC m=+540.690889171,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:58:37.547224231Z E0611 10:58:37.547190       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.547266433Z I0611 10:58:37.547236       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.564252052Z E0611 10:58:37.564198       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.564290154Z I0611 10:58:37.564258       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.591367020Z E0611 10:58:37.591292       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.591367020Z I0611 10:58:37.591344       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.641440529Z E0611 10:58:37.641378       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.641500033Z I0611 10:58:37.641440       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.729703706Z E0611 10:58:37.729651       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.729754209Z I0611 10:58:37.729716       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.929293808Z E0611 10:58:37.929236       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:37.929409614Z I0611 10:58:37.929364       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:38.129477413Z E0611 10:58:38.129393       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:38.129552719Z I0611 10:58:38.129478       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:38.329858798Z E0611 10:58:38.329781       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:38.530230282Z E0611 10:58:38.530161       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:38.730323146Z E0611 10:58:38.730226       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:38.730394951Z I0611 10:58:38.730296       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:38.930407009Z E0611 10:58:38.930336       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:38.930467113Z I0611 10:58:38.930398       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:39.130100842Z E0611 10:58:39.130042       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:39.130193549Z I0611 10:58:39.130142       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:39.329934986Z E0611 10:58:39.329879       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:39.527507961Z E0611 10:58:39.527446       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:39.530227265Z E0611 10:58:39.530175       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:39.729833592Z E0611 10:58:39.729768       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:39.729910498Z I0611 10:58:39.729833       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:39.930340886Z E0611 10:58:39.930260       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:39.930423192Z I0611 10:58:39.930375       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:40.533097662Z E0611 10:58:40.533024       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:40.726256007Z I0611 10:58:40.726169       1 request.go:697] Waited for 1.175193884s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T10:58:40.730880453Z E0611 10:58:40.730840       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:41.019223116Z E0611 10:58:41.019164       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:41.019281720Z I0611 10:58:41.019223       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:41.128907618Z E0611 10:58:41.128841       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:41.128995925Z I0611 10:58:41.128947       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:41.332165919Z E0611 10:58:41.332094       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:41.529539079Z E0611 10:58:41.529482       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:41.726776729Z I0611 10:58:41.726712       1 request.go:697] Waited for 1.183248887s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T10:58:41.727860510Z E0611 10:58:41.727813       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:41.922401558Z E0611 10:58:41.922286       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd3f8631fb1\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator   18789 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 10:58:37.52984099 +0000 UTC m=+540.685832197,Count:31,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:58:41.929671202Z E0611 10:58:41.929611       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:42.104622985Z E0611 10:58:42.104561       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd402fce1d9\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator   18716 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 10:58:37.534897964 +0000 UTC m=+540.690889171,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:58:42.128948204Z E0611 10:58:42.128890       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:42.329422396Z E0611 10:58:42.329361       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:42.329492201Z I0611 10:58:42.329460       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:42.727049565Z I0611 10:58:42.726974       1 request.go:697] Waited for 1.196930544s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T10:58:42.927847637Z E0611 10:58:42.927783       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:43.130626347Z E0611 10:58:43.130567       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:43.514579163Z E0611 10:58:43.514499       1 leaderelection.go:332] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:43.531130415Z E0611 10:58:43.531081       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:43.531338629Z I0611 10:58:43.531180       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:43.588148782Z E0611 10:58:43.588092       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:43.588189185Z I0611 10:58:43.588159       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:43.926593132Z I0611 10:58:43.926503       1 request.go:697] Waited for 1.19815617s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T10:58:43.928689878Z E0611 10:58:43.928650       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:44.127405105Z E0611 10:58:44.127337       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:44.330239418Z E0611 10:58:44.330179       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:44.728676843Z E0611 10:58:44.728619       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:44.728784450Z I0611 10:58:44.728712       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:44.927091849Z I0611 10:58:44.926994       1 request.go:697] Waited for 1.198475592s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-06-11T10:58:45.037295117Z E0611 10:58:45.037226       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   18415 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 10:58:11.384293199 +0000 UTC m=+514.540284306,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:58:45.327365300Z E0611 10:58:45.327257       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:45.528978229Z E0611 10:58:45.528925       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:45.730870777Z E0611 10:58:45.730807       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:45.929388190Z E0611 10:58:45.929319       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:45.929388190Z I0611 10:58:45.929339       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:46.135216712Z I0611 10:58:46.127146       1 request.go:697] Waited for 1.190496837s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-06-11T10:58:46.135216712Z E0611 10:58:46.131761       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:46.329724447Z E0611 10:58:46.329664       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:46.527775027Z E0611 10:58:46.527722       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:46.928811032Z E0611 10:58:46.928747       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:46.928891738Z I0611 10:58:46.928843       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:47.527182068Z I0611 10:58:47.527105       1 request.go:697] Waited for 1.155029869s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T10:58:47.531562773Z E0611 10:58:47.531498       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:47.928581298Z E0611 10:58:47.928499       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:48.129679791Z E0611 10:58:48.129611       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:48.129769497Z I0611 10:58:48.129711       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:48.529566716Z E0611 10:58:48.529497       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:48.720083572Z E0611 10:58:48.720008       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:48.720132176Z I0611 10:58:48.720090       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:48.727259372Z I0611 10:58:48.727168       1 request.go:697] Waited for 1.000022483s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:58:48.729591034Z E0611 10:58:48.729554       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:48.929523646Z E0611 10:58:48.929450       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:48.929604151Z I0611 10:58:48.929532       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:49.528527380Z E0611 10:58:49.528464       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:49.926485707Z I0611 10:58:49.926410       1 request.go:697] Waited for 1.113908798s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T10:58:49.930431195Z E0611 10:58:49.930383       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:50.129523417Z E0611 10:58:50.129446       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:50.129770935Z I0611 10:58:50.129710       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:50.330081846Z E0611 10:58:50.330029       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:50.528864441Z E0611 10:58:50.528817       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:50.929370835Z E0611 10:58:50.929287       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:50.929370835Z I0611 10:58:50.929349       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:51.529294317Z E0611 10:58:51.529232       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:51.727025681Z E0611 10:58:51.726955       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:51.924188004Z E0611 10:58:51.924117       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd3f8631fb1\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator   18789 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 10:58:37.52984099 +0000 UTC m=+540.685832197,Count:31,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:58:51.929369981Z E0611 10:58:51.929320       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:51.929411084Z I0611 10:58:51.929382       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:52.106802470Z E0611 10:58:52.106724       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd402fce1d9\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator   18716 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 10:58:37.534897964 +0000 UTC m=+540.690889171,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:58:52.329093719Z E0611 10:58:52.329030       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:52.728982369Z E0611 10:58:52.728931       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:52.729071775Z I0611 10:58:52.729027       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:53.250711570Z E0611 10:58:53.250634       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:53.250770975Z I0611 10:58:53.250704       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:53.330087136Z E0611 10:58:53.330039       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:53.729432947Z E0611 10:58:53.729354       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:53.729432947Z I0611 10:58:53.729413       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:53.931180403Z E0611 10:58:53.931121       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:54.129135484Z E0611 10:58:54.129062       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:54.329635549Z E0611 10:58:54.329576       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:54.528434791Z E0611 10:58:54.528380       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:54.528491595Z I0611 10:58:54.528452       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:55.039188895Z E0611 10:58:55.039121       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   18415 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 10:58:11.384293199 +0000 UTC m=+514.540284306,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:58:55.131777021Z E0611 10:58:55.131699       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:55.729335431Z E0611 10:58:55.729246       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:55.928535602Z E0611 10:58:55.928473       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:55.928595606Z I0611 10:58:55.928546       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:56.729047655Z E0611 10:58:56.728990       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:57.130849444Z E0611 10:58:57.130790       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:57.331262403Z E0611 10:58:57.331186       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:57.928169766Z E0611 10:58:57.928114       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:57.928229870Z I0611 10:58:57.928176       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:58.729213932Z W0611 10:58:58.729147       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:58.729213932Z E0611 10:58:58.729197       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:58.968507876Z E0611 10:58:58.968443       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:58.968597382Z I0611 10:58:58.968497       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:59.128728380Z E0611 10:58:59.128657       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:59.330895999Z E0611 10:58:59.330826       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:59.527169264Z I0611 10:58:59.527100       1 request.go:697] Waited for 1.037382201s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T10:58:59.529344895Z E0611 10:58:59.529277       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:59.529378597Z I0611 10:58:59.529342       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:59.729710906Z E0611 10:58:59.729649       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:00.331070153Z E0611 10:59:00.331004       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:00.729140415Z E0611 10:59:00.729080       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:00.927812724Z E0611 10:59:00.927734       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:01.729199162Z E0611 10:59:01.729141       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:01.925417924Z E0611 10:59:01.925370       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd3f8631fb1\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator   18789 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 10:58:37.52984099 +0000 UTC m=+540.685832197,Count:31,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:59:02.108636907Z E0611 10:59:02.108577       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd402fce1d9\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator   18716 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 10:58:37.534897964 +0000 UTC m=+540.690889171,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:59:02.128874320Z E0611 10:59:02.128826       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:02.730634692Z E0611 10:59:02.730576       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:03.129156064Z E0611 10:59:03.129087       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:03.528962237Z E0611 10:59:03.528891       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:03.529019141Z I0611 10:59:03.528989       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:03.928985426Z E0611 10:59:03.928927       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:04.329188027Z E0611 10:59:04.329121       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:05.040840742Z E0611 10:59:05.040780       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   18415 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 10:58:11.384293199 +0000 UTC m=+514.540284306,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:59:05.129152298Z E0611 10:59:05.129094       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:05.129206902Z I0611 10:59:05.129163       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:05.329527518Z E0611 10:59:05.329462       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:05.534533472Z E0611 10:59:05.534468       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:06.329387075Z E0611 10:59:06.329331       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:06.529879304Z E0611 10:59:06.529818       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:06.928848650Z E0611 10:59:06.928773       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:07.731293255Z E0611 10:59:07.731238       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:08.894757807Z E0611 10:59:08.894695       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:09.096009204Z E0611 10:59:09.095933       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:09.493776962Z E0611 10:59:09.493713       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:09.513809285Z E0611 10:59:09.513742       1 leaderelection.go:332] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:09.576666950Z E0611 10:59:09.576606       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:10.310984916Z E0611 10:59:10.310904       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:11.169702019Z E0611 10:59:11.169632       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:11.928282108Z E0611 10:59:11.928196       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd3f8631fb1\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator   18789 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 10:58:37.52984099 +0000 UTC m=+540.685832197,Count:31,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:59:12.110622262Z E0611 10:59:12.110554       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd402fce1d9\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator   18716 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 10:58:37.534897964 +0000 UTC m=+540.690889171,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:59:13.772416515Z E0611 10:59:13.772362       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:13.772476719Z I0611 10:59:13.772425       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:14.020543842Z E0611 10:59:14.020465       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:14.220856572Z E0611 10:59:14.220791       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:14.618852622Z E0611 10:59:14.618795       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:15.042661675Z E0611 10:59:15.042588       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   18415 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 10:58:11.384293199 +0000 UTC m=+514.540284306,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:59:15.372473383Z E0611 10:59:15.372413       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:15.372525486Z I0611 10:59:15.372470       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:15.444870731Z E0611 10:59:15.444806       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:19.457359910Z E0611 10:59:19.457287       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:19.457418714Z I0611 10:59:19.457358       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:21.929667536Z E0611 10:59:21.929609       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd3f8631fb1\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator   18789 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 10:58:37.52984099 +0000 UTC m=+540.685832197,Count:31,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T10:59:22.112045337Z E0611 10:59:22.111979       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd402fce1d9\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator   18716 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 10:58:37.534897964 +0000 UTC m=+540.690889171,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T10:59:24.265134259Z E0611 10:59:24.265074       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:24.465932918Z E0611 10:59:24.465872       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:24.863802474Z E0611 10:59:24.863746       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:25.044457122Z E0611 10:59:25.044398       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   18415 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 10:58:11.384293199 +0000 UTC m=+514.540284306,Count:16,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T10:59:25.698218594Z E0611 10:59:25.698164       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:30.061287668Z E0611 10:59:30.061223       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:37.464227269Z E0611 10:59:37.464171       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T10:59:37.527613380Z I0611 10:59:37.527533       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:37Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:37.540337065Z I0611 10:59:37.540252       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded changed from False to True ("NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ")
2024-06-11T10:59:39.146237881Z I0611 10:59:39.146154       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:39Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:39.157524662Z E0611 10:59:39.157472       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:39.158296002Z I0611 10:59:39.158240       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:39Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:39.167275964Z E0611 10:59:39.167219       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:39.167949199Z I0611 10:59:39.167906       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:39Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:39.174339228Z E0611 10:59:39.174215       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:39.178432639Z I0611 10:59:39.178392       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:39Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:39.184865970Z E0611 10:59:39.184751       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:39.226393008Z I0611 10:59:39.226332       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:39Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:39.232720434Z E0611 10:59:39.232663       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:39.313659801Z I0611 10:59:39.313602       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:39Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:39.321174988Z E0611 10:59:39.321122       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:39.482291783Z I0611 10:59:39.482213       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:39Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:39.490368099Z E0611 10:59:39.490290       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:39.812716495Z I0611 10:59:39.812637       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:39Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:39.821458045Z E0611 10:59:39.821404       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:40.463260189Z I0611 10:59:40.463196       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:40Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:40.470659770Z E0611 10:59:40.470586       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:41.751561418Z I0611 10:59:41.751485       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:41Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:41.762079759Z E0611 10:59:41.762024       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:44.323147904Z I0611 10:59:44.323084       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:44Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:44.332322238Z E0611 10:59:44.332246       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:44.965018322Z I0611 10:59:44.964931       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:44Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:44.971355860Z E0611 10:59:44.971261       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:44.971999404Z I0611 10:59:44.971960       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:44Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:44.978158929Z E0611 10:59:44.978113       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:49.454013852Z I0611 10:59:49.453943       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:49Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:59:49.460557687Z E0611 10:59:49.460516       1 base_controller.go:268] StatusSyncer_etcd reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "etcd": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:08.905723498Z I0611 11:00:08.905661       1 reflector.go:351] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:11.784942489Z I0611 11:00:11.784883       1 reflector.go:351] Caches populated for *v1.Job from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:18.765500429Z I0611 11:00:18.765439       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:19.196005334Z I0611 11:00:19.195928       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:20.399366751Z I0611 11:00:20.399293       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:21.444240084Z I0611 11:00:21.444180       1 reflector.go:351] Caches populated for *v1.Network from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:24.191625307Z I0611 11:00:24.191556       1 reflector.go:351] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:25.617082393Z I0611 11:00:25.616999       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:26.959268361Z I0611 11:00:26.959131       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:28.801060312Z I0611 11:00:28.800987       1 reflector.go:351] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:29.081388623Z I0611 11:00:29.081116       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:29.946204146Z I0611 11:00:29.946145       1 reflector.go:351] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:32.105633438Z I0611 11:00:32.105568       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:32.291970078Z I0611 11:00:32.291902       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:33.003729739Z I0611 11:00:33.003651       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:33.465121861Z I0611 11:00:33.465063       1 reflector.go:351] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:35.756008859Z I0611 11:00:35.755938       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:36.431342884Z I0611 11:00:36.431077       1 reflector.go:351] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:36.702925412Z I0611 11:00:36.702831       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:37.154313943Z I0611 11:00:37.154215       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:37.440492065Z E0611 11:00:37.440370       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp: lookup thanos-querier.openshift-monitoring.svc on 172.30.0.10:53: no such host
2024-06-11T11:00:37.792731128Z I0611 11:00:37.792674       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 5.43 %, dbSize: 75337728
2024-06-11T11:00:37.792731128Z I0611 11:00:37.792698       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 4.50 %, dbSize: 74452992
2024-06-11T11:00:37.792731128Z I0611 11:00:37.792704       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 4.50 %, dbSize: 74416128
2024-06-11T11:00:37.792731128Z I0611 11:00:37.792711       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 4.72 %, dbSize: 75104256
2024-06-11T11:00:38.445293145Z I0611 11:00:38.445203       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:40.638541075Z I0611 11:00:40.638480       1 reflector.go:351] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:41.439562018Z I0611 11:00:41.439495       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:42.239545997Z I0611 11:00:42.239475       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:44.168771757Z I0611 11:00:44.168712       1 reflector.go:351] Caches populated for *v1.APIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:46.029175573Z I0611 11:00:46.029081       1 reflector.go:351] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:47.754284346Z I0611 11:00:47.754212       1 reflector.go:351] Caches populated for *v1.Etcd from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:49.224084037Z I0611 11:00:49.224028       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:52.613395126Z I0611 11:00:52.613283       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:54.824273033Z I0611 11:00:54.824205       1 reflector.go:351] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:55.087084739Z I0611 11:00:55.087013       1 reflector.go:351] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:55.088362316Z I0611 11:00:55.088274       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:00:55.167919331Z I0611 11:00:55.167806       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 2.44 %, dbSize: 75337728
2024-06-11T11:00:55.167919331Z I0611 11:00:55.167832       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 1.49 %, dbSize: 74452992
2024-06-11T11:00:55.167919331Z I0611 11:00:55.167839       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 1.51 %, dbSize: 74416128
2024-06-11T11:00:55.167919331Z I0611 11:00:55.167844       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 1.73 %, dbSize: 75104256
2024-06-11T11:00:56.628959057Z I0611 11:00:56.628896       1 installer_controller.go:491] Will retry "ci-op-9xx71rvq-1e28e-w667k-master-0" for revision 7 for the 2nd time because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.628959057Z W0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.628959057Z W0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.628959057Z W0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.628959057Z W0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.628959057Z W0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.628959057Z W0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.628959057Z W0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.628959057Z F0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition
2024-06-11T11:00:56.629041462Z I0611 11:00:56.629004       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:00:56.629041462Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:00:56.629041462Z  CurrentRevision: (int32) 1,
2024-06-11T11:00:56.629041462Z  TargetRevision: (int32) 7,
2024-06-11T11:00:56.629041462Z  LastFailedRevision: (int32) 7,
2024-06-11T11:00:56.629041462Z  LastFailedTime: (*v1.Time)(0xc003499620)(2024-06-11 11:00:56.628881952 +0000 UTC m=+679.784873159),
2024-06-11T11:00:56.629041462Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:00:56.629041462Z  LastFailedCount: (int) 2,
2024-06-11T11:00:56.629041462Z  LastFallbackCount: (int) 0,
2024-06-11T11:00:56.629041462Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:00:56.629041462Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T11:00:56.629041462Z  }
2024-06-11T11:00:56.629041462Z }
2024-06-11T11:00:56.629041462Z  because installer pod failed: installer:  172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629041462Z W0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629041462Z W0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629041462Z W0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629041462Z W0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629041462Z W0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629041462Z W0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629041462Z W0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629041462Z F0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition
2024-06-11T11:00:56.629063463Z I0611 11:00:56.629010       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer:  172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629063463Z W0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629063463Z W0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629063463Z W0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629063463Z W0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629063463Z W0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629063463Z W0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629063463Z W0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:56.629063463Z F0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition
2024-06-11T11:00:56.657630492Z I0611 11:00:56.657563       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:00:56.658686656Z I0611 11:00:56.658609       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:37Z","message":"NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:56.697034277Z I0611 11:00:56.696945       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:23.275218       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:33.274705       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:43.274799       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:54:53.275204       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:03.275731       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.275291       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:55:13.276318       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:55:13.276358       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-06-11T11:00:57.427713899Z I0611 11:00:57.427652       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:57.825460172Z I0611 11:00:57.825391       1 request.go:697] Waited for 1.166522501s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T11:01:00.125655427Z I0611 11:01:00.125577       1 reflector.go:351] Caches populated for *v1.Role from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:02.343812143Z I0611 11:01:02.343746       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 2.28 %, dbSize: 75337728
2024-06-11T11:01:02.343812143Z I0611 11:01:02.343776       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 0.01 %, dbSize: 74452992
2024-06-11T11:01:02.343812143Z I0611 11:01:02.343784       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 0.59 %, dbSize: 74416128
2024-06-11T11:01:02.343812143Z I0611 11:01:02.343791       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.24 %, dbSize: 75104256
2024-06-11T11:01:06.412639586Z I0611 11:01:06.412568       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:07.259797459Z I0611 11:01:07.259737       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:15.005036686Z I0611 11:01:15.004959       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:18.527519043Z I0611 11:01:18.527362       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-retry-2-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-etcd because it was missing
2024-06-11T11:01:18.537249927Z I0611 11:01:18.537197       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:01:18.553413797Z I0611 11:01:18.552934       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:01:20.109344813Z I0611 11:01:20.109270       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:01:21.708621330Z I0611 11:01:21.708553       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:01:37.434682297Z E0611 11:01:37.434626       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp 172.30.142.45:9091: connect: connection refused
2024-06-11T11:01:53.170274464Z I0611 11:01:53.170197       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:01:56.565687224Z I0611 11:01:56.565629       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 1
2024-06-11T11:01:58.364811688Z I0611 11:01:58.364743       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 1
2024-06-11T11:02:03.818284230Z I0611 11:02:03.818226       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 1
2024-06-11T11:02:08.213942767Z W0611 11:02:08.213862       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-0]
2024-06-11T11:02:23.267839958Z W0611 11:02:23.267776       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-0]
2024-06-11T11:02:29.928475330Z I0611 11:02:29.928376       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:02:30.322804119Z I0611 11:02:30.322678       1 request.go:697] Waited for 1.119731486s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:02:31.522988429Z I0611 11:02:31.522844       1 request.go:697] Waited for 1.122832156s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:02:32.522911325Z I0611 11:02:32.522851       1 request.go:697] Waited for 1.126329849s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:02:33.330783858Z I0611 11:02:33.330694       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:02:33.722946327Z I0611 11:02:33.722878       1 request.go:697] Waited for 1.191249319s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:02:36.128668741Z I0611 11:02:36.128580       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:02:37.434990833Z E0611 11:02:37.434935       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp 172.30.142.45:9091: connect: connection refused
2024-06-11T11:02:37.927993753Z I0611 11:02:37.927892       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:02:38.722674573Z I0611 11:02:38.722609       1 request.go:697] Waited for 1.195151037s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T11:02:40.322931856Z I0611 11:02:40.322687       1 request.go:697] Waited for 1.195897028s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:02:44.179208081Z W0611 11:02:44.179145       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-0]
2024-06-11T11:02:52.484133904Z E0611 11:02:52.484049       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-9xx71rvq-1e28e-w667k-master-0, took=, err=create client failure: failed to make etcd client for endpoints [https://10.0.0.8:2379]: context deadline exceeded
2024-06-11T11:02:52.529711955Z E0611 11:02:52.529633       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:02:52.530289386Z I0611 11:02:52.530233       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:02:52.530741510Z I0611 11:02:52.530679       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:37Z","message":"EtcdMembersDegraded: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"EtcdMembers_UnhealthyMembers::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:02:52.534988138Z E0611 11:02:52.534920       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:02:52.545243990Z E0611 11:02:52.545199       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:02:52.551592431Z I0611 11:02:52.551536       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "EtcdMembersDegraded: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-06-11T11:02:52.565556782Z E0611 11:02:52.565510       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:02:52.589227454Z I0611 11:02:52.589178       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:02:52.589915291Z I0611 11:02:52.589857       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:59:37Z","message":"EtcdMembersDegraded: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer:  172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"EtcdMembers_UnhealthyMembers::NodeInstaller_InstallerPodFailed","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:02:52.590338914Z E0611 11:02:52.590252       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:02:52.605736242Z I0611 11:02:52.602137       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 4 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy"
2024-06-11T11:02:52.606729095Z E0611 11:02:52.606655       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:02:52.767186221Z E0611 11:02:52.767124       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:02:52.985013231Z W0611 11:02:52.984951       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-0]
2024-06-11T11:02:53.010225287Z E0611 11:02:53.010162       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:02:53.010884022Z I0611 11:02:53.010835       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:02:53.088127075Z E0611 11:02:53.088066       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:02:53.336616933Z I0611 11:02:53.336551       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:02:53.729658363Z I0611 11:02:53.729593       1 request.go:697] Waited for 1.13970237s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T11:02:54.113721510Z I0611 11:02:54.113658       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:02:54.113831716Z E0611 11:02:54.113732       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:02:54.369038136Z E0611 11:02:54.368969       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:02:54.730475367Z I0611 11:02:54.730412       1 request.go:697] Waited for 1.193868082s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T11:02:55.929823043Z I0611 11:02:55.929736       1 request.go:697] Waited for 1.593747779s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:02:57.130192274Z I0611 11:02:57.130123       1 request.go:697] Waited for 1.393813231s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-06-11T11:02:57.536697628Z I0611 11:02:57.536618       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:02:58.130382744Z I0611 11:02:58.130263       1 request.go:697] Waited for 1.192961533s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:02:59.130454381Z I0611 11:02:59.130392       1 request.go:697] Waited for 1.189390415s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:02:59.250164804Z W0611 11:02:59.250108       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-0]
2024-06-11T11:02:59.490385390Z E0611 11:02:59.490275       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:03:00.330458657Z I0611 11:03:00.330396       1 request.go:697] Waited for 1.07020537s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:03:00.935680995Z I0611 11:03:00.935611       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:03:00.935680995Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:03:00.935680995Z  CurrentRevision: (int32) 7,
2024-06-11T11:03:00.935680995Z  TargetRevision: (int32) 0,
2024-06-11T11:03:00.935680995Z  LastFailedRevision: (int32) 7,
2024-06-11T11:03:00.935680995Z  LastFailedTime: (*v1.Time)(0xc0024b49d8)(2024-06-11 11:00:56 +0000 UTC),
2024-06-11T11:03:00.935680995Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:03:00.935680995Z  LastFailedCount: (int) 2,
2024-06-11T11:03:00.935680995Z  LastFallbackCount: (int) 0,
2024-06-11T11:03:00.935680995Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:03:00.935680995Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T11:03:00.935680995Z  }
2024-06-11T11:03:00.935680995Z }
2024-06-11T11:03:00.935680995Z  because static pod is ready
2024-06-11T11:03:00.958106267Z I0611 11:03:00.958022       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 1 to 7 because static pod is ready
2024-06-11T11:03:00.959065013Z I0611 11:03:00.959010       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:03:00.959548136Z E0611 11:03:00.959508       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:03:00.960600086Z I0611 11:03:00.960551       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 7\nEtcdMembersAvailable: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:03:00.972861273Z I0611 11:03:00.972810       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded changed from True to False ("NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy"),Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7" to "NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 7",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 1; 1 node is at revision 3; 1 node is at revision 5; 0 nodes have achieved new revision 7\nEtcdMembersAvailable: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 7\nEtcdMembersAvailable: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy"
2024-06-11T11:03:01.330653780Z I0611 11:03:01.330577       1 request.go:697] Waited for 1.192826533s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:03:02.530723360Z I0611 11:03:02.530641       1 request.go:697] Waited for 1.570555994s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T11:03:03.730052504Z I0611 11:03:03.729950       1 request.go:697] Waited for 1.188127208s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-06-11T11:03:04.734981575Z I0611 11:03:04.734918       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:03:04.734981575Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:03:04.734981575Z  CurrentRevision: (int32) 7,
2024-06-11T11:03:04.734981575Z  TargetRevision: (int32) 0,
2024-06-11T11:03:04.734981575Z  LastFailedRevision: (int32) 7,
2024-06-11T11:03:04.734981575Z  LastFailedTime: (*v1.Time)(0xc000e24c90)(2024-06-11 11:00:56 +0000 UTC),
2024-06-11T11:03:04.734981575Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:03:04.734981575Z  LastFailedCount: (int) 2,
2024-06-11T11:03:04.734981575Z  LastFallbackCount: (int) 0,
2024-06-11T11:03:04.734981575Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:03:04.734981575Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T11:03:04.734981575Z  }
2024-06-11T11:03:04.734981575Z }
2024-06-11T11:03:04.734981575Z  because static pod is ready
2024-06-11T11:03:04.929860319Z I0611 11:03:04.929801       1 request.go:697] Waited for 1.194829277s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-06-11T11:03:08.339630665Z I0611 11:03:08.339565       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-1 with revision 3 is the oldest and needs new revision 7
2024-06-11T11:03:08.339700369Z I0611 11:03:08.339626       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:03:08.339700369Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:03:08.339700369Z  CurrentRevision: (int32) 3,
2024-06-11T11:03:08.339700369Z  TargetRevision: (int32) 7,
2024-06-11T11:03:08.339700369Z  LastFailedRevision: (int32) 0,
2024-06-11T11:03:08.339700369Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:03:08.339700369Z  LastFailedReason: (string) "",
2024-06-11T11:03:08.339700369Z  LastFailedCount: (int) 0,
2024-06-11T11:03:08.339700369Z  LastFallbackCount: (int) 0,
2024-06-11T11:03:08.339700369Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:03:08.339700369Z }
2024-06-11T11:03:08.366073370Z I0611 11:03:08.366006       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:03:08.366361685Z E0611 11:03:08.366326       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:03:08.368866418Z I0611 11:03:08.368806       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 3 to 7 because node ci-op-9xx71rvq-1e28e-w667k-master-1 with revision 3 is the oldest
2024-06-11T11:03:09.530733946Z I0611 11:03:09.530657       1 request.go:697] Waited for 1.16172222s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:03:09.731453410Z E0611 11:03:09.731395       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:03:10.553979009Z I0611 11:03:10.553888       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-etcd because it was missing
2024-06-11T11:03:10.934086603Z E0611 11:03:10.934005       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:11.333660032Z E0611 11:03:11.333572       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:11.730206799Z I0611 11:03:11.730100       1 request.go:697] Waited for 1.175657361s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:03:11.731471667Z E0611 11:03:11.731413       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:11.933282588Z E0611 11:03:11.933229       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:12.335171640Z E0611 11:03:12.335117       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:12.531736583Z I0611 11:03:12.531667       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-1": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:12.532723835Z E0611 11:03:12.532681       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7ee4be1181679  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-1\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,LastTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T11:03:12.533379470Z E0611 11:03:12.533344       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:12.738986794Z I0611 11:03:12.738913       1 request.go:697] Waited for 1.207134833s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:03:12.935566638Z E0611 11:03:12.935510       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:13.730451768Z I0611 11:03:13.730378       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-1": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:13.732137258Z E0611 11:03:13.732076       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:13.930271284Z I0611 11:03:13.930199       1 request.go:697] Waited for 1.185123163s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:03:13.932536505Z W0611 11:03:13.932483       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:13.932583207Z E0611 11:03:13.932535       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:14.110810276Z E0611 11:03:14.110746       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7ee4be1181679  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-1\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,LastTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T11:03:14.130986148Z E0611 11:03:14.130921       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:14.332863373Z E0611 11:03:14.332793       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:14.534037961Z E0611 11:03:14.533968       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:14.930712096Z I0611 11:03:14.930644       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-1": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:14.932191163Z E0611 11:03:14.932141       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:15.129815879Z I0611 11:03:15.129757       1 request.go:697] Waited for 1.196599939s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:03:15.330891852Z E0611 11:03:15.330823       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:16.130079412Z I0611 11:03:16.130021       1 request.go:697] Waited for 1.196897404s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:03:16.130949451Z I0611 11:03:16.130903       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-1": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:16.132311513Z E0611 11:03:16.132268       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:16.530460177Z E0611 11:03:16.530396       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:16.732188480Z E0611 11:03:16.732126       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:17.130413248Z I0611 11:03:17.130293       1 request.go:697] Waited for 1.196042765s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-06-11T11:03:17.134585138Z E0611 11:03:17.134520       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:17.331289712Z I0611 11:03:17.331214       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-1": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:17.332779880Z E0611 11:03:17.332707       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:17.533005914Z W0611 11:03:17.532931       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:17.533005914Z E0611 11:03:17.532990       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:17.730958045Z E0611 11:03:17.730885       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:18.131832633Z E0611 11:03:18.131763       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:18.329946471Z I0611 11:03:18.329873       1 request.go:697] Waited for 1.184730248s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T11:03:18.531722276Z I0611 11:03:18.531640       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-1": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:18.533346150Z E0611 11:03:18.533311       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:18.931396410Z E0611 11:03:18.931330       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:19.133534832Z E0611 11:03:19.133465       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:19.330407113Z I0611 11:03:19.330349       1 request.go:697] Waited for 1.198307768s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:03:19.730856001Z I0611 11:03:19.730787       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-1": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:19.732356980Z E0611 11:03:19.732277       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:20.130874001Z E0611 11:03:20.130810       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:20.530257867Z I0611 11:03:20.530196       1 request.go:697] Waited for 1.199091419s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:03:20.931160913Z I0611 11:03:20.931083       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-1": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:20.932465182Z E0611 11:03:20.932414       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:21.133000710Z W0611 11:03:21.132920       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:21.133000710Z E0611 11:03:21.132976       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:21.330456275Z E0611 11:03:21.330394       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:21.530536278Z I0611 11:03:21.530473       1 request.go:697] Waited for 1.199105849s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T11:03:21.532763196Z E0611 11:03:21.532711       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:21.732761696Z E0611 11:03:21.732713       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:21.934563591Z E0611 11:03:21.934506       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:22.131681137Z I0611 11:03:22.131607       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-1": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:22.132923503Z E0611 11:03:22.132877       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:22.531178309Z E0611 11:03:22.531124       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:22.729820537Z I0611 11:03:22.729757       1 request.go:697] Waited for 1.196497511s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T11:03:23.331395049Z I0611 11:03:23.331315       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-1": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:23.332834481Z E0611 11:03:23.332788       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:23.730431905Z I0611 11:03:23.730373       1 request.go:697] Waited for 1.11907245s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:03:23.731571230Z E0611 11:03:23.731518       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:23.933117501Z E0611 11:03:23.933059       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:24.112829100Z E0611 11:03:24.112761       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7ee4be1181679  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-1\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,LastTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T11:03:24.533802731Z W0611 11:03:24.533729       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:24.533802731Z E0611 11:03:24.533790       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:24.933101083Z E0611 11:03:24.933041       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:25.538396950Z E0611 11:03:25.538339       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:25.934918629Z E0611 11:03:25.934853       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:26.933109786Z W0611 11:03:26.933037       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:26.933109786Z E0611 11:03:26.933101       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:27.132281573Z E0611 11:03:27.132221       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:27.333600072Z E0611 11:03:27.333544       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:28.734355223Z E0611 11:03:28.734229       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:29.134806607Z E0611 11:03:29.134741       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:29.331522665Z I0611 11:03:29.331456       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-1": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:29.332852235Z E0611 11:03:29.332815       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:29.532377640Z W0611 11:03:29.532317       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:29.532377640Z E0611 11:03:29.532370       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:29.668481638Z E0611 11:03:29.668411       1 leaderelection.go:332] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:29.930494502Z I0611 11:03:29.930437       1 request.go:697] Waited for 1.078169328s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:03:29.931271043Z E0611 11:03:29.931230       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:30.132963461Z E0611 11:03:30.132902       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:30.732835645Z E0611 11:03:30.732780       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:32.132745834Z W0611 11:03:32.132661       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:32.132745834Z E0611 11:03:32.132734       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:32.333112545Z E0611 11:03:32.333050       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:32.532289695Z E0611 11:03:32.532217       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:32.734083178Z E0611 11:03:32.734021       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:33.932289740Z E0611 11:03:33.932231       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:34.114119715Z E0611 11:03:34.114057       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7ee4be1181679  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-1\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,LastTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T11:03:34.533038453Z W0611 11:03:34.532975       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:34.533038453Z E0611 11:03:34.533024       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:34.932275599Z E0611 11:03:34.932212       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:35.532135068Z E0611 11:03:35.532072       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:35.936083451Z E0611 11:03:35.936008       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:36.732704449Z W0611 11:03:36.732630       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:36.732704449Z E0611 11:03:36.732693       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:37.133695083Z E0611 11:03:37.133602       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.334337107Z E0611 11:03:37.334259       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.430662068Z E0611 11:03:37.430602       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-9xx71rvq-1e28e-w667k-master-0, took=, err=create client failure: failed to make etcd client for endpoints [https://10.0.0.8:2379]: context deadline exceeded
2024-06-11T11:03:37.435294201Z E0611 11:03:37.435245       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp 172.30.142.45:9091: connect: connection refused
2024-06-11T11:03:37.539666968Z E0611 11:03:37.539605       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.539750472Z I0611 11:03:37.539685       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.540797225Z E0611 11:03:37.540751       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd402fce1d9\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator   20760 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 11:03:37.539572663 +0000 UTC m=+840.695563770,Count:30,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T11:03:37.552806431Z E0611 11:03:37.552759       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.552861634Z I0611 11:03:37.552839       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.571206860Z E0611 11:03:37.571152       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.571265763Z I0611 11:03:37.571221       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.599839904Z E0611 11:03:37.599775       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.599910508Z I0611 11:03:37.599854       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.648008435Z E0611 11:03:37.647941       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.648075338Z I0611 11:03:37.647995       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.735764263Z E0611 11:03:37.735697       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.735764263Z I0611 11:03:37.735747       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.905063606Z E0611 11:03:37.904992       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:37.905126809Z I0611 11:03:37.905070       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.233377473Z E0611 11:03:38.233264       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.233377473Z I0611 11:03:38.233347       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.332586579Z E0611 11:03:38.332524       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.332586579Z E0611 11:03:38.332552       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.332642482Z I0611 11:03:38.332590       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.332642482Z I0611 11:03:38.332594       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.334048453Z E0611 11:03:38.334003       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   20782 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 11:03:38.332495574 +0000 UTC m=+841.488486781,Count:31,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T11:03:38.334092655Z E0611 11:03:38.334038       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd3f8631fb1\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator   20766 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 11:03:38.332528076 +0000 UTC m=+841.488519283,Count:57,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T11:03:38.340062256Z E0611 11:03:38.340023       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.340098158Z I0611 11:03:38.340069       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.352329875Z E0611 11:03:38.352285       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.352370077Z I0611 11:03:38.352341       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.375398739Z E0611 11:03:38.375281       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.375473043Z I0611 11:03:38.375393       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.418706624Z E0611 11:03:38.418653       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.418761727Z I0611 11:03:38.418704       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.530026742Z I0611 11:03:38.529932       1 request.go:697] Waited for 1.001717446s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T11:03:38.540654678Z E0611 11:03:38.540599       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.540708081Z I0611 11:03:38.540670       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.740590367Z E0611 11:03:38.740526       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:38.940166009Z E0611 11:03:38.940110       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:38.940222312Z I0611 11:03:38.940163       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:39.140604306Z E0611 11:03:39.140517       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:39.140604306Z I0611 11:03:39.140568       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:39.340173759Z E0611 11:03:39.340103       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:39.530149935Z I0611 11:03:39.530083       1 request.go:697] Waited for 1.19605948s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:03:39.540273840Z E0611 11:03:39.540218       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:39.540349443Z I0611 11:03:39.540275       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:39.740084905Z E0611 11:03:39.740019       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:39.740152909Z I0611 11:03:39.740103       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:39.940802316Z W0611 11:03:39.940733       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:39.940802316Z E0611 11:03:39.940793       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:40.140754089Z E0611 11:03:40.140681       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:40.331517004Z E0611 11:03:40.331453       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:40.340594356Z E0611 11:03:40.340526       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:40.530194713Z I0611 11:03:40.530134       1 request.go:697] Waited for 1.198845794s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:03:40.540232613Z E0611 11:03:40.540165       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:40.540344119Z I0611 11:03:40.540228       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:40.740498502Z E0611 11:03:40.740437       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:40.740562805Z I0611 11:03:40.740497       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:40.931689038Z I0611 11:03:40.931616       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-1": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:40.940410573Z E0611 11:03:40.940363       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:41.139799117Z E0611 11:03:41.139684       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:41.340255515Z E0611 11:03:41.340181       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:41.340348520Z I0611 11:03:41.340294       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:41.530533506Z I0611 11:03:41.530470       1 request.go:697] Waited for 1.379236691s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T11:03:41.539993377Z E0611 11:03:41.539920       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:41.730856297Z E0611 11:03:41.730786       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:41.823693627Z E0611 11:03:41.823627       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:41.823743530Z I0611 11:03:41.823698       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:42.139642986Z E0611 11:03:42.139571       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:42.730236642Z I0611 11:03:42.730173       1 request.go:697] Waited for 1.389601608s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:03:42.733155888Z E0611 11:03:42.733055       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:42.733219491Z I0611 11:03:42.733169       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:42.933775394Z E0611 11:03:42.933719       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:43.308855801Z E0611 11:03:43.308809       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:43.308910704Z I0611 11:03:43.308877       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:43.437407313Z E0611 11:03:43.437346       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   20782 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 11:03:38.332495574 +0000 UTC m=+841.488486781,Count:31,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T11:03:43.732801946Z W0611 11:03:43.732712       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:43.732801946Z E0611 11:03:43.732772       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:43.929649464Z I0611 11:03:43.929574       1 request.go:697] Waited for 1.196072455s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:03:43.932128887Z E0611 11:03:43.932071       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:43.932269094Z I0611 11:03:43.932192       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:43.984195884Z E0611 11:03:43.984107       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd402fce1d9\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator   20760 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 11:03:37.539572663 +0000 UTC m=+840.695563770,Count:30,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T11:03:44.116486382Z E0611 11:03:44.116432       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7ee4be1181679  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-1\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,LastTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T11:03:44.133918952Z E0611 11:03:44.133857       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:44.387810215Z E0611 11:03:44.387743       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:44.387876318Z I0611 11:03:44.387806       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:44.532144214Z E0611 11:03:44.532083       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:44.732628713Z E0611 11:03:44.732571       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:44.930511683Z I0611 11:03:44.930456       1 request.go:697] Waited for 1.196968s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:03:45.133440104Z E0611 11:03:45.133383       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:45.133533909Z I0611 11:03:45.133485       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:45.333729393Z E0611 11:03:45.333666       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:45.534552910Z E0611 11:03:45.534479       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:46.134167216Z E0611 11:03:46.134079       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:46.134291222Z I0611 11:03:46.134191       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:46.333640565Z E0611 11:03:46.333569       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:46.732970882Z E0611 11:03:46.732903       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:46.933185047Z W0611 11:03:46.933113       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:46.933185047Z E0611 11:03:46.933160       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:47.118457452Z E0611 11:03:47.118392       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd3f8631fb1\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator   20766 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 11:03:38.332528076 +0000 UTC m=+841.488519283,Count:57,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T11:03:47.130443980Z I0611 11:03:47.130375       1 request.go:697] Waited for 1.068749879s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:03:47.333071394Z E0611 11:03:47.333010       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:47.333165799Z I0611 11:03:47.333111       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:47.733815086Z E0611 11:03:47.733748       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:48.332672456Z E0611 11:03:48.332614       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:48.332738059Z I0611 11:03:48.332708       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:48.437471145Z E0611 11:03:48.437412       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:48.437522248Z I0611 11:03:48.437469       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:48.733489251Z E0611 11:03:48.733433       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:48.932903497Z E0611 11:03:48.932845       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.132698463Z E0611 11:03:49.132639       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.132812469Z I0611 11:03:49.132733       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.333743794Z E0611 11:03:49.333682       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:49.510925775Z E0611 11:03:49.510865       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.510978878Z I0611 11:03:49.510924       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.534285199Z E0611 11:03:49.534206       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:49.930449851Z I0611 11:03:49.930379       1 request.go:697] Waited for 1.07612907s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:03:50.132739047Z E0611 11:03:50.132687       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:50.132818951Z I0611 11:03:50.132775       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:50.533138821Z E0611 11:03:50.533081       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:50.933706904Z E0611 11:03:50.933645       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:50.933768707Z I0611 11:03:50.933737       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:51.333570949Z E0611 11:03:51.333517       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:51.534255862Z W0611 11:03:51.534154       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:51.534255862Z E0611 11:03:51.534228       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:51.732930269Z E0611 11:03:51.732869       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:51.733003373Z I0611 11:03:51.732961       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:52.332572279Z E0611 11:03:52.332507       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:52.332646483Z I0611 11:03:52.332607       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:52.535705120Z E0611 11:03:52.535630       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:52.732519630Z E0611 11:03:52.732463       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:52.932400100Z E0611 11:03:52.932324       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:52.932400100Z I0611 11:03:52.932364       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:53.332925980Z E0611 11:03:53.332865       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:53.332979883Z I0611 11:03:53.332926       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:53.439416658Z E0611 11:03:53.439342       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   20782 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 11:03:38.332495574 +0000 UTC m=+841.488486781,Count:31,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T11:03:53.932752700Z E0611 11:03:53.932691       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:53.986278904Z E0611 11:03:53.986221       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd402fce1d9\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator   20760 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 11:03:37.539572663 +0000 UTC m=+840.695563770,Count:30,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T11:03:54.118495330Z E0611 11:03:54.118441       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7ee4be1181679  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-1\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,LastTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T11:03:54.132576968Z E0611 11:03:54.132527       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:54.132665972Z I0611 11:03:54.132615       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:54.533519970Z E0611 11:03:54.533459       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:54.732792108Z E0611 11:03:54.732635       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:54.732792108Z I0611 11:03:54.732707       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:54.934324769Z E0611 11:03:54.934231       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:55.415497125Z E0611 11:03:55.415440       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:55.415555028Z I0611 11:03:55.415497       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:55.670032274Z E0611 11:03:55.669948       1 leaderelection.go:332] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:56.015931120Z E0611 11:03:56.015868       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:56.015980522Z I0611 11:03:56.015940       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:57.120420172Z E0611 11:03:57.120364       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd3f8631fb1\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator   20766 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 11:03:38.332528076 +0000 UTC m=+841.488519283,Count:57,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T11:03:57.670826460Z E0611 11:03:57.670757       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:57.858018868Z E0611 11:03:57.857948       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:57.979056293Z E0611 11:03:57.978992       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:57.979108696Z I0611 11:03:57.979047       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:58.579220876Z E0611 11:03:58.579162       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:58.579290379Z I0611 11:03:58.579238       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:58.686083118Z E0611 11:03:58.686020       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:58.686132221Z I0611 11:03:58.686076       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:59.057499092Z E0611 11:03:59.057439       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:59.659157146Z E0611 11:03:59.659096       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:59.754057313Z E0611 11:03:59.753990       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:59.754117216Z I0611 11:03:59.754055       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:00.814778359Z E0611 11:04:00.814699       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:01.622621936Z I0611 11:04:01.622550       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 7 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-1": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:01.624418022Z E0611 11:04:01.624366       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:03.102714461Z E0611 11:04:03.102649       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:03.102769664Z I0611 11:04:03.102719       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:03.440853610Z E0611 11:04:03.440780       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   20782 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 11:03:38.332495574 +0000 UTC m=+841.488486781,Count:31,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T11:04:03.704043281Z E0611 11:04:03.703978       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:03.704107184Z I0611 11:04:03.704041       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:03.988617229Z E0611 11:04:03.988540       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd402fce1d9\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator   20760 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 11:03:37.539572663 +0000 UTC m=+840.695563770,Count:30,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T11:04:04.120653787Z E0611 11:04:04.120602       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7ee4be1181679  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-1\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,LastTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T11:04:07.122015419Z E0611 11:04:07.121943       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd3f8631fb1\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator   20766 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 11:03:38.332528076 +0000 UTC m=+841.488519283,Count:57,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T11:04:08.102266544Z E0611 11:04:08.102209       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:09.302477560Z E0611 11:04:09.302408       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:09.417251847Z E0611 11:04:09.417195       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:09.905672574Z E0611 11:04:09.905599       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-etcd-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:12.020515602Z W0611 11:04:12.020437       1 base_controller.go:232] Updating status of "GuardController" failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:12.020515602Z E0611 11:04:12.020500       1 base_controller.go:268] GuardController reconciliation failed: [Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": dial tcp 172.30.0.1:443: connect: connection refused, Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:13.346709159Z E0611 11:04:13.346647       1 base_controller.go:268] ScriptController reconciliation failed: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:13.346763461Z I0611 11:04:13.346697       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:13.442862200Z E0611 11:04:13.442802       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd46e51938b\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd46e51938b  openshift-etcd-operator   20782 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdCertSignerControllerUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,Host:,},FirstTimestamp:2024-06-11 10:54:39 +0000 UTC,LastTimestamp:2024-06-11 11:03:38.332495574 +0000 UTC m=+841.488486781,Count:31,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-cert-signer-controller-etcdcertsignercontroller,ReportingInstance:,}"
2024-06-11T11:04:13.947754821Z E0611 11:04:13.947651       1 base_controller.go:266] "ScriptController" controller failed to sync "", err: "configmap/etcd-pod": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:13.947847225Z I0611 11:04:13.947749       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'ScriptControllerErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:13.989985072Z E0611 11:04:13.989897       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd402fce1d9\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd402fce1d9  openshift-etcd-operator   20760 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:EtcdEndpointsErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 11:03:37.539572663 +0000 UTC m=+840.695563770,Count:30,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-etcd-endpoints-controller-etcdendpointscontroller,ReportingInstance:,}"
2024-06-11T11:04:14.122413789Z E0611 11:04:14.122353       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7ee4be1181679  openshift-etcd-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 7 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-1\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,LastTimestamp:2024-06-11 11:03:12.531543673 +0000 UTC m=+815.687534880,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-installer-controller,ReportingInstance:,}"
2024-06-11T11:04:17.123983087Z E0611 11:04:17.123921       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/events/etcd-operator.17d7edd3f8631fb1\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{etcd-operator.17d7edd3f8631fb1  openshift-etcd-operator   20766 0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-etcd-operator,Name:etcd-operator,UID:ddb3112e-9358-491c-8d18-fd0da304c5a2,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:ScriptControllerErrorUpdatingStatus,Message:Put \"https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:openshift-cluster-etcd-operator-script-controller-scriptcontroller,Host:,},FirstTimestamp:2024-06-11 10:54:37 +0000 UTC,LastTimestamp:2024-06-11 11:03:38.332528076 +0000 UTC m=+841.488519283,Count:57,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:openshift-cluster-etcd-operator-script-controller-scriptcontroller,ReportingInstance:,}"
2024-06-11T11:04:18.161950776Z E0611 11:04:18.161882       1 base_controller.go:268] EtcdStaticResources reconciliation failed: ["etcd/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/minimal-sm.yaml" (string): Get "https://172.30.0.1:443/apis/monitoring.coreos.com/v1/namespaces/openshift-etcd-operator/servicemonitors/etcd-minimal": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/roles/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/prometheus-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-etcd/rolebindings/prometheus-k8s": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-cr.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:operator:etcd-backup-role": dial tcp 172.30.0.1:443: connect: connection refused, "etcd/backups-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:etcd-backup-crb": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:19.173892800Z E0611 11:04:19.173832       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: applying configmap update failed :Get "https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-endpoints": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:19.173946903Z I0611 11:04:19.173900       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdEndpointsErrorUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:20.238019241Z E0611 11:04:20.237961       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: error getting openshift-config/etcd-signer: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/etcd-signer": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:20.238077044Z I0611 11:04:20.238025       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'EtcdCertSignerControllerUpdatingStatus' Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/etcds/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:21.670636990Z E0611 11:04:21.670554       1 leaderelection.go:332] error retrieving resource lock openshift-etcd-operator/openshift-cluster-etcd-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-etcd-operator/leases/openshift-cluster-etcd-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:31.792646618Z I0611 11:04:31.792578       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.01 %, dbSize: 82210816
2024-06-11T11:04:31.792646618Z I0611 11:04:31.792604       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 0.01 %, dbSize: 82079744
2024-06-11T11:04:31.792646618Z I0611 11:04:31.792611       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.02 %, dbSize: 82595840
2024-06-11T11:04:37.437122214Z E0611 11:04:37.437067       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp 172.30.142.45:9091: connect: connection refused
2024-06-11T11:04:37.491058076Z I0611 11:04:37.490965       1 helpers.go:184] lister was stale at resourceVersion=23642, live get showed resourceVersion=23920
2024-06-11T11:04:42.594823750Z I0611 11:04:42.594754       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:04:57.762556398Z I0611 11:04:57.762482       1 reflector.go:351] Caches populated for *v1.Etcd from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:04:58.818403912Z I0611 11:04:58.818292       1 reflector.go:351] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:06.578568097Z I0611 11:05:06.578497       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:11.013502165Z I0611 11:05:11.013405       1 reflector.go:351] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:11.554621453Z I0611 11:05:11.554563       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:14.450287026Z I0611 11:05:14.450222       1 reflector.go:351] Caches populated for *v1.Job from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:14.907283527Z I0611 11:05:14.907221       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:15.114661164Z I0611 11:05:15.114584       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:15.312285939Z I0611 11:05:15.312222       1 reflector.go:351] Caches populated for *v1.Role from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:16.629858646Z I0611 11:05:16.629781       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:16.860538239Z I0611 11:05:16.860483       1 reflector.go:351] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:17.157554373Z I0611 11:05:17.157471       1 reflector.go:351] Caches populated for *v1.Network from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:17.664562239Z I0611 11:05:17.664497       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:19.346178973Z I0611 11:05:19.346103       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:20.064188135Z I0611 11:05:20.064117       1 reflector.go:351] Caches populated for *v1.Endpoints from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:21.265437193Z I0611 11:05:21.265348       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:21.463454779Z I0611 11:05:21.463403       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:21.667883377Z I0611 11:05:21.667813       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:22.402497842Z I0611 11:05:22.402422       1 reflector.go:351] Caches populated for *v1.APIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:22.861453462Z I0611 11:05:22.861392       1 request.go:697] Waited for 1.003354876s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd-operator/secrets?resourceVersion=23467
2024-06-11T11:05:22.863770174Z I0611 11:05:22.863677       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:23.301336383Z I0611 11:05:23.296936       1 reflector.go:351] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:23.463894190Z I0611 11:05:23.463829       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:24.062033247Z I0611 11:05:24.061970       1 request.go:697] Waited for 1.394414869s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:05:24.464390181Z I0611 11:05:24.464291       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:25.062104718Z I0611 11:05:25.062031       1 request.go:697] Waited for 1.596598354s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:05:25.666468859Z I0611 11:05:25.666399       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 3
2024-06-11T11:05:26.262044098Z I0611 11:05:26.261962       1 request.go:697] Waited for 1.39440094s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T11:05:28.467756409Z I0611 11:05:28.467686       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 3
2024-06-11T11:05:29.667640587Z I0611 11:05:29.667581       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:31.545605740Z I0611 11:05:31.545532       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:32.731721181Z W0611 11:05:32.731636       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-1]
2024-06-11T11:05:32.762825112Z I0611 11:05:32.762762       1 helpers.go:184] lister was stale at resourceVersion=23642, live get showed resourceVersion=23923
2024-06-11T11:05:34.582349722Z I0611 11:05:34.582266       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:05:34.951968950Z I0611 11:05:34.951908       1 reflector.go:351] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:35.577436285Z I0611 11:05:35.577356       1 request.go:697] Waited for 1.140655623s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:05:35.738338542Z I0611 11:05:35.738156       1 reflector.go:351] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:36.578404301Z I0611 11:05:36.578240       1 request.go:697] Waited for 1.194392002s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:05:36.725403106Z W0611 11:05:36.725326       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-1]
2024-06-11T11:05:37.438370095Z E0611 11:05:37.438248       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp 172.30.142.45:9091: connect: connection refused
2024-06-11T11:05:37.777983047Z I0611 11:05:37.777929       1 request.go:697] Waited for 1.193857777s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:05:38.183953016Z I0611 11:05:38.183898       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:05:38.652676232Z I0611 11:05:38.652495       1 reflector.go:351] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:38.653018748Z I0611 11:05:38.652973       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:05:38.657378653Z I0611 11:05:38.657339       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:05:38.672964285Z I0611 11:05:38.671906       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 7\nEtcdMembersAvailable: 3 of 4 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 7\nEtcdMembersAvailable: 4 members are available"
2024-06-11T11:05:38.778407138Z I0611 11:05:38.778318       1 request.go:697] Waited for 1.249942211s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T11:05:38.968591871Z I0611 11:05:38.968490       1 reflector.go:351] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:38.982477423Z I0611 11:05:38.982412       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 0.03 %, dbSize: 83828736
2024-06-11T11:05:38.982477423Z I0611 11:05:38.982439       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.13 %, dbSize: 84463616
2024-06-11T11:05:39.977453593Z I0611 11:05:39.977380       1 request.go:697] Waited for 1.592950957s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:05:40.180762384Z I0611 11:05:40.180701       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:40.978094306Z I0611 11:05:40.977950       1 request.go:697] Waited for 1.786533402s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:05:41.978220695Z I0611 11:05:41.978138       1 request.go:697] Waited for 1.59286206s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T11:05:42.380009452Z I0611 11:05:42.379944       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:42.493142233Z I0611 11:05:42.493077       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:05:42.565257800Z I0611 11:05:42.565194       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.04 %, dbSize: 84103168
2024-06-11T11:05:42.565257800Z I0611 11:05:42.565219       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 0.04 %, dbSize: 83935232
2024-06-11T11:05:42.565257800Z I0611 11:05:42.565226       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 0.05 %, dbSize: 83939328
2024-06-11T11:05:42.565257800Z I0611 11:05:42.565232       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.16 %, dbSize: 84561920
2024-06-11T11:05:42.978387086Z I0611 11:05:42.978324       1 request.go:697] Waited for 1.578328882s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:05:43.187621854Z I0611 11:05:43.187547       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:05:44.177880983Z I0611 11:05:44.177808       1 request.go:697] Waited for 1.595145966s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:05:45.177920068Z I0611 11:05:45.177848       1 request.go:697] Waited for 1.387578777s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T11:05:46.177958553Z I0611 11:05:46.177898       1 request.go:697] Waited for 1.195889128s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T11:05:46.782848491Z I0611 11:05:46.782754       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:05:48.720178077Z I0611 11:05:48.720119       1 reflector.go:351] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:54.697971816Z I0611 11:05:54.697877       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:05:54.697971816Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:05:54.697971816Z  CurrentRevision: (int32) 7,
2024-06-11T11:05:54.697971816Z  TargetRevision: (int32) 0,
2024-06-11T11:05:54.697971816Z  LastFailedRevision: (int32) 0,
2024-06-11T11:05:54.697971816Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:05:54.697971816Z  LastFailedReason: (string) "",
2024-06-11T11:05:54.697971816Z  LastFailedCount: (int) 0,
2024-06-11T11:05:54.697971816Z  LastFallbackCount: (int) 0,
2024-06-11T11:05:54.697971816Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:05:54.697971816Z }
2024-06-11T11:05:54.697971816Z  because static pod is ready
2024-06-11T11:05:54.729477531Z I0611 11:05:54.729394       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 3 to 7 because static pod is ready
2024-06-11T11:05:54.744402649Z I0611 11:05:54.744335       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:05:54.744987577Z I0611 11:05:54.744913       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:05:54.762274509Z I0611 11:05:54.758398       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 7" to "NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 7",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 3; 1 node is at revision 5; 1 node is at revision 7\nEtcdMembersAvailable: 4 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 7\nEtcdMembersAvailable: 4 members are available"
2024-06-11T11:05:54.847838824Z I0611 11:05:54.847517       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 0.05 %, dbSize: 84537344
2024-06-11T11:05:54.847838824Z I0611 11:05:54.847552       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 0.08 %, dbSize: 84439040
2024-06-11T11:05:54.847838824Z I0611 11:05:54.847560       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 0.04 %, dbSize: 84484096
2024-06-11T11:05:54.847838824Z I0611 11:05:54.847568       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.07 %, dbSize: 85041152
2024-06-11T11:05:55.692079855Z I0611 11:05:55.691942       1 request.go:697] Waited for 1.144696483s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T11:05:56.692164483Z I0611 11:05:56.692095       1 request.go:697] Waited for 1.395648134s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:05:56.904344749Z I0611 11:05:56.904267       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:57.891896100Z I0611 11:05:57.891840       1 request.go:697] Waited for 1.393767346s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:05:58.697892695Z I0611 11:05:58.697825       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:05:58.697892695Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:05:58.697892695Z  CurrentRevision: (int32) 7,
2024-06-11T11:05:58.697892695Z  TargetRevision: (int32) 0,
2024-06-11T11:05:58.697892695Z  LastFailedRevision: (int32) 0,
2024-06-11T11:05:58.697892695Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:05:58.697892695Z  LastFailedReason: (string) "",
2024-06-11T11:05:58.697892695Z  LastFailedCount: (int) 0,
2024-06-11T11:05:58.697892695Z  LastFallbackCount: (int) 0,
2024-06-11T11:05:58.697892695Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:05:58.697892695Z }
2024-06-11T11:05:58.697892695Z  because static pod is ready
2024-06-11T11:05:59.091853126Z I0611 11:05:59.091781       1 request.go:697] Waited for 1.195372315s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:05:59.604657928Z I0611 11:05:59.604578       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:06:01.894291206Z I0611 11:06:01.894210       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:06:02.696972349Z I0611 11:06:02.696888       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-2 with revision 5 is the oldest and needs new revision 7
2024-06-11T11:06:02.696972349Z I0611 11:06:02.696956       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:06:02.696972349Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:06:02.696972349Z  CurrentRevision: (int32) 5,
2024-06-11T11:06:02.696972349Z  TargetRevision: (int32) 7,
2024-06-11T11:06:02.696972349Z  LastFailedRevision: (int32) 0,
2024-06-11T11:06:02.696972349Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:06:02.696972349Z  LastFailedReason: (string) "",
2024-06-11T11:06:02.696972349Z  LastFailedCount: (int) 0,
2024-06-11T11:06:02.696972349Z  LastFallbackCount: (int) 0,
2024-06-11T11:06:02.696972349Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:06:02.696972349Z }
2024-06-11T11:06:02.720825046Z I0611 11:06:02.720755       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-2" from revision 5 to 7 because node ci-op-9xx71rvq-1e28e-w667k-master-2 with revision 5 is the oldest
2024-06-11T11:06:02.724408411Z I0611 11:06:02.724349       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:06:02.793551893Z I0611 11:06:02.793484       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 0.03 %, dbSize: 84525056
2024-06-11T11:06:02.793551893Z I0611 11:06:02.793511       1 defragcontroller.go:300] etcd member "etcd-bootstrap" backend store fragmented: 0.01 %, dbSize: 85041152
2024-06-11T11:06:03.891998668Z I0611 11:06:03.891868       1 request.go:697] Waited for 1.163125051s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:04.909587752Z I0611 11:06:04.909510       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-etcd because it was missing
2024-06-11T11:06:05.896787034Z I0611 11:06:05.896716       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:06:06.092042049Z I0611 11:06:06.091977       1 request.go:697] Waited for 1.178816429s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:06:07.092477141Z I0611 11:06:07.092384       1 request.go:697] Waited for 1.364293092s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts?resourceVersion=23537
2024-06-11T11:06:07.094690343Z I0611 11:06:07.094641       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:06:08.291747114Z I0611 11:06:08.291676       1 request.go:697] Waited for 1.196301436s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T11:06:08.495861139Z I0611 11:06:08.495782       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:06:09.292196207Z I0611 11:06:09.292114       1 request.go:697] Waited for 1.196029024s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-06-11T11:06:10.495985889Z I0611 11:06:10.495898       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:06:22.204167969Z W0611 11:06:22.204008       1 bootstrap_teardown_controller.go:144] Removing bootstrap member [a48f107742a8605c]
2024-06-11T11:06:22.231784136Z I0611 11:06:22.231726       1 bootstrap_teardown_controller.go:151] Successfully removed bootstrap member [a48f107742a8605c]
2024-06-11T11:06:22.232574772Z I0611 11:06:22.232514       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'MemberRemove' removed member with ID: 11857714448295288924
2024-06-11T11:06:32.586846866Z I0611 11:06:32.586772       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:06:32.599748348Z I0611 11:06:32.599687       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:06:32.625605513Z I0611 11:06:32.625475       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:06:33.787609979Z I0611 11:06:33.787542       1 request.go:697] Waited for 1.15699324s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:06:34.596286423Z I0611 11:06:34.596226       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:06:35.386574678Z I0611 11:06:35.386495       1 request.go:697] Waited for 1.015899823s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:06:37.437819051Z E0611 11:06:37.437742       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp 172.30.142.45:9091: connect: connection refused
2024-06-11T11:06:39.786443657Z I0611 11:06:39.786355       1 request.go:697] Waited for 1.194200344s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:06:40.786772609Z I0611 11:06:40.786660       1 request.go:697] Waited for 1.39481554s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:41.787247768Z I0611 11:06:41.787163       1 request.go:697] Waited for 1.395190957s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:06:41.991516327Z I0611 11:06:41.991444       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 5
2024-06-11T11:06:42.787421813Z I0611 11:06:42.787358       1 request.go:697] Waited for 1.196137432s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T11:06:44.992731668Z I0611 11:06:44.992665       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 5
2024-06-11T11:06:47.627223887Z E0611 11:06:47.627166       1 base_controller.go:268] DefragController reconciliation failed: failed to dial endpoint https://10.0.0.5:2379 with maintenance client: context deadline exceeded
2024-06-11T11:06:51.679604734Z I0611 11:06:51.679523       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 5
2024-06-11T11:06:53.634802894Z W0611 11:06:53.634735       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:07:02.689727354Z E0611 11:07:02.689659       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:02.689976765Z E0611 11:07:02.689945       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:02.700658246Z E0611 11:07:02.700602       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:02.741445985Z E0611 11:07:02.741363       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:02.822684447Z E0611 11:07:02.822607       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:02.983670804Z E0611 11:07:02.983614       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:03.304595671Z E0611 11:07:03.304533       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:03.945876878Z E0611 11:07:03.945813       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:05.227710561Z E0611 11:07:05.227636       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:07.788513334Z E0611 11:07:07.788443       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:08.670446344Z W0611 11:07:08.670383       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:07:12.909969265Z E0611 11:07:12.909882       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:18.199147599Z I0611 11:07:18.199084       1 request.go:697] Waited for 1.040820627s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T11:07:19.199353826Z I0611 11:07:19.199252       1 request.go:697] Waited for 1.148481598s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:07:20.199630856Z I0611 11:07:20.199550       1 request.go:697] Waited for 1.19299497s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:20.206439057Z I0611 11:07:20.206378       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:07:21.202379095Z I0611 11:07:21.199609       1 request.go:697] Waited for 1.195570784s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:07:22.199705394Z I0611 11:07:22.199638       1 request.go:697] Waited for 1.109101952s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:07:23.151060656Z E0611 11:07:23.150999       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:23.611779153Z I0611 11:07:23.611718       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:07:23.719655959Z W0611 11:07:23.719593       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:07:25.607877228Z I0611 11:07:25.607798       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:07:37.432970944Z E0611 11:07:37.432894       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-9xx71rvq-1e28e-w667k-master-2, took=, err=create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded
2024-06-11T11:07:37.437995672Z E0611 11:07:37.437915       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp 172.30.142.45:9091: connect: connection refused
2024-06-11T11:07:37.465906136Z I0611 11:07:37.465845       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:07:37.466109545Z I0611 11:07:37.466051       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 7\nEtcdMembersAvailable: 4 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:07:37.467206795Z E0611 11:07:37.467146       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:37.485029402Z I0611 11:07:37.484924       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy"
2024-06-11T11:07:37.492144224Z I0611 11:07:37.492091       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:07:37.492701949Z I0611 11:07:37.492627       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:49:09Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 2 nodes are at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 7\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:07:37.493451983Z E0611 11:07:37.493406       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:37.508145648Z I0611 11:07:37.507964       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 7\nEtcdMembersAvailable: 4 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 7\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy"
2024-06-11T11:07:38.564173261Z I0611 11:07:38.564111       1 request.go:697] Waited for 1.096165031s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:38.758849976Z W0611 11:07:38.758778       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:07:39.564197887Z I0611 11:07:39.564120       1 request.go:697] Waited for 1.39568654s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:07:40.763748168Z I0611 11:07:40.763687       1 request.go:697] Waited for 1.59491043s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:07:41.764150621Z I0611 11:07:41.764090       1 request.go:697] Waited for 1.38753011s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:41.968335376Z I0611 11:07:41.968248       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:07:43.632084570Z E0611 11:07:43.632016       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:44.168762132Z I0611 11:07:44.168687       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:07:46.771154310Z I0611 11:07:46.771081       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:07:48.364540720Z I0611 11:07:48.364438       1 request.go:697] Waited for 1.09470559s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T11:07:49.563941509Z I0611 11:07:49.563881       1 request.go:697] Waited for 1.194491773s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T11:07:50.169538812Z I0611 11:07:50.169451       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:07:50.169538812Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:07:50.169538812Z  CurrentRevision: (int32) 7,
2024-06-11T11:07:50.169538812Z  TargetRevision: (int32) 0,
2024-06-11T11:07:50.169538812Z  LastFailedRevision: (int32) 0,
2024-06-11T11:07:50.169538812Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:07:50.169538812Z  LastFailedReason: (string) "",
2024-06-11T11:07:50.169538812Z  LastFailedCount: (int) 0,
2024-06-11T11:07:50.169538812Z  LastFallbackCount: (int) 0,
2024-06-11T11:07:50.169538812Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:07:50.169538812Z }
2024-06-11T11:07:50.169538812Z  because static pod is ready
2024-06-11T11:07:50.193948585Z I0611 11:07:50.193881       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-2" from revision 5 to 7 because static pod is ready
2024-06-11T11:07:50.194794822Z I0611 11:07:50.194744       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:07:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 7\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:07:50.195846968Z E0611 11:07:50.195795       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:50.196021676Z E0611 11:07:50.195981       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.204508648Z E0611 11:07:50.204428       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.214997209Z E0611 11:07:50.214948       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.230596594Z I0611 11:07:50.230515       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 7\nEtcdMembersProgressing: No unstarted etcd members found"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 2 nodes are at revision 7\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy"
2024-06-11T11:07:50.242380412Z E0611 11:07:50.242333       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.273056960Z E0611 11:07:50.272989       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.274058404Z E0611 11:07:50.274002       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.274454721Z E0611 11:07:50.274426       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:07:50.274652430Z I0611 11:07:50.274487       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:\"ci-op-9xx71rvq-1e28e-w667k-master-0\" peerURLs:\"https://10.0.0.8:2380\" clientURLs:\"https://10.0.0.8:2379\"  Healthy:true Took:2.898834ms Error:\u003cnil\u003e} {Member:ID:9039689361178516505 name:\"ci-op-9xx71rvq-1e28e-w667k-master-1\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:1.997092ms Error:\u003cnil\u003e} {Member:ID:11862787134384716550 name:\"ci-op-9xx71rvq-1e28e-w667k-master-2\" peerURLs:\"https://10.0.0.7:2380\" clientURLs:\"https://10.0.0.7:2379\"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:07:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 7\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:07:50.283062299Z E0611 11:07:50.283004       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.288793951Z E0611 11:07:50.288696       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.290986747Z I0611 11:07:50.290071       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy" to "NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:\"ci-op-9xx71rvq-1e28e-w667k-master-0\" peerURLs:\"https://10.0.0.8:2380\" clientURLs:\"https://10.0.0.8:2379\"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:\"ci-op-9xx71rvq-1e28e-w667k-master-1\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:\"ci-op-9xx71rvq-1e28e-w667k-master-2\" peerURLs:\"https://10.0.0.7:2380\" clientURLs:\"https://10.0.0.7:2379\"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy"
2024-06-11T11:07:50.312812206Z E0611 11:07:50.312734       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.327009330Z E0611 11:07:50.326944       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.344149783Z E0611 11:07:50.344092       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.433142792Z E0611 11:07:50.433066       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.444184077Z E0611 11:07:50.444132       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.607629157Z E0611 11:07:50.607553       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.765044372Z E0611 11:07:50.764962       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:50.936771816Z E0611 11:07:50.936711       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:51.364816220Z I0611 11:07:51.363840       1 request.go:697] Waited for 1.169326168s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T11:07:51.406817165Z E0611 11:07:51.406747       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:51.592890739Z E0611 11:07:51.592824       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:51.970127510Z E0611 11:07:51.970049       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:51.972399510Z E0611 11:07:51.972346       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:51.977846549Z E0611 11:07:51.977789       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:51.978362872Z E0611 11:07:51.978291       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:51.989100744Z E0611 11:07:51.989052       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:51.997103195Z E0611 11:07:51.997049       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:52.009826354Z E0611 11:07:52.009765       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:52.018591039Z E0611 11:07:52.018543       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:52.051381980Z E0611 11:07:52.051332       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:52.060126564Z E0611 11:07:52.059976       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:52.132904661Z E0611 11:07:52.132829       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:52.140634101Z E0611 11:07:52.140575       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:52.294709069Z E0611 11:07:52.294649       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:52.301108650Z E0611 11:07:52.301051       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:52.564667828Z I0611 11:07:52.564590       1 request.go:697] Waited for 1.595385984s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:07:52.615605366Z E0611 11:07:52.615531       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:52.622225056Z E0611 11:07:52.622179       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:52.687654731Z E0611 11:07:52.687568       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:52.883889051Z E0611 11:07:52.883819       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:53.256788732Z E0611 11:07:53.256721       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:53.263502027Z E0611 11:07:53.263445       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:53.380690875Z I0611 11:07:53.380615       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-etcd because it was missing
2024-06-11T11:07:53.763662999Z I0611 11:07:53.763587       1 request.go:697] Waited for 1.395735013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:54.538049517Z E0611 11:07:54.537987       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:54.544771612Z E0611 11:07:54.544717       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:54.763808734Z I0611 11:07:54.763745       1 request.go:697] Waited for 1.382747943s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:07:55.252460933Z E0611 11:07:55.252381       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:55.453462652Z E0611 11:07:55.453401       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:55.964003646Z I0611 11:07:55.963874       1 request.go:697] Waited for 1.196837568s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods
2024-06-11T11:07:55.975258821Z I0611 11:07:55.975185       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-etcd because it was missing
2024-06-11T11:07:56.964518829Z I0611 11:07:56.964454       1 request.go:697] Waited for 1.193856715s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:07:57.099545034Z E0611 11:07:57.099458       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:57.106140095Z E0611 11:07:57.106095       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:58.164163686Z I0611 11:07:58.164089       1 request.go:697] Waited for 1.192621185s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:07:58.377665464Z I0611 11:07:58.377587       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-etcd because it was missing
2024-06-11T11:07:59.164572911Z I0611 11:07:59.164500       1 request.go:697] Waited for 1.19482548s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:07:59.575008148Z E0611 11:07:59.574922       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.575157455Z E0611 11:07:59.575113       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.591710998Z E0611 11:07:59.591642       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.614073903Z E0611 11:07:59.613993       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.616017690Z E0611 11:07:59.614755       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.616760824Z E0611 11:07:59.616726       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.618711211Z E0611 11:07:59.618443       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.619046926Z E0611 11:07:59.619003       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.619839862Z E0611 11:07:59.619801       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.621034516Z E0611 11:07:59.620933       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.622081163Z E0611 11:07:59.622022       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.623918745Z E0611 11:07:59.623869       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.624081653Z E0611 11:07:59.623909       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.635164950Z E0611 11:07:59.635100       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.635269355Z E0611 11:07:59.635233       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.637540257Z E0611 11:07:59.637423       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:07:59.648454247Z E0611 11:07:59.648408       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.364515413Z I0611 11:08:00.364425       1 request.go:697] Waited for 1.195031881s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:08:00.373250405Z E0611 11:08:00.373056       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.593720609Z E0611 11:08:00.592978       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.775197161Z E0611 11:08:00.775128       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.775927993Z E0611 11:08:00.775866       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.787798127Z E0611 11:08:00.787741       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.787923432Z E0611 11:08:00.787771       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.795082154Z E0611 11:08:00.794042       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.795082154Z E0611 11:08:00.794656       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.795082154Z E0611 11:08:00.794716       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.796675825Z E0611 11:08:00.796636       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.797767374Z E0611 11:08:00.797715       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.798904926Z E0611 11:08:00.798771       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.801460240Z E0611 11:08:00.801395       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.802688196Z E0611 11:08:00.802639       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.803209919Z E0611 11:08:00.803165       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.813982403Z E0611 11:08:00.813943       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:00.823339623Z E0611 11:08:00.823265       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:02.221472627Z E0611 11:08:02.221233       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:02.227665905Z E0611 11:08:02.227600       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:08:37.439125649Z E0611 11:08:37.439056       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp 172.30.142.45:9091: connect: connection refused
2024-06-11T11:08:37.461648121Z I0611 11:08:37.461581       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:\"ci-op-9xx71rvq-1e28e-w667k-master-0\" peerURLs:\"https://10.0.0.8:2380\" clientURLs:\"https://10.0.0.8:2379\"  Healthy:true Took:2.898834ms Error:\u003cnil\u003e} {Member:ID:9039689361178516505 name:\"ci-op-9xx71rvq-1e28e-w667k-master-1\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:1.997092ms Error:\u003cnil\u003e} {Member:ID:11862787134384716550 name:\"ci-op-9xx71rvq-1e28e-w667k-master-2\" peerURLs:\"https://10.0.0.7:2380\" clientURLs:\"https://10.0.0.7:2379\"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:07:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 7\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:08:37.478836208Z I0611 11:08:37.478752       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:\"ci-op-9xx71rvq-1e28e-w667k-master-0\" peerURLs:\"https://10.0.0.8:2380\" clientURLs:\"https://10.0.0.8:2379\"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:\"ci-op-9xx71rvq-1e28e-w667k-master-1\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:\"ci-op-9xx71rvq-1e28e-w667k-master-2\" peerURLs:\"https://10.0.0.7:2380\" clientURLs:\"https://10.0.0.7:2379\"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy" to "NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:\"ci-op-9xx71rvq-1e28e-w667k-master-0\" peerURLs:\"https://10.0.0.8:2380\" clientURLs:\"https://10.0.0.8:2379\"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:\"ci-op-9xx71rvq-1e28e-w667k-master-1\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:\"ci-op-9xx71rvq-1e28e-w667k-master-2\" peerURLs:\"https://10.0.0.7:2380\" clientURLs:\"https://10.0.0.7:2379\"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]\nEtcdMembersDegraded: No unhealthy members found"
2024-06-11T11:08:37.490978541Z I0611 11:08:37.490901       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:\"ci-op-9xx71rvq-1e28e-w667k-master-0\" peerURLs:\"https://10.0.0.8:2380\" clientURLs:\"https://10.0.0.8:2379\"  Healthy:true Took:2.898834ms Error:\u003cnil\u003e} {Member:ID:9039689361178516505 name:\"ci-op-9xx71rvq-1e28e-w667k-master-1\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:1.997092ms Error:\u003cnil\u003e} {Member:ID:11862787134384716550 name:\"ci-op-9xx71rvq-1e28e-w667k-master-2\" peerURLs:\"https://10.0.0.7:2380\" clientURLs:\"https://10.0.0.7:2379\"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:07:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 7\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:08:37.511494894Z I0611 11:08:37.511414       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7\nEtcdMembersAvailable: 3 members are available"
2024-06-11T11:08:37.512121062Z W0611 11:08:37.512058       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.7:2379 https://10.0.0.8:2379]] vs. [[https://10.0.0.6:2379 https://10.0.0.7:2379 https://10.0.0.8:2379]]
2024-06-11T11:08:37.513251687Z I0611 11:08:37.513211       1 core.go:359] ConfigMap "openshift-etcd/etcd-endpoints" changes: {"metadata":{"annotations":{"alpha.installer.openshift.io/etcd-bootstrap":null,"alpha.installer.openshift.io/etcd-bootstrap-":"10.0.0.5"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T11:08:37.513996468Z W0611 11:08:37.513953       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.7:2379 https://10.0.0.8:2379]] vs. [[https://10.0.0.6:2379 https://10.0.0.7:2379 https://10.0.0.8:2379]]
2024-06-11T11:08:37.514428316Z I0611 11:08:37.514372       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-endpoints -n openshift-etcd:
2024-06-11T11:08:37.524227891Z W0611 11:08:37.524175       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.7:2379 https://10.0.0.8:2379]] vs. [[https://10.0.0.6:2379 https://10.0.0.7:2379 https://10.0.0.8:2379]]
2024-06-11T11:08:37.539010014Z I0611 11:08:37.538959       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 27.23 %, dbSize: 89227264
2024-06-11T11:08:37.539010014Z I0611 11:08:37.538985       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 26.93 %, dbSize: 88952832
2024-06-11T11:08:37.539010014Z I0611 11:08:37.538994       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 26.69 %, dbSize: 88678400
2024-06-11T11:08:37.544384104Z W0611 11:08:37.542910       1 etcdcli_pool.go:87] cached client detected change in endpoints [[https://10.0.0.5:2379 https://10.0.0.6:2379 https://10.0.0.7:2379 https://10.0.0.8:2379]] vs. [[https://10.0.0.6:2379 https://10.0.0.7:2379 https://10.0.0.8:2379]]
2024-06-11T11:08:37.546138997Z I0611 11:08:37.546075       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:07:50Z","message":"NodeInstallerProgressing: 3 nodes are at revision 7\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:08:37.567383329Z I0611 11:08:37.563358       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:\"ci-op-9xx71rvq-1e28e-w667k-master-0\" peerURLs:\"https://10.0.0.8:2380\" clientURLs:\"https://10.0.0.8:2379\"  Healthy:true Took:2.898834ms Error:<nil>} {Member:ID:9039689361178516505 name:\"ci-op-9xx71rvq-1e28e-w667k-master-1\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:1.997092ms Error:<nil>} {Member:ID:11862787134384716550 name:\"ci-op-9xx71rvq-1e28e-w667k-master-2\" peerURLs:\"https://10.0.0.7:2380\" clientURLs:\"https://10.0.0.7:2379\"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found"
2024-06-11T11:08:37.588124406Z I0611 11:08:37.588059       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 27.16 %, dbSize: 89227264
2024-06-11T11:08:37.588124406Z I0611 11:08:37.588089       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 26.93 %, dbSize: 88952832
2024-06-11T11:08:37.588124406Z I0611 11:08:37.588098       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 26.62 %, dbSize: 88678400
2024-06-11T11:08:37.627920475Z I0611 11:08:37.627858       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 27.16 %, dbSize: 89227264
2024-06-11T11:08:37.627920475Z I0611 11:08:37.627883       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 26.88 %, dbSize: 88952832
2024-06-11T11:08:37.627920475Z I0611 11:08:37.627889       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 26.62 %, dbSize: 88678400
2024-06-11T11:08:38.661456038Z I0611 11:08:38.661391       1 request.go:697] Waited for 1.170412689s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:08:39.661479723Z I0611 11:08:39.661404       1 request.go:697] Waited for 1.39422526s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T11:08:40.661552312Z I0611 11:08:40.661467       1 request.go:697] Waited for 1.530956271s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:08:41.678205522Z I0611 11:08:41.678120       1 core.go:359] ConfigMap "openshift-etcd/etcd-scripts" changes: {"apiVersion":"v1","data":{"etcd.env":"export ALL_ETCD_ENDPOINTS=\"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\nexport ETCDCTL_API=\"3\"\nexport ETCDCTL_CACERT=\"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\nexport ETCDCTL_CERT=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\nexport ETCDCTL_ENDPOINTS=\"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\nexport ETCDCTL_KEY=\"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\nexport ETCD_CIPHER_SUITES=\"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\nexport ETCD_DATA_DIR=\"/var/lib/etcd\"\nexport ETCD_ELECTION_TIMEOUT=\"2500\"\nexport ETCD_ENABLE_PPROF=\"true\"\nexport ETCD_EXPERIMENTAL_MAX_LEARNERS=\"3\"\nexport ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION=\"200ms\"\nexport ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL=\"5s\"\nexport ETCD_HEARTBEAT_INTERVAL=\"500\"\nexport ETCD_IMAGE=\"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\nexport ETCD_INITIAL_CLUSTER_STATE=\"existing\"\nexport ETCD_QUOTA_BACKEND_BYTES=\"8589934592\"\nexport ETCD_SOCKET_REUSE_ADDRESS=\"true\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME=\"ci-op-9xx71rvq-1e28e-w667k-master-0\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST=\"10.0.0.8\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP=\"10.0.0.8\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME=\"ci-op-9xx71rvq-1e28e-w667k-master-1\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST=\"10.0.0.6\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP=\"10.0.0.6\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME=\"ci-op-9xx71rvq-1e28e-w667k-master-2\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST=\"10.0.0.7\"\nexport NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP=\"10.0.0.7\"\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T11:08:41.678533758Z I0611 11:08:41.678476       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-scripts -n openshift-etcd:
2024-06-11T11:08:41.678533758Z cause by changes in data.etcd.env
2024-06-11T11:08:41.861660962Z I0611 11:08:41.861604       1 request.go:697] Waited for 1.383916929s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T11:08:42.472764950Z I0611 11:08:42.472631       1 core.go:359] ConfigMap "openshift-etcd/etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  annotations:\n    kubectl.kubernetes.io/default-container: etcd\n    target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}'\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  initContainers:\n    - name: setup\n      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          echo -n \"Fixing etcd log permissions.\"\n          mkdir -p /var/log/etcd \u0026\u0026 chmod 0700 /var/log/etcd\n      securityContext:\n        privileged: true\n      resources:\n        requests:\n          memory: 50Mi\n          cpu: 5m\n      volumeMounts:\n        - mountPath: /var/log/etcd\n          name: log-dir\n    - name: etcd-ensure-env-vars\n      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_ETCD_NAME?not set}\"\n          : \"${NODE_NODE_ENVVAR_NAME_IP?not set}\"\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_IP}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected node IP to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_IP}\" \u003e\u00262\n            exit 1\n          fi\n\n          # check for ipv4 addresses as well as ipv6 addresses with extra square brackets\n          if [[ \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"${NODE_IP}\" \u0026\u0026 \"${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" != \"[${NODE_IP}]\" ]]; then\n            # echo the error message to stderr\n            echo \"Expected etcd url host to be ${NODE_IP} got ${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}\" \u003e\u00262\n            exit 1\n          fi\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: NODE_IP\n        valueFrom:\n          fieldRef:\n            fieldPath: status.podIP\n    - name: etcd-resources-copy\n      image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n      imagePullPolicy: IfNotPresent\n      terminationMessagePolicy: FallbackToLogsOnError\n      command:\n        - /bin/sh\n        - -c\n        - |\n          #!/bin/sh\n          set -euo pipefail\n\n          rm -f $(grep -l '^### Created by cluster-etcd-operator' /usr/local/bin/*)\n          cp -p /etc/kubernetes/static-pod-certs/configmaps/etcd-scripts/*.sh /usr/local/bin\n\n      resources:\n        requests:\n          memory: 60Mi\n          cpu: 10m\n      securityContext:\n        privileged: true\n      volumeMounts:\n        - mountPath: /etc/kubernetes/static-pod-resources\n          name: resource-dir\n        - mountPath: /etc/kubernetes/static-pod-certs\n          name: cert-dir\n        - mountPath: /usr/local/bin\n          name: usr-local-bin\n  containers:\n  # The etcdctl container should always be first. It is intended to be used\n  # to open a remote shell via `oc rsh` that is ready to run `etcdctl`.\n  - name: etcdctl\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - \"/bin/bash\"\n      - \"-c\"\n      - \"trap TERM INT; sleep infinity \u0026 wait\"\n    resources:\n      requests:\n        memory: 60Mi\n        cpu: 10m\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_VERSION\"\n        value: \"REVISION\"\n  - name: etcd\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        etcdctl member list || true\n\n        # this has a non-zero return code if the command is non-zero.  If you use an export first, it doesn't and you\n        # will succeed when you should fail.\n        ETCD_INITIAL_CLUSTER=$(discover-etcd-initial-cluster \\\n          --cacert=/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt \\\n          --cert=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --key=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --endpoints=${ALL_ETCD_ENDPOINTS} \\\n          --data-dir=/var/lib/etcd \\\n          --target-peer-url-host=${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST} \\\n          --target-name=NODE_NAME)\n        export ETCD_INITIAL_CLUSTER\n\n        # we cannot use the \"normal\" port conflict initcontainer because when we upgrade, the existing static pod will never yield,\n        # so we do the detection in etcd container itself.\n        echo -n \"Waiting for ports 2379, 2380 and 9978 to be released.\"\n        time while [ -n \"$(ss -Htan '( sport = 2379 or sport = 2380 or sport = 9978 )')\" ]; do\n          echo -n \".\"\n          sleep 1\n        done\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        env | grep ETCD | grep -v NODE\n\n        set -x\n        # See https://etcd.io/docs/v3.4.0/tuning/ for why we use ionice\n        exec nice -n -19 ionice -c2 -n0 etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --experimental-initial-corrupt-check=true \\\n          --snapshot-count=10000 \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-peer-client-ca/ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379,unixs://${NODE_NODE_ENVVAR_NAME_IP}:0 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978 ||  mv /etc/kubernetes/etcd-backup-dir/etcd-member.yaml /etc/kubernetes/manifests\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_VERSION\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      timeoutSeconds: 30\n      failureThreshold: 5\n      periodSeconds: 5\n      successThreshold: 1\n    livenessProbe:\n      httpGet:\n        path: healthz\n        port: 9980\n        scheme: HTTPS\n      timeoutSeconds: 30\n      periodSeconds: 5\n      successThreshold: 1\n      failureThreshold: 5\n    startupProbe:\n      httpGet:\n        port: 9980\n        path: readyz\n        scheme: HTTPS\n      initialDelaySeconds: 10\n      timeoutSeconds: 1\n      periodSeconds: 10\n      successThreshold: 1\n      failureThreshold: 18\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-metrics\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n\n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n\n        exec nice -n -18 etcd grpc-proxy start \\\n          --endpoints https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:9978 \\\n          --metrics-addr https://0.0.0.0:9979 \\\n          --listen-addr 127.0.0.1:9977 \\\n          --advertise-client-url \"\"  \\\n          --key /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --key-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.key \\\n          --cert /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --cert-file /etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-metrics-NODE_NAME.crt \\\n          --cacert /etc/kubernetes/static-pod-certs/configmaps/etcd-peer-client-ca/ca-bundle.crt \\\n          --trusted-ca-file /etc/kubernetes/static-pod-certs/configmaps/etcd-metrics-proxy-serving-ca/ca-bundle.crt \\\n          --listen-cipher-suites TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_AES_128_GCM_SHA256,TLS_AES_256_GCM_SHA384,TLS_CHACHA20_POLY1305_SHA256\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_VERSION\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 200Mi\n        cpu: 40m\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/static-pod-resources\n        name: resource-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n  - name: etcd-readyz\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:5c7cd88272ec1d0a6e1a9814448acb1744650cc1315124b44a8e7b6e711e96ed\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        exec nice -n -18 cluster-etcd-operator readyz \\\n          --target=https://localhost:2379 \\\n          --listen-port=9980 \\\n          --serving-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --serving-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --client-cert-file=$(ETCDCTL_CERT) \\\n          --client-key-file=$(ETCDCTL_KEY) \\\n          --client-cacert-file=$(ETCDCTL_CACERT)\n    securityContext:\n      privileged: true\n    ports:\n    - containerPort: 9980\n      name: readyz\n      protocol: TCP\n    resources:\n      requests:\n        memory: 50Mi\n        cpu: 10m\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n    volumeMounts:\n      - mountPath: /var/log/etcd/\n        name: log-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-pod-REVISION\n      name: resource-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /usr/local/bin\n      name: usr-local-bin\n    - hostPath:\n        path: /var/log/etcd\n      name: log-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T11:08:42.472989475Z I0611 11:08:42.472939       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/etcd-pod -n openshift-etcd:
2024-06-11T11:08:42.472989475Z cause by changes in data.pod.yaml
2024-06-11T11:08:42.482540224Z I0611 11:08:42.482477       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 8 triggered by "required configmap/etcd-pod has changed"
2024-06-11T11:08:43.060730898Z I0611 11:08:43.060646       1 request.go:697] Waited for 1.194803167s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-06-11T11:08:44.473232243Z I0611 11:08:44.473123       1 core.go:359] ConfigMap "openshift-etcd/restore-etcd-pod" changes: {"apiVersion":"v1","data":{"pod.yaml":"apiVersion: v1\nkind: Pod\nmetadata:\n  name: etcd\n  namespace: openshift-etcd\n  labels:\n    app: etcd\n    k8s-app: etcd\n    etcd: \"true\"\n    revision: \"REVISION\"\nspec:\n  containers:\n  - name: etcd\n    image: quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\n    imagePullPolicy: IfNotPresent\n    terminationMessagePolicy: FallbackToLogsOnError\n    command:\n      - /bin/sh\n      - -c\n      - |\n        #!/bin/sh\n        set -euo pipefail\n        \n        # this can be controlled by cluster-restore.sh, which will replace this line entirely when enabled at runtime\n        export ETCD_ETCDCTL_RESTORE_ENABLE_BUMP=\"false\"\n        \n        export ETCD_NAME=${NODE_NODE_ENVVAR_NAME_ETCD_NAME}\n        export ETCD_INITIAL_CLUSTER=\"${ETCD_NAME}=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\"\n        env | grep ETCD | grep -v NODE\n        export ETCD_NODE_PEER_URL=https://${NODE_NODE_ENVVAR_NAME_ETCD_URL_HOST}:2380\n\n        # checking if there are any fio perf file left behind that could be deleted without problems\n        if [ ! -z $(ls -A \"/var/lib/etcd/etcd_perf*\") ]; then\n          rm -f /var/lib/etcd/etcd_perf*\n        fi\n\n        # checking if data directory is empty, if not etcdctl restore will fail\n        if [ ! -z $(ls -A \"/var/lib/etcd\") ]; then\n          echo \"please delete the contents of data directory before restoring, running the restore script will do this for you\"\n          exit 1\n        fi\n        \n        ETCD_ETCDCTL_BIN=\"etcdctl\"\n        if [ -x \"$(command -v etcdutl)\" ]; then\n          echo \"found newer etcdutl, using that instead of etcdctl\"\n          ETCD_ETCDCTL_BIN=\"etcdutl\"\n        fi      \n\n        # check if we have backup file to be restored\n        # if the file exist, check if it has not changed size in last 5 seconds\n        if [ ! -f /var/lib/etcd-backup/snapshot.db ]; then\n          echo \"please make a copy of the snapshot db file, then move that copy to /var/lib/etcd-backup/snapshot.db\"\n          exit 1\n        else\n          filesize=$(stat --format=%s \"/var/lib/etcd-backup/snapshot.db\")\n          sleep 5\n          newfilesize=$(stat --format=%s \"/var/lib/etcd-backup/snapshot.db\")\n          if [ \"$filesize\" != \"$newfilesize\" ]; then\n            echo \"file size has changed since last 5 seconds, retry sometime after copying is complete\"\n            exit 1\n          fi\n        fi\n        \n        BUMP_ARGS=\"\"\n        if [[ \"${ETCD_ETCDCTL_RESTORE_ENABLE_BUMP}\" == \"true\" ]]; then\n          echo \"enabling restore bump\"\n          BUMP_ARGS=\"--bump-revision 1000000000 --mark-compacted\"\n        fi\n                \n        UUID=$(uuidgen)\n        echo \"restoring to a single node cluster\"\n        ${ETCD_ETCDCTL_BIN} snapshot restore /var/lib/etcd-backup/snapshot.db \\\n         --name  $ETCD_NAME \\\n         --initial-cluster=$ETCD_INITIAL_CLUSTER \\\n         --initial-cluster-token \"openshift-etcd-${UUID}\" \\\n         --initial-advertise-peer-urls $ETCD_NODE_PEER_URL \\\n         --data-dir=\"/var/lib/etcd/restore-${UUID}\" \\\n         ${BUMP_ARGS}\n\n        mv /var/lib/etcd/restore-${UUID}/* /var/lib/etcd/\n\n        rmdir /var/lib/etcd/restore-${UUID}\n        rm /var/lib/etcd-backup/snapshot.db\n\n        set -x\n        exec etcd \\\n          --logger=zap \\\n          --log-level=info \\\n          --initial-advertise-peer-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2380 \\\n          --cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.crt \\\n          --key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-serving-NODE_NAME.key \\\n          --trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt \\\n          --client-cert-auth=true \\\n          --peer-cert-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt \\\n          --peer-key-file=/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key \\\n          --peer-trusted-ca-file=/etc/kubernetes/static-pod-certs/configmaps/etcd-peer-client-ca/ca-bundle.crt \\\n          --peer-client-cert-auth=true \\\n          --advertise-client-urls=https://${NODE_NODE_ENVVAR_NAME_IP}:2379 \\\n          --listen-client-urls=https://0.0.0.0:2379 \\\n          --listen-peer-urls=https://0.0.0.0:2380 \\\n          --metrics=extensive \\\n          --listen-metrics-urls=https://0.0.0.0:9978\n    env:\n      - name: \"ALL_ETCD_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_API\"\n        value: \"3\"\n      - name: \"ETCDCTL_CACERT\"\n        value: \"/etc/kubernetes/static-pod-certs/configmaps/etcd-serving-ca/ca-bundle.crt\"\n      - name: \"ETCDCTL_CERT\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.crt\"\n      - name: \"ETCDCTL_ENDPOINTS\"\n        value: \"https://10.0.0.6:2379,https://10.0.0.7:2379,https://10.0.0.8:2379\"\n      - name: \"ETCDCTL_KEY\"\n        value: \"/etc/kubernetes/static-pod-certs/secrets/etcd-all-certs/etcd-peer-NODE_NAME.key\"\n      - name: \"ETCD_CIPHER_SUITES\"\n        value: \"TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\"\n      - name: \"ETCD_DATA_DIR\"\n        value: \"/var/lib/etcd\"\n      - name: \"ETCD_ELECTION_TIMEOUT\"\n        value: \"2500\"\n      - name: \"ETCD_ENABLE_PPROF\"\n        value: \"true\"\n      - name: \"ETCD_EXPERIMENTAL_MAX_LEARNERS\"\n        value: \"3\"\n      - name: \"ETCD_EXPERIMENTAL_WARNING_APPLY_DURATION\"\n        value: \"200ms\"\n      - name: \"ETCD_EXPERIMENTAL_WATCH_PROGRESS_NOTIFY_INTERVAL\"\n        value: \"5s\"\n      - name: \"ETCD_HEARTBEAT_INTERVAL\"\n        value: \"500\"\n      - name: \"ETCD_IMAGE\"\n        value: \"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:4b0f7d2fbb9eebff4bb5c5ba2b23583f78902bc0fa9917566ebc86a6a2ee6b99\"\n      - name: \"ETCD_INITIAL_CLUSTER_STATE\"\n        value: \"existing\"\n      - name: \"ETCD_QUOTA_BACKEND_BYTES\"\n        value: \"8589934592\"\n      - name: \"ETCD_SOCKET_REUSE_ADDRESS\"\n        value: \"true\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-0\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_ETCD_URL_HOST\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_0_IP\"\n        value: \"10.0.0.8\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-1\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_ETCD_URL_HOST\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_1_IP\"\n        value: \"10.0.0.6\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_NAME\"\n        value: \"ci-op-9xx71rvq-1e28e-w667k-master-2\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_ETCD_URL_HOST\"\n        value: \"10.0.0.7\"\n      - name: \"NODE_ci_op_9xx71rvq_1e28e_w667k_master_2_IP\"\n        value: \"10.0.0.7\"\n      - name: \"ETCD_STATIC_POD_REV\"\n        value: \"REVISION\"\n    resources:\n      requests:\n        memory: 600Mi\n        cpu: 300m\n    readinessProbe:\n      tcpSocket:\n        port: 2380\n      failureThreshold: 3\n      initialDelaySeconds: 3\n      periodSeconds: 5\n      successThreshold: 1\n      timeoutSeconds: 5\n    securityContext:\n      privileged: true\n    volumeMounts:\n      - mountPath: /etc/kubernetes/manifests\n        name: static-pod-dir\n      - mountPath: /etc/kubernetes/static-pod-certs\n        name: cert-dir\n      - mountPath: /var/lib/etcd/\n        name: data-dir\n      - mountPath: /var/lib/etcd-backup/\n        name: backup-dir\n  hostNetwork: true\n  priorityClassName: system-node-critical\n  tolerations:\n  - operator: \"Exists\"\n  volumes:\n    - hostPath:\n        path: /etc/kubernetes/manifests\n      name: static-pod-dir\n    - hostPath:\n        path: /etc/kubernetes/static-pod-resources/etcd-certs\n      name: cert-dir\n    - hostPath:\n        path: /var/lib/etcd\n        type: \"\"\n      name: data-dir\n    - hostPath:\n        path: /var/lib/etcd-backup\n        type: \"\"\n      name: backup-dir\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T11:08:44.473528691Z I0611 11:08:44.473465       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/restore-etcd-pod -n openshift-etcd:
2024-06-11T11:08:44.473528691Z cause by changes in data.pod.yaml
2024-06-11T11:08:44.672657426Z I0611 11:08:44.672565       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-pod-8 -n openshift-etcd because it was missing
2024-06-11T11:08:45.473926656Z I0611 11:08:45.473472       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-serving-ca-8 -n openshift-etcd because it was missing
2024-06-11T11:08:46.070737684Z I0611 11:08:46.070656       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-peer-client-ca-8 -n openshift-etcd because it was missing
2024-06-11T11:08:46.673271731Z I0611 11:08:46.673168       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-serving-ca-8 -n openshift-etcd because it was missing
2024-06-11T11:08:47.271568373Z I0611 11:08:47.271473       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-metrics-proxy-client-ca-8 -n openshift-etcd because it was missing
2024-06-11T11:08:47.871087974Z I0611 11:08:47.871010       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/etcd-endpoints-8 -n openshift-etcd because it was missing
2024-06-11T11:08:48.276718531Z I0611 11:08:48.276647       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/etcd-all-certs-8 -n openshift-etcd because it was missing
2024-06-11T11:08:48.672845025Z I0611 11:08:48.672764       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 8 triggered by "required configmap/etcd-pod has changed"
2024-06-11T11:08:48.693983755Z I0611 11:08:48.693900       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 8 created because required configmap/etcd-pod has changed
2024-06-11T11:08:48.716461749Z W0611 11:08:48.716386       1 staticpod.go:38] revision 8 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T11:08:48.716461749Z E0611 11:08:48.716442       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 8
2024-06-11T11:08:48.751991580Z I0611 11:08:48.751925       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 26.69 %, dbSize: 89227264
2024-06-11T11:08:48.751991580Z I0611 11:08:48.751956       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 26.43 %, dbSize: 88952832
2024-06-11T11:08:48.751991580Z I0611 11:08:48.751963       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 26.15 %, dbSize: 88678400
2024-06-11T11:08:49.861556024Z I0611 11:08:49.861416       1 request.go:697] Waited for 1.163158754s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:08:51.061427466Z I0611 11:08:51.061355       1 request.go:697] Waited for 1.194020258s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:08:51.273796610Z I0611 11:08:51.273649       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-etcd because it was missing
2024-06-11T11:08:52.461414790Z I0611 11:08:52.461346       1 request.go:697] Waited for 1.187304048s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:08:53.461676960Z I0611 11:08:53.461602       1 request.go:697] Waited for 1.394198998s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:08:54.072808756Z I0611 11:08:54.072724       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-etcd because it was missing
2024-06-11T11:08:54.661248894Z I0611 11:08:54.661177       1 request.go:697] Waited for 1.194702285s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:08:55.668389964Z I0611 11:08:55.668317       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-0 with revision 7 is the oldest and needs new revision 8
2024-06-11T11:08:55.668463077Z I0611 11:08:55.668439       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:08:55.668463077Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:08:55.668463077Z  CurrentRevision: (int32) 7,
2024-06-11T11:08:55.668463077Z  TargetRevision: (int32) 8,
2024-06-11T11:08:55.668463077Z  LastFailedRevision: (int32) 7,
2024-06-11T11:08:55.668463077Z  LastFailedTime: (*v1.Time)(0xc002e9e2a0)(2024-06-11 11:00:56 +0000 UTC),
2024-06-11T11:08:55.668463077Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:08:55.668463077Z  LastFailedCount: (int) 2,
2024-06-11T11:08:55.668463077Z  LastFallbackCount: (int) 0,
2024-06-11T11:08:55.668463077Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:08:55.668463077Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T11:08:55.668463077Z  }
2024-06-11T11:08:55.668463077Z }
2024-06-11T11:08:55.690360396Z I0611 11:08:55.690239       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 7 to 8 because node ci-op-9xx71rvq-1e28e-w667k-master-0 with revision 7 is the oldest
2024-06-11T11:08:55.692253826Z I0611 11:08:55.692200       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:08:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7; 0 nodes have achieved new revision 8\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:08:55.709765881Z I0611 11:08:55.709701       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing changed from False to True ("NodeInstallerProgressing: 3 nodes are at revision 7; 0 nodes have achieved new revision 8"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7; 0 nodes have achieved new revision 8\nEtcdMembersAvailable: 3 members are available"
2024-06-11T11:08:55.747111395Z I0611 11:08:55.747055       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 26.50 %, dbSize: 89227264
2024-06-11T11:08:55.747111395Z I0611 11:08:55.747080       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 26.24 %, dbSize: 88952832
2024-06-11T11:08:55.747111395Z I0611 11:08:55.747086       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 25.95 %, dbSize: 88678400
2024-06-11T11:08:56.271592177Z I0611 11:08:56.271494       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-8-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-etcd because it was missing
2024-06-11T11:08:56.860785646Z I0611 11:08:56.860717       1 request.go:697] Waited for 1.167683072s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T11:08:57.861400678Z I0611 11:08:57.861339       1 request.go:697] Waited for 1.796315621s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:59.063418738Z I0611 11:08:59.061618       1 request.go:697] Waited for 1.596791619s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods
2024-06-11T11:08:59.073107628Z I0611 11:08:59.073022       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-etcd because it was missing
2024-06-11T11:09:00.061696504Z I0611 11:09:00.061623       1 request.go:697] Waited for 1.391731594s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/services/etcd
2024-06-11T11:09:00.464782881Z I0611 11:09:00.464703       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:09:01.261294595Z I0611 11:09:01.261225       1 request.go:697] Waited for 1.39525118s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:09:02.461097021Z I0611 11:09:02.461026       1 request.go:697] Waited for 1.194321996s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:09:02.866090721Z I0611 11:09:02.865967       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:09:04.264880601Z I0611 11:09:04.264795       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:09:32.808051011Z I0611 11:09:32.807990       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:09:35.005813396Z I0611 11:09:35.005747       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:09:36.998823967Z I0611 11:09:36.998754       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:09:37.438476942Z E0611 11:09:37.438422       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp 172.30.142.45:9091: connect: connection refused
2024-06-11T11:09:43.799386357Z I0611 11:09:43.799292       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:09:47.829288289Z W0611 11:09:47.829218       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-0]
2024-06-11T11:09:52.849451588Z E0611 11:09:52.849360       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-9xx71rvq-1e28e-w667k-master-0, took=, err=create client failure: failed to make etcd client for endpoints [https://10.0.0.8:2379]: context deadline exceeded
2024-06-11T11:09:52.880676446Z E0611 11:09:52.880593       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:09:52.881239343Z I0611 11:09:52.881187       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:08:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7; 0 nodes have achieved new revision 8\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:09:52.888130625Z E0611 11:09:52.888077       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:09:52.903726202Z I0611 11:09:52.903653       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy"
2024-06-11T11:09:52.903981646Z E0611 11:09:52.903935       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:09:52.924916138Z E0611 11:09:52.924829       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:09:52.948695219Z E0611 11:09:52.948625       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:09:52.955328057Z I0611 11:09:52.955249       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:08:55Z","message":"NodeInstallerProgressing: 3 nodes are at revision 7; 0 nodes have achieved new revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7; 0 nodes have achieved new revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:09:52.965684134Z E0611 11:09:52.965621       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:09:52.969033909Z I0611 11:09:52.968973       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7; 0 nodes have achieved new revision 8\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7; 0 nodes have achieved new revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy"
2024-06-11T11:09:53.126675562Z E0611 11:09:53.126611       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:09:53.448044611Z E0611 11:09:53.447976       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:09:53.486038931Z I0611 11:09:53.485965       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:09:54.080814699Z I0611 11:09:54.080743       1 request.go:697] Waited for 1.130877367s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:09:54.088635641Z E0611 11:09:54.088577       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:09:55.081358500Z I0611 11:09:55.081246       1 request.go:697] Waited for 1.394736748s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T11:09:55.369238903Z E0611 11:09:55.369173       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:09:56.280420266Z I0611 11:09:56.280359       1 request.go:697] Waited for 1.194393066s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T11:09:57.281091687Z I0611 11:09:57.281031       1 request.go:697] Waited for 1.196196067s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:09:57.286281519Z I0611 11:09:57.286216       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:09:57.930246356Z E0611 11:09:57.930156       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:10:02.866073485Z W0611 11:10:02.866008       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-0]
2024-06-11T11:10:03.050985986Z E0611 11:10:03.050923       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:10:06.150144697Z I0611 11:10:06.150084       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:10:07.310494629Z I0611 11:10:07.310409       1 request.go:697] Waited for 1.157492062s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T11:10:08.311177034Z I0611 11:10:08.311113       1 request.go:697] Waited for 1.196435182s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:10:09.116427813Z I0611 11:10:09.116343       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:10:09.511264118Z I0611 11:10:09.511166       1 request.go:697] Waited for 1.195123366s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:10:10.511319820Z I0611 11:10:10.511202       1 request.go:697] Waited for 1.393297443s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:10:11.710966657Z I0611 11:10:11.710888       1 request.go:697] Waited for 1.195689485s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:10:12.711041315Z I0611 11:10:12.710974       1 request.go:697] Waited for 1.194190532s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:10:12.916612311Z I0611 11:10:12.916549       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:10:13.292279359Z E0611 11:10:13.292222       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:10:15.314840241Z I0611 11:10:15.314764       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:10:17.901316612Z W0611 11:10:17.901241       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-0]
2024-06-11T11:10:23.527770820Z E0611 11:10:23.527690       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp 172.30.142.45:9091: connect: connection refused
2024-06-11T11:10:32.937746389Z W0611 11:10:32.937671       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-0]
2024-06-11T11:10:33.773177307Z E0611 11:10:33.773103       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:10:36.767407386Z I0611 11:10:36.767293       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:10:37.433638363Z E0611 11:10:37.433520       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-9xx71rvq-1e28e-w667k-master-0, took=, err=create client failure: failed to make etcd client for endpoints [https://10.0.0.8:2379]: context deadline exceeded
2024-06-11T11:10:37.438759988Z E0611 11:10:37.438715       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp 172.30.142.45:9091: connect: connection refused
2024-06-11T11:10:37.941956057Z I0611 11:10:37.941890       1 request.go:697] Waited for 1.130151422s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T11:10:39.141936322Z I0611 11:10:39.141878       1 request.go:697] Waited for 1.394690515s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:10:40.142514226Z I0611 11:10:40.142412       1 request.go:697] Waited for 1.595159819s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-06-11T11:10:40.349209319Z I0611 11:10:40.349121       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:10:40.349209319Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:10:40.349209319Z  CurrentRevision: (int32) 8,
2024-06-11T11:10:40.349209319Z  TargetRevision: (int32) 0,
2024-06-11T11:10:40.349209319Z  LastFailedRevision: (int32) 7,
2024-06-11T11:10:40.349209319Z  LastFailedTime: (*v1.Time)(0xc0038c2f30)(2024-06-11 11:00:56 +0000 UTC),
2024-06-11T11:10:40.349209319Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:10:40.349209319Z  LastFailedCount: (int) 2,
2024-06-11T11:10:40.349209319Z  LastFallbackCount: (int) 0,
2024-06-11T11:10:40.349209319Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:10:40.349209319Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T11:10:40.349209319Z  }
2024-06-11T11:10:40.349209319Z }
2024-06-11T11:10:40.349209319Z  because static pod is ready
2024-06-11T11:10:40.372713767Z I0611 11:10:40.372646       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 7 to 8 because static pod is ready
2024-06-11T11:10:40.375183939Z E0611 11:10:40.375120       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:10:40.375960457Z I0611 11:10:40.375890       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:08:55Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7; 1 node is at revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 7; 1 node is at revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:10:40.395262370Z I0611 11:10:40.395212       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 7; 0 nodes have achieved new revision 8" to "NodeInstallerProgressing: 2 nodes are at revision 7; 1 node is at revision 8",Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7; 0 nodes have achieved new revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 7; 1 node is at revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy"
2024-06-11T11:10:41.341950241Z I0611 11:10:41.341872       1 request.go:697] Waited for 1.396247917s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:10:42.542414611Z I0611 11:10:42.542341       1 request.go:697] Waited for 1.59524735s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T11:10:43.741414641Z I0611 11:10:43.741336       1 request.go:697] Waited for 1.391417773s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:10:44.741761735Z I0611 11:10:44.741618       1 request.go:697] Waited for 1.393996089s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:10:44.749565181Z I0611 11:10:44.749511       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:10:44.749565181Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:10:44.749565181Z  CurrentRevision: (int32) 8,
2024-06-11T11:10:44.749565181Z  TargetRevision: (int32) 0,
2024-06-11T11:10:44.749565181Z  LastFailedRevision: (int32) 7,
2024-06-11T11:10:44.749565181Z  LastFailedTime: (*v1.Time)(0xc00199b098)(2024-06-11 11:00:56 +0000 UTC),
2024-06-11T11:10:44.749565181Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:10:44.749565181Z  LastFailedCount: (int) 2,
2024-06-11T11:10:44.749565181Z  LastFallbackCount: (int) 0,
2024-06-11T11:10:44.749565181Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:10:44.749565181Z   (string) (len=2059) "installer:  172.30.0.1:443: connect: connection refused\nW0611 10:57:51.967859       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:01.968030       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:11.967460       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:21.968015       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:31.968088       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:41.967791       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:41.968659       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:41.968692       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T11:10:44.749565181Z  }
2024-06-11T11:10:44.749565181Z }
2024-06-11T11:10:44.749565181Z  because static pod is ready
2024-06-11T11:10:45.741785690Z I0611 11:10:45.741699       1 request.go:697] Waited for 1.194330614s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-06-11T11:10:47.947902944Z I0611 11:10:47.947836       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-1 with revision 7 is the oldest and needs new revision 8
2024-06-11T11:10:47.947964053Z I0611 11:10:47.947900       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:10:47.947964053Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:10:47.947964053Z  CurrentRevision: (int32) 7,
2024-06-11T11:10:47.947964053Z  TargetRevision: (int32) 8,
2024-06-11T11:10:47.947964053Z  LastFailedRevision: (int32) 0,
2024-06-11T11:10:47.947964053Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:10:47.947964053Z  LastFailedReason: (string) "",
2024-06-11T11:10:47.947964053Z  LastFailedCount: (int) 0,
2024-06-11T11:10:47.947964053Z  LastFallbackCount: (int) 0,
2024-06-11T11:10:47.947964053Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:10:47.947964053Z }
2024-06-11T11:10:47.970023679Z I0611 11:10:47.969926       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 7 to 8 because node ci-op-9xx71rvq-1e28e-w667k-master-1 with revision 7 is the oldest
2024-06-11T11:10:47.972236603Z E0611 11:10:47.972081       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy
2024-06-11T11:10:49.141484625Z I0611 11:10:49.141412       1 request.go:697] Waited for 1.167399051s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:10:50.141599609Z I0611 11:10:50.141477       1 request.go:697] Waited for 1.195448454s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:10:50.359204637Z I0611 11:10:50.359135       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-etcd because it was missing
2024-06-11T11:10:51.142219066Z I0611 11:10:51.142138       1 request.go:697] Waited for 1.193937133s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:10:51.346516548Z I0611 11:10:51.346450       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:10:52.142399298Z I0611 11:10:52.142327       1 request.go:697] Waited for 1.378838521s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-06-11T11:10:53.546094299Z I0611 11:10:53.546027       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:10:54.947073667Z I0611 11:10:54.947015       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:11:14.826911332Z I0611 11:11:14.826835       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 19.94 %, dbSize: 88678400
2024-06-11T11:11:14.826911332Z I0611 11:11:14.826869       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 20.17 %, dbSize: 88952832
2024-06-11T11:11:14.826911332Z I0611 11:11:14.826878       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 20.46 %, dbSize: 89227264
2024-06-11T11:11:24.676000834Z I0611 11:11:24.675928       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:11:26.871893119Z I0611 11:11:26.871835       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:11:28.871821891Z I0611 11:11:28.871761       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:11:37.441233858Z E0611 11:11:37.441160       1 base_controller.go:268] FSyncController reconciliation failed: Post "https://thanos-querier.openshift-monitoring.svc:9091/api/v1/query": dial tcp 172.30.142.45:9091: connect: connection refused
2024-06-11T11:11:37.470950107Z I0611 11:11:37.470878       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:08:55Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7; 1 node is at revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 7; 1 node is at revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:11:37.487483404Z I0611 11:11:37.487410       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found"
2024-06-11T11:11:37.499577711Z I0611 11:11:37.499520       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:08:55Z","message":"NodeInstallerProgressing: 2 nodes are at revision 7; 1 node is at revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 7; 1 node is at revision 8\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:11:37.511573405Z I0611 11:11:37.511467       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 7; 1 node is at revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-0 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 7; 1 node is at revision 8\nEtcdMembersAvailable: 3 members are available"
2024-06-11T11:11:38.667882053Z I0611 11:11:38.667813       1 request.go:697] Waited for 1.162727902s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T11:11:39.075522220Z I0611 11:11:39.075459       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:11:39.668946873Z I0611 11:11:39.668868       1 request.go:697] Waited for 1.393634884s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T11:11:39.705432504Z W0611 11:11:39.705357       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-1]
2024-06-11T11:11:40.868487533Z I0611 11:11:40.868421       1 request.go:697] Waited for 1.710600269s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:11:42.068219518Z I0611 11:11:42.068160       1 request.go:697] Waited for 1.593560558s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:11:43.268247642Z I0611 11:11:43.268162       1 request.go:697] Waited for 1.394373127s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-06-11T11:11:43.479285210Z I0611 11:11:43.479221       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:11:44.268577768Z I0611 11:11:44.268507       1 request.go:697] Waited for 1.192314123s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T11:11:45.872956629Z I0611 11:11:45.872875       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:11:52.506335406Z E0611 11:11:52.506256       1 base_controller.go:268] DefragController reconciliation failed: failed to dial endpoint https://10.0.0.6:2379 with maintenance client: context deadline exceeded
2024-06-11T11:11:54.743104956Z W0611 11:11:54.743046       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-1]
2024-06-11T11:11:59.178656582Z I0611 11:11:59.178584       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:11:59.573102979Z I0611 11:11:59.572995       1 request.go:697] Waited for 1.123018612s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:12:00.573229566Z I0611 11:12:00.573082       1 request.go:697] Waited for 1.194518104s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:12:01.573737899Z I0611 11:12:01.573672       1 request.go:697] Waited for 1.196162197s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:12:02.573756773Z I0611 11:12:02.573701       1 request.go:697] Waited for 1.195872962s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:12:02.791145889Z I0611 11:12:02.791059       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:12:05.579437041Z I0611 11:12:05.579372       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:12:07.525147783Z E0611 11:12:07.525055       1 base_controller.go:268] DefragController reconciliation failed: failed to dial endpoint https://10.0.0.6:2379 with maintenance client: context deadline exceeded
2024-06-11T11:12:07.778459546Z I0611 11:12:07.778392       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:12:13.454766282Z W0611 11:12:13.454698       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-1]
2024-06-11T11:12:16.662855470Z I0611 11:12:16.662785       1 reflector.go:351] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:16.862748029Z I0611 11:12:16.862677       1 reflector.go:351] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:17.369657064Z I0611 11:12:17.369565       1 reflector.go:351] Caches populated for *v1beta1.Machine from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:17.778344122Z I0611 11:12:17.778268       1 reflector.go:351] Caches populated for *v1.APIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:17.898033809Z I0611 11:12:17.897941       1 reflector.go:351] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:18.155390683Z I0611 11:12:18.155296       1 reflector.go:351] Caches populated for *v1.Etcd from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:18.427808717Z I0611 11:12:18.427744       1 reflector.go:351] Caches populated for operator.openshift.io/v1, Resource=etcds from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:19.453887721Z I0611 11:12:19.453823       1 request.go:697] Waited for 1.017386989s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-sa
2024-06-11T11:12:20.454510456Z I0611 11:12:20.454444       1 request.go:697] Waited for 1.19529369s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:12:21.262280727Z I0611 11:12:21.262212       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:12:22.555291342Z E0611 11:12:22.555227       1 base_controller.go:268] DefragController reconciliation failed: failed to dial endpoint https://10.0.0.6:2379 with maintenance client: context deadline exceeded
2024-06-11T11:12:28.239462200Z I0611 11:12:28.239396       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:12:28.323148729Z I0611 11:12:28.323088       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 21.64 %, dbSize: 88911872
2024-06-11T11:12:28.323148729Z I0611 11:12:28.323116       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 21.97 %, dbSize: 89227264
2024-06-11T11:12:28.323148729Z I0611 11:12:28.323124       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 21.67 %, dbSize: 88952832
2024-06-11T11:12:28.397784082Z I0611 11:12:28.397715       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 21.64 %, dbSize: 88911872
2024-06-11T11:12:28.397784082Z I0611 11:12:28.397742       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 21.96 %, dbSize: 89227264
2024-06-11T11:12:28.397784082Z I0611 11:12:28.397748       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 21.67 %, dbSize: 88952832
2024-06-11T11:12:28.500328746Z W0611 11:12:28.500247       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-1]
2024-06-11T11:12:29.801843069Z I0611 11:12:29.801773       1 request.go:697] Waited for 1.193382657s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:12:31.001593913Z I0611 11:12:31.001520       1 request.go:697] Waited for 1.187793354s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:12:31.211664078Z I0611 11:12:31.211594       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:12:31.211664078Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:12:31.211664078Z  CurrentRevision: (int32) 8,
2024-06-11T11:12:31.211664078Z  TargetRevision: (int32) 0,
2024-06-11T11:12:31.211664078Z  LastFailedRevision: (int32) 0,
2024-06-11T11:12:31.211664078Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:12:31.211664078Z  LastFailedReason: (string) "",
2024-06-11T11:12:31.211664078Z  LastFailedCount: (int) 0,
2024-06-11T11:12:31.211664078Z  LastFallbackCount: (int) 0,
2024-06-11T11:12:31.211664078Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:12:31.211664078Z }
2024-06-11T11:12:31.211664078Z  because static pod is ready
2024-06-11T11:12:31.246260911Z I0611 11:12:31.246188       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 7 to 8 because static pod is ready
2024-06-11T11:12:31.250725793Z I0611 11:12:31.248017       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:08:55Z","message":"NodeInstallerProgressing: 1 node is at revision 7; 2 nodes are at revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 7; 2 nodes are at revision 8\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:12:31.266901738Z I0611 11:12:31.266825       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 7; 1 node is at revision 8" to "NodeInstallerProgressing: 1 node is at revision 7; 2 nodes are at revision 8",Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 7; 1 node is at revision 8\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 7; 2 nodes are at revision 8\nEtcdMembersAvailable: 3 members are available"
2024-06-11T11:12:31.302749906Z I0611 11:12:31.302681       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 21.48 %, dbSize: 88911872
2024-06-11T11:12:31.302749906Z I0611 11:12:31.302708       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 21.81 %, dbSize: 89227264
2024-06-11T11:12:31.302749906Z I0611 11:12:31.302714       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 21.52 %, dbSize: 88952832
2024-06-11T11:12:32.401510454Z I0611 11:12:32.401445       1 request.go:697] Waited for 1.153673073s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/revision-pruner-8-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:12:33.402333435Z I0611 11:12:33.402264       1 request.go:697] Waited for 1.593963477s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/restore-etcd-pod
2024-06-11T11:12:34.602158788Z I0611 11:12:34.602090       1 request.go:697] Waited for 1.395490063s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:12:35.006780143Z I0611 11:12:35.006722       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:12:35.006780143Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:12:35.006780143Z  CurrentRevision: (int32) 8,
2024-06-11T11:12:35.006780143Z  TargetRevision: (int32) 0,
2024-06-11T11:12:35.006780143Z  LastFailedRevision: (int32) 0,
2024-06-11T11:12:35.006780143Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:12:35.006780143Z  LastFailedReason: (string) "",
2024-06-11T11:12:35.006780143Z  LastFailedCount: (int) 0,
2024-06-11T11:12:35.006780143Z  LastFallbackCount: (int) 0,
2024-06-11T11:12:35.006780143Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:12:35.006780143Z }
2024-06-11T11:12:35.006780143Z  because static pod is ready
2024-06-11T11:12:35.802185778Z I0611 11:12:35.802110       1 request.go:697] Waited for 1.191425866s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:12:37.470876658Z E0611 11:12:37.470810       1 base_controller.go:268] FSyncController reconciliation failed: client query returned empty vector
2024-06-11T11:12:38.602367012Z I0611 11:12:38.602286       1 request.go:697] Waited for 1.06878634s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T11:12:40.202357588Z I0611 11:12:40.202253       1 request.go:697] Waited for 1.068839983s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:12:41.202488161Z I0611 11:12:41.202415       1 request.go:697] Waited for 1.19484684s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:12:41.208634342Z I0611 11:12:41.208579       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-2 with revision 7 is the oldest and needs new revision 8
2024-06-11T11:12:41.208681047Z I0611 11:12:41.208633       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:12:41.208681047Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:12:41.208681047Z  CurrentRevision: (int32) 7,
2024-06-11T11:12:41.208681047Z  TargetRevision: (int32) 8,
2024-06-11T11:12:41.208681047Z  LastFailedRevision: (int32) 0,
2024-06-11T11:12:41.208681047Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:12:41.208681047Z  LastFailedReason: (string) "",
2024-06-11T11:12:41.208681047Z  LastFailedCount: (int) 0,
2024-06-11T11:12:41.208681047Z  LastFallbackCount: (int) 0,
2024-06-11T11:12:41.208681047Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:12:41.208681047Z }
2024-06-11T11:12:41.230316644Z I0611 11:12:41.230219       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-2" from revision 7 to 8 because node ci-op-9xx71rvq-1e28e-w667k-master-2 with revision 7 is the oldest
2024-06-11T11:12:41.283724159Z I0611 11:12:41.283670       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 21.21 %, dbSize: 88911872
2024-06-11T11:12:41.283724159Z I0611 11:12:41.283693       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 21.52 %, dbSize: 89227264
2024-06-11T11:12:41.283724159Z I0611 11:12:41.283698       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 21.25 %, dbSize: 88952832
2024-06-11T11:12:42.401919209Z I0611 11:12:42.401787       1 request.go:697] Waited for 1.169401221s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T11:12:43.402369018Z I0611 11:12:43.402293       1 request.go:697] Waited for 1.58758974s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd
2024-06-11T11:12:43.819007604Z I0611 11:12:43.818929       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-etcd because it was missing
2024-06-11T11:12:44.601845422Z I0611 11:12:44.601775       1 request.go:697] Waited for 1.394014452s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:12:45.206901991Z I0611 11:12:45.206828       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:12:45.801991270Z I0611 11:12:45.801927       1 request.go:697] Waited for 1.595155164s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:12:46.802154965Z I0611 11:12:46.802080       1 request.go:697] Waited for 1.593735023s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:12:48.002475530Z I0611 11:12:48.002394       1 request.go:697] Waited for 1.196618898s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:12:48.006951974Z I0611 11:12:48.006876       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:12:49.805175479Z I0611 11:12:49.805081       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:13:17.610020045Z I0611 11:13:17.609934       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:13:19.404603604Z I0611 11:13:19.404542       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:13:21.403311379Z I0611 11:13:21.403224       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:13:31.001330940Z I0611 11:13:31.001223       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:13:32.638369757Z W0611 11:13:32.638257       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:13:38.680438168Z I0611 11:13:38.680354       1 request.go:697] Waited for 1.146086368s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:13:39.087295087Z I0611 11:13:39.087220       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:13:39.680871753Z I0611 11:13:39.680720       1 request.go:697] Waited for 1.380465513s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-06-11T11:13:47.674347342Z W0611 11:13:47.674237       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:13:52.470793684Z E0611 11:13:52.470712       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-9xx71rvq-1e28e-w667k-master-2, took=, err=create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded
2024-06-11T11:13:52.470891893Z E0611 11:13:52.470817       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:13:52.476729733Z E0611 11:13:52.476665       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:13:52.487128794Z E0611 11:13:52.487087       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:13:52.497012607Z E0611 11:13:52.496975       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:13:52.497868386Z I0611 11:13:52.497826       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:08:55Z","message":"NodeInstallerProgressing: 1 node is at revision 7; 2 nodes are at revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 7; 2 nodes are at revision 8\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:13:52.507793103Z E0611 11:13:52.507749       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:13:52.512795966Z I0611 11:13:52.512729       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy"
2024-06-11T11:13:52.547318156Z E0611 11:13:52.547247       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:13:52.547566079Z I0611 11:13:52.547509       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:08:55Z","message":"NodeInstallerProgressing: 1 node is at revision 7; 2 nodes are at revision 8","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 7; 2 nodes are at revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:13:52.566362715Z I0611 11:13:52.566231       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 7; 2 nodes are at revision 8\nEtcdMembersAvailable: 3 members are available" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 7; 2 nodes are at revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy"
2024-06-11T11:13:52.588986006Z E0611 11:13:52.588916       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:13:52.909900460Z E0611 11:13:52.909831       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:13:53.550782781Z E0611 11:13:53.550721       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:13:53.697817367Z I0611 11:13:53.697741       1 request.go:697] Waited for 1.150896949s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/installer-sa
2024-06-11T11:13:54.303569242Z I0611 11:13:54.303495       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because waiting for static pod of revision 8, found 7
2024-06-11T11:13:54.832094980Z E0611 11:13:54.832026       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:13:54.896990277Z I0611 11:13:54.896924       1 request.go:697] Waited for 1.393960308s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T11:13:55.897312937Z I0611 11:13:55.897234       1 request.go:697] Waited for 1.195382288s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/revision-pruner-8-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:13:57.097657078Z I0611 11:13:57.097577       1 request.go:697] Waited for 1.595905321s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:13:57.392686604Z E0611 11:13:57.392615       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:13:58.297289075Z I0611 11:13:58.297225       1 request.go:697] Waited for 1.59478604s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:13:58.703579899Z I0611 11:13:58.703505       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:13:59.297414310Z I0611 11:13:59.297344       1 request.go:697] Waited for 1.392377598s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods?labelSelector=app%3Dinstaller
2024-06-11T11:14:00.297560976Z I0611 11:14:00.297481       1 request.go:697] Waited for 1.380736645s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/serviceaccounts/etcd-backup-sa
2024-06-11T11:14:01.497262973Z I0611 11:14:01.497202       1 request.go:697] Waited for 1.395529283s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/installer-8-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:14:02.506287655Z I0611 11:14:02.506223       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:14:02.513232093Z E0611 11:14:02.513188       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:14:02.711547309Z W0611 11:14:02.711470       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:14:04.704135751Z I0611 11:14:04.704068       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:14:12.754178535Z E0611 11:14:12.754116       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:14:17.748741509Z W0611 11:14:17.748672       1 etcdcli.go:351] UnhealthyEtcdMember found: [ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T11:14:21.236560360Z I0611 11:14:21.236496       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:14:25.309423316Z I0611 11:14:25.309250       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 8, but has not made progress because static pod is pending
2024-06-11T11:14:26.486580753Z I0611 11:14:26.486478       1 request.go:697] Waited for 1.149582121s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-pod
2024-06-11T11:14:28.091568318Z I0611 11:14:28.091503       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:14:28.091568318Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:14:28.091568318Z  CurrentRevision: (int32) 8,
2024-06-11T11:14:28.091568318Z  TargetRevision: (int32) 0,
2024-06-11T11:14:28.091568318Z  LastFailedRevision: (int32) 0,
2024-06-11T11:14:28.091568318Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:14:28.091568318Z  LastFailedReason: (string) "",
2024-06-11T11:14:28.091568318Z  LastFailedCount: (int) 0,
2024-06-11T11:14:28.091568318Z  LastFallbackCount: (int) 0,
2024-06-11T11:14:28.091568318Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:14:28.091568318Z }
2024-06-11T11:14:28.091568318Z  because static pod is ready
2024-06-11T11:14:28.112651199Z I0611 11:14:28.112573       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-2" from revision 7 to 8 because static pod is ready
2024-06-11T11:14:28.117724828Z I0611 11:14:28.117668       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:14:28Z","message":"NodeInstallerProgressing: 3 nodes are at revision 8\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:14:28.118503194Z E0611 11:14:28.118396       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:14:28.119533581Z E0611 11:14:28.119480       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.125183458Z E0611 11:14:28.125122       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.134076010Z I0611 11:14:28.127244       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 8\nEtcdMembersProgressing: No unstarted etcd members found"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 7; 2 nodes are at revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy"
2024-06-11T11:14:28.136648127Z E0611 11:14:28.136582       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.157151260Z E0611 11:14:28.157101       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.167126103Z E0611 11:14:28.167081       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.169528205Z E0611 11:14:28.169473       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.169883235Z E0611 11:14:28.169830       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:14:28.170853117Z I0611 11:14:28.170796       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:\"ci-op-9xx71rvq-1e28e-w667k-master-0\" peerURLs:\"https://10.0.0.8:2380\" clientURLs:\"https://10.0.0.8:2379\"  Healthy:true Took:1.508937ms Error:\u003cnil\u003e} {Member:ID:9039689361178516505 name:\"ci-op-9xx71rvq-1e28e-w667k-master-1\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:1.87687ms Error:\u003cnil\u003e} {Member:ID:11862787134384716550 name:\"ci-op-9xx71rvq-1e28e-w667k-master-2\" peerURLs:\"https://10.0.0.7:2380\" clientURLs:\"https://10.0.0.7:2379\"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:14:28Z","message":"NodeInstallerProgressing: 3 nodes are at revision 8\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:14:28.185506256Z I0611 11:14:28.185444       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy" to "NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:\"ci-op-9xx71rvq-1e28e-w667k-master-0\" peerURLs:\"https://10.0.0.8:2380\" clientURLs:\"https://10.0.0.8:2379\"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:\"ci-op-9xx71rvq-1e28e-w667k-master-1\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:\"ci-op-9xx71rvq-1e28e-w667k-master-2\" peerURLs:\"https://10.0.0.7:2380\" clientURLs:\"https://10.0.0.7:2379\"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy"
2024-06-11T11:14:28.189245872Z E0611 11:14:28.189201       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.193552836Z E0611 11:14:28.193503       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.198529756Z E0611 11:14:28.198487       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.207332300Z E0611 11:14:28.207237       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.253132370Z E0611 11:14:28.253052       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.337802225Z E0611 11:14:28.337737       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.359971598Z E0611 11:14:28.359919       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.506207355Z E0611 11:14:28.506132       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.681737487Z E0611 11:14:28.681653       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:28.832463724Z E0611 11:14:28.832357       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:29.287189048Z I0611 11:14:29.287103       1 request.go:697] Waited for 1.16756426s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/revision-pruner-8-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:14:29.322943469Z E0611 11:14:29.322863       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:29.477550634Z E0611 11:14:29.477476       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:29.894269046Z E0611 11:14:29.894195       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:29.894675381Z E0611 11:14:29.894639       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:29.900505974Z E0611 11:14:29.900455       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:29.902054204Z E0611 11:14:29.902001       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:29.911680918Z E0611 11:14:29.911612       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:29.913197746Z E0611 11:14:29.913157       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:29.932612687Z E0611 11:14:29.932555       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:29.934119614Z E0611 11:14:29.934069       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:29.973804867Z E0611 11:14:29.973714       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:29.975447506Z E0611 11:14:29.975392       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:30.055510671Z E0611 11:14:30.055438       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:30.056022115Z E0611 11:14:30.055987       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:30.217076124Z E0611 11:14:30.216992       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:30.218723763Z E0611 11:14:30.218663       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:30.486991932Z I0611 11:14:30.486923       1 request.go:697] Waited for 1.594928672s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:14:30.538090950Z E0611 11:14:30.538007       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:30.540089818Z E0611 11:14:30.540019       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:30.603991918Z E0611 11:14:30.603917       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:30.762739632Z E0611 11:14:30.762676       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:31.178688580Z E0611 11:14:31.178602       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:31.181313602Z E0611 11:14:31.181241       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:31.487398566Z I0611 11:14:31.487296       1 request.go:697] Waited for 1.391430476s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:14:32.459951947Z E0611 11:14:32.459868       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:32.463090312Z E0611 11:14:32.463022       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:32.487743496Z I0611 11:14:32.487564       1 request.go:697] Waited for 1.396766627s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:14:33.165433661Z E0611 11:14:33.165353       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:33.234907831Z E0611 11:14:33.234839       1 base_controller.go:268] DefragController reconciliation failed: cluster is unhealthy: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy
2024-06-11T11:14:33.327222132Z E0611 11:14:33.327160       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:35.021232376Z E0611 11:14:35.021163       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:35.023910402Z E0611 11:14:35.023853       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:37.436903524Z E0611 11:14:37.436810       1 etcdmemberscontroller.go:81] Unhealthy etcd member found: ci-op-9xx71rvq-1e28e-w667k-master-2, took=, err=create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded
2024-06-11T11:14:37.534955044Z E0611 11:14:37.534873       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:37.536359943Z E0611 11:14:37.536290       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:37.538941726Z E0611 11:14:37.538876       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:38.286141058Z E0611 11:14:38.286074       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:38.337478781Z E0611 11:14:38.337417       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:38.452632908Z E0611 11:14:38.452568       1 base_controller.go:268] EtcdEndpointsController reconciliation failed: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:40.143059008Z E0611 11:14:40.142969       1 base_controller.go:268] TargetConfigController reconciliation failed: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:40.144820533Z E0611 11:14:40.144753       1 base_controller.go:266] "TargetConfigController" controller failed to sync "", err: TargetConfigController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:48.527832088Z E0611 11:14:48.527760       1 base_controller.go:268] EtcdCertSignerController reconciliation failed: EtcdCertSignerController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:"ci-op-9xx71rvq-1e28e-w667k-master-0" peerURLs:"https://10.0.0.8:2380" clientURLs:"https://10.0.0.8:2379"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:"ci-op-9xx71rvq-1e28e-w667k-master-1" peerURLs:"https://10.0.0.6:2380" clientURLs:"https://10.0.0.6:2379"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:"ci-op-9xx71rvq-1e28e-w667k-master-2" peerURLs:"https://10.0.0.7:2380" clientURLs:"https://10.0.0.7:2379"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]
2024-06-11T11:14:59.026085056Z I0611 11:14:59.026008       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:14:28Z","message":"NodeInstallerProgressing: 3 nodes are at revision 8\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:14:59.049776192Z I0611 11:14:59.049707       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdEndpointsDegraded: EtcdEndpointsController can't evaluate whether quorum is safe: etcd cluster has quorum of 2 and 2 healthy members which is not fault tolerant: [{Member:ID:3608263143074270988 name:\"ci-op-9xx71rvq-1e28e-w667k-master-0\" peerURLs:\"https://10.0.0.8:2380\" clientURLs:\"https://10.0.0.8:2379\"  Healthy:true Took:1.508937ms Error:<nil>} {Member:ID:9039689361178516505 name:\"ci-op-9xx71rvq-1e28e-w667k-master-1\" peerURLs:\"https://10.0.0.6:2380\" clientURLs:\"https://10.0.0.6:2379\"  Healthy:true Took:1.87687ms Error:<nil>} {Member:ID:11862787134384716550 name:\"ci-op-9xx71rvq-1e28e-w667k-master-2\" peerURLs:\"https://10.0.0.7:2380\" clientURLs:\"https://10.0.0.7:2379\"  Healthy:false Took: Error:create client failure: failed to make etcd client for endpoints [https://10.0.0.7:2379]: context deadline exceeded}]\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy"
2024-06-11T11:14:59.078951975Z I0611 11:14:59.078869       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 17.18 %, dbSize: 89227264
2024-06-11T11:14:59.078951975Z I0611 11:14:59.078907       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 16.93 %, dbSize: 88952832
2024-06-11T11:14:59.078951975Z I0611 11:14:59.078915       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 16.85 %, dbSize: 88911872
2024-06-11T11:15:37.466029854Z I0611 11:15:37.465960       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:14:28Z","message":"NodeInstallerProgressing: 3 nodes are at revision 8\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:15:37.477008693Z I0611 11:15:37.476924       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy" to "NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found"
2024-06-11T11:15:37.514979996Z I0611 11:15:37.514913       1 status_controller.go:218] clusteroperator/etcd diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T11:03:00Z","message":"NodeControllerDegraded: All master nodes are ready\nEtcdMembersDegraded: No unhealthy members found","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:14:28Z","message":"NodeInstallerProgressing: 3 nodes are at revision 8\nEtcdMembersProgressing: No unstarted etcd members found","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:50:12Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 8\nEtcdMembersAvailable: 3 members are available","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:25Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:15:37.526454273Z I0611 11:15:37.526399       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 15.74 %, dbSize: 89227264
2024-06-11T11:15:37.526454273Z I0611 11:15:37.526423       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 15.52 %, dbSize: 88952832
2024-06-11T11:15:37.526454273Z I0611 11:15:37.526429       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 15.40 %, dbSize: 88911872
2024-06-11T11:15:37.530689897Z I0611 11:15:37.530633       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-etcd-operator", Name:"etcd-operator", UID:"ddb3112e-9358-491c-8d18-fd0da304c5a2", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/etcd changed: Available message changed from "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 8\nEtcdMembersAvailable: 2 of 3 members are available, ci-op-9xx71rvq-1e28e-w667k-master-2 is unhealthy" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 8\nEtcdMembersAvailable: 3 members are available"
2024-06-11T11:15:37.574284629Z I0611 11:15:37.574222       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 15.74 %, dbSize: 89227264
2024-06-11T11:15:37.574284629Z I0611 11:15:37.574248       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 15.47 %, dbSize: 88952832
2024-06-11T11:15:37.574284629Z I0611 11:15:37.574253       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 15.40 %, dbSize: 88911872
2024-06-11T11:15:38.666269405Z I0611 11:15:38.666200       1 request.go:697] Waited for 1.179102435s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:15:39.866140227Z I0611 11:15:39.866075       1 request.go:697] Waited for 1.393424219s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/pods/etcd-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:15:40.866432780Z I0611 11:15:40.866314       1 request.go:697] Waited for 1.594422275s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-etcd/configmaps/etcd-scripts
2024-06-11T11:17:17.180196559Z I0611 11:17:17.180120       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 40.41 %, dbSize: 89227264
2024-06-11T11:17:17.180196559Z I0611 11:17:17.180149       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 40.17 %, dbSize: 88952832
2024-06-11T11:17:17.180196559Z I0611 11:17:17.180156       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 40.01 %, dbSize: 88911872
2024-06-11T11:22:37.563142092Z I0611 11:22:37.563075       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 39.63 %, dbSize: 89227264
2024-06-11T11:22:37.563142092Z I0611 11:22:37.563102       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 39.50 %, dbSize: 88952832
2024-06-11T11:22:37.563142092Z I0611 11:22:37.563108       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 39.34 %, dbSize: 88911872
2024-06-11T11:33:37.562225029Z I0611 11:33:37.562139       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-1" backend store fragmented: 36.51 %, dbSize: 89784320
2024-06-11T11:33:37.562225029Z I0611 11:33:37.562190       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-2" backend store fragmented: 36.37 %, dbSize: 89509888
2024-06-11T11:33:37.562225029Z I0611 11:33:37.562197       1 defragcontroller.go:300] etcd member "ci-op-9xx71rvq-1e28e-w667k-master-0" backend store fragmented: 36.11 %, dbSize: 89403392
