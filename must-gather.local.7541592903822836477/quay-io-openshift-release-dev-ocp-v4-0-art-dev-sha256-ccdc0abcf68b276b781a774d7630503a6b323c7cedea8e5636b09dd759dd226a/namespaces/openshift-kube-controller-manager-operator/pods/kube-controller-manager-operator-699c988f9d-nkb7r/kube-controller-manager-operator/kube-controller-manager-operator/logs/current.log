2024-06-11T10:49:46.255188790Z I0611 10:49:46.255029       1 cmd.go:240] Using service-serving-cert provided certificates
2024-06-11T10:49:46.255188790Z I0611 10:49:46.255156       1 leaderelection.go:121] The leader election gives 4 retries and allows for 30s of clock skew. The kube-apiserver downtime tolerance is 78s. Worst non-graceful lease acquisition is 2m43s. Worst graceful lease acquisition is {26s}.
2024-06-11T10:49:46.255843717Z I0611 10:49:46.255792       1 observer_polling.go:159] Starting file observer
2024-06-11T10:49:46.291639469Z I0611 10:49:46.291577       1 builder.go:298] kube-controller-manager-operator version 4.16.0-202406061206.p0.g0338b3b.assembly.stream.el9-0338b3b-0338b3be6912024d03def2c26f0fa10218fc2c25
2024-06-11T10:49:46.858805179Z I0611 10:49:46.858736       1 secure_serving.go:57] Forcing use of http/1.1 only
2024-06-11T10:49:46.858805179Z W0611 10:49:46.858770       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2024-06-11T10:49:46.858805179Z W0611 10:49:46.858780       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2024-06-11T10:49:46.861204877Z I0611 10:49:46.861140       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2024-06-11T10:49:46.861204877Z I0611 10:49:46.861187       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2024-06-11T10:49:46.861255679Z I0611 10:49:46.861208       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-06-11T10:49:46.861255679Z I0611 10:49:46.861208       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
2024-06-11T10:49:46.861255679Z I0611 10:49:46.861155       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2024-06-11T10:49:46.861255679Z I0611 10:49:46.861243       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-06-11T10:49:46.861698397Z I0611 10:49:46.861664       1 leaderelection.go:250] attempting to acquire leader lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock...
2024-06-11T10:49:46.861719798Z I0611 10:49:46.861700       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key"
2024-06-11T10:49:46.862500929Z I0611 10:49:46.862457       1 secure_serving.go:213] Serving securely on [::]:8443
2024-06-11T10:49:46.862662836Z I0611 10:49:46.862503       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2024-06-11T10:49:46.875081240Z I0611 10:49:46.875016       1 leaderelection.go:260] successfully acquired lease openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock
2024-06-11T10:49:46.875327750Z I0611 10:49:46.875229       1 event.go:364] Event(v1.ObjectReference{Kind:"Lease", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator-lock", UID:"eeb2e7a6-85e4-41a9-903f-1c365c03e381", APIVersion:"coordination.k8s.io/v1", ResourceVersion:"11682", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' kube-controller-manager-operator-699c988f9d-nkb7r_120e1ddc-8a3e-4c28-8fcd-e627c865164f became leader
2024-06-11T10:49:46.875854471Z I0611 10:49:46.875813       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2024-06-11T10:49:46.878450976Z I0611 10:49:46.878400       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AdminNetworkPolicy", "AlibabaPlatform", "AzureWorkloadIdentity", "BareMetalLoadBalancer", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ClusterAPIInstallAWS", "ClusterAPIInstallNutanix", "ClusterAPIInstallOpenStack", "ClusterAPIInstallVSphere", "DisableKubeletCloudCredentialProviders", "ExternalCloudProvider", "ExternalCloudProviderAzure", "ExternalCloudProviderExternal", "ExternalCloudProviderGCP", "HardwareSpeed", "KMSv1", "MetricsServer", "NetworkDiagnosticsConfig", "NetworkLiveMigration", "PrivateHostedZoneAWS", "VSphereControlPlaneMachineSet", "VSphereDriverConfiguration", "VSphereStaticIPs"}, Disabled:[]v1.FeatureGateName{"AutomatedEtcdBackup", "CSIDriverSharedResource", "ChunkSizeMiB", "ClusterAPIInstall", "ClusterAPIInstallAzure", "ClusterAPIInstallGCP", "ClusterAPIInstallIBMCloud", "ClusterAPIInstallPowerVS", "DNSNameResolver", "DynamicResourceAllocation", "EtcdBackendQuota", "EventedPLEG", "Example", "ExternalOIDC", "ExternalRouteCertificate", "GCPClusterHostedDNS", "GCPLabelsTags", "GatewayAPI", "ImagePolicy", "InsightsConfig", "InsightsConfigAPI", "InsightsOnDemandDataGather", "InstallAlternateInfrastructureAWS", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MachineConfigNodes", "ManagedBootImages", "MaxUnavailableStatefulSet", "MetricsCollectionProfiles", "MixedCPUsAllocation", "NewOLM", "NodeDisruptionPolicy", "NodeSwap", "OnClusterBuild", "OpenShiftPodSecurityAdmission", "PinnedImages", "PlatformOperators", "RouteExternalCertificate", "ServiceAccountTokenNodeBinding", "ServiceAccountTokenNodeBindingValidation", "ServiceAccountTokenPodNodeInfo", "SignatureStores", "SigstoreImageVerification", "TranslateStreamCloseWebsocketRequests", "UpgradeStatus", "VSphereMultiVCenters", "ValidatingAdmissionPolicy", "VolumeGroupSnapshot"}}
2024-06-11T10:49:46.878539180Z I0611 10:49:46.878426       1 starter.go:88] FeatureGates initialized: knownFeatureGates=[AdminNetworkPolicy AlibabaPlatform AutomatedEtcdBackup AzureWorkloadIdentity BareMetalLoadBalancer BuildCSIVolumes CSIDriverSharedResource ChunkSizeMiB CloudDualStackNodeIPs ClusterAPIInstall ClusterAPIInstallAWS ClusterAPIInstallAzure ClusterAPIInstallGCP ClusterAPIInstallIBMCloud ClusterAPIInstallNutanix ClusterAPIInstallOpenStack ClusterAPIInstallPowerVS ClusterAPIInstallVSphere DNSNameResolver DisableKubeletCloudCredentialProviders DynamicResourceAllocation EtcdBackendQuota EventedPLEG Example ExternalCloudProvider ExternalCloudProviderAzure ExternalCloudProviderExternal ExternalCloudProviderGCP ExternalOIDC ExternalRouteCertificate GCPClusterHostedDNS GCPLabelsTags GatewayAPI HardwareSpeed ImagePolicy InsightsConfig InsightsConfigAPI InsightsOnDemandDataGather InstallAlternateInfrastructureAWS KMSv1 MachineAPIOperatorDisableMachineHealthCheckController MachineAPIProviderOpenStack MachineConfigNodes ManagedBootImages MaxUnavailableStatefulSet MetricsCollectionProfiles MetricsServer MixedCPUsAllocation NetworkDiagnosticsConfig NetworkLiveMigration NewOLM NodeDisruptionPolicy NodeSwap OnClusterBuild OpenShiftPodSecurityAdmission PinnedImages PlatformOperators PrivateHostedZoneAWS RouteExternalCertificate ServiceAccountTokenNodeBinding ServiceAccountTokenNodeBindingValidation ServiceAccountTokenPodNodeInfo SignatureStores SigstoreImageVerification TranslateStreamCloseWebsocketRequests UpgradeStatus VSphereControlPlaneMachineSet VSphereDriverConfiguration VSphereMultiVCenters VSphereStaticIPs ValidatingAdmissionPolicy VolumeGroupSnapshot]
2024-06-11T10:49:46.891233795Z I0611 10:49:46.891171       1 base_controller.go:67] Waiting for caches to sync for GarbageCollectorWatcherController
2024-06-11T10:49:46.892183334Z I0611 10:49:46.892123       1 base_controller.go:67] Waiting for caches to sync for ResourceSyncController
2024-06-11T10:49:46.892426543Z I0611 10:49:46.892384       1 base_controller.go:67] Waiting for caches to sync for CertRotationController
2024-06-11T10:49:46.892523247Z I0611 10:49:46.892419       1 base_controller.go:67] Waiting for caches to sync for MissingStaticPodController
2024-06-11T10:49:46.892587450Z I0611 10:49:46.892357       1 base_controller.go:67] Waiting for caches to sync for WorkerLatencyProfile
2024-06-11T10:49:46.892654753Z I0611 10:49:46.892631       1 base_controller.go:67] Waiting for caches to sync for PruneController
2024-06-11T10:49:46.892722055Z I0611 10:49:46.892331       1 base_controller.go:67] Waiting for caches to sync for SATokenSignerController
2024-06-11T10:49:46.894691235Z I0611 10:49:46.894641       1 base_controller.go:67] Waiting for caches to sync for ConfigObserver
2024-06-11T10:49:46.894691235Z I0611 10:49:46.894665       1 base_controller.go:67] Waiting for caches to sync for TargetConfigController
2024-06-11T10:49:46.894691235Z I0611 10:49:46.894675       1 base_controller.go:67] Waiting for caches to sync for LoggingSyncer
2024-06-11T10:49:46.894691235Z I0611 10:49:46.894683       1 base_controller.go:67] Waiting for caches to sync for NodeController
2024-06-11T10:49:46.894728637Z I0611 10:49:46.894693       1 base_controller.go:67] Waiting for caches to sync for UnsupportedConfigOverridesController
2024-06-11T10:49:46.894728637Z I0611 10:49:46.894702       1 base_controller.go:67] Waiting for caches to sync for RevisionController
2024-06-11T10:49:46.894728637Z I0611 10:49:46.894710       1 base_controller.go:67] Waiting for caches to sync for InstallerStateController
2024-06-11T10:49:46.894939845Z I0611 10:49:46.894894       1 base_controller.go:67] Waiting for caches to sync for KubeControllerManagerStaticResources
2024-06-11T10:49:46.895006548Z I0611 10:49:46.894896       1 base_controller.go:67] Waiting for caches to sync for GuardController
2024-06-11T10:49:46.895056850Z I0611 10:49:46.894903       1 base_controller.go:67] Waiting for caches to sync for StaticPodStateController
2024-06-11T10:49:46.895104152Z I0611 10:49:46.894998       1 base_controller.go:67] Waiting for caches to sync for BackingResourceController
2024-06-11T10:49:46.895146854Z I0611 10:49:46.895059       1 base_controller.go:67] Waiting for caches to sync for InstallerController
2024-06-11T10:49:46.895186355Z I0611 10:49:46.895095       1 base_controller.go:67] Waiting for caches to sync for StatusSyncer_kube-controller-manager
2024-06-11T10:49:46.961334639Z I0611 10:49:46.961261       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-06-11T10:49:46.961373741Z I0611 10:49:46.961357       1 shared_informer.go:318] Caches are synced for RequestHeaderAuthRequestController
2024-06-11T10:49:46.961398142Z I0611 10:49:46.961365       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-06-11T10:49:46.991636769Z I0611 10:49:46.991582       1 base_controller.go:73] Caches are synced for GarbageCollectorWatcherController 
2024-06-11T10:49:46.991636769Z I0611 10:49:46.991606       1 base_controller.go:110] Starting #1 worker of GarbageCollectorWatcherController controller ...
2024-06-11T10:49:46.995023006Z I0611 10:49:46.994971       1 base_controller.go:73] Caches are synced for PruneController 
2024-06-11T10:49:46.995023006Z I0611 10:49:46.994996       1 base_controller.go:110] Starting #1 worker of PruneController controller ...
2024-06-11T10:49:46.995060607Z I0611 10:49:46.995026       1 base_controller.go:73] Caches are synced for LoggingSyncer 
2024-06-11T10:49:46.995060607Z I0611 10:49:46.995040       1 base_controller.go:110] Starting #1 worker of LoggingSyncer controller ...
2024-06-11T10:49:46.995086709Z I0611 10:49:46.995062       1 base_controller.go:73] Caches are synced for UnsupportedConfigOverridesController 
2024-06-11T10:49:46.995086709Z I0611 10:49:46.995081       1 base_controller.go:110] Starting #1 worker of UnsupportedConfigOverridesController controller ...
2024-06-11T10:49:46.995442323Z I0611 10:49:46.995416       1 base_controller.go:73] Caches are synced for StatusSyncer_kube-controller-manager 
2024-06-11T10:49:46.995442323Z I0611 10:49:46.995435       1 base_controller.go:110] Starting #1 worker of StatusSyncer_kube-controller-manager controller ...
2024-06-11T10:49:46.995649931Z I0611 10:49:46.995624       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:49:47.089563042Z I0611 10:49:47.089488       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:47.289167440Z I0611 10:49:47.289115       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:47.488667534Z I0611 10:49:47.488600       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:47.689203270Z I0611 10:49:47.689148       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:47.888952974Z I0611 10:49:47.888878       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:47.893573861Z I0611 10:49:47.893534       1 base_controller.go:73] Caches are synced for CertRotationController 
2024-06-11T10:49:47.893573861Z I0611 10:49:47.893551       1 base_controller.go:110] Starting #1 worker of CertRotationController controller ...
2024-06-11T10:49:48.087095513Z I0611 10:49:48.087025       1 request.go:697] Waited for 1.192496081s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/nodes?limit=500&resourceVersion=0
2024-06-11T10:49:48.089927527Z I0611 10:49:48.089870       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:48.095776965Z I0611 10:49:48.095727       1 base_controller.go:73] Caches are synced for NodeController 
2024-06-11T10:49:48.095776965Z I0611 10:49:48.095751       1 base_controller.go:110] Starting #1 worker of NodeController controller ...
2024-06-11T10:49:48.290190552Z I0611 10:49:48.290128       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:48.294015207Z I0611 10:49:48.293958       1 base_controller.go:73] Caches are synced for SATokenSignerController 
2024-06-11T10:49:48.294015207Z I0611 10:49:48.293985       1 base_controller.go:110] Starting #1 worker of SATokenSignerController controller ...
2024-06-11T10:49:48.489764149Z I0611 10:49:48.489707       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:48.495601386Z I0611 10:49:48.495547       1 base_controller.go:73] Caches are synced for BackingResourceController 
2024-06-11T10:49:48.495601386Z I0611 10:49:48.495568       1 base_controller.go:110] Starting #1 worker of BackingResourceController controller ...
2024-06-11T10:49:48.689382148Z I0611 10:49:48.689312       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:48.695589000Z I0611 10:49:48.695502       1 base_controller.go:73] Caches are synced for InstallerController 
2024-06-11T10:49:48.695589000Z I0611 10:49:48.695544       1 base_controller.go:110] Starting #1 worker of InstallerController controller ...
2024-06-11T10:49:48.695589000Z I0611 10:49:48.695542       1 base_controller.go:73] Caches are synced for InstallerStateController 
2024-06-11T10:49:48.695589000Z I0611 10:49:48.695570       1 base_controller.go:110] Starting #1 worker of InstallerStateController controller ...
2024-06-11T10:49:48.695642602Z I0611 10:49:48.695509       1 base_controller.go:73] Caches are synced for StaticPodStateController 
2024-06-11T10:49:48.695642602Z I0611 10:49:48.695629       1 base_controller.go:110] Starting #1 worker of StaticPodStateController controller ...
2024-06-11T10:49:48.695642602Z I0611 10:49:48.695509       1 base_controller.go:73] Caches are synced for GuardController 
2024-06-11T10:49:48.695656503Z I0611 10:49:48.695646       1 base_controller.go:110] Starting #1 worker of GuardController controller ...
2024-06-11T10:49:48.696079620Z E0611 10:49:48.696042       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:48.696079620Z E0611 10:49:48.696073       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:48.696102021Z E0611 10:49:48.696091       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:48.696283128Z I0611 10:49:48.696224       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4
2024-06-11T10:49:48.696491936Z E0611 10:49:48.696463       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:48.701743149Z E0611 10:49:48.701704       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:48.701743149Z E0611 10:49:48.701735       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:48.701769050Z E0611 10:49:48.701753       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:48.702024561Z E0611 10:49:48.702005       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:48.712973005Z E0611 10:49:48.712935       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4]
2024-06-11T10:49:48.713114511Z E0611 10:49:48.713085       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:48.713131711Z E0611 10:49:48.713121       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:48.713156513Z E0611 10:49:48.713147       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:48.713963845Z E0611 10:49:48.713868       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4]
2024-06-11T10:49:48.714027248Z I0611 10:49:48.714005       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:49:48.714142553Z I0611 10:49:48.714095       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4
2024-06-11T10:49:48.714835181Z I0611 10:49:48.714784       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4]","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:21Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:49:48.715130193Z E0611 10:49:48.715089       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:48.719041551Z I0611 10:49:48.718983       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4
2024-06-11T10:49:48.719167456Z E0611 10:49:48.719131       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4]
2024-06-11T10:49:48.725294205Z I0611 10:49:48.723594       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: configmaps: client-ca" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4]"
2024-06-11T10:49:48.736134245Z E0611 10:49:48.736079       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:48.736134245Z E0611 10:49:48.736113       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:48.736164546Z E0611 10:49:48.736132       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:48.736418856Z E0611 10:49:48.736392       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:48.740693330Z I0611 10:49:48.740641       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4
2024-06-11T10:49:48.740826935Z E0611 10:49:48.740793       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4]
2024-06-11T10:49:48.777433620Z E0611 10:49:48.777362       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:48.777433620Z E0611 10:49:48.777424       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:48.777477022Z E0611 10:49:48.777440       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:48.777709832Z E0611 10:49:48.777647       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:48.781879001Z I0611 10:49:48.781805       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4
2024-06-11T10:49:48.782024307Z E0611 10:49:48.781993       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4]
2024-06-11T10:49:48.858890725Z E0611 10:49:48.858031       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:48.858890725Z E0611 10:49:48.858081       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:48.858890725Z E0611 10:49:48.858106       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:48.859681657Z E0611 10:49:48.859638       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:48.863362007Z E0611 10:49:48.862900       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: [configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4]
2024-06-11T10:49:48.863519513Z I0611 10:49:48.863454       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4
2024-06-11T10:49:48.889334560Z E0611 10:49:48.889237       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:48.889445265Z E0611 10:49:48.889424       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:48.889503767Z E0611 10:49:48.889489       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:48.889989287Z E0611 10:49:48.889955       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:48.905546918Z I0611 10:49:48.905481       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:48.993060569Z I0611 10:49:48.992982       1 base_controller.go:73] Caches are synced for ResourceSyncController 
2024-06-11T10:49:48.993060569Z I0611 10:49:48.993045       1 base_controller.go:110] Starting #1 worker of ResourceSyncController controller ...
2024-06-11T10:49:48.993136372Z I0611 10:49:48.993095       1 base_controller.go:73] Caches are synced for WorkerLatencyProfile 
2024-06-11T10:49:48.993160773Z I0611 10:49:48.993133       1 base_controller.go:110] Starting #1 worker of WorkerLatencyProfile controller ...
2024-06-11T10:49:48.993169373Z I0611 10:49:48.993108       1 base_controller.go:73] Caches are synced for MissingStaticPodController 
2024-06-11T10:49:48.993177573Z I0611 10:49:48.993167       1 base_controller.go:110] Starting #1 worker of MissingStaticPodController controller ...
2024-06-11T10:49:48.995134353Z I0611 10:49:48.995089       1 base_controller.go:73] Caches are synced for RevisionController 
2024-06-11T10:49:48.995134353Z I0611 10:49:48.995106       1 base_controller.go:110] Starting #1 worker of RevisionController controller ...
2024-06-11T10:49:48.995174054Z I0611 10:49:48.995130       1 base_controller.go:73] Caches are synced for ConfigObserver 
2024-06-11T10:49:48.995174054Z I0611 10:49:48.995142       1 base_controller.go:110] Starting #1 worker of ConfigObserver controller ...
2024-06-11T10:49:49.020876497Z E0611 10:49:49.020826       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:49.020911498Z E0611 10:49:49.020874       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:49.020911498Z E0611 10:49:49.020892       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:49.021210611Z E0611 10:49:49.021185       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:49.024312736Z I0611 10:49:49.024228       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca
2024-06-11T10:49:49.040330486Z E0611 10:49:49.040257       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: configmaps: client-ca
2024-06-11T10:49:49.041616638Z I0611 10:49:49.041565       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:49:49.042225963Z I0611 10:49:49.042178       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: configmaps: client-ca","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:21Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:49:49.043669622Z E0611 10:49:49.043626       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: configmaps: client-ca
2024-06-11T10:49:49.044554958Z I0611 10:49:49.044497       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca
2024-06-11T10:49:49.057189570Z I0611 10:49:49.054595       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: [configmaps: aggregator-client-ca,client-ca, configmaps: cluster-policy-controller-config-4,config-4,controller-manager-kubeconfig-4,kube-controller-cert-syncer-kubeconfig-4,kube-controller-manager-pod-4,recycler-config-4,service-ca-4,serviceaccount-ca-4]" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: configmaps: client-ca"
2024-06-11T10:49:49.087463299Z I0611 10:49:49.087399       1 request.go:697] Waited for 2.192390448s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces?limit=500&resourceVersion=0
2024-06-11T10:49:49.090687529Z I0611 10:49:49.090636       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:49:49.095685032Z I0611 10:49:49.095444       1 base_controller.go:73] Caches are synced for TargetConfigController 
2024-06-11T10:49:49.095685032Z I0611 10:49:49.095465       1 base_controller.go:110] Starting #1 worker of TargetConfigController controller ...
2024-06-11T10:49:49.095757135Z I0611 10:49:49.095721       1 base_controller.go:73] Caches are synced for KubeControllerManagerStaticResources 
2024-06-11T10:49:49.095757135Z I0611 10:49:49.095750       1 base_controller.go:110] Starting #1 worker of KubeControllerManagerStaticResources controller ...
2024-06-11T10:49:49.361936134Z E0611 10:49:49.361872       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: configmaps: client-ca
2024-06-11T10:49:49.361978236Z I0611 10:49:49.361925       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca
2024-06-11T10:49:49.662409225Z E0611 10:49:49.662348       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:49.662409225Z E0611 10:49:49.662399       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:49.662464027Z E0611 10:49:49.662428       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:49.662852043Z E0611 10:49:49.662817       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:50.287632191Z I0611 10:49:50.287549       1 request.go:697] Waited for 1.183911632s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2024-06-11T10:49:50.490064804Z I0611 10:49:50.489985       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:49:50.490330614Z E0611 10:49:50.490264       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:49:50.643412225Z I0611 10:49:50.643339       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca
2024-06-11T10:49:50.643586332Z E0611 10:49:50.643556       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: configmaps: client-ca
2024-06-11T10:49:50.809609368Z E0611 10:49:50.809557       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:50.809699572Z E0611 10:49:50.809685       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:50.809755474Z E0611 10:49:50.809741       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:50.810246094Z E0611 10:49:50.810211       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:50.944045522Z E0611 10:49:50.943973       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:50.944045522Z E0611 10:49:50.944011       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:50.944045522Z E0611 10:49:50.944029       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:50.944318233Z E0611 10:49:50.944266       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:52.290413746Z I0611 10:49:52.290315       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:49:52.290764960Z E0611 10:49:52.290588       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:49:52.497244834Z E0611 10:49:52.497187       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:52.497369240Z E0611 10:49:52.497342       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:52.497463544Z E0611 10:49:52.497424       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:52.497896864Z E0611 10:49:52.497830       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:53.204642701Z I0611 10:49:53.204569       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca
2024-06-11T10:49:53.204796508Z E0611 10:49:53.204761       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: configmaps: client-ca
2024-06-11T10:49:53.242781525Z E0611 10:49:53.242696       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:53.242968133Z E0611 10:49:53.242921       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:53.243093139Z E0611 10:49:53.243064       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:53.243784970Z E0611 10:49:53.243729       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:53.889207970Z I0611 10:49:53.889133       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:49:53.889386777Z E0611 10:49:53.889351       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:49:55.290188638Z I0611 10:49:55.290104       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:49:55.290442449Z E0611 10:49:55.290410       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:49:55.831502502Z E0611 10:49:55.828891       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:55.831502502Z E0611 10:49:55.828942       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:55.831502502Z E0611 10:49:55.828974       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:55.831502502Z E0611 10:49:55.829370       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:56.065714311Z E0611 10:49:56.065647       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:56.065714311Z E0611 10:49:56.065708       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:56.065793214Z E0611 10:49:56.065740       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:56.066361539Z E0611 10:49:56.066294       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:56.090178067Z I0611 10:49:56.090110       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:49:56.090257070Z E0611 10:49:56.090220       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:49:56.890761221Z I0611 10:49:56.890666       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:49:56.891020632Z E0611 10:49:56.890935       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:49:57.689873812Z I0611 10:49:57.689771       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:49:57.689998717Z E0611 10:49:57.689951       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:49:58.325686154Z I0611 10:49:58.325606       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca
2024-06-11T10:49:58.325750757Z E0611 10:49:58.325704       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: configmaps: client-ca
2024-06-11T10:49:58.490064549Z I0611 10:49:58.489961       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:49:58.490130052Z E0611 10:49:58.490072       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:49:58.913938944Z E0611 10:49:58.913246       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:49:58.913938944Z E0611 10:49:58.913311       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:49:58.913938944Z E0611 10:49:58.913340       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:49:58.917222486Z E0611 10:49:58.917156       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:49:59.289896371Z I0611 10:49:59.289814       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:49:59.290034077Z E0611 10:49:59.290007       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:50:00.090038706Z E0611 10:50:00.089966       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:50:00.090093509Z I0611 10:50:00.090028       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:50:00.836552927Z E0611 10:50:00.836492       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:00.837554670Z E0611 10:50:00.837510       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:00.837603072Z E0611 10:50:00.837557       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:00.837980289Z E0611 10:50:00.837942       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:01.290355214Z I0611 10:50:01.290268       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:50:01.290690228Z E0611 10:50:01.290645       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:50:02.401836332Z E0611 10:50:02.397594       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:02.401836332Z E0611 10:50:02.397655       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:02.401836332Z E0611 10:50:02.397690       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:02.401836332Z E0611 10:50:02.398129       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:06.417230477Z I0611 10:50:06.417144       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:50:06.417369980Z E0611 10:50:06.417288       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:50:08.566840712Z I0611 10:50:08.566751       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'RequiredInstallerResourcesMissing' configmaps: client-ca
2024-06-11T10:50:08.566978418Z E0611 10:50:08.566950       1 base_controller.go:268] InstallerController reconciliation failed: missing required resources: configmaps: client-ca
2024-06-11T10:50:09.689428883Z E0611 10:50:09.686495       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:09.689428883Z E0611 10:50:09.686551       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:09.689428883Z E0611 10:50:09.686583       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:09.689428883Z E0611 10:50:09.687004       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:15.196529956Z E0611 10:50:15.196466       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:50:15.196674763Z I0611 10:50:15.196626       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:50:15.196810969Z I0611 10:50:15.196770       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/client-ca -n openshift-kube-controller-manager because it was missing
2024-06-11T10:50:17.787442700Z I0611 10:50:17.787366       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:50:17.787785015Z E0611 10:50:17.787730       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:50:18.787973157Z I0611 10:50:18.787878       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:50:18.788163666Z E0611 10:50:18.788114       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:50:21.119070513Z I0611 10:50:21.119007       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: configmaps: client-ca","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:21Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:21.131201769Z I0611 10:50:21.131139       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded changed from False to True ("GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: configmaps: client-ca")
2024-06-11T10:50:21.265510125Z I0611 10:50:21.265406       1 core.go:359] ConfigMap "openshift-kube-controller-manager/serviceaccount-ca" changes: {"data":{"ca-bundle.crt":"-----BEGIN CERTIFICATE-----\nMIIDMjCCAhqgAwIBAgIIOZgkPKjiSXMwDQYJKoZIhvcNAQELBQAwNzESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSEwHwYDVQQDExhrdWJlLWFwaXNlcnZlci1sYi1zaWduZXIw\nHhcNMjQwNjExMTAxOTAxWhcNMzQwNjA5MTAxOTAxWjA3MRIwEAYDVQQLEwlvcGVu\nc2hpZnQxITAfBgNVBAMTGGt1YmUtYXBpc2VydmVyLWxiLXNpZ25lcjCCASIwDQYJ\nKoZIhvcNAQEBBQADggEPADCCAQoCggEBAOMNJQ31plTY73mhN9xkeDKdBtdIMt+4\n7WAaFY8heeQdmlZfUZkZsjl1pvSugZ/hZcRXumQ3K1tdB+cKZOTKJQgPzIzOETHM\nbt0kQ6oQoul19LaT3suFT2TJ9vqNRK6fCd4IQOpLgmg51h3lBfcDz42Dd6vCWWjt\nmlGbLWsDXV0//db2PNdLlSPljFaqPdUJ60cE9eQwdzvDiTZkjN0wm4Cal/QRPmN6\nwm66FafdJAmGNhKqz23eR/KpNvf5UfZjvWXiCAgPH1okpIQswSIdPBCp3lrkftga\nXLqeX48BEJAU2+X5IZjzihzDyPngyHxiH4cXz/x6WKPpoEvdsabiCB8CAwEAAaNC\nMEAwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB/wQFMAMBAf8wHQYDVR0OBBYEFAFe\n+hvToOpBQ1OjZmFKflYn87mGMA0GCSqGSIb3DQEBCwUAA4IBAQDdgDIWYEqHNCNx\nfVGa+5Sgh4qE/rKsILCAPKjFtvSWg5jkfTyTyZgig6ikby1xA8gVjL1dHy6jGv2g\n2RV8zavt9HBLSSHM/Gz+85dADsot5aE+fypMx3TQuFvxXNytcqE8TI1GUroQnwp4\nCEXcRaPJ3Tt9bqS3yJuPcwdREhUFjEdMO9ZFbVUk94tPsZ07tfPvaCTCrikf8Occ\nEmIBN0ahylZk8dw9OmKw3wtYgoLAeLfTFxNYTdVb1VYei4AK/yC29f8/skrwAPBX\n/9TNA9p5xnRtyaa9mYbO20LdfED7m4PsHzCw0U0XjqDvOosN/Xi1xD5ZxKsDRuxj\nEpPdHinx\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDQDCCAiigAwIBAgIIK/muZYsht/cwDQYJKoZIhvcNAQELBQAwPjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSgwJgYDVQQDEx9rdWJlLWFwaXNlcnZlci1sb2NhbGhvc3Qt\nc2lnbmVyMB4XDTI0MDYxMTEwMTkwMVoXDTM0MDYwOTEwMTkwMVowPjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSgwJgYDVQQDEx9rdWJlLWFwaXNlcnZlci1sb2NhbGhvc3Qt\nc2lnbmVyMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA4iXHckm/7n1U\nQUlmnOPjm6Co/1q/cl/cWJRtsdAMvd9V5hsKehnPJ4Q4mDCQ3rkpz7fagNbHSEvO\nP9rAjEI6Bgzwbo+JAwMqDelN7CbEO9p2AW2ciuXQX2OhMow+13NBbbZxa8UHZcqG\n2rh+yRv/SIYT+A/WotWCQZwQJc9JiGsK1q1oLe5kNNr/2sCjVe3o63Tf74TTMC52\nAY1rDbnhrsx2VKB3JMV2XcQS5k9IxZbFPLJWzvGM2t4zZBnu0U9hN4JtzArsNSgl\nb3LiKAC6PCLV3kCVGbXlOiTykOTyNq3lhARHJzd5Lm6cN+uXywmVtj+QE45pgfbJ\nyroFyOiOZwIDAQABo0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB\n/zAdBgNVHQ4EFgQUUZKSa8GUZ9qjiL/E7pSges35z4AwDQYJKoZIhvcNAQELBQAD\nggEBAC6QwBuPhM8F+wB5zqt9ldzYXOzzlVy7u1+4agEvTlfz0vB7l2Bi22rFEimw\nhEXsmuZhVIJxgGNWVqLbg2dr8ax1QZ/gPeXqZXJY8wz0kzlNQB3tERBlxCQhIIoa\ncuQipYTA51C7WEoIQQc68+HrPmmHnhBbFw5LZbN6k6jRmLFotg7RCtjZLDS+2bxw\nqZT0YencAZMBVpvDoDZyW4HEdUd4bzrmK2p1DUNkMlZuSR+Rjjp8CLz+0ikveesK\ncGanBxN+oW1OzlVyaCI2Epu+aagPwHbUUFdlw7hsyNc5lofab+nfm2ViHZhZwBcj\nA0LSVVmltDG7jfi0Xj49ug51mUA=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDTDCCAjSgAwIBAgIINO0yAMSHeFcwDQYJKoZIhvcNAQELBQAwRDESMBAGA1UE\nCxMJb3BlbnNoaWZ0MS4wLAYDVQQDEyVrdWJlLWFwaXNlcnZlci1zZXJ2aWNlLW5l\ndHdvcmstc2lnbmVyMB4XDTI0MDYxMTEwMTkwMVoXDTM0MDYwOTEwMTkwMVowRDES\nMBAGA1UECxMJb3BlbnNoaWZ0MS4wLAYDVQQDEyVrdWJlLWFwaXNlcnZlci1zZXJ2\naWNlLW5ldHdvcmstc2lnbmVyMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKC\nAQEA3PLsu6vfUb4qCKyXxaExvUXWGRiUrV3b1BiEvyER08XIovGzpHDQ41aD7mxT\nw1+mjW19MsSWD8XXLHaj8ad6GiZ3aNJ2iIAp6PGATQrKWY+LlOFnSrk21XArYOx3\n8HNx6kjgFdQOs3A4unbbCBNQh3MTbnJXfUaSDNBEYY+QMWaHSAoQPVThS4VcD6rI\nF8d7GG726ogUuAM4eDum3b7Dw6h9xZWFHS9A3L/05S1jD/p6r/E7BghRNRvvJsSm\nM78c68fQmygMIwAHYV0iQTXYzFl4qeMovCUTlm933P56flpghXTLbV858pJEiVKq\neInZ6QWrH4oEp1Wvduxsm6I3AQIDAQABo0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYD\nVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUxgNzyToLk4YHrryxwHRdCi1YVZ4wDQYJ\nKoZIhvcNAQELBQADggEBACMEI0/eYMPlJf/TKVlQh+8zuFaqsmV4SEo4bcz2QR/5\nytw7cC3W87lCAJ+yhWLF0c8ddjn2EgckASE97MVEvdY7z/JqD48tzS4MTBzKu5V6\n7g4qX0N8sPG8i7fKeB5VIdtpvk1THhwpJBgAYeRs2Vt3oR3hts38Hunf1Fm1Iq9a\nuC2a63NTfI5SFAg2jiICuokbdPcRSJWQhufS5vwBR5rTAoyP2iVJLtHrtPp+2+Fq\nO7G4qMDY8M8sVOsmTLnuXdoS7z+j9bwMGhYZG3xW3nvgEFLUEtB62OjM/8YQGzKj\n8PBR8CmLd/3Zz8/Bf4nIwJ9bB9acCCYHXh2Vr23X0sE=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDlzCCAn+gAwIBAgIIEtJWch74/5wwDQYJKoZIhvcNAQELBQAwWTFXMFUGA1UE\nAwxOb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9wZXJhdG9yX2xvY2FsaG9zdC1y\nZWNvdmVyeS1zZXJ2aW5nLXNpZ25lckAxNzE4MTAyOTAzMB4XDTI0MDYxMTEwNDgy\nMloXDTM0MDYwOTEwNDgyM1owWTFXMFUGA1UEAwxOb3BlbnNoaWZ0LWt1YmUtYXBp\nc2VydmVyLW9wZXJhdG9yX2xvY2FsaG9zdC1yZWNvdmVyeS1zZXJ2aW5nLXNpZ25l\nckAxNzE4MTAyOTAzMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA2gfY\nieeA1s5yIPIyr4nreolJtWJU316iq04zgL77CwCJSCLdqovBxvSFgaprS5Cd+V3+\n7w3t5JrZ+/o1DeVfvMGcQdeYG0ruYp6tPAqzbV9huKjXNC4B1tipWTWL0xKfjfol\nVJJ+idbKQQm5cFg0q4MgwG8gT0B8sfJr7Tnz9pfjmUffcTqHk9xkq8A6ba+HnWc+\nAA5iZl7fmGUAtIRwaFHDZgMTGER7Hy7iY6DlaZhga2tHwk2srdj80gxFDutzIDXm\nDQla8I2ZEoEVbWZndub5JPpl0OrVc1l6JZ1Zo4dKz0Dg9ef9vd/AKTinVx+9sFUy\nXKBsbJnqWssuUNMYbwIDAQABo2MwYTAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/\nBAUwAwEB/zAdBgNVHQ4EFgQUVC5qGhSPlvXcUxjPlGQx5kRN+JAwHwYDVR0jBBgw\nFoAUVC5qGhSPlvXcUxjPlGQx5kRN+JAwDQYJKoZIhvcNAQELBQADggEBADlCo4YF\naa3VGBLnkAvygstPOaeCRAeUXTVPeFeo6IgkrNBrkR2l1lP3cmH2XhGfxEbTILxT\nenFFwDjhM1zm4LsygLqA9FC08TzWuQyS1uDOajvLaXxtam6s6d3N6nDAElZzuwh2\n19XYLGEFWxgs1Pt71KoN16kVdPW/rVFgCPFyn0CVTjbPeoPSmqgJbsqyK/Rs2VOR\n4segDUoBmTmGYAsBx0Kq9BuOAAtfaA7UlluIQ8q5qrGd9xQ/3s8qmCV+syah0ljJ\nX0/Z2S0DrWBqX5bzkR6i6vzUg/ACMt+5B/j++NCyqs03ls862GD7AeiP8jaS51a2\nVBPno2MjcbkakiI=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDsTCCApmgAwIBAgIIdCvH9RE3lzgwDQYJKoZIhvcNAQELBQAwJjEkMCIGA1UE\nAwwbaW5ncmVzcy1vcGVyYXRvckAxNzE4MTAyOTYzMB4XDTI0MDYxMTEwNDkyNFoX\nDTI2MDYxMTEwNDkyNVowSDFGMEQGA1UEAww9Ki5hcHBzLmNpLW9wLTl4eDcxcnZx\nLTFlMjhlLnFlLmF6dXJlLmRldmNsdXN0ZXIub3BlbnNoaWZ0LmNvbTCCASIwDQYJ\nKoZIhvcNAQEBBQADggEPADCCAQoCggEBAMEXt7td5wBAHJLibHXL3j6/zeypnUlZ\nzFwfnYhxHFpmHdDXkj4+8yXVj/asJOtL9gTHh9VqNwnSr1slC+yq16+KEQPMGiwc\nZ94MpCUV4zNHTHqxCXOHWFCmQ+gXZXExRpWnZXN6jzUv29dCax/XJ+xA+Rre2Aly\nB45hkmfnDx3tggIcypQoFG3MMJVZxktKJZA/W9R/rRcQyYHRvIaWD96CNzaApjnR\nZ9l+FJ3U8zXEb2jUeNH9oa2/t2zPc5JOwaHFG0xaTPyTIif77qES6XbaqJgco6zr\ncCfim6/w6/9oaYcz9MD6cR1hGAoxokGphkazISMxL3UroLA+SFZ/cj8CAwEAAaOB\nwDCBvTAOBgNVHQ8BAf8EBAMCBaAwEwYDVR0lBAwwCgYIKwYBBQUHAwEwDAYDVR0T\nAQH/BAIwADAdBgNVHQ4EFgQUxxTcJW1j1SIm1srEoxJRfxoYXv0wHwYDVR0jBBgw\nFoAU0EJZY45sDzwQHJ9Fbs4J0+5YQXAwSAYDVR0RBEEwP4I9Ki5hcHBzLmNpLW9w\nLTl4eDcxcnZxLTFlMjhlLnFlLmF6dXJlLmRldmNsdXN0ZXIub3BlbnNoaWZ0LmNv\nbTANBgkqhkiG9w0BAQsFAAOCAQEAJyrM8ojm2I0nTliQ9ax/wRX5mFQ9rB00O/Oo\nGIeyObuNTQPkyxEjAr7s/Gdh0FriZMZbfYj1LeEg9kwjRsufzZqxvpLmJxMPFZxp\nol4n8LNctWlYIWWG4KH2edc6c/pvBaxOJC9R0MgnjuNqPfvrKAk1OcNada1QQF4H\nPHJGeDSR2nBUBJj8WTLD9EbAaXkuiK2hf6xBBKsn3+Eu8wOVtphxs7CpPj3bwZsM\nn5N7IqLMaE9exNFXVMd+0tALBpte6UmpRG7YpAzNkDSCVHVTR9H+KdpdPmTyZ8Al\n+LGjhyal9KyTiDFwlwUa3hnK2P3w4Q0EjH7jRBj85bALW2454w==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDDDCCAfSgAwIBAgIBATANBgkqhkiG9w0BAQsFADAmMSQwIgYDVQQDDBtpbmdy\nZXNzLW9wZXJhdG9yQDE3MTgxMDI5NjMwHhcNMjQwNjExMTA0OTIzWhcNMjYwNjEx\nMTA0OTI0WjAmMSQwIgYDVQQDDBtpbmdyZXNzLW9wZXJhdG9yQDE3MTgxMDI5NjMw\nggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDWuPsQsmr2xRHEfP71JdYl\n0GBQDYw3/OmIHjvzE6uOfM1PAGtVQ482iExzYG0AIJq5AFMr7L3+XJuPdaDiudWu\n2+x32AOlFayWaWzBnbIqkdT1Gmotprgj5qXnCVI2maXzsQbJwefEFMfjkq0+4hs0\nK1y5aKQKqgNP8cl4OdENL3J7B1AJT4i3zqHB7Uu1li72TYRs0K68+IVN37GdBFi4\nkpdpOLTjE+akA2mg7A9MbC5gZsIN0hfbBNxhkPRf8137YfajsfCCxMLbjb94mW5M\npcNZAfMnrFTMgAX3ADOckuw2EndjLmPyRjQHDplJrcjF4TxQ83IReEZRNcvvXN1v\nAgMBAAGjRTBDMA4GA1UdDwEB/wQEAwICpDASBgNVHRMBAf8ECDAGAQH/AgEAMB0G\nA1UdDgQWBBTQQlljjmwPPBAcn0VuzgnT7lhBcDANBgkqhkiG9w0BAQsFAAOCAQEA\nUjk7rdAYEprDClAOKLCbnuv1FiAFrZgSp+JHHxujTTupCisSmcLeShXtg9g0DJ+l\nae2bW9ukn4UVTrXjIXgurE98HhOXf+7+VGDlFehPcfBNvwHr9vbOI1TXfyB0bPov\nm4YAfVVY7XEH9yDCqzPIWuEfPyBlY1/k+XPezEoMukrAT5d49nuBdtqsIN3cQEN9\n+0HTffr3BEZcxBdDAhp2/tpmxwPWcC4G4W9V/ptCKBoYDarSzCUViTvEV2VpC8Yl\nv24kgR5RgQWWaLN1jUI6lxZtcUVelHV98UBTpjhNPXPEVjzWhUzxLcPjwJXfLPyA\nCCnuScmLsxK+fnsBo6WM0Q==\n-----END CERTIFICATE-----\n"},"metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:50:21.265799439Z I0611 10:50:21.265739       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/serviceaccount-ca -n openshift-kube-controller-manager:
2024-06-11T10:50:21.265799439Z cause by changes in data.ca-bundle.crt
2024-06-11T10:50:21.269426905Z I0611 10:50:21.269370       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 5 triggered by "required configmap/serviceaccount-ca has changed"
2024-06-11T10:50:22.397537417Z I0611 10:50:22.397462       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-5 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:50:22.997836234Z I0611 10:50:22.997744       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-5 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:50:23.592030771Z I0611 10:50:23.591937       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-5 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:50:23.936828776Z E0611 10:50:23.936770       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:23.939520300Z E0611 10:50:23.936904       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:23.939520300Z E0611 10:50:23.936941       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:23.939520300Z E0611 10:50:23.937327       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:24.190341497Z I0611 10:50:24.190234       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-5 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:50:24.790700617Z I0611 10:50:24.790626       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-5 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:50:25.393784762Z I0611 10:50:25.393675       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-5 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:50:25.995609875Z I0611 10:50:25.995519       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-5 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:50:27.350417550Z I0611 10:50:27.350349       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-5 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:50:27.664339966Z I0611 10:50:27.664226       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-5 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:50:27.687282156Z I0611 10:50:27.687212       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-5 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:50:27.810196796Z E0611 10:50:27.810134       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:50:27.810959332Z I0611 10:50:27.810280       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:50:28.393022589Z I0611 10:50:28.392934       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-5 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:50:29.190859799Z I0611 10:50:29.190775       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 5 triggered by "required configmap/serviceaccount-ca has changed"
2024-06-11T10:50:29.211519381Z I0611 10:50:29.211442       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 5 created because required configmap/serviceaccount-ca has changed
2024-06-11T10:50:29.213484074Z I0611 10:50:29.213431       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:29.231528031Z W0611 10:50:29.231477       1 staticpod.go:38] revision 5 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T10:50:29.231528031Z E0611 10:50:29.231517       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 5
2024-06-11T10:50:29.387994366Z I0611 10:50:29.387903       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:50:29.388195875Z E0611 10:50:29.388138       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:50:29.988140682Z I0611 10:50:29.988082       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-0 static pod not found and needs new revision 4
2024-06-11T10:50:29.988199985Z I0611 10:50:29.988141       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:50:29.988199985Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:50:29.988199985Z  CurrentRevision: (int32) 0,
2024-06-11T10:50:29.988199985Z  TargetRevision: (int32) 4,
2024-06-11T10:50:29.988199985Z  LastFailedRevision: (int32) 0,
2024-06-11T10:50:29.988199985Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:50:29.988199985Z  LastFailedReason: (string) "",
2024-06-11T10:50:29.988199985Z  LastFailedCount: (int) 0,
2024-06-11T10:50:29.988199985Z  LastFallbackCount: (int) 0,
2024-06-11T10:50:29.988199985Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:50:29.988199985Z }
2024-06-11T10:50:30.006701164Z I0611 10:50:30.006622       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 0 to 4 because node ci-op-9xx71rvq-1e28e-w667k-master-0 static pod not found
2024-06-11T10:50:30.013765100Z I0611 10:50:30.013713       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:30.015079862Z I0611 10:50:30.015011       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: configmaps: client-ca","reason":"GuardController_SyncError::InstallerController_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:21Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:30.026518106Z I0611 10:50:30.026455       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 4" to "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5",Available message changed from "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 4" to "StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5"
2024-06-11T10:50:30.051808307Z I0611 10:50:30.051739       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:30.052442737Z I0611 10:50:30.052391       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:21Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:50:30.065687667Z I0611 10:50:30.064494       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nInstallerControllerDegraded: missing required resources: configmaps: client-ca" to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]"
2024-06-11T10:50:30.384653623Z I0611 10:50:30.384591       1 request.go:697] Waited for 1.170439114s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T10:50:31.384718041Z I0611 10:50:31.384656       1 request.go:697] Waited for 1.194213544s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:31.787556182Z I0611 10:50:31.787471       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:50:31.788003203Z E0611 10:50:31.787948       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:50:32.387806803Z I0611 10:50:32.387735       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:50:32.387806803Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:50:32.387806803Z  CurrentRevision: (int32) 0,
2024-06-11T10:50:32.387806803Z  TargetRevision: (int32) 5,
2024-06-11T10:50:32.387806803Z  LastFailedRevision: (int32) 0,
2024-06-11T10:50:32.387806803Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:50:32.387806803Z  LastFailedReason: (string) "",
2024-06-11T10:50:32.387806803Z  LastFailedCount: (int) 0,
2024-06-11T10:50:32.387806803Z  LastFallbackCount: (int) 0,
2024-06-11T10:50:32.387806803Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:50:32.387806803Z }
2024-06-11T10:50:32.387806803Z  because new revision pending
2024-06-11T10:50:32.411209415Z I0611 10:50:32.411152       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:50:32.586374638Z I0611 10:50:32.586315       1 request.go:697] Waited for 1.194576761s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:32.870930359Z E0611 10:50:32.870865       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:32.872188619Z E0611 10:50:32.872124       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:32.872188619Z E0611 10:50:32.872172       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:32.872557336Z E0611 10:50:32.872505       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:33.784245255Z I0611 10:50:33.784172       1 request.go:697] Waited for 1.19287348s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:33.988064489Z I0611 10:50:33.987981       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:50:33.988259097Z E0611 10:50:33.988212       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:50:34.587830139Z I0611 10:50:34.587764       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:50:34.587830139Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:50:34.587830139Z  CurrentRevision: (int32) 0,
2024-06-11T10:50:34.587830139Z  TargetRevision: (int32) 5,
2024-06-11T10:50:34.587830139Z  LastFailedRevision: (int32) 0,
2024-06-11T10:50:34.587830139Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:50:34.587830139Z  LastFailedReason: (string) "",
2024-06-11T10:50:34.587830139Z  LastFailedCount: (int) 0,
2024-06-11T10:50:34.587830139Z  LastFallbackCount: (int) 0,
2024-06-11T10:50:34.587830139Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:50:34.587830139Z }
2024-06-11T10:50:34.587830139Z  because new revision pending
2024-06-11T10:50:36.000180377Z E0611 10:50:36.000110       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:50:36.000704200Z I0611 10:50:36.000585       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:50:36.594686202Z E0611 10:50:36.594632       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:36.594800307Z E0611 10:50:36.594764       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:36.594800307Z E0611 10:50:36.594793       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:36.594935913Z I0611 10:50:36.594893       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:50:36.595110520Z E0611 10:50:36.595083       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:36.603170666Z E0611 10:50:36.603107       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:36.603170666Z E0611 10:50:36.603150       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:36.603217468Z E0611 10:50:36.603175       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:36.603560583Z E0611 10:50:36.603527       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:36.618230213Z E0611 10:50:36.618190       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:36.618273614Z E0611 10:50:36.618235       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:36.618273614Z E0611 10:50:36.618264       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:36.618648731Z E0611 10:50:36.618608       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:37.120591481Z E0611 10:50:37.120524       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:37.120591481Z E0611 10:50:37.120560       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:37.120669584Z E0611 10:50:37.120585       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:37.120952297Z E0611 10:50:37.120906       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:37.188195284Z I0611 10:50:37.188126       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 5, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:50:38.984351400Z I0611 10:50:38.984267       1 request.go:697] Waited for 1.093567351s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T10:50:39.388229740Z I0611 10:50:39.388170       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 5, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:50:40.067170089Z E0611 10:50:40.065072       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:40.067170089Z E0611 10:50:40.065130       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:40.067170089Z E0611 10:50:40.065160       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:40.067170089Z E0611 10:50:40.065554       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:41.538348153Z E0611 10:50:41.538150       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:41.538348153Z E0611 10:50:41.538199       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:41.538348153Z E0611 10:50:41.538228       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:41.538654966Z E0611 10:50:41.538587       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:43.188553850Z I0611 10:50:43.188482       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:50:47.357472550Z E0611 10:50:47.357407       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:47.358514197Z E0611 10:50:47.358477       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:47.358656103Z E0611 10:50:47.358637       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:47.359072922Z E0611 10:50:47.359040       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:48.301849930Z E0611 10:50:48.301786       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:50:48.302040538Z I0611 10:50:48.301968       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:50:52.383019857Z E0611 10:50:52.382959       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:52.383174664Z E0611 10:50:52.383154       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:52.383235567Z E0611 10:50:52.383221       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:52.383677486Z E0611 10:50:52.383641       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:54.357747649Z E0611 10:50:54.357685       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:54.357904955Z E0611 10:50:54.357876       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:54.357973758Z E0611 10:50:54.357958       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:54.358442479Z E0611 10:50:54.358402       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:50:57.387360310Z E0611 10:50:57.386262       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:50:57.387360310Z E0611 10:50:57.386347       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:50:57.387360310Z E0611 10:50:57.386376       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:50:57.387360310Z E0611 10:50:57.386774       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:01.499554938Z I0611 10:51:01.499454       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:51:01.499837550Z E0611 10:51:01.499724       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:51:03.816666497Z E0611 10:51:03.816602       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:03.817720942Z E0611 10:51:03.817687       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:03.817805546Z E0611 10:51:03.817792       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:03.818240765Z E0611 10:51:03.818219       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:08.475990436Z E0611 10:51:08.475905       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:08.475990436Z E0611 10:51:08.475951       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:08.475990436Z E0611 10:51:08.475974       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:08.476605263Z E0611 10:51:08.476361       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:08.483039248Z E0611 10:51:08.482234       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:08.483039248Z E0611 10:51:08.482289       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:08.483039248Z E0611 10:51:08.482340       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:08.483039248Z E0611 10:51:08.482718       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:09.610344106Z E0611 10:51:09.607854       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:09.610344106Z E0611 10:51:09.607908       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:09.610344106Z E0611 10:51:09.607935       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:09.610344106Z E0611 10:51:09.608376       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:10.832920785Z E0611 10:51:10.832855       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:10.833188997Z E0611 10:51:10.833145       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:10.833292202Z E0611 10:51:10.833271       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:10.833839326Z E0611 10:51:10.833801       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:13.730267583Z E0611 10:51:13.730189       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:13.730267583Z E0611 10:51:13.730226       1 guard_controller.go:293] Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 on node ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:13.730267583Z E0611 10:51:13.730255       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:13.737780716Z I0611 10:51:13.737725       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:13.739208280Z I0611 10:51:13.739160       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-controller-manager version "kube-controller-manager" changed from "" to "1.29.5"
2024-06-11T10:51:13.739208280Z I0611 10:51:13.739191       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorVersionChanged' clusteroperator/kube-controller-manager version "operator" changed from "" to "4.16.0-0.nightly-2024-06-10-211334"
2024-06-11T10:51:13.739456591Z I0611 10:51:13.739427       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"versions":[{"name":"raw-internal","version":"4.16.0-0.nightly-2024-06-10-211334"},{"name":"kube-controller-manager","version":"1.29.5"},{"name":"operator","version":"4.16.0-0.nightly-2024-06-10-211334"}]}}
2024-06-11T10:51:13.753229901Z E0611 10:51:13.753176       1 base_controller.go:268] GuardController reconciliation failed: [Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:13.753568016Z I0611 10:51:13.753497       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: status.versions changed from [{"raw-internal" "4.16.0-0.nightly-2024-06-10-211334"}] to [{"raw-internal" "4.16.0-0.nightly-2024-06-10-211334"} {"kube-controller-manager" "1.29.5"} {"operator" "4.16.0-0.nightly-2024-06-10-211334"}]
2024-06-11T10:51:13.755231990Z I0611 10:51:13.755191       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:13.756047126Z I0611 10:51:13.756009       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:21Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:51:13.767345427Z I0611 10:51:13.765990       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]" to "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]"
2024-06-11T10:51:14.333269651Z I0611 10:51:14.333155       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:51:14.333509962Z E0611 10:51:14.333471       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:51:14.930730760Z I0611 10:51:14.930572       1 request.go:697] Waited for 1.127831157s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-06-11T10:51:15.332820671Z I0611 10:51:15.332762       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:16.130909117Z I0611 10:51:16.130849       1 request.go:697] Waited for 1.194390094s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-06-11T10:51:17.329950523Z I0611 10:51:17.329887       1 request.go:697] Waited for 1.195075525s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-06-11T10:51:17.537446973Z W0611 10:51:17.537374       1 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
2024-06-11T10:51:17.537577579Z E0611 10:51:17.537532       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:17.537577579Z E0611 10:51:17.537565       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:17.537748187Z I0611 10:51:17.537678       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:51:17.559742288Z E0611 10:51:17.559688       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:17.566841612Z I0611 10:51:17.566769       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:21Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:51:17.567071022Z I0611 10:51:17.567022       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:17.579967809Z I0611 10:51:17.579892       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 on node ci-op-9xx71rvq-1e28e-w667k-master-0, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]"
2024-06-11T10:51:18.330356883Z I0611 10:51:18.330251       1 request.go:697] Waited for 1.196423986s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller
2024-06-11T10:51:19.334840729Z I0611 10:51:19.334775       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:51:19.529955414Z I0611 10:51:19.529895       1 request.go:697] Waited for 1.596329699s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:19.571521407Z I0611 10:51:19.571455       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: ","reason":"GuardController_SyncError::StaticPods_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:21Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:51:19.571744418Z I0611 10:51:19.571688       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:19.590918891Z I0611 10:51:19.588994       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]" to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: "
2024-06-11T10:51:20.334552757Z I0611 10:51:20.334478       1 core.go:227] Pod "openshift-kube-controller-manager/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:95cb052ed20a9c01d1029497da60445a5425edcc6a6f642ebed4f1d5c3411d51","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.8","path":"healthz","port":10257,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-06-11T10:51:20.530562283Z I0611 10:51:20.530426       1 request.go:697] Waited for 1.396816013s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/default/endpoints/kubernetes
2024-06-11T10:51:20.536742365Z I0611 10:51:20.536652       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:51:20.536905372Z E0611 10:51:20.536867       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:51:21.730448528Z I0611 10:51:21.730381       1 request.go:697] Waited for 1.596614412s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-06-11T10:51:21.944027750Z E0611 10:51:21.943937       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:21.944027750Z E0611 10:51:21.943987       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:21.944111067Z I0611 10:51:21.944015       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-controller-manager because it changed
2024-06-11T10:51:21.944460835Z E0611 10:51:21.944423       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:22.930495356Z I0611 10:51:22.930422       1 request.go:697] Waited for 1.385838872s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2024-06-11T10:51:23.533820654Z I0611 10:51:23.533733       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:51:23.533926275Z E0611 10:51:23.533896       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:51:23.734028545Z I0611 10:51:23.733960       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:51:23.950267765Z I0611 10:51:23.950207       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:23.951525610Z I0611 10:51:23.951470       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:48:21Z","message":"StaticPodsAvailable: 0 nodes are active; 3 nodes are at revision 0; 0 nodes have achieved new revision 5","reason":"StaticPods_ZeroNodesActive","status":"False","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:51:23.965447929Z I0611 10:51:23.965387       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: " to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]"
2024-06-11T10:51:24.130350726Z I0611 10:51:24.130242       1 request.go:697] Waited for 1.396251215s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/csr-signer
2024-06-11T10:51:24.537611443Z E0611 10:51:24.537528       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:24.537611443Z E0611 10:51:24.537565       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:24.537873594Z E0611 10:51:24.537826       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:25.130824466Z I0611 10:51:25.130753       1 request.go:697] Waited for 1.180232538s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T10:51:26.330202843Z I0611 10:51:26.330138       1 request.go:697] Waited for 1.596032923s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:51:26.733660317Z I0611 10:51:26.733574       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:51:26.733766638Z E0611 10:51:26.733746       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:51:27.330859719Z I0611 10:51:27.330803       1 request.go:697] Waited for 1.397481456s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa
2024-06-11T10:51:27.533147515Z E0611 10:51:27.533081       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:27.533147515Z E0611 10:51:27.533119       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:27.533477680Z E0611 10:51:27.533447       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:27.734000732Z I0611 10:51:27.733945       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:51:29.534074482Z E0611 10:51:29.534020       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:29.534074482Z E0611 10:51:29.534054       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:29.534361195Z E0611 10:51:29.534338       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:30.533696946Z I0611 10:51:30.533635       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:51:35.533593621Z E0611 10:51:35.533529       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:35.533649624Z E0611 10:51:35.533638       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:35.534064642Z E0611 10:51:35.534039       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:36.533232909Z I0611 10:51:36.533164       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:51:36.533232909Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:51:36.533232909Z  CurrentRevision: (int32) 5,
2024-06-11T10:51:36.533232909Z  TargetRevision: (int32) 0,
2024-06-11T10:51:36.533232909Z  LastFailedRevision: (int32) 0,
2024-06-11T10:51:36.533232909Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:51:36.533232909Z  LastFailedReason: (string) "",
2024-06-11T10:51:36.533232909Z  LastFailedCount: (int) 0,
2024-06-11T10:51:36.533232909Z  LastFallbackCount: (int) 0,
2024-06-11T10:51:36.533232909Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:51:36.533232909Z }
2024-06-11T10:51:36.533232909Z  because static pod is ready
2024-06-11T10:51:36.551156909Z I0611 10:51:36.551068       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 0 to 5 because static pod is ready
2024-06-11T10:51:36.552923188Z I0611 10:51:36.552871       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:51:36.553392408Z I0611 10:51:36.553345       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:36.568879699Z I0611 10:51:36.568796       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 3 nodes are at revision 0; 0 nodes have achieved new revision 5" to "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 5",Available changed from False to True ("StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 5")
2024-06-11T10:51:36.934116390Z E0611 10:51:36.934043       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:36.934116390Z E0611 10:51:36.934090       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:36.934443005Z E0611 10:51:36.934414       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:37.730454810Z I0611 10:51:37.730391       1 request.go:697] Waited for 1.17724001s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T10:51:38.532932370Z I0611 10:51:38.532873       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-1 static pod not found and needs new revision 5
2024-06-11T10:51:38.532932370Z I0611 10:51:38.532924       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T10:51:38.532932370Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T10:51:38.532932370Z  CurrentRevision: (int32) 0,
2024-06-11T10:51:38.532932370Z  TargetRevision: (int32) 5,
2024-06-11T10:51:38.532932370Z  LastFailedRevision: (int32) 0,
2024-06-11T10:51:38.532932370Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:51:38.532932370Z  LastFailedReason: (string) "",
2024-06-11T10:51:38.532932370Z  LastFailedCount: (int) 0,
2024-06-11T10:51:38.532932370Z  LastFallbackCount: (int) 0,
2024-06-11T10:51:38.532932370Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:51:38.532932370Z }
2024-06-11T10:51:38.550718279Z I0611 10:51:38.550660       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:51:38.552544064Z I0611 10:51:38.552439       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 0 to 5 because node ci-op-9xx71rvq-1e28e-w667k-master-1 static pod not found
2024-06-11T10:51:38.734230487Z I0611 10:51:38.734137       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:51:38.734479216Z E0611 10:51:38.734390       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:51:39.730960167Z I0611 10:51:39.730881       1 request.go:697] Waited for 1.178628199s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:40.739615489Z I0611 10:51:40.739527       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:51:40.933057717Z I0611 10:51:40.932975       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:51:40.933202224Z E0611 10:51:40.933150       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:51:41.930358276Z I0611 10:51:41.930260       1 request.go:697] Waited for 1.190723787s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:41.933692933Z I0611 10:51:41.933645       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:51:42.930564573Z I0611 10:51:42.930504       1 request.go:697] Waited for 1.196017536s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-06-11T10:51:43.333613891Z E0611 10:51:43.333551       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:43.333613891Z E0611 10:51:43.333586       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:43.334042811Z E0611 10:51:43.333985       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:43.930778869Z I0611 10:51:43.930716       1 request.go:697] Waited for 1.190669784s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider
2024-06-11T10:51:44.334294710Z I0611 10:51:44.334210       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:45.130694090Z I0611 10:51:45.130624       1 request.go:697] Waited for 1.184566596s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2024-06-11T10:51:45.535078471Z E0611 10:51:45.534997       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:45.535078471Z E0611 10:51:45.535052       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:45.535417787Z E0611 10:51:45.535380       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:51:46.334017891Z I0611 10:51:46.333954       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:51:49.733343912Z I0611 10:51:49.733152       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:51:49.733343912Z E0611 10:51:49.733260       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:51:50.130456225Z I0611 10:51:50.130387       1 request.go:697] Waited for 1.033405042s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2024-06-11T10:51:55.260728999Z E0611 10:51:55.260645       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:51:55.932929533Z E0611 10:51:55.932869       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:51:55.933181087Z E0611 10:51:55.933148       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:52:09.511086825Z I0611 10:52:09.511006       1 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:00 +0000 UTC to 2034-06-09 10:19:00 +0000 UTC (now=2024-06-11 10:52:09.510940698 +0000 UTC))"
2024-06-11T10:52:09.511086825Z I0611 10:52:09.511060       1 tlsconfig.go:178] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2024-06-12 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.511044717 +0000 UTC))"
2024-06-11T10:52:09.511135634Z I0611 10:52:09.511097       1 tlsconfig.go:178] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2025-06-11 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.511072723 +0000 UTC))"
2024-06-11T10:52:09.511150637Z I0611 10:52:09.511131       1 tlsconfig.go:178] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2025-06-11 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.51111013 +0000 UTC))"
2024-06-11T10:52:09.511167040Z I0611 10:52:09.511160       1 tlsconfig.go:178] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:01 +0000 UTC to 2034-06-09 10:19:01 +0000 UTC (now=2024-06-11 10:52:09.511147036 +0000 UTC))"
2024-06-11T10:52:09.511240554Z I0611 10:52:09.511198       1 tlsconfig.go:178] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1718102903\" [] issuer=\"kubelet-signer\" (2024-06-11 10:48:22 +0000 UTC to 2024-06-12 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.511170941 +0000 UTC))"
2024-06-11T10:52:09.511288763Z I0611 10:52:09.511240       1 tlsconfig.go:178] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1718102900\" [] issuer=\"<self>\" (2024-06-11 10:48:20 +0000 UTC to 2025-06-11 10:48:21 +0000 UTC (now=2024-06-11 10:52:09.51121805 +0000 UTC))"
2024-06-11T10:52:09.511288763Z I0611 10:52:09.511274       1 tlsconfig.go:178] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:02 +0000 UTC to 2024-06-12 10:19:02 +0000 UTC (now=2024-06-11 10:52:09.511252656 +0000 UTC))"
2024-06-11T10:52:09.511867771Z I0611 10:52:09.511823       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/var/run/secrets/serving-cert/tls.crt::/var/run/secrets/serving-cert/tls.key" certDetail="\"metrics.openshift-kube-controller-manager-operator.svc\" [serving] validServingFor=[metrics.openshift-kube-controller-manager-operator.svc,metrics.openshift-kube-controller-manager-operator.svc.cluster.local] issuer=\"openshift-service-serving-signer@1718102902\" (2024-06-11 10:48:33 +0000 UTC to 2026-06-11 10:48:34 +0000 UTC (now=2024-06-11 10:52:09.511796958 +0000 UTC))"
2024-06-11T10:52:09.512371566Z I0611 10:52:09.512265       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1718102986\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1718102986\" (2024-06-11 09:49:46 +0000 UTC to 2025-06-11 09:49:46 +0000 UTC (now=2024-06-11 10:52:09.512241341 +0000 UTC))"
2024-06-11T10:52:14.625331415Z E0611 10:52:14.625254       1 guard_controller.go:293] Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:14.625392226Z E0611 10:52:14.625328       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:14.626600641Z I0611 10:52:14.626555       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:52:14.641844853Z E0611 10:52:14.641794       1 base_controller.go:268] GuardController reconciliation failed: [Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:52:14.642901341Z I0611 10:52:14.642856       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:14.646073005Z I0611 10:52:14.646005       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:52:14.660864736Z I0611 10:52:14.660810       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]" to "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]"
2024-06-11T10:52:15.419322367Z I0611 10:52:15.419217       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:52:15.419473394Z E0611 10:52:15.419439       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:52:15.816551035Z I0611 10:52:15.816486       1 request.go:697] Waited for 1.130936795s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2024-06-11T10:52:16.019099969Z I0611 10:52:16.019039       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:52:17.016380587Z I0611 10:52:17.016287       1 request.go:697] Waited for 1.196620181s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager
2024-06-11T10:52:17.619473378Z E0611 10:52:17.619412       1 guard_controller.go:293] Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:17.619473378Z E0611 10:52:17.619449       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:17.619762729Z E0611 10:52:17.619734       1 base_controller.go:268] GuardController reconciliation failed: [Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]
2024-06-11T10:52:17.620057282Z E0611 10:52:17.620027       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:17.838839303Z I0611 10:52:17.838775       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:17.839435910Z I0611 10:52:17.839384       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: ","reason":"GuardController_SyncError::StaticPods_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:52:17.851322524Z I0611 10:52:17.849165       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]" to "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: "
2024-06-11T10:52:18.016647244Z I0611 10:52:18.016578       1 request.go:697] Waited for 1.182437565s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/cluster-policy-controller-config
2024-06-11T10:52:19.016656399Z I0611 10:52:19.016588       1 request.go:697] Waited for 1.178936693s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:20.028628479Z I0611 10:52:20.028554       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:52:20.217653429Z I0611 10:52:20.216479       1 request.go:697] Waited for 1.39631495s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:20.618857034Z I0611 10:52:20.618786       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:52:20.619269411Z E0611 10:52:20.619208       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:52:21.416388038Z I0611 10:52:21.416285       1 request.go:697] Waited for 1.195956593s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:23.219515036Z I0611 10:52:23.219440       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:52:23.427081033Z W0611 10:52:23.426903       1 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
2024-06-11T10:52:23.427956996Z I0611 10:52:23.427595       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:52:23.449369378Z E0611 10:52:23.449182       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:23.455985808Z I0611 10:52:23.455929       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:23.457059208Z I0611 10:52:23.456995       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: ","reason":"GuardController_SyncError::StaticPods_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:52:23.471464787Z I0611 10:52:23.471376       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 on node ci-op-9xx71rvq-1e28e-w667k-master-1, Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: " to "GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: "
2024-06-11T10:52:24.616248963Z I0611 10:52:24.616157       1 request.go:697] Waited for 1.166186956s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:25.815996161Z I0611 10:52:25.815911       1 request.go:697] Waited for 1.591441934s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-06-11T10:52:26.627537091Z I0611 10:52:26.627454       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:52:26.627839046Z E0611 10:52:26.627774       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:52:26.816388385Z I0611 10:52:26.816328       1 request.go:697] Waited for 1.57281817s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:27.419495603Z I0611 10:52:27.419408       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:52:28.016858778Z I0611 10:52:28.016800       1 request.go:697] Waited for 1.38878699s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T10:52:29.019479644Z I0611 10:52:29.019403       1 core.go:227] Pod "openshift-kube-controller-manager/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:95cb052ed20a9c01d1029497da60445a5425edcc6a6f642ebed4f1d5c3411d51","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.6","path":"healthz","port":10257,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"qosClass":null,"startTime":null}}
2024-06-11T10:52:29.216028936Z I0611 10:52:29.215968       1 request.go:697] Waited for 1.390281261s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T10:52:29.419630008Z I0611 10:52:29.419548       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:52:29.419749429Z E0611 10:52:29.419703       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:52:30.416226680Z I0611 10:52:30.416164       1 request.go:697] Waited for 1.596093835s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:30.623891090Z E0611 10:52:30.623813       1 guard_controller.go:359] Unable to apply pod kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1 changes: Operation cannot be fulfilled on pods "kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:52:30.623891090Z E0611 10:52:30.623869       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:30.624434288Z I0611 10:52:30.624361       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'PodUpdateFailed' Failed to update Pod/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-controller-manager: Operation cannot be fulfilled on pods "kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:52:30.649257796Z E0611 10:52:30.649198       1 base_controller.go:268] GuardController reconciliation failed: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2, Unable to apply pod kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1 changes: Operation cannot be fulfilled on pods "kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1": the object has been modified; please apply your changes to the latest version and try again]
2024-06-11T10:52:30.652104013Z I0611 10:52:30.652038       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2, Unable to apply pod kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1 changes: Operation cannot be fulfilled on pods \"kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1\": the object has been modified; please apply your changes to the latest version and try again]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: ","reason":"GuardController_SyncError::StaticPods_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:52:30.653830526Z I0611 10:52:30.653773       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:30.677686859Z I0611 10:52:30.677624       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: " to "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2, Unable to apply pod kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1 changes: Operation cannot be fulfilled on pods \"kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1\": the object has been modified; please apply your changes to the latest version and try again]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: "
2024-06-11T10:52:31.616537144Z I0611 10:52:31.616475       1 request.go:697] Waited for 1.388804593s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider
2024-06-11T10:52:31.821378542Z I0611 10:52:31.821317       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:52:32.419383534Z I0611 10:52:32.419282       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:52:32.419650582Z E0611 10:52:32.419620       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:52:32.616636053Z I0611 10:52:32.616581       1 request.go:697] Waited for 1.597593807s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:33.419872713Z I0611 10:52:33.419815       1 core.go:227] Pod "openshift-kube-controller-manager/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:95cb052ed20a9c01d1029497da60445a5425edcc6a6f642ebed4f1d5c3411d51","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.6","path":"healthz","port":10257,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-06-11T10:52:33.816254392Z I0611 10:52:33.816189       1 request.go:697] Waited for 1.196473268s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:34.626291636Z E0611 10:52:34.626201       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:34.627020763Z I0611 10:52:34.626941       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-controller-manager because it changed
2024-06-11T10:52:34.816350069Z I0611 10:52:34.816249       1 request.go:697] Waited for 1.196195689s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/default/endpoints/kubernetes
2024-06-11T10:52:34.819592733Z I0611 10:52:34.819498       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:52:34.819776165Z E0611 10:52:34.819721       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:52:35.819568434Z I0611 10:52:35.819504       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:52:36.016395044Z I0611 10:52:36.016339       1 request.go:697] Waited for 1.389050025s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:37.016625290Z I0611 10:52:37.016551       1 request.go:697] Waited for 1.195764831s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:37.236004319Z E0611 10:52:37.235936       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:37.237571992Z I0611 10:52:37.237518       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:37.238828910Z I0611 10:52:37.238766       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: ","reason":"GuardController_SyncError::StaticPods_Error","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:52:37.258972211Z I0611 10:52:37.258876       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: [Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2, Unable to apply pod kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1 changes: Operation cannot be fulfilled on pods \"kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1\": the object has been modified; please apply your changes to the latest version and try again]\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: " to "GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: "
2024-06-11T10:52:37.438484012Z I0611 10:52:37.438268       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:37.438669844Z I0611 10:52:37.438617       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:52:37.450083728Z I0611 10:52:37.450023       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"cluster-policy-controller\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is waiting: ContainerCreating: \nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-recovery-controller\" is waiting: ContainerCreating: " to "GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2"
2024-06-11T10:52:38.416735537Z I0611 10:52:38.416676       1 request.go:697] Waited for 1.179402687s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T10:52:39.419159965Z I0611 10:52:39.419093       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:52:39.616203512Z I0611 10:52:39.616141       1 request.go:697] Waited for 1.396727959s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:40.019054930Z I0611 10:52:40.018981       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:52:40.019254265Z E0611 10:52:40.019223       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:52:40.616714807Z I0611 10:52:40.616662       1 request.go:697] Waited for 1.387306022s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider
2024-06-11T10:52:41.815765709Z I0611 10:52:41.815704       1 request.go:697] Waited for 1.183401582s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2024-06-11T10:52:42.219706489Z E0611 10:52:42.219640       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:42.219934028Z E0611 10:52:42.219904       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:42.419090826Z I0611 10:52:42.419013       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:52:42.419312564Z E0611 10:52:42.419246       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:52:42.791728099Z E0611 10:52:42.791245       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:42.816833622Z I0611 10:52:42.816781       1 request.go:697] Waited for 1.198102659s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps/csr-signer-ca
2024-06-11T10:52:43.218992680Z I0611 10:52:43.218934       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 5, but has not made progress because static pod is pending
2024-06-11T10:52:46.015953254Z I0611 10:52:46.015872       1 request.go:697] Waited for 1.07523147s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:46.220274941Z E0611 10:52:46.220205       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:47.016288426Z I0611 10:52:47.016220       1 request.go:697] Waited for 1.196928828s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:48.219105867Z I0611 10:52:48.218981       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T10:52:48.219105867Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T10:52:48.219105867Z  CurrentRevision: (int32) 5,
2024-06-11T10:52:48.219105867Z  TargetRevision: (int32) 0,
2024-06-11T10:52:48.219105867Z  LastFailedRevision: (int32) 0,
2024-06-11T10:52:48.219105867Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:52:48.219105867Z  LastFailedReason: (string) "",
2024-06-11T10:52:48.219105867Z  LastFailedCount: (int) 0,
2024-06-11T10:52:48.219105867Z  LastFallbackCount: (int) 0,
2024-06-11T10:52:48.219105867Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:52:48.219105867Z }
2024-06-11T10:52:48.219105867Z  because static pod is ready
2024-06-11T10:52:48.237245091Z I0611 10:52:48.237167       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 0 to 5 because static pod is ready
2024-06-11T10:52:48.238515710Z I0611 10:52:48.238475       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:48.239277841Z I0611 10:52:48.239232       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 5","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 5","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:52:48.253662719Z I0611 10:52:48.250223       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 0; 1 node is at revision 5" to "NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 5",Available message changed from "StaticPodsAvailable: 1 nodes are active; 2 nodes are at revision 0; 1 node is at revision 5" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 5"
2024-06-11T10:52:49.415749346Z I0611 10:52:49.415653       1 request.go:697] Waited for 1.177036101s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-apiserver/pods?labelSelector=app%3Dopenshift-kube-apiserver
2024-06-11T10:52:50.416712764Z I0611 10:52:50.416622       1 request.go:697] Waited for 1.597035971s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:51.019984154Z I0611 10:52:51.019864       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:52:51.020173285Z E0611 10:52:51.020108       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:52:51.419497641Z E0611 10:52:51.419439       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:51.419821194Z E0611 10:52:51.419783       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:51.616708164Z I0611 10:52:51.616638       1 request.go:697] Waited for 1.596922596s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2024-06-11T10:52:52.019220646Z I0611 10:52:52.019162       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-2 static pod not found and needs new revision 5
2024-06-11T10:52:52.019275755Z I0611 10:52:52.019213       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T10:52:52.019275755Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T10:52:52.019275755Z  CurrentRevision: (int32) 0,
2024-06-11T10:52:52.019275755Z  TargetRevision: (int32) 5,
2024-06-11T10:52:52.019275755Z  LastFailedRevision: (int32) 0,
2024-06-11T10:52:52.019275755Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:52:52.019275755Z  LastFailedReason: (string) "",
2024-06-11T10:52:52.019275755Z  LastFailedCount: (int) 0,
2024-06-11T10:52:52.019275755Z  LastFallbackCount: (int) 0,
2024-06-11T10:52:52.019275755Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:52:52.019275755Z }
2024-06-11T10:52:52.037638583Z I0611 10:52:52.037233       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-2" from revision 0 to 5 because node ci-op-9xx71rvq-1e28e-w667k-master-2 static pod not found
2024-06-11T10:52:52.038590140Z I0611 10:52:52.038523       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:52:53.216517602Z I0611 10:52:53.216395       1 request.go:697] Waited for 1.177848548s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T10:52:53.419193627Z I0611 10:52:53.419110       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:52:53.419421764Z E0611 10:52:53.419386       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:52:54.216786764Z I0611 10:52:54.216724       1 request.go:697] Waited for 1.196444615s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:52:55.220839650Z I0611 10:52:55.220776       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-2 static pod not found and needs new revision 5
2024-06-11T10:52:55.220902761Z I0611 10:52:55.220833       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T10:52:55.220902761Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T10:52:55.220902761Z  CurrentRevision: (int32) 0,
2024-06-11T10:52:55.220902761Z  TargetRevision: (int32) 5,
2024-06-11T10:52:55.220902761Z  LastFailedRevision: (int32) 0,
2024-06-11T10:52:55.220902761Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:52:55.220902761Z  LastFailedReason: (string) "",
2024-06-11T10:52:55.220902761Z  LastFailedCount: (int) 0,
2024-06-11T10:52:55.220902761Z  LastFallbackCount: (int) 0,
2024-06-11T10:52:55.220902761Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:52:55.220902761Z }
2024-06-11T10:52:55.420270740Z I0611 10:52:55.420195       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerStuck' unexpected addresses: 10.0.0.5
2024-06-11T10:52:55.420517281Z E0611 10:52:55.420481       1 base_controller.go:268] SATokenSignerController reconciliation failed: unexpected addresses: 10.0.0.5
2024-06-11T10:52:57.029883794Z I0611 10:52:57.029779       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:52:57.030185744Z E0611 10:52:57.030145       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:52:57.824404825Z I0611 10:52:57.824338       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:52:58.216556492Z I0611 10:52:58.216488       1 request.go:697] Waited for 1.185794965s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:52:59.416645126Z I0611 10:52:59.416570       1 request.go:697] Waited for 1.196836838s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:53:00.219477783Z I0611 10:53:00.219414       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:53:01.220060741Z E0611 10:53:01.219992       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:03.216023724Z I0611 10:53:03.215956       1 request.go:697] Waited for 1.085082925s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-5-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:04.219469765Z I0611 10:53:04.219392       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 5, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:53:04.818697076Z E0611 10:53:04.818645       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:04.818962122Z E0611 10:53:04.818936       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:06.819932880Z E0611 10:53:06.819860       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:06.820262524Z E0611 10:53:06.820221       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:07.819404667Z E0611 10:53:07.819344       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:07.819668602Z E0611 10:53:07.819643       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:20.023711353Z I0611 10:53:20.023641       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 6 triggered by "required secret/localhost-recovery-client-token has changed"
2024-06-11T10:53:20.044806031Z I0611 10:53:20.044687       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-6 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:53:20.044851938Z I0611 10:53:20.044822       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SATokenSignerControllerOK' found expected kube-apiserver endpoints
2024-06-11T10:53:20.052599979Z I0611 10:53:20.052530       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-6 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:53:20.063108362Z I0611 10:53:20.063045       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-6 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:53:20.227752729Z I0611 10:53:20.227684       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-6 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:53:20.833328511Z I0611 10:53:20.829884       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-6 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:53:21.434009908Z I0611 10:53:21.433816       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-6 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:53:22.030012756Z I0611 10:53:22.029922       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-6 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:53:22.628575377Z I0611 10:53:22.628439       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-6 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:53:23.229172791Z I0611 10:53:23.229027       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-6 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:53:23.631759565Z I0611 10:53:23.631637       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/next-service-account-private-key -n openshift-kube-controller-manager-operator because it was missing
2024-06-11T10:53:24.030932322Z I0611 10:53:24.030825       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-6 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:53:24.433156141Z I0611 10:53:24.433094       1 core.go:359] ConfigMap "openshift-config-managed/sa-token-signing-certs" changes: {"data":{"service-account-002.pub":"-----BEGIN RSA PUBLIC KEY-----\nMIICIjANBgkqhkiG9w0BAQEFAAOCAg8AMIICCgKCAgEA0lLI821QC67Q8wCCu+Bi\n0XYC8PIijizmrIkTu/OIeel1Oi4uwDQRTZq3dKfe+ZT6B/ZdcSPu8TeWgnj+igi2\n80OphuevFy+H9avbc0LsIlj09boksG8wnTy01/aTR3+/c7+eRfhdOypceFc/U5P6\nL2e887/YtExUHXhfxLs54G+iblGnEdGwe8ba3EGIVTb7vaF/kgHb9WRO0/YNAUS3\niyaoFjL5tfchOZN6XKrC9WE3TDbpq/fb0we0hMB8b4ukwJrrjY2mYY11vQDp/qur\niFw53Wema+X1Pf/u14xZuWMbMHbIES1FNCGRSX6Ko9xuXESp3nX9IFl+f39wj3xn\nENPpdLmxZ7MZDLIub35gd/FbDYeiyQFAYNCK/RmzQmqbkmDQ7UCticorTPi7X4OZ\nLVtCVHsjg60gcX2+iDmSLLEDafjjSPlfUSnve0MAWcPuhe2D4GoRrO5bNO07VhEH\nDpLi7Mck0h+X0FRz76ioiQBLOtOe6c8moWwyh5v6nBZIrVmVN5VoGMW74cF53bPj\nBtJdA/FCFdiYH817O6Df25I19ZxLJRl1QyDgJibf+4kXOvvx7QeLN5wd7rhttRcZ\nBfQY/BHaDKrln5lpgureRaZuomtXh1lgbWEQq2vF80PWGrnvmyQ5a+fM77kpLDHR\nroj9Xizndq8Dl79EiZXarosCAwEAAQ==\n-----END RSA PUBLIC KEY-----\n"}}
2024-06-11T10:53:24.434840696Z I0611 10:53:24.434775       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/sa-token-signing-certs -n openshift-config-managed:
2024-06-11T10:53:24.434840696Z cause by changes in data.service-account-002.pub
2024-06-11T10:53:24.831363853Z I0611 10:53:24.831275       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-6 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:53:25.432251111Z I0611 10:53:25.431916       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 6 triggered by "required secret/localhost-recovery-client-token has changed"
2024-06-11T10:53:25.456212434Z I0611 10:53:25.456123       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 6 created because required secret/localhost-recovery-client-token has changed
2024-06-11T10:53:25.462197839Z I0611 10:53:25.462141       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:53:25.475057684Z W0611 10:53:25.474982       1 staticpod.go:38] revision 6 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T10:53:25.475057684Z E0611 10:53:25.475031       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 6
2024-06-11T10:53:27.231397854Z I0611 10:53:27.231322       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T10:53:27.231397854Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T10:53:27.231397854Z  CurrentRevision: (int32) 0,
2024-06-11T10:53:27.231397854Z  TargetRevision: (int32) 6,
2024-06-11T10:53:27.231397854Z  LastFailedRevision: (int32) 0,
2024-06-11T10:53:27.231397854Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:53:27.231397854Z  LastFailedReason: (string) "",
2024-06-11T10:53:27.231397854Z  LastFailedCount: (int) 0,
2024-06-11T10:53:27.231397854Z  LastFallbackCount: (int) 0,
2024-06-11T10:53:27.231397854Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:53:27.231397854Z }
2024-06-11T10:53:27.231397854Z  because new revision pending
2024-06-11T10:53:27.249285858Z I0611 10:53:27.249209       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:53:27.251166543Z I0611 10:53:27.251079       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 5; 0 nodes have achieved new revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:53:27.264719692Z I0611 10:53:27.264652       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 5" to "NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 5; 0 nodes have achieved new revision 6",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 5" to "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 5; 0 nodes have achieved new revision 6"
2024-06-11T10:53:28.421799150Z I0611 10:53:28.421744       1 request.go:697] Waited for 1.172268454s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T10:53:29.422399347Z I0611 10:53:29.422329       1 request.go:697] Waited for 1.197134914s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:53:29.425578928Z E0611 10:53:29.425536       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:29.634587632Z I0611 10:53:29.634492       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:53:30.625249734Z I0611 10:53:30.625174       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:53:30.827220021Z I0611 10:53:30.827149       1 request.go:697] Waited for 1.192640792s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-06-11T10:53:31.626039728Z E0611 10:53:31.625982       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:32.022176535Z I0611 10:53:32.022117       1 request.go:697] Waited for 1.182813055s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-06-11T10:53:33.022418954Z I0611 10:53:33.022357       1 request.go:697] Waited for 1.196873077s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:33.025624192Z I0611 10:53:33.025577       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:53:34.222178625Z I0611 10:53:34.222106       1 request.go:697] Waited for 1.195416677s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:35.422402159Z I0611 10:53:35.422337       1 request.go:697] Waited for 1.196111072s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:35.426868569Z I0611 10:53:35.426814       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:53:36.235116994Z E0611 10:53:36.235044       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:36.235399137Z E0611 10:53:36.235348       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:38.625206623Z E0611 10:53:38.625135       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:38.625469854Z E0611 10:53:38.625420       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:40.226786687Z E0611 10:53:40.226733       1 guard_controller.go:287] Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:53:40.227080622Z E0611 10:53:40.227020       1 base_controller.go:268] GuardController reconciliation failed: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:54:13.558330036Z E0611 10:54:13.558187       1 guard_controller.go:293] Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:54:13.565872867Z I0611 10:54:13.565823       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:54:13.590570916Z E0611 10:54:13.590502       1 base_controller.go:268] GuardController reconciliation failed: Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:54:13.592628870Z I0611 10:54:13.592583       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 5; 0 nodes have achieved new revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 5; 0 nodes have achieved new revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:54:13.593736906Z I0611 10:54:13.593673       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:54:13.605987719Z I0611 10:54:13.604079       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "GuardControllerDegraded: Missing operand on node ci-op-9xx71rvq-1e28e-w667k-master-2" to "GuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2"
2024-06-11T10:54:14.760993793Z E0611 10:54:14.760938       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:15.559837502Z I0611 10:54:15.559754       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:15.560938738Z E0611 10:54:15.560884       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:15.561126962Z E0611 10:54:15.561094       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:15.761133887Z E0611 10:54:15.761074       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.359774760Z I0611 10:54:16.359696       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:16.361083438Z E0611 10:54:16.361041       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:17.159869283Z I0611 10:54:17.159790       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:17.161467101Z E0611 10:54:17.161407       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:17.960073222Z I0611 10:54:17.959986       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:17.962110600Z E0611 10:54:17.962061       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:18.160708638Z E0611 10:54:18.160662       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:18.760017590Z I0611 10:54:18.759939       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:18.761397126Z E0611 10:54:18.761349       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:19.165607852Z E0611 10:54:19.165542       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:19.559361253Z I0611 10:54:19.559277       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:19.561035717Z E0611 10:54:19.560987       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:20.361431182Z E0611 10:54:20.361367       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:20.561165363Z E0611 10:54:20.561108       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:20.759569413Z I0611 10:54:20.759499       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:20.762454696Z E0611 10:54:20.762400       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:21.362068778Z E0611 10:54:21.362001       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:22.161982241Z E0611 10:54:22.161923       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:22.360285101Z I0611 10:54:22.360201       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:22.362261665Z E0611 10:54:22.362221       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:22.667390279Z E0611 10:54:22.667288       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:23.162035981Z E0611 10:54:23.161976       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:23.361308071Z E0611 10:54:23.361245       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.762395089Z E0611 10:54:23.762249       1 base_controller.go:268] TargetConfigController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.763011271Z E0611 10:54:23.762963       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.769292509Z E0611 10:54:23.769256       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.790434530Z E0611 10:54:23.790377       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.831730741Z E0611 10:54:23.831691       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.912623034Z E0611 10:54:23.912574       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.961799596Z E0611 10:54:23.961745       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:24.074078678Z E0611 10:54:24.074027       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.395014502Z E0611 10:54:24.394959       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.559249716Z I0611 10:54:24.559184       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.560486181Z E0611 10:54:24.560435       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.761403690Z E0611 10:54:24.761345       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:25.036990663Z E0611 10:54:25.036903       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.163346923Z E0611 10:54:25.163250       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:25.362519099Z E0611 10:54:25.362458       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:25.561150703Z E0611 10:54:25.561086       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.162555091Z E0611 10:54:26.162486       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:26.318688350Z E0611 10:54:26.318614       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.761597001Z E0611 10:54:26.761539       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:27.162119449Z E0611 10:54:27.162058       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:27.760186639Z I0611 10:54:27.760111       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:27.761552607Z E0611 10:54:27.761500       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:28.361625943Z E0611 10:54:28.361559       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:28.762279308Z E0611 10:54:28.762218       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:28.880924367Z E0611 10:54:28.880856       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:28.965416736Z E0611 10:54:28.965342       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:29.761448318Z E0611 10:54:29.761393       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:31.366293052Z E0611 10:54:31.364765       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:31.561289680Z E0611 10:54:31.561230       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:31.761686372Z E0611 10:54:31.761611       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:32.668882395Z E0611 10:54:32.668825       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:32.845170828Z E0611 10:54:32.845106       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:32.884781189Z I0611 10:54:32.884699       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:32.885954833Z E0611 10:54:32.885878       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:33.019810058Z E0611 10:54:33.019743       1 leaderelection.go:332] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:34.002391177Z E0611 10:54:34.002335       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:34.563345122Z E0611 10:54:34.563262       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:35.409842177Z E0611 10:54:35.409769       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:37.163711693Z E0611 10:54:37.163652       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:37.964249259Z E0611 10:54:37.964170       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:40.534431017Z E0611 10:54:40.534370       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:41.163646992Z E0611 10:54:41.163582       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:42.670394604Z E0611 10:54:42.670291       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:43.128551741Z I0611 10:54:43.128474       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:43.129833497Z E0611 10:54:43.129790       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.243801860Z E0611 10:54:44.243718       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:44.364139526Z E0611 10:54:44.364071       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:47.563963297Z E0611 10:54:47.563893       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:47.764073485Z E0611 10:54:47.763999       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:48.502815818Z E0611 10:54:48.502757       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:48.699064035Z E0611 10:54:48.699004       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.701588043Z E0611 10:54:48.701544       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.705392607Z E0611 10:54:48.705348       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.716391447Z E0611 10:54:48.716348       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.737278293Z E0611 10:54:48.737228       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.778385403Z E0611 10:54:48.778323       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:48.859653607Z E0611 10:54:48.859598       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.020526013Z E0611 10:54:49.020466       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.099705663Z E0611 10:54:49.099635       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.342156311Z E0611 10:54:49.342095       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:50.301456290Z E0611 10:54:50.301394       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:51.102078688Z E0611 10:54:51.102022       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:51.163504870Z E0611 10:54:51.163442       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:51.583355990Z E0611 10:54:51.583284       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:52.672199747Z E0611 10:54:52.672138       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:54:54.145923250Z E0611 10:54:54.145857       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:54.364476291Z E0611 10:54:54.364399       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:57.563484491Z E0611 10:54:57.563407       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:54:59.021254988Z E0611 10:54:59.021175       1 leaderelection.go:332] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:59.267998025Z E0611 10:54:59.267931       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:00.763832099Z E0611 10:55:00.763763       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:02.674428148Z E0611 10:55:02.674359       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:03.612470227Z I0611 10:55:03.612383       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:03.613763683Z E0611 10:55:03.613719       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:04.725558463Z E0611 10:55:04.725490       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:08.248755457Z E0611 10:55:08.248684       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:09.509338426Z E0611 10:55:09.509237       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:12.675574798Z E0611 10:55:12.675519       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:22.450530283Z E0611 10:55:22.450405       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:22.678014183Z E0611 10:55:22.677955       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:25.021138946Z E0611 10:55:25.021025       1 leaderelection.go:332] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:29.990938634Z E0611 10:55:29.990874       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:32.065942627Z E0611 10:55:32.065882       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:32.680385767Z E0611 10:55:32.680284       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:42.682622011Z E0611 10:55:42.682543       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:55:44.577544109Z I0611 10:55:44.577447       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' Failed to create installer pod for revision 6 count 0 on node "ci-op-9xx71rvq-1e28e-w667k-master-2": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:44.578975764Z E0611 10:55:44.578930       1 base_controller.go:268] InstallerController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:48.503832094Z E0611 10:55:48.503730       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:48.700240726Z E0611 10:55:48.700164       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:48.702771688Z E0611 10:55:48.702718       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:49.101042515Z E0611 10:55:49.100967       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:50.305550803Z E0611 10:55:50.305476       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:55:51.021965164Z E0611 10:55:51.021868       1 leaderelection.go:332] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:52.684971814Z E0611 10:55:52.684908       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:56:02.687294590Z E0611 10:56:02.687191       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:56:02.687294590Z E0611 10:56:02.687269       1 event.go:294] "Unable to write event (retry limit exceeded!)" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:56:02.688573822Z E0611 10:56:02.688517       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events/kube-controller-manager-operator.17d7edcedb1285d9\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:16.359595135 +0000 UTC m=+270.170236817,Count:2,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:56:04.616968241Z E0611 10:56:04.616896       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:56:04.775385664Z E0611 10:56:04.775321       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Patch \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events/kube-controller-manager-operator.17d7edcedb1285d9\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7edcedb1285d9  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:InstallerPodFailed,Message:Failed to create installer pod for revision 6 count 0 on node \"ci-op-9xx71rvq-1e28e-w667k-master-2\": Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-installer-controller,Host:,},FirstTimestamp:2024-06-11 10:54:15.559603673 +0000 UTC m=+269.370245355,LastTimestamp:2024-06-11 10:54:16.359595135 +0000 UTC m=+270.170236817,Count:2,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-installer-controller,ReportingInstance:,}"
2024-06-11T10:56:38.645342844Z I0611 10:56:38.645264       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:43.068248049Z I0611 10:56:43.068189       1 reflector.go:351] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:44.979225932Z I0611 10:56:44.979156       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:48.828260603Z I0611 10:56:48.828171       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:50.716147073Z I0611 10:56:50.716013       1 reflector.go:351] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:55.646880939Z I0611 10:56:55.646815       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:56.844865070Z I0611 10:56:56.844783       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:58.248976318Z I0611 10:56:58.248914       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:58.315055291Z I0611 10:56:58.314970       1 reflector.go:351] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:56:59.240142225Z I0611 10:56:59.240067       1 reflector.go:351] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:00.148659223Z I0611 10:57:00.148602       1 reflector.go:351] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:01.588781434Z I0611 10:57:01.588723       1 reflector.go:351] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:01.646003098Z I0611 10:57:01.645941       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:02.367332248Z I0611 10:57:02.367247       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:04.247998771Z I0611 10:57:04.247914       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:04.846753689Z I0611 10:57:04.846688       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:06.043735977Z I0611 10:57:06.043371       1 request.go:697] Waited for 1.195188126s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:06.245456209Z I0611 10:57:06.245394       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:07.043633183Z I0611 10:57:07.043547       1 request.go:697] Waited for 1.393755605s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:07.644851718Z I0611 10:57:07.644773       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:08.242763067Z I0611 10:57:08.242691       1 request.go:697] Waited for 1.193997539s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:08.650616034Z I0611 10:57:08.650550       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T10:57:08.650616034Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T10:57:08.650616034Z  CurrentRevision: (int32) 6,
2024-06-11T10:57:08.650616034Z  TargetRevision: (int32) 0,
2024-06-11T10:57:08.650616034Z  LastFailedRevision: (int32) 0,
2024-06-11T10:57:08.650616034Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:57:08.650616034Z  LastFailedReason: (string) "",
2024-06-11T10:57:08.650616034Z  LastFailedCount: (int) 0,
2024-06-11T10:57:08.650616034Z  LastFallbackCount: (int) 0,
2024-06-11T10:57:08.650616034Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:57:08.650616034Z }
2024-06-11T10:57:08.650616034Z  because static pod is ready
2024-06-11T10:57:08.679555044Z I0611 10:57:08.679470       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-2" from revision 0 to 6 because static pod is ready
2024-06-11T10:57:08.871590296Z I0611 10:57:08.871517       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:09.082418279Z I0611 10:57:09.082336       1 reflector.go:351] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:09.083279953Z I0611 10:57:09.083229       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:57:09.084911095Z I0611 10:57:09.084872       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:50:21Z","message":"GuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"GuardController_SyncError","status":"True","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:57:09.097353174Z I0611 10:57:09.097132       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 0; 2 nodes are at revision 5; 0 nodes have achieved new revision 6" to "NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6",Available message changed from "StaticPodsAvailable: 2 nodes are active; 1 node is at revision 0; 2 nodes are at revision 5; 0 nodes have achieved new revision 6" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6"
2024-06-11T10:57:09.243572953Z I0611 10:57:09.243499       1 request.go:697] Waited for 1.19574049s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2024-06-11T10:57:09.648945306Z E0611 10:57:09.648884       1 guard_controller.go:293] Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:09.649207028Z E0611 10:57:09.649179       1 base_controller.go:268] GuardController reconciliation failed: Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:10.248535900Z I0611 10:57:10.243574       1 request.go:697] Waited for 1.160536437s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T10:57:11.047084347Z I0611 10:57:11.047004       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:11.243710398Z I0611 10:57:11.243631       1 request.go:697] Waited for 1.395746934s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:11.847516958Z I0611 10:57:11.847438       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:12.443446434Z I0611 10:57:12.443376       1 request.go:697] Waited for 1.195169641s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:12.449187532Z I0611 10:57:12.449129       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T10:57:12.449187532Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T10:57:12.449187532Z  CurrentRevision: (int32) 6,
2024-06-11T10:57:12.449187532Z  TargetRevision: (int32) 0,
2024-06-11T10:57:12.449187532Z  LastFailedRevision: (int32) 0,
2024-06-11T10:57:12.449187532Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:57:12.449187532Z  LastFailedReason: (string) "",
2024-06-11T10:57:12.449187532Z  LastFailedCount: (int) 0,
2024-06-11T10:57:12.449187532Z  LastFallbackCount: (int) 0,
2024-06-11T10:57:12.449187532Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:57:12.449187532Z }
2024-06-11T10:57:12.449187532Z  because static pod is ready
2024-06-11T10:57:13.053814163Z I0611 10:57:13.053757       1 reflector.go:351] Caches populated for *v1.APIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:14.243029687Z I0611 10:57:14.242971       1 request.go:697] Waited for 1.023306637s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra/configmaps?resourceVersion=17372
2024-06-11T10:57:14.248416555Z I0611 10:57:14.248344       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:14.421192988Z I0611 10:57:14.421138       1 reflector.go:351] Caches populated for *v1.Proxy from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:17.060060465Z W0611 10:57:17.059993       1 warnings.go:70] metadata.name: this is used in the Pod's hostname, which can result in surprising behavior; a DNS label is recommended: [must be no more than 63 characters]
2024-06-11T10:57:17.060336882Z I0611 10:57:17.060243       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:57:17.084590851Z I0611 10:57:17.084518       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:57:17.085720819Z I0611 10:57:17.085660       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T10:57:17.111730795Z I0611 10:57:17.111658       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded changed from True to False ("NodeControllerDegraded: All master nodes are ready")
2024-06-11T10:57:17.337062747Z I0611 10:57:17.337006       1 reflector.go:351] Caches populated for *v1.Role from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:17.387422698Z I0611 10:57:17.387350       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:17.808743485Z I0611 10:57:17.808672       1 reflector.go:351] Caches populated for *v1.Network from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:18.243038791Z I0611 10:57:18.242968       1 request.go:697] Waited for 1.1594925s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:57:18.649342753Z I0611 10:57:18.649245       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-0 with revision 5 is the oldest and needs new revision 6
2024-06-11T10:57:18.649401558Z I0611 10:57:18.649349       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:57:18.649401558Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:57:18.649401558Z  CurrentRevision: (int32) 5,
2024-06-11T10:57:18.649401558Z  TargetRevision: (int32) 6,
2024-06-11T10:57:18.649401558Z  LastFailedRevision: (int32) 0,
2024-06-11T10:57:18.649401558Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:57:18.649401558Z  LastFailedReason: (string) "",
2024-06-11T10:57:18.649401558Z  LastFailedCount: (int) 0,
2024-06-11T10:57:18.649401558Z  LastFallbackCount: (int) 0,
2024-06-11T10:57:18.649401558Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:57:18.649401558Z }
2024-06-11T10:57:18.845821501Z I0611 10:57:18.845752       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:18.924277349Z I0611 10:57:18.924190       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 5 to 6 because node ci-op-9xx71rvq-1e28e-w667k-master-0 with revision 5 is the oldest
2024-06-11T10:57:18.926212418Z I0611 10:57:18.926157       1 prune_controller.go:269] Nothing to prune
2024-06-11T10:57:18.994594286Z I0611 10:57:18.994532       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:19.243068473Z I0611 10:57:19.242989       1 request.go:697] Waited for 1.590517009s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2024-06-11T10:57:19.875865503Z I0611 10:57:19.875805       1 reflector.go:351] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:20.243516292Z I0611 10:57:20.243454       1 request.go:697] Waited for 1.317472589s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T10:57:21.243768094Z I0611 10:57:21.243631       1 request.go:697] Waited for 1.39540109s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T10:57:24.249808831Z I0611 10:57:24.249739       1 core.go:227] Pod "openshift-kube-controller-manager/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-2" changes: {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{"k8s.ovn.org/pod-networks":null,"k8s.v1.cni.cncf.io/network-status":null,"target.workload.openshift.io/management":"{\"effect\": \"PreferredDuringScheduling\"}"},"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null},"spec":{"containers":[{"args":["-c","# properly handle TERM and exit as soon as it is signaled\nset -euo pipefail\ntrap 'jobs -p | xargs -r kill; exit 0' TERM\nsleep infinity \u0026 wait\n"],"command":["/bin/bash"],"image":"quay.io/openshift-release-dev/ocp-v4.0-art-dev@sha256:95cb052ed20a9c01d1029497da60445a5425edcc6a6f642ebed4f1d5c3411d51","imagePullPolicy":"IfNotPresent","name":"guard","readinessProbe":{"failureThreshold":3,"httpGet":{"host":"10.0.0.7","path":"healthz","port":10257,"scheme":"HTTPS"},"periodSeconds":5,"successThreshold":1,"timeoutSeconds":5},"resources":{"requests":{"cpu":"10m","memory":"5Mi"}},"terminationMessagePolicy":"FallbackToLogsOnError"}],"dnsPolicy":null,"enableServiceLinks":null,"preemptionPolicy":null,"priority":null,"restartPolicy":null,"schedulerName":null,"securityContext":null,"serviceAccount":null,"serviceAccountName":null,"volumes":null},"status":{"conditions":null,"containerStatuses":null,"hostIP":null,"hostIPs":null,"phase":null,"podIP":null,"podIPs":null,"qosClass":null,"startTime":null}}
2024-06-11T10:57:25.066987239Z I0611 10:57:25.066901       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodUpdated' Updated Pod/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-controller-manager because it changed
2024-06-11T10:57:25.248217611Z I0611 10:57:25.248160       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-0 with revision 5 is the oldest and needs new revision 6
2024-06-11T10:57:25.248254114Z I0611 10:57:25.248219       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T10:57:25.248254114Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T10:57:25.248254114Z  CurrentRevision: (int32) 5,
2024-06-11T10:57:25.248254114Z  TargetRevision: (int32) 6,
2024-06-11T10:57:25.248254114Z  LastFailedRevision: (int32) 0,
2024-06-11T10:57:25.248254114Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T10:57:25.248254114Z  LastFailedReason: (string) "",
2024-06-11T10:57:25.248254114Z  LastFailedCount: (int) 0,
2024-06-11T10:57:25.248254114Z  LastFallbackCount: (int) 0,
2024-06-11T10:57:25.248254114Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T10:57:25.248254114Z }
2024-06-11T10:57:26.243350823Z I0611 10:57:26.243276       1 request.go:697] Waited for 1.175842543s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:57:27.045930141Z I0611 10:57:27.045845       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:27.442743685Z I0611 10:57:27.442664       1 request.go:697] Waited for 1.194599572s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:57:27.660553439Z I0611 10:57:27.660463       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-controller-manager because it was missing
2024-06-11T10:57:28.646995943Z I0611 10:57:28.646934       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T10:57:28.843306045Z I0611 10:57:28.843236       1 request.go:697] Waited for 1.181876534s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-06-11T10:57:29.645954429Z I0611 10:57:29.645871       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:30.042857105Z I0611 10:57:30.042656       1 request.go:697] Waited for 1.394467047s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T10:57:31.042964468Z I0611 10:57:31.042895       1 request.go:697] Waited for 1.19432059s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:31.249088598Z I0611 10:57:31.249018       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:57:32.043115938Z I0611 10:57:32.043031       1 request.go:697] Waited for 1.194192878s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T10:57:33.449534461Z I0611 10:57:33.449423       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-06-11T10:57:41.434257944Z I0611 10:57:41.434190       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:42.851290041Z I0611 10:57:42.851202       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:43.908124740Z I0611 10:57:43.908044       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:47.486034807Z I0611 10:57:47.485931       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:57:53.657204261Z I0611 10:57:53.657114       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T10:58:27.111530167Z E0611 10:58:27.111450       1 leaderelection.go:332] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.634891188Z I0611 10:58:33.634821       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.635755652Z E0611 10:58:33.635694       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7ee0af18b77e7  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretUpdateFailed,Message:Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-satokensignercontroller,Host:,},FirstTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,LastTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-satokensignercontroller,ReportingInstance:,}"
2024-06-11T10:58:33.636201685Z E0611 10:58:33.636163       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.643314514Z I0611 10:58:33.643255       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.644413396Z E0611 10:58:33.644384       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.656764413Z I0611 10:58:33.656714       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.657984504Z E0611 10:58:33.657958       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.680324764Z I0611 10:58:33.680269       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.681478650Z E0611 10:58:33.681445       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.723956206Z I0611 10:58:33.723896       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.725265303Z E0611 10:58:33.725215       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.807951747Z I0611 10:58:33.807885       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.809221942Z E0611 10:58:33.809189       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.973171024Z I0611 10:58:33.973096       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:33.974655534Z E0611 10:58:33.974623       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:34.297638734Z I0611 10:58:34.297568       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:34.299011136Z E0611 10:58:34.298968       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:34.941773527Z I0611 10:58:34.941682       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:34.943010194Z E0611 10:58:34.942979       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:36.227345701Z I0611 10:58:36.227234       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:36.229212502Z E0611 10:58:36.229142       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:36.686901171Z E0611 10:58:36.686811       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7ee0af18b77e7  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretUpdateFailed,Message:Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-satokensignercontroller,Host:,},FirstTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,LastTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-satokensignercontroller,ReportingInstance:,}"
2024-06-11T10:58:38.793556775Z I0611 10:58:38.793477       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:38.795339108Z E0611 10:58:38.795265       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:43.918254852Z I0611 10:58:43.918179       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:43.919520340Z E0611 10:58:43.919473       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:46.688343500Z E0611 10:58:46.688217       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7ee0af18b77e7  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretUpdateFailed,Message:Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-satokensignercontroller,Host:,},FirstTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,LastTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-satokensignercontroller,ReportingInstance:,}"
2024-06-11T10:58:48.310143248Z I0611 10:58:48.310073       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:48.311772761Z E0611 10:58:48.311722       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:48.701555483Z E0611 10:58:48.701480       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:48.711697889Z E0611 10:58:48.711636       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:48.861530514Z E0611 10:58:48.861466       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:48.910745739Z E0611 10:58:48.910688       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:49.102773225Z E0611 10:58:49.102706       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:49.108845267Z E0611 10:58:49.108798       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:49.120808240Z E0611 10:58:49.120766       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:49.141900879Z E0611 10:58:49.141848       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:49.183050880Z E0611 10:58:49.182992       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:49.264066990Z E0611 10:58:49.264017       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:49.312244204Z E0611 10:58:49.312185       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:49.425729181Z E0611 10:58:49.425661       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:49.510617573Z E0611 10:58:49.510567       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:49.747022517Z E0611 10:58:49.746952       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:50.063595908Z E0611 10:58:50.063510       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:50.261937675Z E0611 10:58:50.261871       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:50.310762437Z E0611 10:58:50.310687       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:50.388205986Z E0611 10:58:50.388135       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:50.511856305Z E0611 10:58:50.511805       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:51.110621402Z E0611 10:58:51.110553       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:51.262004900Z E0611 10:58:51.261941       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:51.510207331Z E0611 10:58:51.510148       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:51.670137649Z E0611 10:58:51.670079       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:52.061244061Z E0611 10:58:52.061187       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:52.110151614Z E0611 10:58:52.110094       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:52.312703028Z E0611 10:58:52.312636       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:52.661583773Z E0611 10:58:52.661521       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:52.910596362Z E0611 10:58:52.910537       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:53.113158278Z E0611 10:58:53.113085       1 leaderelection.go:332] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:53.512450484Z E0611 10:58:53.512397       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:53.912544249Z E0611 10:58:53.912464       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:54.109940889Z E0611 10:58:54.109879       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:54.231345509Z E0611 10:58:54.231277       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:54.513100777Z E0611 10:58:54.513036       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:54.911146393Z I0611 10:58:54.911060       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:54.912984627Z E0611 10:58:54.912927       1 base_controller.go:268] SATokenSignerController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:55.712623617Z E0611 10:58:55.712564       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:55.912948970Z E0611 10:58:55.912885       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:56.110552925Z E0611 10:58:56.110420       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:56.315506813Z E0611 10:58:56.315426       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:56.689794104Z E0611 10:58:56.689737       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7ee0af18b77e7  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretUpdateFailed,Message:Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-satokensignercontroller,Host:,},FirstTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,LastTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-satokensignercontroller,ReportingInstance:,}"
2024-06-11T10:58:57.112479710Z E0611 10:58:57.112415       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:57.512971004Z E0611 10:58:57.512915       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:58:58.512924846Z E0611 10:58:58.512858       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:58.910518100Z E0611 10:58:58.910447       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:59.353122832Z E0611 10:58:59.353053       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:58:59.514882828Z E0611 10:58:59.514799       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:00.113871134Z E0611 10:59:00.113812       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:00.513502789Z E0611 10:59:00.513441       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:01.911934516Z E0611 10:59:01.911867       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:02.114364650Z E0611 10:59:02.114262       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:03.196433606Z E0611 10:59:03.196350       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:04.110843513Z E0611 10:59:04.110768       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:05.114605651Z E0611 10:59:05.114356       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:05.762426373Z E0611 10:59:05.762360       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:05.913208124Z E0611 10:59:05.913147       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:06.691636398Z E0611 10:59:06.691551       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7ee0af18b77e7  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretUpdateFailed,Message:Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-satokensignercontroller,Host:,},FirstTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,LastTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-satokensignercontroller,ReportingInstance:,}"
2024-06-11T10:59:08.514098366Z E0611 10:59:08.514019       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:09.595226469Z E0611 10:59:09.595157       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:10.887483870Z E0611 10:59:10.887413       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:11.713961483Z E0611 10:59:11.713885       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:14.352536427Z E0611 10:59:14.352477       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:14.913836338Z E0611 10:59:14.913750       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:16.514672380Z E0611 10:59:16.514606       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:16.692844481Z E0611 10:59:16.692790       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7ee0af18b77e7  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretUpdateFailed,Message:Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-satokensignercontroller,Host:,},FirstTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,LastTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-satokensignercontroller,ReportingInstance:,}"
2024-06-11T10:59:18.314266959Z E0611 10:59:18.314191       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:19.112884421Z E0611 10:59:19.112793       1 leaderelection.go:332] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:21.131494214Z E0611 10:59:21.131436       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:21.514134471Z E0611 10:59:21.514063       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:24.713160527Z E0611 10:59:24.713087       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:26.696178665Z E0611 10:59:26.696114       1 event.go:355] "Unable to write event (may retry after sleeping)" err="Post \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/events\": dial tcp 172.30.0.1:443: connect: connection refused" event="&Event{ObjectMeta:{kube-controller-manager-operator.17d7ee0af18b77e7  openshift-kube-controller-manager-operator    0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[] map[] [] [] []},InvolvedObject:ObjectReference{Kind:Deployment,Namespace:openshift-kube-controller-manager-operator,Name:kube-controller-manager-operator,UID:dc25edff-39bb-4cee-96b9-1cf35650ef3e,APIVersion:apps/v1,ResourceVersion:,FieldPath:,},Reason:SecretUpdateFailed,Message:Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Put \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/service-account-private-key\": dial tcp 172.30.0.1:443: connect: connection refused,Source:EventSource{Component:kube-controller-manager-operator-satokensignercontroller,Host:,},FirstTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,LastTimestamp:2024-06-11 10:58:33.634666471 +0000 UTC m=+527.445308153,Count:1,Type:Warning,EventTime:0001-01-01 00:00:00 +0000 UTC,Series:nil,Action:,Related:nil,ReportingController:kube-controller-manager-operator-satokensignercontroller,ReportingInstance:,}"
2024-06-11T10:59:27.913671306Z E0611 10:59:27.913591       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:30.076542236Z E0611 10:59:30.076465       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:31.113909351Z E0611 10:59:31.113838       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T10:59:35.884756813Z I0611 10:59:35.884667       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretUpdated' Updated Secret/service-account-private-key -n openshift-kube-controller-manager because it changed
2024-06-11T10:59:48.321432753Z I0611 10:59:48.321354       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:48.407443405Z E0611 10:59:48.407377       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:48.421030618Z I0611 10:59:48.420967       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:48.471199015Z I0611 10:59:48.471111       1 helpers.go:184] lister was stale at resourceVersion=19693, live get showed resourceVersion=20882
2024-06-11T10:59:48.471273318Z E0611 10:59:48.471233       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:48.494391092Z I0611 10:59:48.494316       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:48.532828245Z I0611 10:59:48.532757       1 helpers.go:184] lister was stale at resourceVersion=19693, live get showed resourceVersion=20882
2024-06-11T10:59:48.532891147Z E0611 10:59:48.532874       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:48.675983857Z I0611 10:59:48.675907       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:48.724074375Z I0611 10:59:48.724013       1 helpers.go:184] lister was stale at resourceVersion=19693, live get showed resourceVersion=20882
2024-06-11T10:59:48.724125177Z E0611 10:59:48.724104       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:48.770727139Z I0611 10:59:48.770651       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:48.804192704Z I0611 10:59:48.804122       1 helpers.go:184] lister was stale at resourceVersion=19693, live get showed resourceVersion=20882
2024-06-11T10:59:48.804288808Z E0611 10:59:48.804266       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:48.891349399Z I0611 10:59:48.891265       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:48.931066601Z I0611 10:59:48.930995       1 helpers.go:184] lister was stale at resourceVersion=19693, live get showed resourceVersion=20882
2024-06-11T10:59:48.931167504Z E0611 10:59:48.931138       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:49.098238806Z I0611 10:59:49.098159       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:49.145111121Z I0611 10:59:49.145039       1 helpers.go:184] lister was stale at resourceVersion=19693, live get showed resourceVersion=20882
2024-06-11T10:59:49.145194027Z E0611 10:59:49.145137       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:49.915442720Z I0611 10:59:49.915343       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:49.950152326Z I0611 10:59:49.950088       1 helpers.go:184] lister was stale at resourceVersion=19693, live get showed resourceVersion=20882
2024-06-11T10:59:49.950230032Z E0611 10:59:49.950209       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:51.115401072Z I0611 10:59:51.115310       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:51.151660782Z I0611 10:59:51.151598       1 helpers.go:184] lister was stale at resourceVersion=19693, live get showed resourceVersion=20882
2024-06-11T10:59:51.151713785Z E0611 10:59:51.151701       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:52.715723433Z I0611 10:59:52.715637       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:52.747220326Z I0611 10:59:52.747143       1 helpers.go:184] lister was stale at resourceVersion=19693, live get showed resourceVersion=20882
2024-06-11T10:59:52.747286131Z E0611 10:59:52.747254       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:55.515413717Z I0611 10:59:55.515285       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T10:59:55.547025319Z I0611 10:59:55.546954       1 helpers.go:184] lister was stale at resourceVersion=19693, live get showed resourceVersion=20882
2024-06-11T10:59:55.547224530Z E0611 10:59:55.547157       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:00.673847030Z I0611 11:00:00.673773       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:00.708449753Z I0611 11:00:00.708392       1 helpers.go:184] lister was stale at resourceVersion=19693, live get showed resourceVersion=20882
2024-06-11T11:00:00.708518158Z E0611 11:00:00.708487       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:06.454433064Z I0611 11:00:06.454361       1 reflector.go:351] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:06.454945199Z I0611 11:00:06.454892       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:00:06.455684750Z I0611 11:00:06.455632       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:06.469191778Z I0611 11:00:06.469097       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:06.469242282Z E0611 11:00:06.469197       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:06.469512900Z I0611 11:00:06.469448       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again"
2024-06-11T11:00:06.471763255Z I0611 11:00:06.471712       1 installer_controller.go:491] Will retry "ci-op-9xx71rvq-1e28e-w667k-master-0" for revision 6 for the 1st time because installer pod failed: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471763255Z W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471763255Z W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471763255Z W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471763255Z W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471763255Z W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471763255Z W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471763255Z F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition
2024-06-11T11:00:06.471885564Z I0611 11:00:06.471835       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:00:06.471885564Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:00:06.471885564Z  CurrentRevision: (int32) 5,
2024-06-11T11:00:06.471885564Z  TargetRevision: (int32) 6,
2024-06-11T11:00:06.471885564Z  LastFailedRevision: (int32) 6,
2024-06-11T11:00:06.471885564Z  LastFailedTime: (*v1.Time)(0xc002804a80)(2024-06-11 11:00:06.47169335 +0000 UTC m=+620.282335132),
2024-06-11T11:00:06.471885564Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:00:06.471885564Z  LastFailedCount: (int) 1,
2024-06-11T11:00:06.471885564Z  LastFallbackCount: (int) 0,
2024-06-11T11:00:06.471885564Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:00:06.471885564Z   (string) (len=2059) "installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T11:00:06.471885564Z  }
2024-06-11T11:00:06.471885564Z }
2024-06-11T11:00:06.471885564Z  because installer pod failed: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471885564Z W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471885564Z W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471885564Z W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471885564Z W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471885564Z W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471885564Z W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.471885564Z F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition
2024-06-11T11:00:06.472083677Z I0611 11:00:06.471832       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.472083677Z W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.472083677Z W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.472083677Z W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.472083677Z W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.472083677Z W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.472083677Z W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:06.472083677Z F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition
2024-06-11T11:00:06.495106660Z I0611 11:00:06.495056       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:06.504410800Z I0611 11:00:06.504348       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:00:06.507578318Z E0611 11:00:06.507520       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:06.508375873Z I0611 11:00:06.508314       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:06.514688907Z E0611 11:00:06.514629       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:06.515322850Z I0611 11:00:06.515276       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:06.525766468Z E0611 11:00:06.525693       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:06.526377310Z I0611 11:00:06.526343       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:06.532690044Z E0611 11:00:06.532641       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:06.546489993Z I0611 11:00:06.546433       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:06.553511276Z E0611 11:00:06.553456       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:06.635243896Z I0611 11:00:06.635147       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:06.642358785Z E0611 11:00:06.642290       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:06.804460630Z I0611 11:00:06.804381       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:06.811739431Z E0611 11:00:06.811682       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:07.132703399Z I0611 11:00:07.132622       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:07.139343156Z E0611 11:00:07.139255       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:07.265060700Z I0611 11:00:07.264961       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:07.265172008Z E0611 11:00:07.265139       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:07.780538043Z I0611 11:00:07.780477       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:07.788988624Z E0611 11:00:07.788928       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:08.460129452Z I0611 11:00:08.460056       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:08.466915090Z E0611 11:00:08.466852       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:08.467650537Z I0611 11:00:08.467613       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:08.474895004Z E0611 11:00:08.474839       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:09.070762045Z I0611 11:00:09.070676       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:09.076957044Z E0611 11:00:09.076902       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:11.460573311Z I0611 11:00:11.460491       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'SecretUpdateFailed' Failed to update Secret/service-account-private-key -n openshift-kube-controller-manager: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:11.460661216Z E0611 11:00:11.460631       1 base_controller.go:268] SATokenSignerController reconciliation failed: Operation cannot be fulfilled on secrets "service-account-private-key": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:17.791854867Z I0611 11:00:17.791733       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:19.107174899Z I0611 11:00:19.107108       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:19.318472477Z I0611 11:00:19.318407       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: \nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:19.339725982Z E0611 11:00:19.339660       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:21.025160927Z I0611 11:00:21.025085       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-6-retry-1-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:00:21.029096250Z I0611 11:00:21.029037       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:00:21.073317657Z I0611 11:00:21.073211       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:23.190288465Z I0611 11:00:23.190218       1 reflector.go:351] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:25.261774639Z I0611 11:00:25.261720       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:26.014793151Z I0611 11:00:26.014726       1 reflector.go:351] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:27.605238613Z I0611 11:00:27.605121       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:27.804600767Z I0611 11:00:27.804533       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:28.206545575Z I0611 11:00:28.206476       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:28.210590928Z I0611 11:00:28.210511       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'StartingNewRevision' new revision 7 triggered by "required secret/service-account-private-key has changed"
2024-06-11T11:00:28.235373876Z I0611 11:00:28.234931       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:28.235660794Z I0611 11:00:28.235612       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:00:28.242625529Z E0611 11:00:28.242575       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:28.394418311Z I0611 11:00:28.394356       1 reflector.go:351] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:29.406251417Z I0611 11:00:29.406189       1 request.go:697] Waited for 1.170667728s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:00:30.010990693Z I0611 11:00:30.010918       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-manager-pod-7 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:00:30.412589979Z I0611 11:00:30.411749       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:00:30.448497122Z I0611 11:00:30.448430       1 reflector.go:351] Caches populated for *v1.Proxy from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:30.552570223Z I0611 11:00:30.552504       1 reflector.go:351] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:30.602226225Z I0611 11:00:30.602103       1 request.go:697] Waited for 1.19087059s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:00:31.212123524Z I0611 11:00:31.212038       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/config-7 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:00:31.408769707Z I0611 11:00:31.408559       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:31.415370420Z E0611 11:00:31.415243       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:31.416494990Z I0611 11:00:31.416423       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:31.424537092Z E0611 11:00:31.424479       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:32.013812302Z I0611 11:00:32.013709       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/cluster-policy-controller-config-7 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:00:32.617516014Z I0611 11:00:32.617421       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/controller-manager-kubeconfig-7 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:00:33.210571060Z I0611 11:00:33.210470       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-controller-cert-syncer-kubeconfig-7 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:00:33.818291422Z I0611 11:00:33.818217       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/serviceaccount-ca-7 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:00:34.006658689Z I0611 11:00:34.006591       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:34.406426461Z I0611 11:00:34.406361       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:34.802623042Z I0611 11:00:34.802448       1 request.go:697] Waited for 1.144593436s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager-operator/configmaps?resourceVersion=20416
2024-06-11T11:00:34.805128844Z I0611 11:00:34.805079       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:35.017625373Z I0611 11:00:35.017559       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/service-ca-7 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:00:35.802897863Z I0611 11:00:35.802831       1 request.go:697] Waited for 1.395478141s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:00:36.414290091Z I0611 11:00:36.414198       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/recycler-config-7 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:00:37.002866793Z I0611 11:00:37.002786       1 request.go:697] Waited for 1.392995669s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:00:37.407742035Z I0611 11:00:37.407680       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:00:37.606006486Z I0611 11:00:37.605954       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:38.013253285Z I0611 11:00:38.013161       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/service-account-private-key-7 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:00:38.203004250Z I0611 11:00:38.202923       1 request.go:697] Waited for 1.595493209s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2024-06-11T11:00:38.407474320Z I0611 11:00:38.407410       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:38.414435948Z E0611 11:00:38.414383       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:38.414981281Z I0611 11:00:38.414954       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:38.421233365Z E0611 11:00:38.421188       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:38.485842637Z I0611 11:00:38.485766       1 reflector.go:351] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:38.486721091Z I0611 11:00:38.486666       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:38.504262270Z E0611 11:00:38.504199       1 base_controller.go:268] StatusSyncer_kube-controller-manager reconciliation failed: Operation cannot be fulfilled on clusteroperators.config.openshift.io "kube-controller-manager": the object has been modified; please apply your changes to the latest version and try again
2024-06-11T11:00:38.505167425Z I0611 11:00:38.505093       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:38.519006176Z I0611 11:00:38.518951       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nSATokenSignerDegraded: Operation cannot be fulfilled on secrets \"service-account-private-key\": the object has been modified; please apply your changes to the latest version and try again" to "NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-06-11T11:00:38.992741099Z I0611 11:00:38.992639       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:39.203141133Z I0611 11:00:39.203010       1 request.go:697] Waited for 1.189873848s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets
2024-06-11T11:00:39.221624370Z I0611 11:00:39.221537       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/serving-cert-7 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:00:40.006738735Z I0611 11:00:40.006680       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:40.208669748Z I0611 11:00:40.208525       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 6, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:00:40.402530866Z I0611 11:00:40.402434       1 request.go:697] Waited for 1.470913225s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-config/configmaps?resourceVersion=19854
2024-06-11T11:00:40.405181629Z I0611 11:00:40.405117       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:40.812769085Z I0611 11:00:40.812646       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/localhost-recovery-client-token-7 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:00:41.402536441Z I0611 11:00:41.402471       1 request.go:697] Waited for 1.594841243s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:00:41.810944648Z I0611 11:00:41.810866       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionTriggered' new revision 7 triggered by "required secret/service-account-private-key has changed"
2024-06-11T11:00:41.834515797Z I0611 11:00:41.834444       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RevisionCreate' Revision 7 created because required secret/service-account-private-key has changed
2024-06-11T11:00:41.836506620Z I0611 11:00:41.836453       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:00:41.858353763Z W0611 11:00:41.858267       1 staticpod.go:38] revision 7 is unexpectedly already the latest available revision. This is a possible race!
2024-06-11T11:00:41.858422667Z E0611 11:00:41.858348       1 base_controller.go:268] RevisionController reconciliation failed: conflicting latestAvailableRevision 7
2024-06-11T11:00:43.002234897Z I0611 11:00:43.002170       1 request.go:697] Waited for 1.163963769s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T11:00:44.002988600Z I0611 11:00:44.002897       1 request.go:697] Waited for 1.195559386s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-6-retry-1-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:00:44.031894718Z I0611 11:00:44.031822       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:00:44.031894718Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:00:44.031894718Z  CurrentRevision: (int32) 5,
2024-06-11T11:00:44.031894718Z  TargetRevision: (int32) 7,
2024-06-11T11:00:44.031894718Z  LastFailedRevision: (int32) 6,
2024-06-11T11:00:44.031894718Z  LastFailedTime: (*v1.Time)(0xc000c02468)(2024-06-11 11:00:06 +0000 UTC),
2024-06-11T11:00:44.031894718Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:00:44.031894718Z  LastFailedCount: (int) 1,
2024-06-11T11:00:44.031894718Z  LastFallbackCount: (int) 0,
2024-06-11T11:00:44.031894718Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:00:44.031894718Z   (string) (len=2059) "installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T11:00:44.031894718Z  }
2024-06-11T11:00:44.031894718Z }
2024-06-11T11:00:44.031894718Z  because new revision pending
2024-06-11T11:00:44.083955714Z I0611 11:00:44.083897       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:00:44.088385177Z I0611 11:00:44.084321       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:00:44.112026783Z I0611 11:00:44.111349       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 6:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "NodeControllerDegraded: All master nodes are ready",Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6" to "NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6; 0 nodes have achieved new revision 7",Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6" to "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6; 0 nodes have achieved new revision 7"
2024-06-11T11:00:45.004840168Z I0611 11:00:45.004738       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:45.202344011Z I0611 11:00:45.202263       1 request.go:697] Waited for 1.163134558s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-06-11T11:00:46.202707291Z I0611 11:00:46.202639       1 request.go:697] Waited for 1.588249035s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:00:46.298216370Z I0611 11:00:46.298122       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:46.329097406Z I0611 11:00:46.329038       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:46.604597587Z I0611 11:00:46.604542       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:46.817280433Z I0611 11:00:46.817206       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:00:47.402614936Z I0611 11:00:47.402516       1 request.go:697] Waited for 1.353022149s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services?resourceVersion=20306
2024-06-11T11:00:47.404212731Z I0611 11:00:47.404178       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:47.804701143Z I0611 11:00:47.804643       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:48.407347376Z I0611 11:00:48.407271       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:00:48.484253548Z I0611 11:00:48.484189       1 reflector.go:351] Caches populated for *v1.Network from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:48.603117016Z I0611 11:00:48.603056       1 request.go:697] Waited for 1.595036439s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/serviceaccount-ca
2024-06-11T11:00:49.802885452Z I0611 11:00:49.802829       1 request.go:697] Waited for 1.300664935s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T11:00:50.624015875Z I0611 11:00:50.623936       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:51.002556934Z I0611 11:00:51.002444       1 request.go:697] Waited for 1.593489298s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-06-11T11:00:51.206830797Z I0611 11:00:51.206772       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:51.409064737Z I0611 11:00:51.408978       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:00:51.826930627Z I0611 11:00:51.826863       1 reflector.go:351] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:52.002834273Z I0611 11:00:52.002757       1 request.go:697] Waited for 1.595173862s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:00:53.406416221Z I0611 11:00:53.406356       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:00:54.204489922Z I0611 11:00:54.204420       1 reflector.go:351] Caches populated for *v1.APIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:54.602968639Z I0611 11:00:54.602906       1 request.go:697] Waited for 1.182978197s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:00:55.802819157Z I0611 11:00:55.802744       1 request.go:697] Waited for 1.19476121s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:00:55.807178821Z I0611 11:00:55.807125       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:00:56.804854402Z I0611 11:00:56.804789       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:00:57.002875287Z I0611 11:00:57.002810       1 request.go:697] Waited for 1.194364286s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:00:58.007591795Z I0611 11:00:58.007504       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:01:00.605168098Z I0611 11:01:00.605108       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:04.604904582Z I0611 11:01:04.604835       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:06.691294357Z I0611 11:01:06.691229       1 reflector.go:351] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:09.614976939Z I0611 11:01:09.614911       1 reflector.go:351] Caches populated for *v1.Role from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:10.803707148Z I0611 11:01:10.803643       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:01:19.407987104Z I0611 11:01:19.407789       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:01:19.635509064Z I0611 11:01:19.635446       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:01:19.636157203Z I0611 11:01:19.636101       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"kube-controller-manager-cert-syncer\" is terminated: Error: https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500\u0026resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: E0611 11:00:39.166556       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500\u0026resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: W0611 11:00:58.851680       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500\u0026resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: E0611 11:00:58.851777       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.Secret: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500\u0026resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: W0611 11:01:18.217883       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500\u0026resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: E0611 11:01:18.217957       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500\u0026resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: F0611 11:01:18.351928       1 base_controller.go:96] unable to sync caches for CertSyncController\nStaticPodsDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:01:19.655180245Z I0611 11:01:19.655070       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"kube-controller-manager-cert-syncer\" is terminated: Error: https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500&resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: E0611 11:00:39.166556       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500&resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: W0611 11:00:58.851680       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500&resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: E0611 11:00:58.851777       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.Secret: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500&resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: W0611 11:01:18.217883       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500&resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: E0611 11:01:18.217957       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500&resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: F0611 11:01:18.351928       1 base_controller.go:96] unable to sync caches for CertSyncController\nStaticPodsDegraded: "
2024-06-11T11:01:20.802635737Z I0611 11:01:20.802576       1 request.go:697] Waited for 1.146549037s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2024-06-11T11:01:21.803095702Z I0611 11:01:21.803034       1 request.go:697] Waited for 1.196258121s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:01:21.816973336Z I0611 11:01:21.816901       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:01:22.495827293Z I0611 11:01:22.495765       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:01:22.496341124Z I0611 11:01:22.496272       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6; 0 nodes have achieved new revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:01:22.607481196Z I0611 11:01:22.607386       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0 container \"kube-controller-manager-cert-syncer\" is terminated: Error: https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500&resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: E0611 11:00:39.166556       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500&resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: W0611 11:00:58.851680       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500&resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: E0611 11:00:58.851777       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.Secret: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500&resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: W0611 11:01:18.217883       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500&resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: E0611 11:01:18.217957       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500&resourceVersion=0\": tls: failed to verify certificate: x509: certificate signed by unknown authority\nStaticPodsDegraded: F0611 11:01:18.351928       1 base_controller.go:96] unable to sync caches for CertSyncController\nStaticPodsDegraded: " to "NodeControllerDegraded: All master nodes are ready"
2024-06-11T11:01:23.002590719Z I0611 11:01:23.002517       1 request.go:697] Waited for 1.184021988s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:01:24.002944778Z I0611 11:01:24.002879       1 request.go:697] Waited for 1.180551151s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T11:01:24.208586680Z I0611 11:01:24.208529       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:01:25.203107393Z I0611 11:01:25.203036       1 request.go:697] Waited for 1.191357292s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T11:01:26.407240444Z I0611 11:01:26.407175       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:01:34.808539787Z I0611 11:01:34.808463       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 5
2024-06-11T11:01:37.407644840Z I0611 11:01:37.407567       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 5
2024-06-11T11:01:43.408190496Z I0611 11:01:43.408117       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 5
2024-06-11T11:01:46.407794385Z I0611 11:01:46.407626       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:01:47.202927229Z I0611 11:01:47.202855       1 request.go:697] Waited for 1.06310976s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2024-06-11T11:01:48.403061996Z I0611 11:01:48.402975       1 request.go:697] Waited for 1.194522947s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2024-06-11T11:01:49.602233907Z I0611 11:01:49.602166       1 request.go:697] Waited for 1.193840308s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/cluster-policy-controller-config
2024-06-11T11:01:50.207682297Z I0611 11:01:50.207625       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:01:50.602653997Z I0611 11:01:50.602595       1 request.go:697] Waited for 1.39575221s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa
2024-06-11T11:01:51.602786070Z I0611 11:01:51.602696       1 request.go:697] Waited for 1.19581282s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:53.409057566Z I0611 11:01:53.408977       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-0" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:01:56.403346488Z I0611 11:01:56.403168       1 request.go:697] Waited for 1.184034039s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:01:57.602519086Z I0611 11:01:57.602449       1 request.go:697] Waited for 1.194422859s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:01:58.602857218Z I0611 11:01:58.602790       1 request.go:697] Waited for 1.191149295s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:01:58.819859193Z I0611 11:01:58.819771       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:01:58.819859193Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:01:58.819859193Z  CurrentRevision: (int32) 7,
2024-06-11T11:01:58.819859193Z  TargetRevision: (int32) 0,
2024-06-11T11:01:58.819859193Z  LastFailedRevision: (int32) 6,
2024-06-11T11:01:58.819859193Z  LastFailedTime: (*v1.Time)(0xc001124498)(2024-06-11 11:00:06 +0000 UTC),
2024-06-11T11:01:58.819859193Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:01:58.819859193Z  LastFailedCount: (int) 1,
2024-06-11T11:01:58.819859193Z  LastFallbackCount: (int) 0,
2024-06-11T11:01:58.819859193Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:01:58.819859193Z   (string) (len=2059) "installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T11:01:58.819859193Z  }
2024-06-11T11:01:58.819859193Z }
2024-06-11T11:01:58.819859193Z  because static pod is ready
2024-06-11T11:01:58.844853346Z I0611 11:01:58.844789       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-0" from revision 5 to 7 because static pod is ready
2024-06-11T11:01:58.845929100Z I0611 11:01:58.845882       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:01:58.847290668Z I0611 11:01:58.847231       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:01:58.863124562Z I0611 11:01:58.863058       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing message changed from "NodeInstallerProgressing: 2 nodes are at revision 5; 1 node is at revision 6; 0 nodes have achieved new revision 7" to "NodeInstallerProgressing: 1 node is at revision 5; 1 node is at revision 6; 1 node is at revision 7",Available message changed from "StaticPodsAvailable: 3 nodes are active; 2 nodes are at revision 5; 1 node is at revision 6; 0 nodes have achieved new revision 7" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 1 node is at revision 6; 1 node is at revision 7"
2024-06-11T11:02:00.004516863Z I0611 11:02:00.004438       1 request.go:697] Waited for 1.157465307s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T11:02:02.008760259Z I0611 11:02:02.008675       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-0" moving to (v1.NodeStatus) {
2024-06-11T11:02:02.008760259Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-0",
2024-06-11T11:02:02.008760259Z  CurrentRevision: (int32) 7,
2024-06-11T11:02:02.008760259Z  TargetRevision: (int32) 0,
2024-06-11T11:02:02.008760259Z  LastFailedRevision: (int32) 6,
2024-06-11T11:02:02.008760259Z  LastFailedTime: (*v1.Time)(0xc001307f98)(2024-06-11 11:00:06 +0000 UTC),
2024-06-11T11:02:02.008760259Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:02:02.008760259Z  LastFailedCount: (int) 1,
2024-06-11T11:02:02.008760259Z  LastFallbackCount: (int) 0,
2024-06-11T11:02:02.008760259Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:02:02.008760259Z   (string) (len=2059) "installer: i-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:57:49.957147       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:57:59.956878       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:09.957084       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:19.957109       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:29.957559       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 10:58:29.958346       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-0: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 10:58:29.958383       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T11:02:02.008760259Z  }
2024-06-11T11:02:02.008760259Z }
2024-06-11T11:02:02.008760259Z  because static pod is ready
2024-06-11T11:02:07.408796397Z I0611 11:02:07.408680       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-1 with revision 5 is the oldest and needs new revision 7
2024-06-11T11:02:07.408796397Z I0611 11:02:07.408738       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:02:07.408796397Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:02:07.408796397Z  CurrentRevision: (int32) 5,
2024-06-11T11:02:07.408796397Z  TargetRevision: (int32) 7,
2024-06-11T11:02:07.408796397Z  LastFailedRevision: (int32) 0,
2024-06-11T11:02:07.408796397Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:02:07.408796397Z  LastFailedReason: (string) "",
2024-06-11T11:02:07.408796397Z  LastFailedCount: (int) 0,
2024-06-11T11:02:07.408796397Z  LastFallbackCount: (int) 0,
2024-06-11T11:02:07.408796397Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:02:07.408796397Z }
2024-06-11T11:02:07.446906650Z I0611 11:02:07.446481       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 5 to 7 because node ci-op-9xx71rvq-1e28e-w667k-master-1 with revision 5 is the oldest
2024-06-11T11:02:07.449041670Z I0611 11:02:07.448988       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:02:09.253682584Z I0611 11:02:09.253597       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:02:10.006868719Z I0611 11:02:10.006755       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:02:10.402754276Z I0611 11:02:10.402662       1 request.go:697] Waited for 1.147467501s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:02:11.602925065Z I0611 11:02:11.602868       1 request.go:697] Waited for 1.194991097s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:02:12.407333535Z I0611 11:02:12.407132       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:02:12.802828602Z I0611 11:02:12.802747       1 request.go:697] Waited for 1.195144876s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:02:14.607499771Z I0611 11:02:14.607428       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:02:33.638201566Z I0611 11:02:33.638137       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:02:33.672162634Z I0611 11:02:33.672095       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:02:33.678755397Z I0611 11:02:33.676538       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is terminated: Error: resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: W0611 11:01:36.959923       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500\u0026resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: E0611 11:01:36.959973       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.Secret: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500\u0026resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: W0611 11:02:17.482829       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500\u0026resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: E0611 11:02:17.482901       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500\u0026resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: W0611 11:02:20.579286       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500\u0026resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: E0611 11:02:20.579365       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.Secret: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500\u0026resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: F0611 11:02:33.216726       1 base_controller.go:96] unable to sync caches for CertSyncController\nStaticPodsDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:02:33.697415223Z I0611 11:02:33.695812       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is terminated: Error: resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: W0611 11:01:36.959923       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500&resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: E0611 11:01:36.959973       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.Secret: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500&resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: W0611 11:02:17.482829       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500&resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: E0611 11:02:17.482901       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500&resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: W0611 11:02:20.579286       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500&resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: E0611 11:02:20.579365       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.Secret: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500&resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: F0611 11:02:33.216726       1 base_controller.go:96] unable to sync caches for CertSyncController\nStaticPodsDegraded: "
2024-06-11T11:02:34.805029542Z I0611 11:02:34.804955       1 request.go:697] Waited for 1.108155549s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2024-06-11T11:02:35.609320682Z I0611 11:02:35.609251       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:02:36.005258705Z I0611 11:02:36.005181       1 request.go:697] Waited for 1.195583208s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2024-06-11T11:02:36.639935151Z I0611 11:02:36.639869       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:02:36.640408271Z I0611 11:02:36.640358       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:02:36.656247056Z I0611 11:02:36.656181       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nStaticPodsDegraded: pod/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1 container \"kube-controller-manager-cert-syncer\" is terminated: Error: resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: W0611 11:01:36.959923       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500&resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: E0611 11:01:36.959973       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.Secret: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500&resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: W0611 11:02:17.482829       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500&resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: E0611 11:02:17.482901       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/configmaps?limit=500&resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: W0611 11:02:20.579286       1 reflector.go:539] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500&resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: E0611 11:02:20.579365       1 reflector.go:147] k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229: Failed to watch *v1.Secret: failed to list *v1.Secret: Get \"https://localhost:6443/api/v1/namespaces/openshift-kube-controller-manager/secrets?limit=500&resourceVersion=0\": dial tcp [::1]:6443: connect: connection refused\nStaticPodsDegraded: F0611 11:02:33.216726       1 base_controller.go:96] unable to sync caches for CertSyncController\nStaticPodsDegraded: " to "NodeControllerDegraded: All master nodes are ready"
2024-06-11T11:02:37.804998634Z I0611 11:02:37.804918       1 request.go:697] Waited for 1.164221247s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T11:02:38.010483420Z I0611 11:02:38.010402       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:02:38.805020364Z I0611 11:02:38.804938       1 request.go:697] Waited for 1.194396635s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:02:40.012753638Z I0611 11:02:40.012639       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:03:13.251359315Z E0611 11:03:13.251248       1 leaderelection.go:332] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:39.253496336Z E0611 11:03:39.253422       1 leaderelection.go:332] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:48.507669722Z E0611 11:03:48.507611       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:48.515710744Z E0611 11:03:48.515668       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:48.528928336Z E0611 11:03:48.528880       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:48.553086101Z E0611 11:03:48.553018       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:48.596680485Z E0611 11:03:48.596614       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:48.680238762Z E0611 11:03:48.680162       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:48.705076363Z E0611 11:03:48.705010       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:48.707701500Z E0611 11:03:48.707662       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:48.711399894Z E0611 11:03:48.711364       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.106070768Z E0611 11:03:49.105996       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.106288379Z E0611 11:03:49.106258       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.113265545Z E0611 11:03:49.113214       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.124120413Z E0611 11:03:49.124074       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.145016308Z E0611 11:03:49.144951       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.186183764Z E0611 11:03:49.186126       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.267470222Z E0611 11:03:49.267413       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.308113551Z E0611 11:03:49.308053       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:49.508100927Z E0611 11:03:49.508040       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.830615421Z E0611 11:03:49.830532       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:49.905625350Z E0611 11:03:49.905564       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:50.107592630Z E0611 11:03:50.107533       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:50.309252093Z E0611 11:03:50.309191       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:50.472419640Z E0611 11:03:50.472350       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:50.706705513Z E0611 11:03:50.706627       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:51.305770593Z E0611 11:03:51.305706       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:51.708694899Z E0611 11:03:51.708635       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:51.753576250Z E0611 11:03:51.753524       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:52.106006411Z E0611 11:03:52.105942       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:52.307808482Z E0611 11:03:52.307751       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:52.906503643Z E0611 11:03:52.906426       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:53.509345621Z E0611 11:03:53.509255       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:53.711062188Z E0611 11:03:53.710996       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:53.906988451Z E0611 11:03:53.906928       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:54.105479048Z E0611 11:03:54.105409       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:54.314579101Z E0611 11:03:54.314511       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:55.307205313Z E0611 11:03:55.307149       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:55.706434126Z E0611 11:03:55.706378       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:56.509113054Z E0611 11:03:56.509050       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:56.908113955Z E0611 11:03:56.908037       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:57.110622801Z E0611 11:03:57.110551       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:03:57.908067577Z E0611 11:03:57.907991       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:58.706361494Z E0611 11:03:58.706282       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:59.436932752Z E0611 11:03:59.436849       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:59.508038474Z E0611 11:03:59.507981       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:03:59.912150521Z E0611 11:03:59.912078       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:00.715535583Z E0611 11:04:00.715465       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:01.908799408Z E0611 11:04:01.908714       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:02.510561508Z E0611 11:04:02.510496       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:02.708229321Z E0611 11:04:02.708155       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:03.827640112Z E0611 11:04:03.827577       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:05.253553009Z E0611 11:04:05.253482       1 leaderelection.go:332] error retrieving resource lock openshift-kube-controller-manager-operator/kube-controller-manager-operator-lock: Get "https://172.30.0.1:443/apis/coordination.k8s.io/v1/namespaces/openshift-kube-controller-manager-operator/leases/kube-controller-manager-operator-lock?timeout=1m47s": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:05.272351257Z E0611 11:04:05.272281       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:05.711606404Z E0611 11:04:05.711528       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:08.910407692Z E0611 11:04:08.910295       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:09.679057848Z E0611 11:04:09.678971       1 base_controller.go:268] TargetConfigController reconciliation failed: Get "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:10.397419469Z E0611 11:04:10.397358       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:12.110948579Z E0611 11:04:12.110868       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:12.310838012Z E0611 11:04:12.310775       1 base_controller.go:268] BackingResourceController reconciliation failed: ["manifests/installer-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa": dial tcp 172.30.0.1:443: connect: connection refused, "manifests/installer-cluster-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:openshift-kube-controller-manager-installer": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:14.069087825Z E0611 11:04:14.069026       1 base_controller.go:268] InstallerStateController reconciliation failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:15.511235538Z E0611 11:04:15.511170       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:18.710547807Z E0611 11:04:18.710466       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:20.642106374Z E0611 11:04:20.642048       1 base_controller.go:268] StaticPodStateController reconciliation failed: Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:04:21.910926151Z E0611 11:04:21.910855       1 base_controller.go:268] KubeControllerManagerStaticResources reconciliation failed: ["assets/kube-controller-manager/ns.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/kube-system/rolebindings/system:openshift:leader-locking-kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-role.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/roles/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/leader-election-cluster-policy-controller-rolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/namespaces/openshift-kube-controller-manager/rolebindings/system:openshift:leader-election-lock-cluster-policy-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-security-allocation-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:namespace-security-allocation-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:podsecurity-admission-label-syncer-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/podsecurity-admission-label-privileged-namespaces-syncer-controller-clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:privileged-namespaces-psa-label-syncer": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/namespace-openshift-infra.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/svc.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/kube-controller-manager-sa": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/recycler-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-infra/serviceaccounts/pv-recycler-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-client-crb.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:operator:kube-controller-manager-recovery": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/localhost-recovery-sa.yaml" (string): Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/localhost-recovery-client": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrole.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/csr_approver_clusterrolebinding.yaml" (string): Get "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:controller:cluster-csr-approver-controller": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-sa.yaml" (string): Delete "https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/vsphere/legacy-cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:vsphere-legacy-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-role.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterroles/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, "assets/kube-controller-manager/gce/cloud-provider-binding.yaml" (string): Delete "https://172.30.0.1:443/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/system:openshift:kube-controller-manager:gce-cloud-provider": dial tcp 172.30.0.1:443: connect: connection refused, Put "https://172.30.0.1:443/apis/operator.openshift.io/v1/kubecontrollermanagers/cluster/status": dial tcp 172.30.0.1:443: connect: connection refused]
2024-06-11T11:04:56.233621359Z I0611 11:04:56.233547       1 reflector.go:351] Caches populated for *v1.Service from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:04.237132453Z I0611 11:05:04.237056       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:06.387675126Z I0611 11:05:06.387593       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:08.788590878Z I0611 11:05:08.788509       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:09.572576165Z I0611 11:05:09.572511       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:11.390985904Z I0611 11:05:11.390917       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:15.410562557Z I0611 11:05:15.410489       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:15.790328039Z I0611 11:05:15.790235       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:16.619823677Z I0611 11:05:16.619749       1 reflector.go:351] Caches populated for *v1.Proxy from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:16.956455770Z I0611 11:05:16.956393       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:19.655939470Z I0611 11:05:19.655858       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:19.792677090Z I0611 11:05:19.792615       1 reflector.go:351] Caches populated for *v1.ClusterRole from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:24.283898657Z I0611 11:05:24.283833       1 reflector.go:351] Caches populated for *v1.Role from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:24.998031799Z I0611 11:05:24.997967       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:25.417215200Z I0611 11:05:25.417159       1 reflector.go:351] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:25.418343752Z I0611 11:05:25.418278       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:05:25.570130169Z I0611 11:05:25.570061       1 reflector.go:351] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:27.190597911Z I0611 11:05:27.190503       1 installer_controller.go:491] Will retry "ci-op-9xx71rvq-1e28e-w667k-master-1" for revision 7 for the 1st time because installer pod failed: installer: i-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190597911Z W0611 11:02:31.404102       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190597911Z W0611 11:02:41.402998       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190597911Z W0611 11:02:51.403092       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190597911Z W0611 11:03:01.403769       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190597911Z W0611 11:03:11.402960       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190597911Z W0611 11:03:11.404078       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190597911Z F0611 11:03:11.404123       1 cmd.go:105] timed out waiting for the condition
2024-06-11T11:05:27.190715616Z I0611 11:05:27.190630       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Warning' reason: 'InstallerPodFailed' installer errors: installer: i-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z W0611 11:02:31.404102       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z W0611 11:02:41.402998       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z W0611 11:02:51.403092       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z W0611 11:03:01.403769       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z W0611 11:03:11.402960       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z W0611 11:03:11.404078       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z F0611 11:03:11.404123       1 cmd.go:105] timed out waiting for the condition
2024-06-11T11:05:27.190715616Z I0611 11:05:27.190674       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:05:27.190715616Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:05:27.190715616Z  CurrentRevision: (int32) 5,
2024-06-11T11:05:27.190715616Z  TargetRevision: (int32) 7,
2024-06-11T11:05:27.190715616Z  LastFailedRevision: (int32) 7,
2024-06-11T11:05:27.190715616Z  LastFailedTime: (*v1.Time)(0xc001306090)(2024-06-11 11:05:27.190476806 +0000 UTC m=+941.001118588),
2024-06-11T11:05:27.190715616Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:05:27.190715616Z  LastFailedCount: (int) 1,
2024-06-11T11:05:27.190715616Z  LastFallbackCount: (int) 0,
2024-06-11T11:05:27.190715616Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:05:27.190715616Z   (string) (len=2059) "installer: i-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:02:31.404102       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:02:41.402998       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:02:51.403092       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:03:01.403769       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:03:11.402960       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:03:11.404078       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 11:03:11.404123       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T11:05:27.190715616Z  }
2024-06-11T11:05:27.190715616Z }
2024-06-11T11:05:27.190715616Z  because installer pod failed: installer: i-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z W0611 11:02:31.404102       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z W0611 11:02:41.402998       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z W0611 11:02:51.403092       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z W0611 11:03:01.403769       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z W0611 11:03:11.402960       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z W0611 11:03:11.404078       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:05:27.190715616Z F0611 11:03:11.404123       1 cmd.go:105] timed out waiting for the condition
2024-06-11T11:05:27.235994780Z I0611 11:05:27.235932       1 prune_controller.go:269] Nothing to prune
2024-06-11T11:05:27.236397698Z I0611 11:05:27.236352       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:02:31.404102       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:02:41.402998       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:02:51.403092       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:03:01.403769       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:03:11.402960       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:03:11.404078       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 11:03:11.404123       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: ","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 1 node is at revision 5; 1 node is at revision 6; 1 node is at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 1 node is at revision 6; 1 node is at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:05:27.272361137Z I0611 11:05:27.271380       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:02:31.404102       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:02:41.402998       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:02:51.403092       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:03:01.403769       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:03:11.402960       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:03:11.404078       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 11:03:11.404123       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: "
2024-06-11T11:05:27.535253617Z I0611 11:05:27.535178       1 reflector.go:351] Caches populated for *v1.PodDisruptionBudget from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:28.387843168Z I0611 11:05:28.387770       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:28.477628559Z I0611 11:05:28.477572       1 reflector.go:351] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:29.506184729Z I0611 11:05:29.506114       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:30.391560675Z I0611 11:05:30.391470       1 reflector.go:351] Caches populated for *v1.Namespace from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:30.535648340Z I0611 11:05:30.535574       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:30.938367092Z I0611 11:05:30.935845       1 reflector.go:351] Caches populated for *v1.APIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:31.388143308Z I0611 11:05:31.388051       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:33.787747575Z I0611 11:05:33.787694       1 reflector.go:351] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:36.547413146Z I0611 11:05:36.547357       1 reflector.go:351] Caches populated for *v1.Network from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:36.589524824Z I0611 11:05:36.589466       1 reflector.go:351] Caches populated for *v1.Pod from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:40.588344311Z I0611 11:05:40.588234       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:41.188675737Z I0611 11:05:41.188575       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:43.211983491Z I0611 11:05:43.211858       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-retry-1-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:05:43.790455796Z I0611 11:05:43.790395       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:05:45.791666620Z I0611 11:05:45.791585       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:05:47.590932359Z I0611 11:05:47.590796       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:05:49.388005600Z I0611 11:05:49.387940       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:49.786633174Z I0611 11:05:49.786351       1 request.go:697] Waited for 1.08022546s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:05:50.790371255Z I0611 11:05:50.790258       1 reflector.go:351] Caches populated for *v1.RoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:52.369107595Z I0611 11:05:52.369039       1 reflector.go:351] Caches populated for *v1.ClusterRoleBinding from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:56.988575425Z I0611 11:05:56.988506       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:05:58.486199852Z I0611 11:05:58.486113       1 reflector.go:351] Caches populated for *v1.Infrastructure from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:06:02.389085978Z I0611 11:06:02.389012       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:06:02.788056341Z I0611 11:06:02.787976       1 reflector.go:351] Caches populated for *v1.ServiceAccount from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:06:09.390516447Z I0611 11:06:09.390431       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:06:09.788974945Z I0611 11:06:09.788904       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:06:17.866548197Z I0611 11:06:17.866467       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:06:20.060826235Z I0611 11:06:20.060765       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 5
2024-06-11T11:06:22.081738852Z I0611 11:06:22.081617       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 5
2024-06-11T11:06:28.801956498Z I0611 11:06:28.801875       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 5
2024-06-11T11:06:32.404354742Z I0611 11:06:32.403941       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:06:34.593219185Z I0611 11:06:34.593143       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:06:36.589785027Z I0611 11:06:36.589707       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:06:42.460013933Z I0611 11:06:42.459954       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-1" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:06:45.052471454Z I0611 11:06:45.052389       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:06:45.052471454Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:06:45.052471454Z  CurrentRevision: (int32) 7,
2024-06-11T11:06:45.052471454Z  TargetRevision: (int32) 0,
2024-06-11T11:06:45.052471454Z  LastFailedRevision: (int32) 7,
2024-06-11T11:06:45.052471454Z  LastFailedTime: (*v1.Time)(0xc0024399f8)(2024-06-11 11:05:27 +0000 UTC),
2024-06-11T11:06:45.052471454Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:06:45.052471454Z  LastFailedCount: (int) 1,
2024-06-11T11:06:45.052471454Z  LastFallbackCount: (int) 0,
2024-06-11T11:06:45.052471454Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:06:45.052471454Z   (string) (len=2059) "installer: i-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:02:31.404102       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:02:41.402998       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:02:51.403092       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:03:01.403769       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:03:11.402960       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:03:11.404078       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 11:03:11.404123       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T11:06:45.052471454Z  }
2024-06-11T11:06:45.052471454Z }
2024-06-11T11:06:45.052471454Z  because static pod is ready
2024-06-11T11:06:45.074443984Z I0611 11:06:45.074366       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-1" from revision 5 to 7 because static pod is ready
2024-06-11T11:06:45.077385682Z I0611 11:06:45.077289       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 1 node is at revision 6; 2 nodes are at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 6; 2 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:06:45.088562154Z I0611 11:06:45.088498       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nNodeInstallerDegraded: 1 nodes are failing on revision 7:\nNodeInstallerDegraded: installer: i-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:02:31.404102       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:02:41.402998       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:02:51.403092       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:03:01.403769       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:03:11.402960       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: W0611 11:03:11.404078       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nNodeInstallerDegraded: F0611 11:03:11.404123       1 cmd.go:105] timed out waiting for the condition\nNodeInstallerDegraded: " to "NodeControllerDegraded: All master nodes are ready",Progressing message changed from "NodeInstallerProgressing: 1 node is at revision 5; 1 node is at revision 6; 1 node is at revision 7" to "NodeInstallerProgressing: 1 node is at revision 6; 2 nodes are at revision 7",Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 5; 1 node is at revision 6; 1 node is at revision 7" to "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 6; 2 nodes are at revision 7"
2024-06-11T11:06:46.248414400Z I0611 11:06:46.248348       1 request.go:697] Waited for 1.166712772s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:06:47.447807013Z I0611 11:06:47.447744       1 request.go:697] Waited for 1.196135463s due to client-side throttling, not priority and fairness, request: POST:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods
2024-06-11T11:06:47.457544662Z I0611 11:06:47.457471       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-0 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:06:48.253116452Z I0611 11:06:48.253041       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-1" moving to (v1.NodeStatus) {
2024-06-11T11:06:48.253116452Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-1",
2024-06-11T11:06:48.253116452Z  CurrentRevision: (int32) 7,
2024-06-11T11:06:48.253116452Z  TargetRevision: (int32) 0,
2024-06-11T11:06:48.253116452Z  LastFailedRevision: (int32) 7,
2024-06-11T11:06:48.253116452Z  LastFailedTime: (*v1.Time)(0xc00266bf08)(2024-06-11 11:05:27 +0000 UTC),
2024-06-11T11:06:48.253116452Z  LastFailedReason: (string) (len=15) "InstallerFailed",
2024-06-11T11:06:48.253116452Z  LastFailedCount: (int) 1,
2024-06-11T11:06:48.253116452Z  LastFallbackCount: (int) 0,
2024-06-11T11:06:48.253116452Z  LastFailedRevisionErrors: ([]string) (len=1 cap=1) {
2024-06-11T11:06:48.253116452Z   (string) (len=2059) "installer: i-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:02:31.404102       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:02:41.402998       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:02:51.403092       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:03:01.403769       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:03:11.402960       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nW0611 11:03:11.404078       1 cmd.go:466] Error getting installer pods on current node ci-op-9xx71rvq-1e28e-w667k-master-1: Get \"https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller\": dial tcp 172.30.0.1:443: connect: connection refused\nF0611 11:03:11.404123       1 cmd.go:105] timed out waiting for the condition\n"
2024-06-11T11:06:48.253116452Z  }
2024-06-11T11:06:48.253116452Z }
2024-06-11T11:06:48.253116452Z  because static pod is ready
2024-06-11T11:06:48.450376049Z I0611 11:06:48.450229       1 request.go:697] Waited for 1.193953962s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager
2024-06-11T11:06:49.648454802Z I0611 11:06:49.648390       1 request.go:697] Waited for 1.394167996s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:06:50.459530707Z I0611 11:06:50.459325       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-1 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:06:50.648723632Z I0611 11:06:50.648658       1 request.go:697] Waited for 1.577747562s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/recycler-config
2024-06-11T11:06:51.848078776Z I0611 11:06:51.848017       1 request.go:697] Waited for 1.388708176s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:53.049759853Z I0611 11:06:53.049668       1 request.go:697] Waited for 1.394740005s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods?labelSelector=app%3Dinstaller
2024-06-11T11:06:53.258018951Z I0611 11:06:53.257949       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:06:54.248128584Z I0611 11:06:54.248067       1 request.go:697] Waited for 1.38921476s due to client-side throttling, not priority and fairness, request: DELETE:https://172.30.0.1:443/api/v1/namespaces/kube-system/serviceaccounts/vsphere-legacy-cloud-provider
2024-06-11T11:06:55.448191989Z I0611 11:06:55.448133       1 request.go:697] Waited for 1.59500845s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:06:56.648508606Z I0611 11:06:56.648444       1 request.go:697] Waited for 1.396182468s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:57.053853210Z I0611 11:06:57.053785       1 installer_controller.go:524] node ci-op-9xx71rvq-1e28e-w667k-master-2 with revision 6 is the oldest and needs new revision 7
2024-06-11T11:06:57.053853210Z I0611 11:06:57.053835       1 installer_controller.go:532] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:06:57.053853210Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:06:57.053853210Z  CurrentRevision: (int32) 6,
2024-06-11T11:06:57.053853210Z  TargetRevision: (int32) 7,
2024-06-11T11:06:57.053853210Z  LastFailedRevision: (int32) 0,
2024-06-11T11:06:57.053853210Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:06:57.053853210Z  LastFailedReason: (string) "",
2024-06-11T11:06:57.053853210Z  LastFailedCount: (int) 0,
2024-06-11T11:06:57.053853210Z  LastFallbackCount: (int) 0,
2024-06-11T11:06:57.053853210Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:06:57.053853210Z }
2024-06-11T11:06:57.084714673Z I0611 11:06:57.084633       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeTargetRevisionChanged' Updating node "ci-op-9xx71rvq-1e28e-w667k-master-2" from revision 6 to 7 because node ci-op-9xx71rvq-1e28e-w667k-master-2 with revision 6 is the oldest
2024-06-11T11:06:57.848078790Z I0611 11:06:57.847951       1 request.go:697] Waited for 1.195101287s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:06:58.848694286Z I0611 11:06:58.848631       1 request.go:697] Waited for 1.595607777s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager
2024-06-11T11:06:59.863124236Z I0611 11:06:59.863055       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodCreated' Created Pod/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-2 -n openshift-kube-controller-manager because it was missing
2024-06-11T11:07:00.047789260Z I0611 11:07:00.047720       1 request.go:697] Waited for 1.395293139s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:07:01.048452168Z I0611 11:07:01.048367       1 request.go:697] Waited for 1.394529263s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:01.332117755Z I0611 11:07:01.332058       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Pending phase
2024-06-11T11:07:02.248034243Z I0611 11:07:02.247975       1 request.go:697] Waited for 1.561905707s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/localhost-recovery-client-token
2024-06-11T11:07:03.448683666Z I0611 11:07:03.448389       1 request.go:697] Waited for 1.188464574s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/controller-manager-kubeconfig
2024-06-11T11:07:04.072095668Z I0611 11:07:04.072023       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:07:06.070239041Z I0611 11:07:06.070179       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:07:33.969552833Z I0611 11:07:33.969477       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because installer is not finished, but in Running phase
2024-06-11T11:07:35.967950914Z I0611 11:07:35.967856       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 6
2024-06-11T11:07:38.077268216Z I0611 11:07:38.077202       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 6
2024-06-11T11:07:47.700872866Z I0611 11:07:47.700792       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because waiting for static pod of revision 7, found 6
2024-06-11T11:07:50.278087081Z I0611 11:07:50.277979       1 request.go:697] Waited for 1.170425716s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager
2024-06-11T11:07:51.082138202Z I0611 11:07:51.082060       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:07:51.477351763Z I0611 11:07:51.477273       1 request.go:697] Waited for 1.147089091s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-infra
2024-06-11T11:07:52.281935008Z E0611 11:07:52.281780       1 guard_controller.go:293] Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:52.302211699Z E0611 11:07:52.302143       1 base_controller.go:268] GuardController reconciliation failed: Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:52.304412895Z I0611 11:07:52.304361       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 1 node is at revision 6; 2 nodes are at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 6; 2 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:07:52.318930833Z I0611 11:07:52.317344       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready" to "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2"
2024-06-11T11:07:53.478011950Z I0611 11:07:53.477932       1 request.go:697] Waited for 1.173900269s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/serviceaccounts/installer-sa
2024-06-11T11:07:54.481417529Z I0611 11:07:54.481355       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:07:54.677956263Z I0611 11:07:54.677815       1 request.go:697] Waited for 1.396912565s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-guard-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:07:55.678390356Z I0611 11:07:55.678258       1 request.go:697] Waited for 1.195546568s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:56.877484000Z I0611 11:07:56.877419       1 request.go:697] Waited for 1.195473955s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:07:57.885503967Z I0611 11:07:57.885443       1 installer_controller.go:512] "ci-op-9xx71rvq-1e28e-w667k-master-2" is in transition to 7, but has not made progress because static pod is pending
2024-06-11T11:07:58.877989338Z I0611 11:07:58.877916       1 request.go:697] Waited for 1.19238516s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-0
2024-06-11T11:07:59.308265466Z I0611 11:07:59.308161       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T10:48:58Z","message":"NodeInstallerProgressing: 1 node is at revision 6; 2 nodes are at revision 7","reason":"NodeInstaller","status":"True","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 1 node is at revision 6; 2 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:07:59.323406246Z I0611 11:07:59.323288       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Degraded message changed from "NodeControllerDegraded: All master nodes are ready\nGuardControllerDegraded: Missing PodIP in operand kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2 on node ci-op-9xx71rvq-1e28e-w667k-master-2" to "NodeControllerDegraded: All master nodes are ready"
2024-06-11T11:08:00.077595124Z I0611 11:08:00.077524       1 request.go:697] Waited for 1.194961677s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:08:01.078350778Z I0611 11:08:01.078264       1 request.go:697] Waited for 1.57033154s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/services/kube-controller-manager
2024-06-11T11:08:01.882408797Z I0611 11:08:01.882338       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:08:01.882408797Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:08:01.882408797Z  CurrentRevision: (int32) 7,
2024-06-11T11:08:01.882408797Z  TargetRevision: (int32) 0,
2024-06-11T11:08:01.882408797Z  LastFailedRevision: (int32) 0,
2024-06-11T11:08:01.882408797Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:08:01.882408797Z  LastFailedReason: (string) "",
2024-06-11T11:08:01.882408797Z  LastFailedCount: (int) 0,
2024-06-11T11:08:01.882408797Z  LastFallbackCount: (int) 0,
2024-06-11T11:08:01.882408797Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:08:01.882408797Z }
2024-06-11T11:08:01.882408797Z  because static pod is ready
2024-06-11T11:08:01.906895797Z I0611 11:08:01.906818       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NodeCurrentRevisionChanged' Updated node "ci-op-9xx71rvq-1e28e-w667k-master-2" from revision 6 to 7 because static pod is ready
2024-06-11T11:08:01.908494668Z I0611 11:08:01.908428       1 status_controller.go:218] clusteroperator/kube-controller-manager diff {"status":{"conditions":[{"lastTransitionTime":"2024-06-11T10:57:17Z","message":"NodeControllerDegraded: All master nodes are ready","reason":"AsExpected","status":"False","type":"Degraded"},{"lastTransitionTime":"2024-06-11T11:08:01Z","message":"NodeInstallerProgressing: 3 nodes are at revision 7","reason":"AsExpected","status":"False","type":"Progressing"},{"lastTransitionTime":"2024-06-11T10:51:36Z","message":"StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7","reason":"AsExpected","status":"True","type":"Available"},{"lastTransitionTime":"2024-06-11T10:48:20Z","message":"All is well","reason":"AsExpected","status":"True","type":"Upgradeable"},{"lastTransitionTime":"2024-06-11T10:48:20Z","reason":"NoData","status":"Unknown","type":"EvaluationConditionsDetected"}]}}
2024-06-11T11:08:01.923571046Z I0611 11:08:01.922598       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-kube-controller-manager-operator", Name:"kube-controller-manager-operator", UID:"dc25edff-39bb-4cee-96b9-1cf35650ef3e", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'OperatorStatusChanged' Status for clusteroperator/kube-controller-manager changed: Progressing changed from True to False ("NodeInstallerProgressing: 3 nodes are at revision 7"),Available message changed from "StaticPodsAvailable: 3 nodes are active; 1 node is at revision 6; 2 nodes are at revision 7" to "StaticPodsAvailable: 3 nodes are active; 3 nodes are at revision 7"
2024-06-11T11:08:02.277479443Z I0611 11:08:02.277399       1 request.go:697] Waited for 1.3958114s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/revision-pruner-7-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:08:03.277551738Z I0611 11:08:03.277486       1 request.go:697] Waited for 1.369251078s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/installer-7-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:04.278076394Z I0611 11:08:04.277981       1 request.go:697] Waited for 1.395976991s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-1
2024-06-11T11:08:05.478161417Z I0611 11:08:05.478086       1 request.go:697] Waited for 1.195202309s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/pods/kube-controller-manager-ci-op-9xx71rvq-1e28e-w667k-master-2
2024-06-11T11:08:05.682252383Z I0611 11:08:05.682171       1 installer_controller.go:500] "ci-op-9xx71rvq-1e28e-w667k-master-2" moving to (v1.NodeStatus) {
2024-06-11T11:08:05.682252383Z  NodeName: (string) (len=35) "ci-op-9xx71rvq-1e28e-w667k-master-2",
2024-06-11T11:08:05.682252383Z  CurrentRevision: (int32) 7,
2024-06-11T11:08:05.682252383Z  TargetRevision: (int32) 0,
2024-06-11T11:08:05.682252383Z  LastFailedRevision: (int32) 0,
2024-06-11T11:08:05.682252383Z  LastFailedTime: (*v1.Time)(<nil>),
2024-06-11T11:08:05.682252383Z  LastFailedReason: (string) "",
2024-06-11T11:08:05.682252383Z  LastFailedCount: (int) 0,
2024-06-11T11:08:05.682252383Z  LastFallbackCount: (int) 0,
2024-06-11T11:08:05.682252383Z  LastFailedRevisionErrors: ([]string) <nil>
2024-06-11T11:08:05.682252383Z }
2024-06-11T11:08:05.682252383Z  because static pod is ready
2024-06-11T11:08:06.478216752Z I0611 11:08:06.478156       1 request.go:697] Waited for 1.195281412s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/secrets/serving-cert
2024-06-11T11:08:07.678338677Z I0611 11:08:07.678233       1 request.go:697] Waited for 1.196696374s due to client-side throttling, not priority and fairness, request: GET:https://172.30.0.1:443/api/v1/namespaces/openshift-kube-controller-manager/configmaps/config
2024-06-11T11:12:17.621565702Z I0611 11:12:17.621500       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:17.757371071Z I0611 11:12:17.757251       1 reflector.go:351] Caches populated for operator.openshift.io/v1, Resource=kubecontrollermanagers from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:12:57.767712785Z I0611 11:12:57.767603       1 gcwatcher_controller.go:250] Synced alerting rules cache
2024-06-11T11:12:57.767712785Z W0611 11:12:57.767638       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-06-11T11:14:46.999680407Z W0611 11:14:46.999612       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-06-11T11:15:16.192356138Z I0611 11:15:16.192272       1 reflector.go:351] Caches populated for *v1.Node from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:15:16.661323066Z I0611 11:15:16.661248       1 reflector.go:351] Caches populated for *v1.ClusterVersion from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:15:16.778345659Z I0611 11:15:16.778278       1 reflector.go:351] Caches populated for *v1.FeatureGate from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:15:16.811875449Z I0611 11:15:16.811791       1 reflector.go:351] Caches populated for *v1.Network from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:15:16.987465092Z I0611 11:15:16.987387       1 reflector.go:351] Caches populated for *v1.APIServer from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:15:17.192361162Z I0611 11:15:17.192283       1 reflector.go:351] Caches populated for *v1.ClusterOperator from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:15:17.309888187Z I0611 11:15:17.309787       1 reflector.go:351] Caches populated for *v1.Proxy from k8s.io/client-go@v0.29.0/tools/cache/reflector.go:229
2024-06-11T11:19:47.000401334Z W0611 11:19:47.000322       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-06-11T11:24:47.001434912Z W0611 11:24:47.001254       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
2024-06-11T11:29:47.001458018Z W0611 11:29:47.001390       1 gcwatcher_controller.go:223] missing required alerts: GarbageCollectorSyncFailed
