2024-06-11T10:49:22.885638198Z W0611 10:49:22.885472       1 client_config.go:618] Neither --kubeconfig nor --master was specified.  Using the inClusterConfig.  This might not work.
2024-06-11T10:49:22.955517033Z I0611 10:49:22.954193       1 simple_featuregate_reader.go:171] Starting feature-gate-detector
2024-06-11T10:49:22.960043242Z I0611 10:49:22.959793       1 reflector.go:351] Caches populated for *v1.ClusterVersion from github.com/openshift/client-go/config/informers/externalversions/factory.go:125
2024-06-11T10:49:22.960853780Z I0611 10:49:22.960815       1 reflector.go:351] Caches populated for *v1.FeatureGate from github.com/openshift/client-go/config/informers/externalversions/factory.go:125
2024-06-11T10:49:22.962413052Z I0611 10:49:22.962381       1 operator.go:482] Metrics Server enabled
2024-06-11T10:49:22.992745656Z I0611 10:49:22.992633       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'FeatureGatesInitialized' FeatureGates updated to featuregates.Features{Enabled:[]v1.FeatureGateName{"AdminNetworkPolicy", "AlibabaPlatform", "AzureWorkloadIdentity", "BareMetalLoadBalancer", "BuildCSIVolumes", "CloudDualStackNodeIPs", "ClusterAPIInstallAWS", "ClusterAPIInstallNutanix", "ClusterAPIInstallOpenStack", "ClusterAPIInstallVSphere", "DisableKubeletCloudCredentialProviders", "ExternalCloudProvider", "ExternalCloudProviderAzure", "ExternalCloudProviderExternal", "ExternalCloudProviderGCP", "HardwareSpeed", "KMSv1", "MetricsServer", "NetworkDiagnosticsConfig", "NetworkLiveMigration", "PrivateHostedZoneAWS", "VSphereControlPlaneMachineSet", "VSphereDriverConfiguration", "VSphereStaticIPs"}, Disabled:[]v1.FeatureGateName{"AutomatedEtcdBackup", "CSIDriverSharedResource", "ChunkSizeMiB", "ClusterAPIInstall", "ClusterAPIInstallAzure", "ClusterAPIInstallGCP", "ClusterAPIInstallIBMCloud", "ClusterAPIInstallPowerVS", "DNSNameResolver", "DynamicResourceAllocation", "EtcdBackendQuota", "EventedPLEG", "Example", "ExternalOIDC", "ExternalRouteCertificate", "GCPClusterHostedDNS", "GCPLabelsTags", "GatewayAPI", "ImagePolicy", "InsightsConfig", "InsightsConfigAPI", "InsightsOnDemandDataGather", "InstallAlternateInfrastructureAWS", "MachineAPIOperatorDisableMachineHealthCheckController", "MachineAPIProviderOpenStack", "MachineConfigNodes", "ManagedBootImages", "MaxUnavailableStatefulSet", "MetricsCollectionProfiles", "MixedCPUsAllocation", "NewOLM", "NodeDisruptionPolicy", "NodeSwap", "OnClusterBuild", "OpenShiftPodSecurityAdmission", "PinnedImages", "PlatformOperators", "RouteExternalCertificate", "ServiceAccountTokenNodeBinding", "ServiceAccountTokenNodeBindingValidation", "ServiceAccountTokenPodNodeInfo", "SignatureStores", "SigstoreImageVerification", "TranslateStreamCloseWebsocketRequests", "UpgradeStatus", "VSphereMultiVCenters", "ValidatingAdmissionPolicy", "VolumeGroupSnapshot"}}
2024-06-11T10:49:22.998727333Z I0611 10:49:22.998672       1 reflector.go:351] Caches populated for *v1.Secret from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:49:23.002093689Z I0611 10:49:23.002050       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:566
2024-06-11T10:49:23.002650415Z I0611 10:49:23.002597       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:49:23.002830823Z I0611 10:49:23.002805       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:49:23.005069627Z I0611 10:49:23.003873       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:49:23.006664801Z I0611 10:49:23.006623       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/cluster-monitoring-config
2024-06-11T10:49:23.008261075Z I0611 10:49:23.001999       1 dynamic_serving_content.go:113] "Loaded a new cert/key pair" name="serving-cert::/etc/tls/private/tls.crt::/etc/tls/private/tls.key"
2024-06-11T10:49:23.009406528Z I0611 10:49:23.008920       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go/informers/factory.go:159
2024-06-11T10:49:23.012122453Z I0611 10:49:23.012082       1 reflector.go:351] Caches populated for *v1.Infrastructure from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:49:23.012359464Z I0611 10:49:23.012328       1 reflector.go:351] Caches populated for *v1.APIServer from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:49:23.013064297Z I0611 10:49:23.013028       1 reflector.go:351] Caches populated for *v1.Console from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:49:23.013605422Z I0611 10:49:23.013567       1 reflector.go:351] Caches populated for *v1.CustomResourceDefinition from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:49:23.037440925Z I0611 10:49:23.035983       1 reflector.go:351] Caches populated for *v1.ClusterVersion from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:49:23.054387510Z I0611 10:49:23.048444       1 operator.go:650] Triggering an update due to a change in *v1.APIServer/cluster
2024-06-11T10:49:23.054387510Z I0611 10:49:23.048862       1 operator.go:650] Triggering an update due to a change in *v1.Infrastructure/cluster
2024-06-11T10:49:23.110349401Z I0611 10:49:23.108978       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:49:23.130062213Z I0611 10:49:23.130002       1 reflector.go:351] Caches populated for *v1.ClusterOperator from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:49:23.131790993Z I0611 10:49:23.130233       1 operator.go:650] Triggering an update due to a change in ClusterOperator.config.openshift.io/ingress
2024-06-11T10:49:23.151348699Z I0611 10:49:23.150594       1 reflector.go:351] Caches populated for *v1.CertificateSigningRequest from k8s.io/client-go/informers/factory.go:159
2024-06-11T10:49:23.304384383Z I0611 10:49:23.301449       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:49:23.397002471Z I0611 10:49:23.396905       1 base_controller.go:67] Waiting for caches to sync for OpenShiftMonitoringClientCertRequester
2024-06-11T10:49:23.397997417Z I0611 10:49:23.396950       1 base_controller.go:73] Caches are synced for OpenShiftMonitoringClientCertRequester 
2024-06-11T10:49:23.397997417Z I0611 10:49:23.397387       1 base_controller.go:110] Starting #1 worker of OpenShiftMonitoringClientCertRequester controller ...
2024-06-11T10:49:23.397997417Z I0611 10:49:23.397041       1 rule_controller.go:113] Starting alerting rules controller
2024-06-11T10:49:23.397997417Z I0611 10:49:23.397080       1 relabel_controller.go:117] Starting alert relabel config controller
2024-06-11T10:49:23.397997417Z I0611 10:49:23.397529       1 shared_informer.go:311] Waiting for caches to sync for AlertRelabelConfig controller
2024-06-11T10:49:23.398043619Z I0611 10:49:23.397995       1 shared_informer.go:311] Waiting for caches to sync for AlertingRule controller
2024-06-11T10:49:23.398173625Z I0611 10:49:23.397106       1 base_controller.go:67] Waiting for caches to sync for OpenShiftMonitoringTelemeterClientCertRequester
2024-06-11T10:49:23.398226327Z I0611 10:49:23.398212       1 base_controller.go:73] Caches are synced for OpenShiftMonitoringTelemeterClientCertRequester 
2024-06-11T10:49:23.398252329Z I0611 10:49:23.398243       1 base_controller.go:110] Starting #1 worker of OpenShiftMonitoringTelemeterClientCertRequester controller ...
2024-06-11T10:49:23.408164888Z I0611 10:49:23.407043       1 reflector.go:351] Caches populated for *v1.AlertingRule from github.com/openshift/cluster-monitoring-operator/pkg/alert/rule_controller.go:118
2024-06-11T10:49:23.409407645Z I0611 10:49:23.409069       1 reflector.go:351] Caches populated for *v1.Secret from github.com/openshift/cluster-monitoring-operator/pkg/alert/relabel_controller.go:122
2024-06-11T10:49:23.412961210Z I0611 10:49:23.409579       1 reflector.go:351] Caches populated for *v1.AlertRelabelConfig from github.com/openshift/cluster-monitoring-operator/pkg/alert/relabel_controller.go:121
2024-06-11T10:49:23.412961210Z I0611 10:49:23.410085       1 reflector.go:351] Caches populated for *v1.PrometheusRule from github.com/openshift/cluster-monitoring-operator/pkg/alert/rule_controller.go:117
2024-06-11T10:49:23.412961210Z I0611 10:49:23.410743       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NoValidCertificateFound' No valid client certificate for OpenShiftMonitoringTelemeterClientCertRequester is found: unable to parse certificate: data does not contain any valid RSA or ECDSA certificates
2024-06-11T10:49:23.412961210Z I0611 10:49:23.410778       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'NoValidCertificateFound' No valid client certificate for OpenShiftMonitoringClientCertRequester is found: unable to parse certificate: data does not contain any valid RSA or ECDSA certificates
2024-06-11T10:49:23.424730854Z I0611 10:49:23.424641       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'CSRCreated' A csr "system:openshift:openshift-monitoring-mndv5" is created for OpenShiftMonitoringTelemeterClientCertRequester
2024-06-11T10:49:23.424796358Z I0611 10:49:23.424728       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'CSRCreated' A csr "system:openshift:openshift-monitoring-dhl9x" is created for OpenShiftMonitoringClientCertRequester
2024-06-11T10:49:23.457865888Z I0611 10:49:23.457811       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T10:49:23.486257103Z I0611 10:49:23.486209       1 tasks.go:49] processing task group 1 of 3
2024-06-11T10:49:23.486364208Z I0611 10:49:23.486345       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T10:49:23.487452858Z I0611 10:49:23.487413       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/metrics-client-certs
2024-06-11T10:49:23.488207593Z I0611 10:49:23.488175       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:49:23.488751318Z I0611 10:49:23.488709       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClientCertificateCreated' A new client certificate for OpenShiftMonitoringClientCertRequester is available
2024-06-11T10:49:23.497660531Z I0611 10:49:23.497622       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/federate-client-certs
2024-06-11T10:49:23.497977945Z I0611 10:49:23.497938       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClientCertificateCreated' A new client certificate for OpenShiftMonitoringTelemeterClientCertRequester is available
2024-06-11T10:49:23.498245258Z I0611 10:49:23.498216       1 shared_informer.go:318] Caches are synced for AlertingRule controller
2024-06-11T10:49:23.500759474Z I0611 10:49:23.500726       1 shared_informer.go:318] Caches are synced for AlertRelabelConfig controller
2024-06-11T10:49:23.517095130Z I0611 10:49:23.517044       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountCreated' Created ServiceAccount/prometheus-operator -n openshift-monitoring because it was missing
2024-06-11T10:49:23.528878976Z I0611 10:49:23.528319       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/metrics-client-ca -n openshift-monitoring because it was missing
2024-06-11T10:49:23.541512861Z I0611 10:49:23.541472       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:49:23.542081587Z I0611 10:49:23.541978       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/prometheus-operator because it was missing
2024-06-11T10:49:23.542155891Z I0611 10:49:23.542131       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/alert-relabel-configs -n openshift-monitoring because it was missing
2024-06-11T10:49:23.581197498Z I0611 10:49:23.581136       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleBindingCreated' Created ClusterRoleBinding.rbac.authorization.k8s.io/prometheus-operator because it was missing
2024-06-11T10:49:23.597722963Z I0611 10:49:23.597665       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountCreated' Created ServiceAccount/prometheus-operator-admission-webhook -n openshift-monitoring because it was missing
2024-06-11T10:49:23.627930361Z I0611 10:49:23.627866       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceCreated' Created Service/prometheus-operator-admission-webhook -n openshift-monitoring because it was missing
2024-06-11T10:49:23.646190607Z I0611 10:49:23.646126       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodDisruptionBudgetCreated' Created PodDisruptionBudget.policy/prometheus-operator-admission-webhook -n openshift-monitoring because it was missing
2024-06-11T10:49:23.746554553Z I0611 10:49:23.746490       1 requestheader_controller.go:244] Loaded a new request header values for RequestHeaderAuthRequestController
2024-06-11T10:49:23.752376522Z I0611 10:49:23.751712       1 maxinflight.go:139] "Initialized nonMutatingChan" len=400
2024-06-11T10:49:23.752376522Z I0611 10:49:23.751748       1 maxinflight.go:145] "Initialized mutatingChan" len=200
2024-06-11T10:49:23.752376522Z I0611 10:49:23.751787       1 maxinflight.go:116] "Set denominator for readonly requests" limit=400
2024-06-11T10:49:23.752376522Z I0611 10:49:23.751796       1 maxinflight.go:120] "Set denominator for mutating requests" limit=200
2024-06-11T10:49:23.764226271Z I0611 10:49:23.764177       1 secure_serving.go:57] Forcing use of http/1.1 only
2024-06-11T10:49:23.764390779Z W0611 10:49:23.764314       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256' detected.
2024-06-11T10:49:23.764390779Z W0611 10:49:23.764334       1 secure_serving.go:69] Use of insecure cipher 'TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256' detected.
2024-06-11T10:49:23.764711193Z I0611 10:49:23.764673       1 genericapiserver.go:523] MuxAndDiscoveryComplete has all endpoints registered and discovery information is complete
2024-06-11T10:49:23.770332954Z I0611 10:49:23.770264       1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController
2024-06-11T10:49:23.770332954Z I0611 10:49:23.770289       1 shared_informer.go:311] Waiting for caches to sync for RequestHeaderAuthRequestController
2024-06-11T10:49:23.770364155Z I0611 10:49:23.770342       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
2024-06-11T10:49:23.770364155Z I0611 10:49:23.770356       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-06-11T10:49:23.770400757Z I0611 10:49:23.770380       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file"
2024-06-11T10:49:23.770400757Z I0611 10:49:23.770393       1 shared_informer.go:311] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-06-11T10:49:23.770857678Z I0611 10:49:23.770827       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/etc/tls/private/tls.crt::/etc/tls/private/tls.key" certDetail="\"*.cluster-monitoring-operator.openshift-monitoring.svc\" [serving] validServingFor=[*.cluster-monitoring-operator.openshift-monitoring.svc,*.cluster-monitoring-operator.openshift-monitoring.svc.cluster.local,cluster-monitoring-operator.openshift-monitoring.svc,cluster-monitoring-operator.openshift-monitoring.svc.cluster.local] issuer=\"openshift-service-serving-signer@1718102902\" (2024-06-11 10:48:39 +0000 UTC to 2026-06-11 10:48:40 +0000 UTC (now=2024-06-11 10:49:23.770779774 +0000 UTC))"
2024-06-11T10:49:23.771539009Z I0611 10:49:23.771486       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1718102963\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1718102963\" (2024-06-11 09:49:23 +0000 UTC to 2025-06-11 09:49:23 +0000 UTC (now=2024-06-11 10:49:23.771448605 +0000 UTC))"
2024-06-11T10:49:23.771628214Z I0611 10:49:23.771567       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/etc/tls/private/tls.crt::/etc/tls/private/tls.key"
2024-06-11T10:49:23.771828223Z I0611 10:49:23.771604       1 secure_serving.go:213] Serving securely on [::]:8443
2024-06-11T10:49:23.771896026Z I0611 10:49:23.771880       1 genericapiserver.go:671] [graceful-termination] waiting for shutdown to be initiated
2024-06-11T10:49:23.772628760Z I0611 10:49:23.771625       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
2024-06-11T10:49:23.773124383Z I0611 10:49:23.773069       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172
2024-06-11T10:49:23.773461498Z I0611 10:49:23.773425       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206
2024-06-11T10:49:23.773941621Z I0611 10:49:23.773877       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206
2024-06-11T10:49:23.871492837Z I0611 10:49:23.871447       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file
2024-06-11T10:49:23.871598742Z I0611 10:49:23.871577       1 shared_informer.go:318] Caches are synced for RequestHeaderAuthRequestController
2024-06-11T10:49:23.871735748Z I0611 10:49:23.871717       1 shared_informer.go:318] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
2024-06-11T10:49:23.872062263Z I0611 10:49:23.872017       1 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:02 +0000 UTC to 2024-06-12 10:19:02 +0000 UTC (now=2024-06-11 10:49:23.871973659 +0000 UTC))"
2024-06-11T10:49:23.872761695Z I0611 10:49:23.872719       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/etc/tls/private/tls.crt::/etc/tls/private/tls.key" certDetail="\"*.cluster-monitoring-operator.openshift-monitoring.svc\" [serving] validServingFor=[*.cluster-monitoring-operator.openshift-monitoring.svc,*.cluster-monitoring-operator.openshift-monitoring.svc.cluster.local,cluster-monitoring-operator.openshift-monitoring.svc,cluster-monitoring-operator.openshift-monitoring.svc.cluster.local] issuer=\"openshift-service-serving-signer@1718102902\" (2024-06-11 10:48:39 +0000 UTC to 2026-06-11 10:48:40 +0000 UTC (now=2024-06-11 10:49:23.872673491 +0000 UTC))"
2024-06-11T10:49:23.873375924Z I0611 10:49:23.873343       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1718102963\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1718102963\" (2024-06-11 09:49:23 +0000 UTC to 2025-06-11 09:49:23 +0000 UTC (now=2024-06-11 10:49:23.87329262 +0000 UTC))"
2024-06-11T10:49:23.874050355Z I0611 10:49:23.874016       1 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:00 +0000 UTC to 2034-06-09 10:19:00 +0000 UTC (now=2024-06-11 10:49:23.873976552 +0000 UTC))"
2024-06-11T10:49:23.874158860Z I0611 10:49:23.874136       1 tlsconfig.go:178] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2024-06-12 10:19:05 +0000 UTC (now=2024-06-11 10:49:23.874106958 +0000 UTC))"
2024-06-11T10:49:23.874235764Z I0611 10:49:23.874219       1 tlsconfig.go:178] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2025-06-11 10:19:05 +0000 UTC (now=2024-06-11 10:49:23.874191462 +0000 UTC))"
2024-06-11T10:49:23.874321468Z I0611 10:49:23.874287       1 tlsconfig.go:178] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2025-06-11 10:19:05 +0000 UTC (now=2024-06-11 10:49:23.874263465 +0000 UTC))"
2024-06-11T10:49:23.874406472Z I0611 10:49:23.874388       1 tlsconfig.go:178] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:01 +0000 UTC to 2034-06-09 10:19:01 +0000 UTC (now=2024-06-11 10:49:23.874359569 +0000 UTC))"
2024-06-11T10:49:23.874492276Z I0611 10:49:23.874473       1 tlsconfig.go:178] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:02 +0000 UTC to 2024-06-12 10:19:02 +0000 UTC (now=2024-06-11 10:49:23.874449174 +0000 UTC))"
2024-06-11T10:49:23.875112204Z I0611 10:49:23.875080       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/etc/tls/private/tls.crt::/etc/tls/private/tls.key" certDetail="\"*.cluster-monitoring-operator.openshift-monitoring.svc\" [serving] validServingFor=[*.cluster-monitoring-operator.openshift-monitoring.svc,*.cluster-monitoring-operator.openshift-monitoring.svc.cluster.local,cluster-monitoring-operator.openshift-monitoring.svc,cluster-monitoring-operator.openshift-monitoring.svc.cluster.local] issuer=\"openshift-service-serving-signer@1718102902\" (2024-06-11 10:48:39 +0000 UTC to 2026-06-11 10:48:40 +0000 UTC (now=2024-06-11 10:49:23.875047701 +0000 UTC))"
2024-06-11T10:49:23.875647429Z I0611 10:49:23.875617       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1718102963\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1718102963\" (2024-06-11 09:49:23 +0000 UTC to 2025-06-11 09:49:23 +0000 UTC (now=2024-06-11 10:49:23.875588226 +0000 UTC))"
2024-06-11T10:49:37.259151021Z I0611 10:49:37.259067       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:49:37.282594995Z I0611 10:49:37.282519       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:49:52.255085512Z I0611 10:49:52.255024       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:50:07.271995581Z I0611 10:50:07.271935       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:50:22.252534270Z I0611 10:50:22.252478       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:50:31.935070991Z I0611 10:50:31.934990       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:50:52.253077333Z I0611 10:50:52.253013       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:52:07.254611139Z I0611 10:52:07.254490       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:52:07.274249912Z I0611 10:52:07.274197       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:52:09.494514725Z I0611 10:52:09.494445       1 operator.go:681] Triggering an update due to ConfigMap or Secret: kube-system/extension-apiserver-authentication
2024-06-11T10:52:09.506715207Z I0611 10:52:09.506665       1 tlsconfig.go:178] "Loaded client CA" index=0 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"admin-kubeconfig-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:00 +0000 UTC to 2034-06-09 10:19:00 +0000 UTC (now=2024-06-11 10:52:09.506589084 +0000 UTC))"
2024-06-11T10:52:09.506858834Z I0611 10:52:09.506831       1 tlsconfig.go:178] "Loaded client CA" index=1 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2024-06-12 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.506800323 +0000 UTC))"
2024-06-11T10:52:09.506941650Z I0611 10:52:09.506924       1 tlsconfig.go:178] "Loaded client CA" index=2 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-control-plane-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2025-06-11 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.506898642 +0000 UTC))"
2024-06-11T10:52:09.507027566Z I0611 10:52:09.507008       1 tlsconfig.go:178] "Loaded client CA" index=3 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-apiserver-to-kubelet-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:05 +0000 UTC to 2025-06-11 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.506986858 +0000 UTC))"
2024-06-11T10:52:09.507124484Z I0611 10:52:09.507104       1 tlsconfig.go:178] "Loaded client CA" index=4 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kubelet-bootstrap-kubeconfig-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:01 +0000 UTC to 2034-06-09 10:19:01 +0000 UTC (now=2024-06-11 10:52:09.507080776 +0000 UTC))"
2024-06-11T10:52:09.507224903Z I0611 10:52:09.507204       1 tlsconfig.go:178] "Loaded client CA" index=5 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"kube-csr-signer_@1718102903\" [] issuer=\"kubelet-signer\" (2024-06-11 10:48:22 +0000 UTC to 2024-06-12 10:19:05 +0000 UTC (now=2024-06-11 10:52:09.507177094 +0000 UTC))"
2024-06-11T10:52:09.507362929Z I0611 10:52:09.507334       1 tlsconfig.go:178] "Loaded client CA" index=6 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"openshift-kube-apiserver-operator_node-system-admin-signer@1718102900\" [] issuer=\"<self>\" (2024-06-11 10:48:20 +0000 UTC to 2025-06-11 10:48:21 +0000 UTC (now=2024-06-11 10:52:09.507294616 +0000 UTC))"
2024-06-11T10:52:09.507449545Z I0611 10:52:09.507433       1 tlsconfig.go:178] "Loaded client CA" index=7 certName="client-ca::kube-system::extension-apiserver-authentication::client-ca-file,client-ca::kube-system::extension-apiserver-authentication::requestheader-client-ca-file" certDetail="\"aggregator-signer\" [] issuer=\"<self>\" (2024-06-11 10:19:02 +0000 UTC to 2024-06-12 10:19:02 +0000 UTC (now=2024-06-11 10:52:09.507406937 +0000 UTC))"
2024-06-11T10:52:09.508385620Z I0611 10:52:09.508339       1 tlsconfig.go:200] "Loaded serving cert" certName="serving-cert::/etc/tls/private/tls.crt::/etc/tls/private/tls.key" certDetail="\"*.cluster-monitoring-operator.openshift-monitoring.svc\" [serving] validServingFor=[*.cluster-monitoring-operator.openshift-monitoring.svc,*.cluster-monitoring-operator.openshift-monitoring.svc.cluster.local,cluster-monitoring-operator.openshift-monitoring.svc,cluster-monitoring-operator.openshift-monitoring.svc.cluster.local] issuer=\"openshift-service-serving-signer@1718102902\" (2024-06-11 10:48:39 +0000 UTC to 2026-06-11 10:48:40 +0000 UTC (now=2024-06-11 10:52:09.508273899 +0000 UTC))"
2024-06-11T10:52:09.509349500Z I0611 10:52:09.509190       1 named_certificates.go:53] "Loaded SNI cert" index=0 certName="self-signed loopback" certDetail="\"apiserver-loopback-client@1718102963\" [serving] validServingFor=[apiserver-loopback-client] issuer=\"apiserver-loopback-client-ca@1718102963\" (2024-06-11 09:49:23 +0000 UTC to 2025-06-11 09:49:23 +0000 UTC (now=2024-06-11 10:52:09.50913486 +0000 UTC))"
2024-06-11T10:52:52.275900077Z I0611 10:52:52.275657       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:53:04.354470820Z I0611 10:53:04.352573       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:53:11.968959456Z I0611 10:53:11.967967       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:53:28.717499962Z I0611 10:53:28.717435       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:53:28.736033364Z I0611 10:53:28.735980       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:53:28.780121931Z I0611 10:53:28.780065       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:53:28.820021064Z I0611 10:53:28.819947       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:53:28.837873563Z I0611 10:53:28.837814       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:53:43.714525676Z I0611 10:53:43.714469       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:53:43.725616232Z I0611 10:53:43.725568       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:53:58.718924062Z I0611 10:53:58.718870       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:54:23.399284038Z E0611 10:54:23.399213       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.399284038Z E0611 10:54:23.399240       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.405162622Z E0611 10:54:23.405122       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.406767436Z E0611 10:54:23.406739       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.416449728Z E0611 10:54:23.416408       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.418054743Z E0611 10:54:23.418026       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.437901891Z E0611 10:54:23.437847       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.439644123Z E0611 10:54:23.439595       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.479246908Z E0611 10:54:23.479195       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.480880226Z E0611 10:54:23.480842       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.560858397Z E0611 10:54:23.560799       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.562520719Z E0611 10:54:23.562474       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.671458355Z W0611 10:54:23.671406       1 tasks.go:73] task 2 of 2: UpdatingPrometheusOperator failed: reconciling Prometheus Operator Admission Webhook Deployment failed: creating Deployment object failed: waiting for DeploymentRollout of openshift-monitoring/prometheus-operator-admission-webhook: context deadline exceeded
2024-06-11T10:54:23.671458355Z I0611 10:54:23.671451       1 operator.go:887] 1 reconciliation(s) failed, 2 more attempt(s) will be made before reporting failures.
2024-06-11T10:54:23.671503361Z E0611 10:54:23.671461       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T10:54:23.671503361Z E0611 10:54:23.671475       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: UpdatingPrometheusOperatorFailed)
2024-06-11T10:54:23.672444387Z W0611 10:54:23.672401       1 operator.go:1052] Could not fetch cluster version from API. Proceeding without it: error loading cluster version: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusterversions/version": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.672996760Z W0611 10:54:23.672964       1 operator.go:1060] Error loading token from API. Proceeding without it: error loading secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/pull-secret": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.673589439Z W0611 10:54:23.673553       1 operator.go:926] Error getting cluster proxy configuration: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/proxies/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.673589439Z I0611 10:54:23.673574       1 operator.go:932] Using last known proxy configuration
2024-06-11T10:54:23.674158915Z W0611 10:54:23.674114       1 operator.go:944] failed to get api server config: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/apiservers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.674760696Z W0611 10:54:23.674727       1 operator.go:778] Fail to load ConsoleConfig, AlertManager's externalURL may be outdated
2024-06-11T10:54:23.675891347Z W0611 10:54:23.675846       1 operator.go:903] Error getting cluster infrastructure: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.675891347Z I0611 10:54:23.675865       1 operator.go:910] Using last known infrastructure configuration
2024-06-11T10:54:23.675923151Z I0611 10:54:23.675894       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T10:54:23.676472324Z E0611 10:54:23.676434       1 operator.go:845] error occurred while setting status to InProgress: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.676472324Z I0611 10:54:23.676456       1 tasks.go:49] processing task group 1 of 3
2024-06-11T10:54:23.676520531Z I0611 10:54:23.676471       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T10:54:23.676520531Z I0611 10:54:23.676486       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:54:23.677051301Z W0611 10:54:23.677013       1 tasks.go:73] task 1 of 2: UpdatingMetricsScrapingClientCA failed: failed to load kube-system/extension-apiserver-authentication configmap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.677085906Z W0611 10:54:23.677062       1 tasks.go:73] task 2 of 2: UpdatingPrometheusOperator failed: reconciling Prometheus Operator ServiceAccount failed: updating ServiceAccount object failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/serviceaccounts/prometheus-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.677109509Z I0611 10:54:23.677094       1 operator.go:887] 2 reconciliation(s) failed, 1 more attempt(s) will be made before reporting failures.
2024-06-11T10:54:23.677109509Z E0611 10:54:23.677104       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T10:54:23.677123411Z E0611 10:54:23.677112       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: PlatformTasksFailed)
2024-06-11T10:54:23.721876783Z E0611 10:54:23.721824       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.722669888Z W0611 10:54:23.722629       1 operator.go:1052] Could not fetch cluster version from API. Proceeding without it: error loading cluster version: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusterversions/version": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.723410087Z W0611 10:54:23.723368       1 operator.go:1060] Error loading token from API. Proceeding without it: error loading secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/pull-secret": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.723410087Z E0611 10:54:23.723381       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.724010467Z W0611 10:54:23.723977       1 operator.go:926] Error getting cluster proxy configuration: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/proxies/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.724010467Z I0611 10:54:23.723999       1 operator.go:932] Using last known proxy configuration
2024-06-11T10:54:23.724637951Z W0611 10:54:23.724606       1 operator.go:944] failed to get api server config: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/apiservers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.725330043Z W0611 10:54:23.725289       1 operator.go:778] Fail to load ConsoleConfig, AlertManager's externalURL may be outdated
2024-06-11T10:54:23.726502700Z W0611 10:54:23.726460       1 operator.go:903] Error getting cluster infrastructure: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.726502700Z I0611 10:54:23.726480       1 operator.go:910] Using last known infrastructure configuration
2024-06-11T10:54:23.726533804Z I0611 10:54:23.726510       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T10:54:23.727524836Z E0611 10:54:23.727485       1 operator.go:845] error occurred while setting status to InProgress: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.727524836Z I0611 10:54:23.727514       1 tasks.go:49] processing task group 1 of 3
2024-06-11T10:54:23.727556640Z I0611 10:54:23.727531       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T10:54:23.727579143Z I0611 10:54:23.727552       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:54:23.728210128Z W0611 10:54:23.728172       1 tasks.go:73] task 1 of 2: UpdatingMetricsScrapingClientCA failed: failed to load kube-system/extension-apiserver-authentication configmap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.728238931Z W0611 10:54:23.728205       1 tasks.go:73] task 2 of 2: UpdatingPrometheusOperator failed: reconciling Prometheus Operator ServiceAccount failed: updating ServiceAccount object failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/serviceaccounts/prometheus-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.728250233Z I0611 10:54:23.728234       1 operator.go:890] 3 reconciliations failed in a row, the threshold of 3 attempts has been reached, failures will be reported.
2024-06-11T10:54:23.728866215Z E0611 10:54:23.728836       1 operator.go:894] "failed to update cluster operator status" err="Get \"https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-06-11T10:54:23.728866215Z E0611 10:54:23.728858       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T10:54:23.728893219Z E0611 10:54:23.728870       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: PlatformTasksFailed)
2024-06-11T10:54:23.930768256Z W0611 10:54:23.930710       1 operator.go:1052] Could not fetch cluster version from API. Proceeding without it: error loading cluster version: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusterversions/version": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.931493252Z W0611 10:54:23.931446       1 operator.go:1060] Error loading token from API. Proceeding without it: error loading secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/pull-secret": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.932146640Z W0611 10:54:23.932097       1 operator.go:926] Error getting cluster proxy configuration: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/proxies/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.932146640Z I0611 10:54:23.932122       1 operator.go:932] Using last known proxy configuration
2024-06-11T10:54:23.932785625Z W0611 10:54:23.932741       1 operator.go:944] failed to get api server config: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/apiservers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.933319996Z W0611 10:54:23.933272       1 operator.go:778] Fail to load ConsoleConfig, AlertManager's externalURL may be outdated
2024-06-11T10:54:23.934457948Z W0611 10:54:23.934417       1 operator.go:903] Error getting cluster infrastructure: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.934457948Z I0611 10:54:23.934440       1 operator.go:910] Using last known infrastructure configuration
2024-06-11T10:54:23.934491252Z I0611 10:54:23.934476       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T10:54:23.935045726Z E0611 10:54:23.935003       1 operator.go:845] error occurred while setting status to InProgress: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.935045726Z I0611 10:54:23.935024       1 tasks.go:49] processing task group 1 of 3
2024-06-11T10:54:23.935045726Z I0611 10:54:23.935040       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T10:54:23.935092433Z I0611 10:54:23.935062       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:54:23.935708015Z W0611 10:54:23.935659       1 tasks.go:73] task 1 of 2: UpdatingMetricsScrapingClientCA failed: failed to load kube-system/extension-apiserver-authentication configmap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.935738919Z W0611 10:54:23.935707       1 tasks.go:73] task 2 of 2: UpdatingPrometheusOperator failed: reconciling Prometheus Operator ServiceAccount failed: updating ServiceAccount object failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/serviceaccounts/prometheus-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:23.935751921Z I0611 10:54:23.935740       1 operator.go:890] 4 reconciliations failed in a row, the threshold of 3 attempts has been reached, failures will be reported.
2024-06-11T10:54:23.936343100Z E0611 10:54:23.936277       1 operator.go:894] "failed to update cluster operator status" err="Get \"https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-06-11T10:54:23.936343100Z E0611 10:54:23.936331       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T10:54:23.936373304Z E0611 10:54:23.936346       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: PlatformTasksFailed)
2024-06-11T10:54:24.043073541Z E0611 10:54:24.043002       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.044968394Z E0611 10:54:24.044906       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.338150714Z W0611 10:54:24.338085       1 operator.go:1052] Could not fetch cluster version from API. Proceeding without it: error loading cluster version: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusterversions/version": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.338842106Z W0611 10:54:24.338801       1 operator.go:1060] Error loading token from API. Proceeding without it: error loading secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/pull-secret": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.339486492Z W0611 10:54:24.339438       1 operator.go:926] Error getting cluster proxy configuration: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/proxies/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.339486492Z I0611 10:54:24.339462       1 operator.go:932] Using last known proxy configuration
2024-06-11T10:54:24.340011362Z W0611 10:54:24.339981       1 operator.go:944] failed to get api server config: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/apiservers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.340557035Z W0611 10:54:24.340530       1 operator.go:778] Fail to load ConsoleConfig, AlertManager's externalURL may be outdated
2024-06-11T10:54:24.341588873Z W0611 10:54:24.341557       1 operator.go:903] Error getting cluster infrastructure: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.341588873Z I0611 10:54:24.341575       1 operator.go:910] Using last known infrastructure configuration
2024-06-11T10:54:24.341614276Z I0611 10:54:24.341603       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T10:54:24.342162649Z E0611 10:54:24.342129       1 operator.go:845] error occurred while setting status to InProgress: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.342162649Z I0611 10:54:24.342150       1 tasks.go:49] processing task group 1 of 3
2024-06-11T10:54:24.342184452Z I0611 10:54:24.342166       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T10:54:24.342197554Z I0611 10:54:24.342183       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:54:24.342823037Z W0611 10:54:24.342779       1 tasks.go:73] task 1 of 2: UpdatingMetricsScrapingClientCA failed: failed to load kube-system/extension-apiserver-authentication configmap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.342823037Z W0611 10:54:24.342815       1 tasks.go:73] task 2 of 2: UpdatingPrometheusOperator failed: reconciling Prometheus Operator ServiceAccount failed: updating ServiceAccount object failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/serviceaccounts/prometheus-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.342862143Z I0611 10:54:24.342845       1 operator.go:890] 5 reconciliations failed in a row, the threshold of 3 attempts has been reached, failures will be reported.
2024-06-11T10:54:24.343479925Z E0611 10:54:24.343454       1 operator.go:894] "failed to update cluster operator status" err="Get \"https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-06-11T10:54:24.343479925Z E0611 10:54:24.343471       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T10:54:24.343504328Z E0611 10:54:24.343481       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: PlatformTasksFailed)
2024-06-11T10:54:24.684282600Z E0611 10:54:24.684231       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:24.686084440Z E0611 10:54:24.686040       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.145263310Z W0611 10:54:25.145204       1 operator.go:1052] Could not fetch cluster version from API. Proceeding without it: error loading cluster version: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusterversions/version": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.146059416Z W0611 10:54:25.146011       1 operator.go:1060] Error loading token from API. Proceeding without it: error loading secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/pull-secret": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.146794314Z W0611 10:54:25.146747       1 operator.go:926] Error getting cluster proxy configuration: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/proxies/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.146794314Z I0611 10:54:25.146771       1 operator.go:932] Using last known proxy configuration
2024-06-11T10:54:25.147562016Z W0611 10:54:25.147516       1 operator.go:944] failed to get api server config: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/apiservers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.148379326Z W0611 10:54:25.148330       1 operator.go:778] Fail to load ConsoleConfig, AlertManager's externalURL may be outdated
2024-06-11T10:54:25.149617591Z W0611 10:54:25.149578       1 operator.go:903] Error getting cluster infrastructure: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.149617591Z I0611 10:54:25.149598       1 operator.go:910] Using last known infrastructure configuration
2024-06-11T10:54:25.149656996Z I0611 10:54:25.149637       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T10:54:25.150467404Z E0611 10:54:25.150422       1 operator.go:845] error occurred while setting status to InProgress: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.150467404Z I0611 10:54:25.150451       1 tasks.go:49] processing task group 1 of 3
2024-06-11T10:54:25.150503409Z I0611 10:54:25.150472       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T10:54:25.150503409Z I0611 10:54:25.150492       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:54:25.151171698Z W0611 10:54:25.151121       1 tasks.go:73] task 1 of 2: UpdatingMetricsScrapingClientCA failed: failed to load kube-system/extension-apiserver-authentication configmap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.151171698Z W0611 10:54:25.151145       1 tasks.go:73] task 2 of 2: UpdatingPrometheusOperator failed: reconciling Prometheus Operator ServiceAccount failed: updating ServiceAccount object failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/serviceaccounts/prometheus-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.151201802Z I0611 10:54:25.151176       1 operator.go:890] 6 reconciliations failed in a row, the threshold of 3 attempts has been reached, failures will be reported.
2024-06-11T10:54:25.151886994Z E0611 10:54:25.151845       1 operator.go:894] "failed to update cluster operator status" err="Get \"https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-06-11T10:54:25.151886994Z E0611 10:54:25.151868       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T10:54:25.151886994Z E0611 10:54:25.151881       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: PlatformTasksFailed)
2024-06-11T10:54:25.965940115Z E0611 10:54:25.965884       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:25.967741156Z E0611 10:54:25.967707       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.753906757Z W0611 10:54:26.753857       1 operator.go:1052] Could not fetch cluster version from API. Proceeding without it: error loading cluster version: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusterversions/version": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.754589841Z W0611 10:54:26.754547       1 operator.go:1060] Error loading token from API. Proceeding without it: error loading secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/pull-secret": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.755147309Z W0611 10:54:26.755106       1 operator.go:926] Error getting cluster proxy configuration: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/proxies/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.755147309Z I0611 10:54:26.755128       1 operator.go:932] Using last known proxy configuration
2024-06-11T10:54:26.755806890Z W0611 10:54:26.755764       1 operator.go:944] failed to get api server config: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/apiservers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.756373260Z W0611 10:54:26.756327       1 operator.go:778] Fail to load ConsoleConfig, AlertManager's externalURL may be outdated
2024-06-11T10:54:26.757392485Z W0611 10:54:26.757354       1 operator.go:903] Error getting cluster infrastructure: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.757392485Z I0611 10:54:26.757373       1 operator.go:910] Using last known infrastructure configuration
2024-06-11T10:54:26.757426389Z I0611 10:54:26.757401       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T10:54:26.757965355Z E0611 10:54:26.757923       1 operator.go:845] error occurred while setting status to InProgress: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.757965355Z I0611 10:54:26.757949       1 tasks.go:49] processing task group 1 of 3
2024-06-11T10:54:26.757998159Z I0611 10:54:26.757966       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T10:54:26.757998159Z I0611 10:54:26.757982       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:54:26.758644638Z W0611 10:54:26.758605       1 tasks.go:73] task 1 of 2: UpdatingMetricsScrapingClientCA failed: failed to load kube-system/extension-apiserver-authentication configmap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.758682443Z W0611 10:54:26.758636       1 tasks.go:73] task 2 of 2: UpdatingPrometheusOperator failed: reconciling Prometheus Operator ServiceAccount failed: updating ServiceAccount object failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/serviceaccounts/prometheus-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:26.758704046Z I0611 10:54:26.758678       1 operator.go:890] 7 reconciliations failed in a row, the threshold of 3 attempts has been reached, failures will be reported.
2024-06-11T10:54:26.759399731Z E0611 10:54:26.759369       1 operator.go:894] "failed to update cluster operator status" err="Get \"https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-06-11T10:54:26.759399731Z E0611 10:54:26.759388       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T10:54:26.759426534Z E0611 10:54:26.759397       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: PlatformTasksFailed)
2024-06-11T10:54:28.527632614Z E0611 10:54:28.527572       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:28.529403632Z E0611 10:54:28.529353       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.963739542Z W0611 10:54:29.963681       1 operator.go:1052] Could not fetch cluster version from API. Proceeding without it: error loading cluster version: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusterversions/version": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.964455930Z W0611 10:54:29.964416       1 operator.go:1060] Error loading token from API. Proceeding without it: error loading secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/pull-secret": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.965362641Z W0611 10:54:29.965279       1 operator.go:926] Error getting cluster proxy configuration: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/proxies/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.965362641Z I0611 10:54:29.965345       1 operator.go:932] Using last known proxy configuration
2024-06-11T10:54:29.966085730Z W0611 10:54:29.966039       1 operator.go:944] failed to get api server config: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/apiservers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.966687204Z W0611 10:54:29.966654       1 operator.go:778] Fail to load ConsoleConfig, AlertManager's externalURL may be outdated
2024-06-11T10:54:29.967746034Z W0611 10:54:29.967710       1 operator.go:903] Error getting cluster infrastructure: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.967746034Z I0611 10:54:29.967730       1 operator.go:910] Using last known infrastructure configuration
2024-06-11T10:54:29.967787339Z I0611 10:54:29.967756       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T10:54:29.968322304Z E0611 10:54:29.968248       1 operator.go:845] error occurred while setting status to InProgress: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.968322304Z I0611 10:54:29.968278       1 tasks.go:49] processing task group 1 of 3
2024-06-11T10:54:29.968380611Z I0611 10:54:29.968327       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T10:54:29.968380611Z I0611 10:54:29.968355       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:54:29.969036392Z W0611 10:54:29.968998       1 tasks.go:73] task 1 of 2: UpdatingMetricsScrapingClientCA failed: failed to load kube-system/extension-apiserver-authentication configmap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.969064295Z W0611 10:54:29.969055       1 tasks.go:73] task 2 of 2: UpdatingPrometheusOperator failed: reconciling Prometheus Operator ServiceAccount failed: updating ServiceAccount object failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/serviceaccounts/prometheus-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:29.969119402Z I0611 10:54:29.969096       1 operator.go:890] 8 reconciliations failed in a row, the threshold of 3 attempts has been reached, failures will be reported.
2024-06-11T10:54:29.969740378Z E0611 10:54:29.969704       1 operator.go:894] "failed to update cluster operator status" err="Get \"https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-06-11T10:54:29.969740378Z E0611 10:54:29.969727       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T10:54:29.969775283Z E0611 10:54:29.969739       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: PlatformTasksFailed)
2024-06-11T10:54:33.648652518Z E0611 10:54:33.648599       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:33.650366241Z E0611 10:54:33.650293       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:36.371437922Z W0611 10:54:36.371375       1 operator.go:1052] Could not fetch cluster version from API. Proceeding without it: error loading cluster version: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusterversions/version": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:36.372106184Z W0611 10:54:36.372067       1 operator.go:1060] Error loading token from API. Proceeding without it: error loading secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/pull-secret": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:36.372833753Z W0611 10:54:36.372778       1 operator.go:926] Error getting cluster proxy configuration: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/proxies/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:36.372833753Z I0611 10:54:36.372804       1 operator.go:932] Using last known proxy configuration
2024-06-11T10:54:36.373477913Z W0611 10:54:36.373423       1 operator.go:944] failed to get api server config: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/apiservers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:36.374040166Z W0611 10:54:36.374010       1 operator.go:778] Fail to load ConsoleConfig, AlertManager's externalURL may be outdated
2024-06-11T10:54:36.375170672Z W0611 10:54:36.375128       1 operator.go:903] Error getting cluster infrastructure: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:36.375170672Z I0611 10:54:36.375146       1 operator.go:910] Using last known infrastructure configuration
2024-06-11T10:54:36.375200974Z I0611 10:54:36.375175       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T10:54:36.375848835Z E0611 10:54:36.375798       1 operator.go:845] error occurred while setting status to InProgress: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:36.375848835Z I0611 10:54:36.375828       1 tasks.go:49] processing task group 1 of 3
2024-06-11T10:54:36.375883839Z I0611 10:54:36.375848       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T10:54:36.375883839Z I0611 10:54:36.375871       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:54:36.376568003Z W0611 10:54:36.376526       1 tasks.go:73] task 1 of 2: UpdatingMetricsScrapingClientCA failed: failed to load kube-system/extension-apiserver-authentication configmap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:36.376568003Z W0611 10:54:36.376557       1 tasks.go:73] task 2 of 2: UpdatingPrometheusOperator failed: reconciling Prometheus Operator ServiceAccount failed: updating ServiceAccount object failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/serviceaccounts/prometheus-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:36.376636309Z I0611 10:54:36.376614       1 operator.go:890] 9 reconciliations failed in a row, the threshold of 3 attempts has been reached, failures will be reported.
2024-06-11T10:54:36.377325974Z E0611 10:54:36.377269       1 operator.go:894] "failed to update cluster operator status" err="Get \"https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-06-11T10:54:36.377325974Z E0611 10:54:36.377288       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T10:54:36.377325974Z E0611 10:54:36.377316       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: PlatformTasksFailed)
2024-06-11T10:54:43.889993940Z E0611 10:54:43.889939       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:43.891738053Z E0611 10:54:43.891705       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.179644805Z W0611 10:54:49.179589       1 operator.go:1052] Could not fetch cluster version from API. Proceeding without it: error loading cluster version: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusterversions/version": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.180236877Z W0611 10:54:49.180183       1 operator.go:1060] Error loading token from API. Proceeding without it: error loading secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/pull-secret": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.180852952Z W0611 10:54:49.180811       1 operator.go:926] Error getting cluster proxy configuration: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/proxies/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.180852952Z I0611 10:54:49.180833       1 operator.go:932] Using last known proxy configuration
2024-06-11T10:54:49.181374216Z W0611 10:54:49.181336       1 operator.go:944] failed to get api server config: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/apiservers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.181894779Z W0611 10:54:49.181857       1 operator.go:778] Fail to load ConsoleConfig, AlertManager's externalURL may be outdated
2024-06-11T10:54:49.182992513Z W0611 10:54:49.182955       1 operator.go:903] Error getting cluster infrastructure: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.182992513Z I0611 10:54:49.182972       1 operator.go:910] Using last known infrastructure configuration
2024-06-11T10:54:49.183023017Z I0611 10:54:49.182998       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T10:54:49.183899224Z E0611 10:54:49.183852       1 operator.go:845] error occurred while setting status to InProgress: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.183899224Z I0611 10:54:49.183879       1 tasks.go:49] processing task group 1 of 3
2024-06-11T10:54:49.183940429Z I0611 10:54:49.183901       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T10:54:49.183940429Z I0611 10:54:49.183925       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:54:49.184609810Z W0611 10:54:49.184568       1 tasks.go:73] task 1 of 2: UpdatingMetricsScrapingClientCA failed: failed to load kube-system/extension-apiserver-authentication configmap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.184640414Z W0611 10:54:49.184605       1 tasks.go:73] task 2 of 2: UpdatingPrometheusOperator failed: reconciling Prometheus Operator ServiceAccount failed: updating ServiceAccount object failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/serviceaccounts/prometheus-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:54:49.184650415Z I0611 10:54:49.184635       1 operator.go:890] 10 reconciliations failed in a row, the threshold of 3 attempts has been reached, failures will be reported.
2024-06-11T10:54:49.185329898Z E0611 10:54:49.185287       1 operator.go:894] "failed to update cluster operator status" err="Get \"https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-06-11T10:54:49.185365802Z E0611 10:54:49.185342       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T10:54:49.185365802Z E0611 10:54:49.185357       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: PlatformTasksFailed)
2024-06-11T10:55:04.372244259Z E0611 10:55:04.372182       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:04.372839731Z E0611 10:55:04.372798       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:14.787363744Z W0611 10:55:14.787289       1 operator.go:1052] Could not fetch cluster version from API. Proceeding without it: error loading cluster version: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusterversions/version": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:14.788052096Z W0611 10:55:14.788011       1 operator.go:1060] Error loading token from API. Proceeding without it: error loading secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/pull-secret": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:14.788693444Z W0611 10:55:14.788637       1 operator.go:926] Error getting cluster proxy configuration: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/proxies/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:14.788693444Z I0611 10:55:14.788668       1 operator.go:932] Using last known proxy configuration
2024-06-11T10:55:14.789377295Z W0611 10:55:14.789332       1 operator.go:944] failed to get api server config: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/apiservers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:14.789920736Z W0611 10:55:14.789888       1 operator.go:778] Fail to load ConsoleConfig, AlertManager's externalURL may be outdated
2024-06-11T10:55:14.791167030Z W0611 10:55:14.791129       1 operator.go:903] Error getting cluster infrastructure: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:14.791167030Z I0611 10:55:14.791146       1 operator.go:910] Using last known infrastructure configuration
2024-06-11T10:55:14.791200132Z I0611 10:55:14.791174       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T10:55:14.791778575Z E0611 10:55:14.791737       1 operator.go:845] error occurred while setting status to InProgress: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:14.791778575Z I0611 10:55:14.791760       1 tasks.go:49] processing task group 1 of 3
2024-06-11T10:55:14.791811878Z I0611 10:55:14.791796       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:55:14.791924486Z I0611 10:55:14.791798       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T10:55:14.792513430Z W0611 10:55:14.792476       1 tasks.go:73] task 1 of 2: UpdatingMetricsScrapingClientCA failed: failed to load kube-system/extension-apiserver-authentication configmap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:14.792823754Z W0611 10:55:14.792793       1 tasks.go:73] task 2 of 2: UpdatingPrometheusOperator failed: reconciling Prometheus Operator ServiceAccount failed: updating ServiceAccount object failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/serviceaccounts/prometheus-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:14.792850456Z I0611 10:55:14.792826       1 operator.go:890] 11 reconciliations failed in a row, the threshold of 3 attempts has been reached, failures will be reported.
2024-06-11T10:55:14.793440500Z E0611 10:55:14.793410       1 operator.go:894] "failed to update cluster operator status" err="Get \"https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-06-11T10:55:14.793440500Z E0611 10:55:14.793430       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T10:55:14.793469002Z E0611 10:55:14.793439       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: PlatformTasksFailed)
2024-06-11T10:55:45.334636913Z E0611 10:55:45.334575       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:55:45.335419297Z E0611 10:55:45.335358       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:56:05.996045111Z W0611 10:56:05.995993       1 operator.go:1052] Could not fetch cluster version from API. Proceeding without it: error loading cluster version: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusterversions/version": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:56:05.996913201Z W0611 10:56:05.996867       1 operator.go:1060] Error loading token from API. Proceeding without it: error loading secret: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-config/secrets/pull-secret": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:56:05.997839797Z W0611 10:56:05.997770       1 operator.go:926] Error getting cluster proxy configuration: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/proxies/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:56:05.997839797Z I0611 10:56:05.997825       1 operator.go:932] Using last known proxy configuration
2024-06-11T10:56:05.998669183Z W0611 10:56:05.998621       1 operator.go:944] failed to get api server config: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/apiservers/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:56:05.999267445Z W0611 10:56:05.999236       1 operator.go:778] Fail to load ConsoleConfig, AlertManager's externalURL may be outdated
2024-06-11T10:56:06.000533076Z W0611 10:56:06.000493       1 operator.go:903] Error getting cluster infrastructure: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/infrastructures/cluster": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:56:06.000533076Z I0611 10:56:06.000512       1 operator.go:910] Using last known infrastructure configuration
2024-06-11T10:56:06.000566579Z I0611 10:56:06.000543       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T10:56:06.001218047Z E0611 10:56:06.001171       1 operator.go:845] error occurred while setting status to InProgress: Get "https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:56:06.001218047Z I0611 10:56:06.001198       1 tasks.go:49] processing task group 1 of 3
2024-06-11T10:56:06.001250050Z I0611 10:56:06.001220       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T10:56:06.001250050Z I0611 10:56:06.001236       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:56:06.001975025Z W0611 10:56:06.001931       1 tasks.go:73] task 1 of 2: UpdatingMetricsScrapingClientCA failed: failed to load kube-system/extension-apiserver-authentication configmap: Get "https://172.30.0.1:443/api/v1/namespaces/kube-system/configmaps/extension-apiserver-authentication": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:56:06.001975025Z W0611 10:56:06.001936       1 tasks.go:73] task 2 of 2: UpdatingPrometheusOperator failed: reconciling Prometheus Operator ServiceAccount failed: updating ServiceAccount object failed: Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/serviceaccounts/prometheus-operator": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:56:06.002005929Z I0611 10:56:06.001993       1 operator.go:890] 12 reconciliations failed in a row, the threshold of 3 attempts has been reached, failures will be reported.
2024-06-11T10:56:06.002714402Z E0611 10:56:06.002676       1 operator.go:894] "failed to update cluster operator status" err="Get \"https://172.30.0.1:443/apis/config.openshift.io/v1/clusteroperators/monitoring\": dial tcp 172.30.0.1:443: connect: connection refused"
2024-06-11T10:56:06.002714402Z E0611 10:56:06.002699       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T10:56:06.002749406Z E0611 10:56:06.002712       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: PlatformTasksFailed)
2024-06-11T10:56:10.831985616Z I0611 10:56:10.831804       1 operator.go:650] Triggering an update due to a change in *v1.Infrastructure/cluster
2024-06-11T10:56:10.885017369Z I0611 10:56:10.884938       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T10:56:10.888787536Z I0611 10:56:10.888739       1 tasks.go:49] processing task group 1 of 3
2024-06-11T10:56:10.888787536Z I0611 10:56:10.888782       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T10:56:10.888836340Z I0611 10:56:10.888810       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:56:10.911725765Z I0611 10:56:10.911648       1 core.go:350] ConfigMap "openshift-monitoring/metrics-client-ca" changes: {"apiVersion":"v1","data":{"client-ca.crt":"-----BEGIN CERTIFICATE-----\nMIIDMDCCAhigAwIBAgIIUfFG0cnQdlwwDQYJKoZIhvcNAQELBQAwNjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSAwHgYDVQQDExdhZG1pbi1rdWJlY29uZmlnLXNpZ25lcjAe\nFw0yNDA2MTExMDE5MDBaFw0zNDA2MDkxMDE5MDBaMDYxEjAQBgNVBAsTCW9wZW5z\naGlmdDEgMB4GA1UEAxMXYWRtaW4ta3ViZWNvbmZpZy1zaWduZXIwggEiMA0GCSqG\nSIb3DQEBAQUAA4IBDwAwggEKAoIBAQDQPHiIAcIULFZFvWWBXQwukB6ZLZu8Hpgc\n05RseFEIO9DX47IOOR3n4cWU/47oZj2ioYyOlFlllIALsEJJdJQGTiVLxAV+kXqt\nP7UeNA0PlHAmS7B9x/9Yn7orL5FnuM+RDcknQnFUhXkRnb8WzuIWKQOazKsthkMc\n1OJA5ONqbA0IWPJ68gshU9ObFGFH8lQ6ZCO+M7YmUMA1U4W6/62kQ/pgHg13Ta/m\n1c5fWYtm0a3K7E2ieAAbkOcc6nMzQD5d9DZaxgteYNt3RBqi3BmV9ZMC8aNEOwNn\n55Qgin/Vr5WXguH4uLtsLnAShV5lW2LSnpKtQYB3PooDkv9kh2ahAgMBAAGjQjBA\nMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBTfpIjk\n93BzqYwAri6z3h1EFgDINTANBgkqhkiG9w0BAQsFAAOCAQEAYFGqJZyra3vhNHZ4\nam82uCHfQTEtJUkBL6UcK7UE/T/LQ/aOhiVthOfxOPlga4Kviq9lEm5n6VLXg+zs\nKYUtiXarZa3OJDeiDiTN4JIyib4ksWDjON9yaM4IOy6im1MFhkiA43uZxPJeIuRt\neIhZiVSMIdE77qN77JVOUzuhYJwRPmWjqZC3CtzcmJXKmyKe4NQpLyZ15h92sK/K\naBKBGXf5jPD6IPOUwjsYshBJC+RiABZag3EMPz4YrhXWjHdZ3e+yoC+JG5aaVd3o\nE2eDP+i2Gmc1y2lXTtaFvhyKD4kcNG+KEAtMeOB8G4UjrtxE37PEfkTY5DnMgWCi\noKYDgg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDHjCCAgagAwIBAgIIcV2hmXi3/A8wDQYJKoZIhvcNAQELBQAwLTESMBAGA1UE\nCxMJb3BlbnNoaWZ0MRcwFQYDVQQDEw5rdWJlbGV0LXNpZ25lcjAeFw0yNDA2MTEx\nMDE5MDVaFw0yNDA2MTIxMDE5MDVaMC0xEjAQBgNVBAsTCW9wZW5zaGlmdDEXMBUG\nA1UEAxMOa3ViZWxldC1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK\nAoIBAQCb6mxWX5tlBPkCLyWtXlqfdry3uUHy0YUCRohDhL0zRXN44xWOAxLIFMCj\n0PRelpwyMU3eXLHd23QN6lse1nWXd+1e5/lujTQi6EG9irZUCwCBbp2kC8YgAEHC\nuK3IsI1bcFzRg23vXEcBl2sZO3LrmIrXFXGKIYOdwu0wXIvBtafTgA+K2S3SyvJE\nKDRBd6slBCObf6XhhE7yrNiu7eFrxosIxrWCdMvWEcTmu1EiZMb5r7jp8xqj/xSn\nCxmBd3NEGBDy/oNeeYJRRpbrmOl54ElN577R7g/CIs1fRmng0VzrgYq83yR+Mlm7\npvbDgf2VloIpVfsD2V22qgHZPNPxAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAP\nBgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBT7lmbbr5mww/A4TwDUzWKyi4OerTAN\nBgkqhkiG9w0BAQsFAAOCAQEAljYQSE1mqcAlp0KgwNWArWRLE3t5XmRJyQjLFKos\n2uaQXBl1gJjOSpPM00IJD8ax0HzeJKE0DSxpYDYPokgv2vBIk8i3zHn8X47BdSRP\nCcNAFEAEA5H0hDTOr/UTB8ULgYjx9kXXvcGvGXWy9WNwjMtpGnPEyNh0qxqoKG77\n+gshWS3udBauxNjV4ye2qCPmTYgLQu3TknjjGvSykqMecF/elLCoW4JIPHBOaDDz\nfmkDuki6RzKBGNS6u/CkLiTIs1jeCHY3NxK4wD8KgoGzT/6HzzjbOuGHvbet3ub1\n6cLEsXgrB6aP6H0EmRbMnR9ZzGeNR2KKGnelkixGhyE0Pw==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDNDCCAhygAwIBAgIIHm+X2EOS+HIwDQYJKoZIhvcNAQELBQAwODESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSIwIAYDVQQDExlrdWJlLWNvbnRyb2wtcGxhbmUtc2lnbmVy\nMB4XDTI0MDYxMTEwMTkwNVoXDTI1MDYxMTEwMTkwNVowODESMBAGA1UECxMJb3Bl\nbnNoaWZ0MSIwIAYDVQQDExlrdWJlLWNvbnRyb2wtcGxhbmUtc2lnbmVyMIIBIjAN\nBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAo+t/BqIZldcTt5PWJJG6TnWJxE/m\npNSRfSVii+s3WAr443i94gY1KAi2wKREe6S9VJrmmVwI+grpt+Jlw1dDWXlUHmVV\n1sl2kqEhyaQAFqzRIlh1SrMklT7pPPwSvWAxamMKkXHkYbcSejjI1C/J1BxGkphW\nPpRblYSnw1FPRd886bbbAsent3pD0dngbPHF65jna5N07kGwNlnl5EtZTvy7demt\nV8bLf4j6PYTpwHWmPH/zk7H8V3Guo0J+NRUg0bHUP+5a+0rOCnIHVK5E4LCwpoAN\ngFxhAOQVDOpX4FF1gl6QR3gimimO9B6Z/C7KQlDoByFjp9kiJS+unh3meQIDAQAB\no0IwQDAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQU\nvqFTbnnFyl9Rq71mDeV3b68fp40wDQYJKoZIhvcNAQELBQADggEBACFg1whQ+y1f\nEad9T3YfVPIAxtHWrQ2umwywclY/od/uRQiRbPKaFZZKaOqJR/f7nmNIyIB3vI7T\ntKfpbJMTuCRGEovfKd64aQhhkd+Rrq54x0vnE6KoH7Jaew3XEuWe5tCmkZvi9AI7\n+E4wo9nFQ5KU1YHqaQf6IoEDS0cPUKztcGT+ZFXJ1UOh0l/8xenFEXzCyOlVyKcb\ntVcaLlTpLG/9dsXI9FRtssXf40mmOqpZCp8O6muWIluo6biimgViEO/hI7/yir6Y\nVFbhAtQj7ilOsNJgfq/sAufQB9BRW9KeQuKnKJ/7xqD2rPVogqqGdBpgACI14CIg\n4utztrD3ue0=\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDQjCCAiqgAwIBAgIILRFRfL+pVowwDQYJKoZIhvcNAQELBQAwPzESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSkwJwYDVQQDEyBrdWJlLWFwaXNlcnZlci10by1rdWJlbGV0\nLXNpZ25lcjAeFw0yNDA2MTExMDE5MDVaFw0yNTA2MTExMDE5MDVaMD8xEjAQBgNV\nBAsTCW9wZW5zaGlmdDEpMCcGA1UEAxMga3ViZS1hcGlzZXJ2ZXItdG8ta3ViZWxl\ndC1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCw1VEXo/Xo\nlj2UX5/0LpHzKtOXDRZ14UB6I6eUAeW7z/LBUqdl81x8lrfRitbkmJYf/soI7oHQ\nr/RfBAKR2BdPZS9NuwRaqPkukvirwUJ+y4amtqlsKQxXXQqCKpeD5EjWQub5pm5I\nfGcJzVX8sVorM5f7acK+s/IwzdilgC7UuQZSGtOqGtRXu/4GmW3CCReSxJKHxJAC\n4gNPuAVFWSjYT9QWXIz0x0pbplo3GiTKuLx/oyB2JZnUd78p4cwkZ6R2SBaicSCT\na2GBnm6T8pi1sElfI3MYjEUtdcqmUzMKJPzqp+HrgFaY5L27fmcp9qHGJEPgjKxf\nQWQq6bhw+kcLAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMBAf8EBTAD\nAQH/MB0GA1UdDgQWBBS2AwPD70Xw+VhwR486gixW3JqOMjANBgkqhkiG9w0BAQsF\nAAOCAQEAJofTZCqWLi4lAVBW8JsVDcJDU8T527p73z4ZM40vzYD5ehDhd90kv+15\nKvHMa+/JjWEnW772LgnQWw3X6cCuk8n48fpWiNARQ/KkWi77Tu28DCoquI5FF+M7\nQ9ATaSzd8P9/Y8AOtrgHN/bY7jsEHJNcmXjvFxxLrHqdFAk7Whd9saqGtlVNkSOw\nRbIF8w/tEBGRglqoD7AD9mwzk6weAJ7j/9Lub5REByB9e03WzdzGI2wpHsPufwCF\nDwnPbSs36OgVmHX0n+Ubs+LV/2KID6SeHSN7TptRTSVb4hIV/h1Mero6JoRedETN\nT5na3rpz4NBQZIdEYtbq8A9w129ffg==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDSDCCAjCgAwIBAgIIFebDL4cHJhkwDQYJKoZIhvcNAQELBQAwQjESMBAGA1UE\nCxMJb3BlbnNoaWZ0MSwwKgYDVQQDEyNrdWJlbGV0LWJvb3RzdHJhcC1rdWJlY29u\nZmlnLXNpZ25lcjAeFw0yNDA2MTExMDE5MDFaFw0zNDA2MDkxMDE5MDFaMEIxEjAQ\nBgNVBAsTCW9wZW5zaGlmdDEsMCoGA1UEAxMja3ViZWxldC1ib290c3RyYXAta3Vi\nZWNvbmZpZy1zaWduZXIwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCh\nheGYkCYk5KMVc18UC2SYKbI/4a1WGM4kVmsh8n3gdH3MYynctCGLq6QPESa2jxq7\nyJsdDb8DgmfKYw9g9rMH5eJqqdO2/H1m6C9ArbTwhPEpZ0R7W9fG/C19cXGmG/0B\n+5peFk00LDwddTGVRx1rzmL3YsiONDmDnBGk0MQ8l7ItrSs8fNaonQ9N4n012uqq\n/IcbTcxw08s46O3wSCU+xrrJE15n15wN1sx/y5UOz/pqnyL7GDxzRhaKwr+octlj\nT0M4Jt09rveeGW1fVZs8+LHFo/nzVnQcWi6DIz6oVgntbiZ9vK5H/fV1WNOtiH/s\nOUFX3fEQOGu1QbXsXsUZAgMBAAGjQjBAMA4GA1UdDwEB/wQEAwICpDAPBgNVHRMB\nAf8EBTADAQH/MB0GA1UdDgQWBBSmCtLZmYcpAQY/dWm+iVLhOznT0jANBgkqhkiG\n9w0BAQsFAAOCAQEAXWtrsW8yXKuoQogAlYcJsc2L5i1ewbI/0C8ATyWJXHzHKjop\nFcNLwngV8kNXnFlPs2y53T4HrfO2mshLbn9jHZy27/1QVPRJzX2U5z54ssnfmAi0\nfT5DQoIYAhBDrXFUgZpL9iQd6+IY3de55exTKbKZLq1/hdw3nMZ4yHMuVSfcdiHU\n9fXteW5vZtsKgLLuEnijpMK71qatzsQkKiQ0WgXxg4S0qeWVD2Wn/ygiip91ejRS\nL+HeIMnxOPeOtI6TXRqWKFqNchz2qunG+31PonqCnKAXngtEhxnded8uPtNUoUxL\n+QHZyewwLGn4mMmg0YYCS3chYJSCXC3WIHmaNw==\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDODCCAiCgAwIBAgIIWo6I69kjppswDQYJKoZIhvcNAQELBQAwLTESMBAGA1UE\nCxMJb3BlbnNoaWZ0MRcwFQYDVQQDEw5rdWJlbGV0LXNpZ25lcjAeFw0yNDA2MTEx\nMDQ4MjJaFw0yNDA2MTIxMDE5MDVaMCYxJDAiBgNVBAMMG2t1YmUtY3NyLXNpZ25l\ncl9AMTcxODEwMjkwMzCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAKqp\nH3/dDW77MAc6pbnfbiz0lBMJ6bpq1F2OYNlCEwqiuq7Wgn9AcZfWra3UCLHswN6T\n0WzSNeQ5/Urxyfg93v+jyoUCqygVTSCsKQW7rzsLlA6wmJuhNi1PI+iVbvqzFKbJ\nWA6sTRx9YUTRqAQnujJjNJ/WlG4VsYZpyHlk3eSMtMTYQ3+1YtJphtHQQSXSrd0Q\nCKS5cjLFDe8ShEt3CoHFXAyNhXZ8LbjFDNdHx7h26yhVR1CXIGVPbYLOnzge6FDa\nkJlXnSHykQVzq4R5j6f7LdqrNJlaz1uDnsp8/5aizqqLhj5KIszJa8gG0GWU9ufC\nl44ZvrQk9Nh5WESGKTMCAwEAAaNjMGEwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB\n/wQFMAMBAf8wHQYDVR0OBBYEFFIXeg5o52wZ7pSc9WVTlbO4JTDdMB8GA1UdIwQY\nMBaAFPuWZtuvmbDD8DhPANTNYrKLg56tMA0GCSqGSIb3DQEBCwUAA4IBAQAl1loP\n0F+N1c8J3jbc8wXLdzgP14r34lseHEX1r+3a3abjltabdnDLVIztP1Q648waGTKH\nNLN95MGvrvzCR1N3c0fdrtw3NOqP52/XYZViE8pJutfJ0ypZpypP0C0cql3/emNH\n/TNRQ0OoQOKoTGob8FHXiGsG8hgGT3kq6trl+D65NsvS/uBbKontFiaKvtQmGM5J\nZsWQiZ1NJ0LQlEZL79Hc2aRWe3EIFWzcI6jLzYGZJabQsOi4VuAm8dF9y3AgTDPc\nr30/NM+SABxVyrbtn9Otou8/Akehirrr5xlU6V63AV7+7B3bv+Typ03rydiCmWzk\n6VUKXGebIkTA/Bkw\n-----END CERTIFICATE-----\n-----BEGIN CERTIFICATE-----\nMIIDhTCCAm2gAwIBAgIIQ9HgPNoIqPswDQYJKoZIhvcNAQELBQAwUDFOMEwGA1UE\nAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9wZXJhdG9yX25vZGUtc3lzdGVt\nLWFkbWluLXNpZ25lckAxNzE4MTAyOTAwMB4XDTI0MDYxMTEwNDgyMFoXDTI1MDYx\nMTEwNDgyMVowUDFOMEwGA1UEAwxFb3BlbnNoaWZ0LWt1YmUtYXBpc2VydmVyLW9w\nZXJhdG9yX25vZGUtc3lzdGVtLWFkbWluLXNpZ25lckAxNzE4MTAyOTAwMIIBIjAN\nBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAmB2p8+ggzj8RJ7evt3D8yFg+yRWm\nfH8Rm9dDZ2rUQT0r/IGi5Pcjg54AnJHxRKbDZf5qB9VjyZGcXy0b4IrtYrgcAUwz\naOVWRojL3OX8JUGZmO1wr7i9jKO7gxywRl5ft8HTAPKp9/QvOgm/9LJfF1og9Wxy\nfX40KKdCrhn9/qUgXvr5M/Z2aLl+rP50oDbzklJC6VCdsLbu/fS5lo6Q3ThWyCca\nmdq7JdEKoq7gNxWbFWONGsyyRB0lK+K0UpuWA6581m6D+9XJ6vD6yBC46WasRrtz\nUIvJRFZwoiDELZVy6xjW/BlG0NUkEYwfCrVMhKDeyMOthxYAsYUcwdBnSwIDAQAB\no2MwYTAOBgNVHQ8BAf8EBAMCAqQwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQU\nuzce/faO4j4rypoVYYKfWL2wauMwHwYDVR0jBBgwFoAUuzce/faO4j4rypoVYYKf\nWL2wauMwDQYJKoZIhvcNAQELBQADggEBAEseWda+x170eQxgL+p8yD6I1CQLzfSV\npEal7Y86OjyrM55ngEP15sQ4ZfbFSM79RfyfuJUO2buUOjIuhSb2EqZYjY9k+tRx\nGzZTULNomnX5z2GiYa6pZaIrKbFBoq5fjJf5xTPumCKXgUkjIvULNhAFPpenP0du\nsjEL7m5EycG+8iRvApM7y4rXRoYfZ+KMRgQDjNAwQhLd6OGLPg0PoqBypIIsArGW\n7w/y4xi8E05QcWUsUk9f+FDrU55a11FnWZNlDVnxgGmDBgv6Mz6cE1w0wCBxrkGI\njKf+tRRb63MBBLq7//qLng+7qaEQyAaP6PKqH2xy0a6tQh69IEPxlHk=\n-----END CERTIFICATE-----\n"},"kind":"ConfigMap","metadata":{"creationTimestamp":null,"managedFields":null,"resourceVersion":null,"uid":null}}
2024-06-11T10:56:10.912054497Z I0611 10:56:10.911988       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapUpdated' Updated ConfigMap/metrics-client-ca -n openshift-monitoring:
2024-06-11T10:56:10.912054497Z cause by changes in data.client-ca.crt
2024-06-11T10:56:10.916049485Z I0611 10:56:10.915995       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T10:56:25.640753498Z I0611 10:56:25.640682       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:56:39.369864561Z I0611 10:56:39.369786       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:56:46.246352453Z I0611 10:56:46.246251       1 operator.go:650] Triggering an update due to a change in *v1.APIServer/cluster
2024-06-11T10:56:47.909217783Z I0611 10:56:47.909152       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:566
2024-06-11T10:56:47.909309291Z I0611 10:56:47.909246       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/cluster-monitoring-config
2024-06-11T10:56:50.444217615Z I0611 10:56:50.444160       1 reflector.go:351] Caches populated for *v1.Secret from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:56:50.444318623Z I0611 10:56:50.444274       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/federate-client-certs
2024-06-11T10:56:50.444340325Z I0611 10:56:50.444319       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/metrics-client-certs
2024-06-11T10:56:53.444166084Z I0611 10:56:53.444070       1 reflector.go:351] Caches populated for *v1.FeatureGate from github.com/openshift/client-go/config/informers/externalversions/factory.go:125
2024-06-11T10:56:53.736126726Z I0611 10:56:53.736051       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go/informers/factory.go:159
2024-06-11T10:56:59.471634374Z I0611 10:56:59.471560       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:57:00.686541003Z I0611 10:57:00.686457       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:57:00.686654412Z I0611 10:57:00.686616       1 operator.go:681] Triggering an update due to ConfigMap or Secret: kube-system/extension-apiserver-authentication
2024-06-11T10:57:01.779265328Z I0611 10:57:01.779133       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206
2024-06-11T10:57:04.433361425Z I0611 10:57:04.433294       1 reflector.go:351] Caches populated for *v1.CertificateSigningRequest from k8s.io/client-go/informers/factory.go:159
2024-06-11T10:57:06.767860169Z I0611 10:57:06.767793       1 reflector.go:351] Caches populated for *v1.ClusterVersion from github.com/openshift/client-go/config/informers/externalversions/factory.go:125
2024-06-11T10:57:09.055598853Z I0611 10:57:09.055536       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:57:18.786185696Z I0611 10:57:18.786114       1 reflector.go:351] Caches populated for *v1.PrometheusRule from github.com/openshift/cluster-monitoring-operator/pkg/alert/rule_controller.go:117
2024-06-11T10:57:25.836843589Z I0611 10:57:25.836776       1 reflector.go:351] Caches populated for *v1.Secret from github.com/openshift/cluster-monitoring-operator/pkg/alert/relabel_controller.go:122
2024-06-11T10:57:26.448837073Z I0611 10:57:26.448763       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206
2024-06-11T10:57:27.116517295Z I0611 10:57:27.116453       1 reflector.go:351] Caches populated for *v1.Console from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:57:27.116587301Z I0611 10:57:27.116564       1 operator.go:650] Triggering an update due to a change in Console.config.openshift.io/cluster
2024-06-11T10:57:29.139269168Z I0611 10:57:29.139206       1 reflector.go:351] Caches populated for *v1.AlertingRule from github.com/openshift/cluster-monitoring-operator/pkg/alert/rule_controller.go:118
2024-06-11T10:57:30.319339034Z I0611 10:57:30.319270       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T10:57:30.319606556Z I0611 10:57:30.319568       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-config-managed/kubelet-serving-ca
2024-06-11T10:57:35.862657807Z I0611 10:57:35.862601       1 reflector.go:351] Caches populated for *v1.AlertRelabelConfig from github.com/openshift/cluster-monitoring-operator/pkg/alert/relabel_controller.go:121
2024-06-11T10:57:39.371408954Z I0611 10:57:39.371337       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:57:54.371841413Z I0611 10:57:54.371758       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:57:56.006379026Z I0611 10:57:56.006289       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172
2024-06-11T10:58:09.366799442Z I0611 10:58:09.366735       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T10:59:23.400189701Z E0611 10:59:23.400119       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.400189701Z E0611 10:59:23.400143       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.406259626Z E0611 10:59:23.406214       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.407854338Z E0611 10:59:23.407795       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.417581919Z E0611 10:59:23.417540       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.419121927Z E0611 10:59:23.419095       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.438951215Z E0611 10:59:23.438902       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.440741640Z E0611 10:59:23.440683       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.481225275Z E0611 10:59:23.481158       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.482069434Z E0611 10:59:23.482009       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.563149410Z E0611 10:59:23.563095       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.564171382Z E0611 10:59:23.564130       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.724604414Z E0611 10:59:23.724546       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:23.725218257Z E0611 10:59:23.725168       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:24.046589858Z E0611 10:59:24.046496       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:24.047234603Z E0611 10:59:24.047167       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:24.688175878Z E0611 10:59:24.688113       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:24.689897998Z E0611 10:59:24.689823       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:25.969926217Z E0611 10:59:25.969872       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:25.970729574Z E0611 10:59:25.970683       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:28.532019199Z E0611 10:59:28.531962       1 base_controller.go:268] OpenShiftMonitoringTelemeterClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/federate-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/federate-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T10:59:28.532699346Z E0611 10:59:28.532650       1 base_controller.go:268] OpenShiftMonitoringClientCertRequester reconciliation failed: unable to get secret "openshift-monitoring/metrics-client-certs": Get "https://172.30.0.1:443/api/v1/namespaces/openshift-monitoring/secrets/metrics-client-certs": dial tcp 172.30.0.1:443: connect: connection refused
2024-06-11T11:00:13.340166752Z I0611 11:00:13.340112       1 reflector.go:351] Caches populated for *v1.FeatureGate from github.com/openshift/client-go/config/informers/externalversions/factory.go:125
2024-06-11T11:00:15.996789388Z I0611 11:00:15.996726       1 operator.go:650] Triggering an update due to a change in *v1.APIServer/cluster
2024-06-11T11:00:16.744508523Z I0611 11:00:16.744450       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:00:18.651177749Z I0611 11:00:18.651123       1 operator.go:650] Triggering an update due to a change in *v1.Infrastructure/cluster
2024-06-11T11:00:18.669097564Z I0611 11:00:18.669050       1 reflector.go:351] Caches populated for *v1.ClusterVersion from github.com/openshift/client-go/config/informers/externalversions/factory.go:125
2024-06-11T11:00:18.731956928Z I0611 11:00:18.731894       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go/informers/factory.go:159
2024-06-11T11:00:28.158830594Z I0611 11:00:28.158748       1 reflector.go:351] Caches populated for *v1.AlertingRule from github.com/openshift/cluster-monitoring-operator/pkg/alert/rule_controller.go:118
2024-06-11T11:00:31.868608632Z I0611 11:00:31.868521       1 reflector.go:351] Caches populated for *v1.PrometheusRule from github.com/openshift/cluster-monitoring-operator/pkg/alert/rule_controller.go:117
2024-06-11T11:00:34.517897425Z I0611 11:00:34.517830       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T11:00:36.844831075Z I0611 11:00:36.844753       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T11:00:37.376841780Z I0611 11:00:37.376773       1 reflector.go:351] Caches populated for *v1.Secret from github.com/openshift/cluster-monitoring-operator/pkg/alert/relabel_controller.go:122
2024-06-11T11:00:39.962529317Z I0611 11:00:39.962424       1 reflector.go:351] Caches populated for *v1.AlertRelabelConfig from github.com/openshift/cluster-monitoring-operator/pkg/alert/relabel_controller.go:121
2024-06-11T11:00:40.445276794Z I0611 11:00:40.445010       1 reflector.go:351] Caches populated for *v1.Console from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T11:00:40.445276794Z I0611 11:00:40.445132       1 operator.go:650] Triggering an update due to a change in Console.config.openshift.io/cluster
2024-06-11T11:00:45.112166250Z I0611 11:00:45.112112       1 reflector.go:351] Caches populated for *v1.CertificateSigningRequest from k8s.io/client-go/informers/factory.go:159
2024-06-11T11:00:47.970893825Z I0611 11:00:47.970824       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172
2024-06-11T11:00:49.666521044Z I0611 11:00:49.666461       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206
2024-06-11T11:00:51.434581081Z I0611 11:00:51.434524       1 reflector.go:351] Caches populated for *v1.Secret from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T11:00:51.434690288Z I0611 11:00:51.434659       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/federate-client-certs
2024-06-11T11:00:51.434711789Z I0611 11:00:51.434686       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/metrics-client-certs
2024-06-11T11:00:52.837153468Z I0611 11:00:52.837049       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T11:00:52.837448286Z I0611 11:00:52.837372       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-config-managed/kubelet-serving-ca
2024-06-11T11:00:54.372976220Z I0611 11:00:54.372903       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T11:00:54.373048124Z I0611 11:00:54.373005       1 operator.go:681] Triggering an update due to ConfigMap or Secret: kube-system/extension-apiserver-authentication
2024-06-11T11:00:59.957771964Z I0611 11:00:59.957642       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206
2024-06-11T11:01:00.644058783Z I0611 11:01:00.643999       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:566
2024-06-11T11:01:00.644157589Z I0611 11:01:00.644112       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/cluster-monitoring-config
2024-06-11T11:01:09.393427749Z I0611 11:01:09.393365       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:01:09.408227237Z I0611 11:01:09.408176       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:01:10.937029145Z W0611 11:01:10.936949       1 tasks.go:73] task 2 of 2: UpdatingPrometheusOperator failed: reconciling Prometheus Operator Admission Webhook Deployment failed: updating Deployment object failed: waiting for DeploymentRollout of openshift-monitoring/prometheus-operator-admission-webhook: context deadline exceeded
2024-06-11T11:01:10.937029145Z I0611 11:01:10.937017       1 operator.go:890] 13 reconciliations failed in a row, the threshold of 3 attempts has been reached, failures will be reported.
2024-06-11T11:01:10.957035646Z E0611 11:01:10.956958       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T11:01:10.957035646Z E0611 11:01:10.956990       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: UpdatingPrometheusOperatorFailed)
2024-06-11T11:01:10.991719826Z I0611 11:01:10.991666       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T11:01:10.996365905Z I0611 11:01:10.996321       1 tasks.go:49] processing task group 1 of 3
2024-06-11T11:01:10.996422108Z I0611 11:01:10.996360       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:01:10.996422108Z I0611 11:01:10.996395       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:01:11.011525914Z I0611 11:01:11.011484       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:01:15.071191432Z I0611 11:01:15.071109       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ValidatingWebhookConfigurationCreated' Created ValidatingWebhookConfiguration.admissionregistration.k8s.io/prometheusrules.openshift.io because it was missing
2024-06-11T11:01:15.095196001Z I0611 11:01:15.095104       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ValidatingWebhookConfigurationCreated' Created ValidatingWebhookConfiguration.admissionregistration.k8s.io/alertmanagerconfigs.openshift.io because it was missing
2024-06-11T11:01:15.120625333Z I0611 11:01:15.120544       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceCreated' Created Service/prometheus-operator -n openshift-monitoring because it was missing
2024-06-11T11:01:21.234164745Z I0611 11:01:21.234101       1 tasks.go:76] ran task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:01:21.234164745Z I0611 11:01:21.234142       1 tasks.go:49] processing task group 2 of 3
2024-06-11T11:01:21.234234849Z I0611 11:01:21.234178       1 tasks.go:70] running task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:01:21.234234849Z I0611 11:01:21.234193       1 tasks.go:70] running task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:01:21.234234849Z I0611 11:01:21.234208       1 tasks.go:70] running task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:01:21.234234849Z I0611 11:01:21.234216       1 tasks.go:70] running task 3 of 16: UpdatingAlertmanager
2024-06-11T11:01:21.234234849Z I0611 11:01:21.234201       1 tasks.go:70] running task 2 of 16: UpdatingPrometheus
2024-06-11T11:01:21.234234849Z I0611 11:01:21.234226       1 tasks.go:70] running task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:01:21.234255450Z I0611 11:01:21.234230       1 tasks.go:70] running task 4 of 16: UpdatingNodeExporter
2024-06-11T11:01:21.234255450Z I0611 11:01:21.234245       1 tasks.go:70] running task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:01:21.234255450Z I0611 11:01:21.234246       1 tasks.go:70] running task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:01:21.234369957Z I0611 11:01:21.234252       1 tasks.go:70] running task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:01:21.234369957Z I0611 11:01:21.234256       1 tasks.go:70] running task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:01:21.234369957Z I0611 11:01:21.234261       1 tasks.go:76] ran task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:01:21.234369957Z I0611 11:01:21.234269       1 tasks.go:70] running task 8 of 16: UpdatingMetricsServer
2024-06-11T11:01:21.234369957Z I0611 11:01:21.234270       1 tasks.go:70] running task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:01:21.234369957Z I0611 11:01:21.234277       1 tasks.go:70] running task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:01:21.234369957Z I0611 11:01:21.234294       1 tasks.go:70] running task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:01:21.234413760Z I0611 11:01:21.234387       1 tasks.go:70] running task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:01:21.249208048Z W0611 11:01:21.249133       1 tasks.go:73] task 3 of 16: UpdatingAlertmanager failed: reconciling Alertmanager Route failed: creating Route object failed: the server could not find the requested resource (post routes.route.openshift.io)
2024-06-11T11:01:21.254619973Z I0611 11:01:21.254549       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountCreated' Created ServiceAccount/kube-state-metrics -n openshift-monitoring because it was missing
2024-06-11T11:01:21.259062040Z I0611 11:01:21.259006       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountCreated' Created ServiceAccount/openshift-state-metrics -n openshift-monitoring because it was missing
2024-06-11T11:01:21.283749722Z I0611 11:01:21.283681       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceCreated' Created Service/thanos-querier -n openshift-monitoring because it was missing
2024-06-11T11:01:21.304017639Z I0611 11:01:21.303957       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountCreated' Created ServiceAccount/node-exporter -n openshift-monitoring because it was missing
2024-06-11T11:01:21.312293836Z W0611 11:01:21.312242       1 tasks.go:73] task 10 of 16: UpdatingThanosQuerier failed: reconciling Thanos Querier Route failed: creating Route object failed: the server could not find the requested resource (post routes.route.openshift.io)
2024-06-11T11:01:21.314969896Z I0611 11:01:21.314901       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kubelet-serving-ca-bundle -n openshift-monitoring because it was missing
2024-06-11T11:01:21.351520591Z I0611 11:01:21.351467       1 tasks.go:76] ran task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:01:21.351955217Z I0611 11:01:21.351905       1 tasks.go:76] ran task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:01:21.368020181Z I0611 11:01:21.367968       1 tasks.go:76] ran task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:01:21.386440887Z I0611 11:01:21.386368       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/prometheus-k8s because it was missing
2024-06-11T11:01:21.399567075Z I0611 11:01:21.399502       1 tasks.go:76] ran task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:01:21.448407108Z I0611 11:01:21.448338       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/kube-state-metrics because it was missing
2024-06-11T11:01:21.463791631Z I0611 11:01:21.463705       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/cluster-monitoring-view because it was missing
2024-06-11T11:01:21.498801833Z I0611 11:01:21.498738       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/openshift-state-metrics because it was missing
2024-06-11T11:01:21.526023868Z I0611 11:01:21.525939       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/node-exporter because it was missing
2024-06-11T11:01:21.644261866Z I0611 11:01:21.644187       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleBindingCreated' Created ClusterRoleBinding.rbac.authorization.k8s.io/prometheus-k8s because it was missing
2024-06-11T11:01:21.659501981Z I0611 11:01:21.659439       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountCreated' Created ServiceAccount/metrics-server -n openshift-monitoring because it was missing
2024-06-11T11:01:21.664509682Z I0611 11:01:21.664164       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/system:aggregated-metrics-reader because it was missing
2024-06-11T11:01:21.671724415Z I0611 11:01:21.671647       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleBindingCreated' Created ClusterRoleBinding.rbac.authorization.k8s.io/kube-state-metrics because it was missing
2024-06-11T11:01:21.699125260Z I0611 11:01:21.699057       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleBindingCreated' Created ClusterRoleBinding.rbac.authorization.k8s.io/openshift-state-metrics because it was missing
2024-06-11T11:01:21.721252489Z I0611 11:01:21.721184       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceCreated' Created Service/openshift-state-metrics -n openshift-monitoring because it was missing
2024-06-11T11:01:21.727020235Z I0611 11:01:21.726966       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleBindingCreated' Created ClusterRoleBinding.rbac.authorization.k8s.io/node-exporter because it was missing
2024-06-11T11:01:21.740928170Z I0611 11:01:21.740868       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceCreated' Created Service/kube-state-metrics -n openshift-monitoring because it was missing
2024-06-11T11:01:21.787628374Z I0611 11:01:21.787550       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/kube-state-metrics-custom-resource-state-configmap -n openshift-monitoring because it was missing
2024-06-11T11:01:21.795191828Z I0611 11:01:21.795131       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceCreated' Created Service/node-exporter -n openshift-monitoring because it was missing
2024-06-11T11:01:22.145484559Z I0611 11:01:22.145361       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/system:metrics-server because it was missing
2024-06-11T11:01:22.147154859Z I0611 11:01:22.147093       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/monitoring-rules-edit because it was missing
2024-06-11T11:01:22.806170064Z I0611 11:01:22.806059       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleBindingCreated' Created ClusterRoleBinding.rbac.authorization.k8s.io/system:metrics-server because it was missing
2024-06-11T11:01:22.819914079Z I0611 11:01:22.819834       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/monitoring-rules-view because it was missing
2024-06-11T11:01:22.892154866Z I0611 11:01:22.892063       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/monitoring-edit because it was missing
2024-06-11T11:01:22.901260706Z I0611 11:01:22.901186       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleBindingCreated' Created ClusterRoleBinding.rbac.authorization.k8s.io/metrics-server:system:auth-delegator because it was missing
2024-06-11T11:01:22.973243878Z I0611 11:01:22.973170       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/alert-routing-edit because it was missing
2024-06-11T11:01:23.008930895Z I0611 11:01:23.008864       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleBindingCreated' Created RoleBinding.rbac.authorization.k8s.io/metrics-server-auth-reader -n kube-system because it was missing
2024-06-11T11:01:23.048037916Z I0611 11:01:23.047761       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceCreated' Created Service/metrics-server -n openshift-monitoring because it was missing
2024-06-11T11:01:23.100959956Z I0611 11:01:23.100881       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleCreated' Created Role.rbac.authorization.k8s.io/user-workload-monitoring-config-edit -n openshift-user-workload-monitoring because it was missing
2024-06-11T11:01:23.181098211Z I0611 11:01:23.181019       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleCreated' Created Role.rbac.authorization.k8s.io/monitoring-alertmanager-api-reader -n openshift-user-workload-monitoring because it was missing
2024-06-11T11:01:23.251495388Z I0611 11:01:23.251403       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleCreated' Created Role.rbac.authorization.k8s.io/monitoring-alertmanager-api-writer -n openshift-user-workload-monitoring because it was missing
2024-06-11T11:01:23.328429854Z I0611 11:01:23.328356       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleCreated' Created Role.rbac.authorization.k8s.io/monitoring-alertmanager-edit -n openshift-monitoring because it was missing
2024-06-11T11:01:23.400202612Z I0611 11:01:23.400114       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleCreated' Created Role.rbac.authorization.k8s.io/monitoring-alertmanager-view -n openshift-monitoring because it was missing
2024-06-11T11:01:23.491018601Z I0611 11:01:23.490945       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleCreated' Created Role.rbac.authorization.k8s.io/cluster-monitoring-metrics-api -n openshift-monitoring because it was missing
2024-06-11T11:01:24.179664364Z I0611 11:01:24.179599       1 tasks.go:76] ran task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:01:24.179725768Z I0611 11:01:24.179682       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/grpc-tls -n openshift-monitoring because it was missing
2024-06-11T11:01:24.181717186Z I0611 11:01:24.181663       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/grpc-tls
2024-06-11T11:01:24.352718033Z I0611 11:01:24.352628       1 tasks.go:76] ran task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:01:24.371625855Z I0611 11:01:24.371566       1 tasks.go:76] ran task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:01:26.078943563Z I0611 11:01:26.078871       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/metrics-server-audit-profiles -n openshift-monitoring because it was missing
2024-06-11T11:01:26.823724157Z I0611 11:01:26.823662       1 tasks.go:76] ran task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:01:26.900702925Z I0611 11:01:26.900626       1 tasks.go:76] ran task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:01:27.920600443Z I0611 11:01:27.920534       1 tasks.go:76] ran task 4 of 16: UpdatingNodeExporter
2024-06-11T11:01:28.114050922Z I0611 11:01:28.113971       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/metrics-server-9a6ldng0krfu1 -n openshift-monitoring because it was missing
2024-06-11T11:02:09.248037565Z I0611 11:02:09.247923       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodDisruptionBudgetCreated' Created PodDisruptionBudget.policy/metrics-server -n openshift-monitoring because it was missing
2024-06-11T11:02:09.282369904Z I0611 11:02:09.282279       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'APIServiceCreated' Created APIService.apiregistration.k8s.io/v1beta1.metrics.k8s.io because it was missing
2024-06-11T11:02:09.328065085Z I0611 11:02:09.328003       1 tasks.go:76] ran task 8 of 16: UpdatingMetricsServer
2024-06-11T11:02:24.363980585Z I0611 11:02:24.363087       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:04:23.012577804Z I0611 11:04:23.012517       1 operator.go:650] Triggering an update due to a change in *v1.Infrastructure/cluster
2024-06-11T11:04:23.013615851Z I0611 11:04:23.013569       1 operator.go:650] Triggering an update due to a change in *v1.APIServer/cluster
2024-06-11T11:04:23.036781008Z I0611 11:04:23.036721       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:04:31.312695884Z I0611 11:04:31.312628       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:04:34.045163345Z I0611 11:04:34.045093       1 operator.go:650] Triggering an update due to a change in *v1.APIServer/cluster
2024-06-11T11:04:39.365929602Z I0611 11:04:39.365870       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:04:53.364087788Z I0611 11:04:53.363998       1 operator.go:650] Triggering an update due to a change in *v1.Infrastructure/cluster
2024-06-11T11:05:02.194783783Z I0611 11:05:02.194715       1 reflector.go:351] Caches populated for *v1.CertificateSigningRequest from k8s.io/client-go/informers/factory.go:159
2024-06-11T11:05:09.358717375Z I0611 11:05:09.358641       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:05:15.259870010Z I0611 11:05:15.259808       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T11:05:15.260111818Z I0611 11:05:15.260078       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-config-managed/kubelet-serving-ca
2024-06-11T11:05:16.205931639Z I0611 11:05:16.205871       1 reflector.go:351] Caches populated for *v1.Secret from github.com/openshift/cluster-monitoring-operator/pkg/alert/relabel_controller.go:122
2024-06-11T11:05:17.433124919Z I0611 11:05:17.433072       1 reflector.go:351] Caches populated for *v1.Secret from k8s.io/client-go/informers/factory.go:159
2024-06-11T11:05:17.694841254Z I0611 11:05:17.694787       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T11:05:17.863022445Z I0611 11:05:17.862950       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:566
2024-06-11T11:05:17.863096948Z I0611 11:05:17.863069       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/cluster-monitoring-config
2024-06-11T11:05:21.347167749Z I0611 11:05:21.347053       1 reflector.go:351] Caches populated for *v1.Console from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T11:05:21.347240253Z I0611 11:05:21.347157       1 operator.go:650] Triggering an update due to a change in Console.config.openshift.io/cluster
2024-06-11T11:05:23.984733624Z I0611 11:05:23.984671       1 reflector.go:351] Caches populated for *v1.FeatureGate from github.com/openshift/client-go/config/informers/externalversions/factory.go:125
2024-06-11T11:05:24.160599138Z I0611 11:05:24.160481       1 reflector.go:351] Caches populated for *v1.AlertingRule from github.com/openshift/cluster-monitoring-operator/pkg/alert/rule_controller.go:118
2024-06-11T11:05:25.292039196Z I0611 11:05:25.291970       1 reflector.go:351] Caches populated for *v1.ClusterVersion from github.com/openshift/client-go/config/informers/externalversions/factory.go:125
2024-06-11T11:05:26.049704722Z I0611 11:05:26.049636       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T11:05:26.049793326Z I0611 11:05:26.049754       1 operator.go:681] Triggering an update due to ConfigMap or Secret: kube-system/extension-apiserver-authentication
2024-06-11T11:05:28.506860291Z I0611 11:05:28.506809       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206
2024-06-11T11:05:29.194421523Z I0611 11:05:29.194266       1 reflector.go:351] Caches populated for *v1.Secret from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T11:05:29.194503426Z I0611 11:05:29.194478       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/federate-client-certs
2024-06-11T11:05:29.194518727Z I0611 11:05:29.194511       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/grpc-tls
2024-06-11T11:05:29.194530528Z I0611 11:05:29.194523       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/metrics-client-certs
2024-06-11T11:05:30.602326879Z I0611 11:05:30.602241       1 reflector.go:351] Caches populated for *v1.AlertRelabelConfig from github.com/openshift/cluster-monitoring-operator/pkg/alert/relabel_controller.go:121
2024-06-11T11:05:35.488426304Z I0611 11:05:35.488166       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/apiserver/pkg/server/dynamiccertificates/configmap_cafile_content.go:206
2024-06-11T11:05:39.355207444Z I0611 11:05:39.355142       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:05:46.205088520Z I0611 11:05:46.205028       1 reflector.go:351] Caches populated for *v1.ConfigMap from k8s.io/apiserver/pkg/authentication/request/headerrequest/requestheader_controller.go:172
2024-06-11T11:05:50.003295796Z I0611 11:05:50.003226       1 reflector.go:351] Caches populated for *v1.ConfigMap from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T11:06:07.284701017Z I0611 11:06:07.284633       1 reflector.go:351] Caches populated for *v1.PrometheusRule from github.com/openshift/cluster-monitoring-operator/pkg/alert/rule_controller.go:117
2024-06-11T11:06:21.253085134Z W0611 11:06:21.253017       1 tasks.go:73] task 12 of 16: UpdatingConsolePluginComponents failed: reconciling Console Plugin failed: waiting for ConsolePlugin failed: context deadline exceeded: creating ConsolePlugin object failed: the server could not find the requested resource (post consoleplugins.console.openshift.io)
2024-06-11T11:06:21.330473485Z W0611 11:06:21.330393       1 tasks.go:73] task 2 of 16: UpdatingPrometheus failed: [reconciling Prometheus API Route failed: creating Route object failed: the server could not find the requested resource (post routes.route.openshift.io), unavailable (unknown): prometheuses.monitoring.coreos.com "k8s" not found, degraded (unknown): prometheuses.monitoring.coreos.com "k8s" not found]
2024-06-11T11:06:21.330545688Z I0611 11:06:21.330514       1 operator.go:890] 14 reconciliations failed in a row, the threshold of 3 attempts has been reached, failures will be reported.
2024-06-11T11:06:21.353572345Z E0611 11:06:21.353365       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T11:06:21.353691250Z E0611 11:06:21.353666       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: PlatformTasksFailed)
2024-06-11T11:06:21.390353932Z I0611 11:06:21.390287       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T11:06:21.395211255Z I0611 11:06:21.395159       1 tasks.go:49] processing task group 1 of 3
2024-06-11T11:06:21.395211255Z I0611 11:06:21.395202       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:06:21.395262057Z I0611 11:06:21.395223       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:06:21.412288838Z I0611 11:06:21.412238       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:06:25.778426952Z I0611 11:06:25.777484       1 admissionregistration.go:141] ValidatingWebhookConfiguration "/prometheusrules.openshift.io" changes: {"webhooks":[{"admissionReviewVersions":["v1"],"clientConfig":{"caBundle":"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURVVENDQWptZ0F3SUJBZ0lJUWRnbVZUSlFUNGt3RFFZSktvWklodmNOQVFFTEJRQXdOakUwTURJR0ExVUUKQXd3cmIzQmxibk5vYVdaMExYTmxjblpwWTJVdGMyVnlkbWx1WnkxemFXZHVaWEpBTVRjeE9ERXdNamt3TWpBZQpGdzB5TkRBMk1URXhNRFE0TWpGYUZ3MHlOakE0TVRBeE1EUTRNakphTURZeE5EQXlCZ05WQkFNTUsyOXdaVzV6CmFHbG1kQzF6WlhKMmFXTmxMWE5sY25acGJtY3RjMmxuYm1WeVFERTNNVGd4TURJNU1ESXdnZ0VpTUEwR0NTcUcKU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLQW9JQkFRRFZQNm03ZDBHRGRwcWorMis2NGE2aVZqazl4N3ZKK0V1NQpMZlV0eTFpVFZybEFVQWhsdUlpNzQ2N2sxMmlaK0VPTTR6WndRMStXL05IOElnbDQwS2hqNHJ4Z25EeXlHVysrCk51T3k2Zmc4QVhxMXQyRjJlNHJMNWt4NUNsMFUrQ21jR0pFSS9XZy8wdjlrZ0ZiVlBGVS9YcUJrNmkxZG0yYkYKdDBMd25qVTZpci9sYzFXK2VoWUFscFFoQW5ucUs2K2Nnd3lOczBMYUhYS0MzdkhIc1NpL2RiRzhlejBMbWdrNgpoeHJUS0MzYkNMRU5hYnZmc09CMXhaV3ZFYnNrMEQzNEIvUUR6N0FXQktOQXlKRHVPOHNJOGtsKzZnRkZCd2w4Cm5XU05GcmF3bHVGdmtkY0FJVUl1U2RuQ2o1eE1qWmhJbXNIWmhxNWFEZTdlMWlKQ1ZiOVpBZ01CQUFHall6QmgKTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQQmdOVkhSTUJBZjhFQlRBREFRSC9NQjBHQTFVZERnUVdCQlRhUVpGOAp6U2prSGVoVEJRWk1iaklKdC9zQTZqQWZCZ05WSFNNRUdEQVdnQlRhUVpGOHpTamtIZWhUQlFaTWJqSUp0L3NBCjZqQU5CZ2txaGtpRzl3MEJBUXNGQUFPQ0FRRUFmN0F4L2lpbW1KY2JZMEE3bTFwa0FZTllPTTZmUlA3MklTR3UKNmMrU3Q3N0VBREE5cjNmWW4zanRJSi9Cci9ybnN4Tk9Bd0FjR3hVa29mYjhQYThJRk82MUw4YXlrY0VabGpNMgp0OThxODkwdi9IV0d0K21zVXFrYVZEYWdFTi93VVZua2JMOHFjdkk1STRDTUdBbnFPYjNDb2N5dS82TmdwRmx3CjVFa1AybmN4YURONldJWWU3RFp2WnpzTEhna0hicUZLcTJaOU5YSm95WlQzb2g4d2xXOFlteFV4US84N0JTL28KbDJ1ai9BOUh1QVlCKzBGMFFSaDE2N2pDUzFCUTBuSzFoSW54Sjlaa3pQTWNwTGQ1WjVKQzZFNzFzaFFweDA0dQo0ZWdRejI4aWNUcnhqVUVjWlhZaFg2YUorNGVIUkUvSG94c3Q2UUFPeDFXSzZrTzZ0QT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K","service":{"name":"prometheus-operator-admission-webhook","namespace":"openshift-monitoring","path":"/admission-prometheusrules/validate","port":8443}},"failurePolicy":"Ignore","name":"prometheusrules.openshift.io","rules":[{"apiGroups":["monitoring.coreos.com"],"apiVersions":["v1"],"operations":["CREATE","UPDATE"],"resources":["prometheusrules"],"scope":"Namespaced"}],"sideEffects":"None","timeoutSeconds":5}]}
2024-06-11T11:06:25.800268154Z I0611 11:06:25.800066       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ValidatingWebhookConfigurationUpdated' Updated ValidatingWebhookConfiguration.admissionregistration.k8s.io/prometheusrules.openshift.io because it changed
2024-06-11T11:06:25.814389402Z I0611 11:06:25.812680       1 admissionregistration.go:141] ValidatingWebhookConfiguration "/alertmanagerconfigs.openshift.io" changes: {"webhooks":[{"admissionReviewVersions":["v1"],"clientConfig":{"caBundle":"LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURVVENDQWptZ0F3SUJBZ0lJUWRnbVZUSlFUNGt3RFFZSktvWklodmNOQVFFTEJRQXdOakUwTURJR0ExVUUKQXd3cmIzQmxibk5vYVdaMExYTmxjblpwWTJVdGMyVnlkbWx1WnkxemFXZHVaWEpBTVRjeE9ERXdNamt3TWpBZQpGdzB5TkRBMk1URXhNRFE0TWpGYUZ3MHlOakE0TVRBeE1EUTRNakphTURZeE5EQXlCZ05WQkFNTUsyOXdaVzV6CmFHbG1kQzF6WlhKMmFXTmxMWE5sY25acGJtY3RjMmxuYm1WeVFERTNNVGd4TURJNU1ESXdnZ0VpTUEwR0NTcUcKU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLQW9JQkFRRFZQNm03ZDBHRGRwcWorMis2NGE2aVZqazl4N3ZKK0V1NQpMZlV0eTFpVFZybEFVQWhsdUlpNzQ2N2sxMmlaK0VPTTR6WndRMStXL05IOElnbDQwS2hqNHJ4Z25EeXlHVysrCk51T3k2Zmc4QVhxMXQyRjJlNHJMNWt4NUNsMFUrQ21jR0pFSS9XZy8wdjlrZ0ZiVlBGVS9YcUJrNmkxZG0yYkYKdDBMd25qVTZpci9sYzFXK2VoWUFscFFoQW5ucUs2K2Nnd3lOczBMYUhYS0MzdkhIc1NpL2RiRzhlejBMbWdrNgpoeHJUS0MzYkNMRU5hYnZmc09CMXhaV3ZFYnNrMEQzNEIvUUR6N0FXQktOQXlKRHVPOHNJOGtsKzZnRkZCd2w4Cm5XU05GcmF3bHVGdmtkY0FJVUl1U2RuQ2o1eE1qWmhJbXNIWmhxNWFEZTdlMWlKQ1ZiOVpBZ01CQUFHall6QmgKTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQQmdOVkhSTUJBZjhFQlRBREFRSC9NQjBHQTFVZERnUVdCQlRhUVpGOAp6U2prSGVoVEJRWk1iaklKdC9zQTZqQWZCZ05WSFNNRUdEQVdnQlRhUVpGOHpTamtIZWhUQlFaTWJqSUp0L3NBCjZqQU5CZ2txaGtpRzl3MEJBUXNGQUFPQ0FRRUFmN0F4L2lpbW1KY2JZMEE3bTFwa0FZTllPTTZmUlA3MklTR3UKNmMrU3Q3N0VBREE5cjNmWW4zanRJSi9Cci9ybnN4Tk9Bd0FjR3hVa29mYjhQYThJRk82MUw4YXlrY0VabGpNMgp0OThxODkwdi9IV0d0K21zVXFrYVZEYWdFTi93VVZua2JMOHFjdkk1STRDTUdBbnFPYjNDb2N5dS82TmdwRmx3CjVFa1AybmN4YURONldJWWU3RFp2WnpzTEhna0hicUZLcTJaOU5YSm95WlQzb2g4d2xXOFlteFV4US84N0JTL28KbDJ1ai9BOUh1QVlCKzBGMFFSaDE2N2pDUzFCUTBuSzFoSW54Sjlaa3pQTWNwTGQ1WjVKQzZFNzFzaFFweDA0dQo0ZWdRejI4aWNUcnhqVUVjWlhZaFg2YUorNGVIUkUvSG94c3Q2UUFPeDFXSzZrTzZ0QT09Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K","service":{"name":"prometheus-operator-admission-webhook","namespace":"openshift-monitoring","path":"/admission-alertmanagerconfigs/validate","port":8443}},"failurePolicy":"Ignore","name":"alertmanagerconfigs.openshift.io","rules":[{"apiGroups":["monitoring.coreos.com"],"apiVersions":["v1alpha1"],"operations":["CREATE","UPDATE"],"resources":["alertmanagerconfigs"],"scope":"Namespaced"}],"sideEffects":"None","timeoutSeconds":5}]}
2024-06-11T11:06:25.834430321Z I0611 11:06:25.834083       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ValidatingWebhookConfigurationUpdated' Updated ValidatingWebhookConfiguration.admissionregistration.k8s.io/alertmanagerconfigs.openshift.io because it changed
2024-06-11T11:06:27.964740668Z I0611 11:06:27.964669       1 tasks.go:76] ran task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:06:27.964740668Z I0611 11:06:27.964707       1 tasks.go:49] processing task group 2 of 3
2024-06-11T11:06:27.964807071Z I0611 11:06:27.964755       1 tasks.go:70] running task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:06:27.964807071Z I0611 11:06:27.964776       1 tasks.go:70] running task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:06:27.964807071Z I0611 11:06:27.964775       1 tasks.go:70] running task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:06:27.964853673Z I0611 11:06:27.964820       1 tasks.go:70] running task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:06:27.964912776Z I0611 11:06:27.964863       1 tasks.go:70] running task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:06:27.965000380Z I0611 11:06:27.964981       1 tasks.go:76] ran task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:06:27.965077383Z I0611 11:06:27.964877       1 tasks.go:70] running task 8 of 16: UpdatingMetricsServer
2024-06-11T11:06:27.965174988Z I0611 11:06:27.964748       1 tasks.go:70] running task 3 of 16: UpdatingAlertmanager
2024-06-11T11:06:27.965458400Z I0611 11:06:27.964899       1 tasks.go:70] running task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:06:27.965664810Z I0611 11:06:27.964903       1 tasks.go:70] running task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:06:27.965756014Z I0611 11:06:27.964912       1 tasks.go:70] running task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:06:27.965850018Z I0611 11:06:27.964910       1 tasks.go:70] running task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:06:27.966099729Z I0611 11:06:27.964922       1 tasks.go:70] running task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:06:27.966217835Z I0611 11:06:27.964924       1 tasks.go:70] running task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:06:27.966289638Z I0611 11:06:27.964930       1 tasks.go:70] running task 4 of 16: UpdatingNodeExporter
2024-06-11T11:06:27.966581551Z I0611 11:06:27.964933       1 tasks.go:70] running task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:06:27.966760659Z I0611 11:06:27.964763       1 tasks.go:70] running task 2 of 16: UpdatingPrometheus
2024-06-11T11:06:27.976742509Z W0611 11:06:27.976506       1 tasks.go:73] task 3 of 16: UpdatingAlertmanager failed: reconciling Alertmanager Route failed: creating Route object failed: the server could not find the requested resource (post routes.route.openshift.io)
2024-06-11T11:06:27.980748990Z W0611 11:06:27.980707       1 tasks.go:73] task 10 of 16: UpdatingThanosQuerier failed: reconciling Thanos Querier Route failed: creating Route object failed: the server could not find the requested resource (post routes.route.openshift.io)
2024-06-11T11:06:28.009702094Z I0611 11:06:28.009647       1 tasks.go:76] ran task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:06:28.015216143Z I0611 11:06:28.015175       1 tasks.go:76] ran task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:06:28.030543734Z I0611 11:06:28.030443       1 tasks.go:76] ran task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:06:28.075116442Z I0611 11:06:28.075009       1 tasks.go:76] ran task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:06:28.106866573Z I0611 11:06:28.106803       1 tasks.go:76] ran task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:06:29.032982109Z I0611 11:06:29.032927       1 tasks.go:76] ran task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:06:29.041569196Z I0611 11:06:29.041506       1 tasks.go:76] ran task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:06:29.055357417Z I0611 11:06:29.055264       1 tasks.go:76] ran task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:06:29.056077550Z I0611 11:06:29.056024       1 tasks.go:76] ran task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:06:29.095685235Z I0611 11:06:29.095628       1 tasks.go:76] ran task 4 of 16: UpdatingNodeExporter
2024-06-11T11:06:34.107572399Z I0611 11:06:34.107514       1 tasks.go:76] ran task 8 of 16: UpdatingMetricsServer
2024-06-11T11:06:54.471071931Z I0611 11:06:54.471017       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:06:58.028894877Z I0611 11:06:58.028816       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/monitoring-plugin -n openshift-monitoring because it was missing
2024-06-11T11:06:58.044659573Z I0611 11:06:58.044585       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountCreated' Created ServiceAccount/monitoring-plugin -n openshift-monitoring because it was missing
2024-06-11T11:06:58.073364141Z I0611 11:06:58.073255       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceCreated' Created Service/monitoring-plugin -n openshift-monitoring because it was missing
2024-06-11T11:07:04.199406007Z I0611 11:07:04.198782       1 tasks.go:76] ran task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:07:04.199406007Z I0611 11:07:04.199033       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodDisruptionBudgetCreated' Created PodDisruptionBudget.policy/monitoring-plugin -n openshift-monitoring because it was missing
2024-06-11T11:07:10.441112182Z I0611 11:07:10.441046       1 operator.go:650] Triggering an update due to a change in *v1.Console/cluster
2024-06-11T11:07:24.354283820Z I0611 11:07:24.354221       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:07:39.350792719Z I0611 11:07:39.350729       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:10:09.361018444Z I0611 11:10:09.360942       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:11:27.992576535Z W0611 11:11:27.992471       1 tasks.go:73] task 2 of 16: UpdatingPrometheus failed: [reconciling Prometheus API Route failed: creating Route object failed: the server could not find the requested resource (post routes.route.openshift.io), unavailable (unknown): client rate limiter Wait returned an error: context deadline exceeded, degraded (unknown): client rate limiter Wait returned an error: context deadline exceeded]
2024-06-11T11:11:27.992661247Z I0611 11:11:27.992571       1 operator.go:890] 15 reconciliations failed in a row, the threshold of 3 attempts has been reached, failures will be reported.
2024-06-11T11:11:28.017541664Z E0611 11:11:28.014171       1 operator.go:709] Syncing "openshift-monitoring/cluster-monitoring-config" failed
2024-06-11T11:11:28.017541664Z E0611 11:11:28.014207       1 operator.go:710] sync "openshift-monitoring/cluster-monitoring-config" failed: cluster monitoring update failed (reason: PlatformTasksFailed)
2024-06-11T11:11:28.047563387Z I0611 11:11:28.047497       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T11:11:28.051129177Z I0611 11:11:28.051087       1 tasks.go:49] processing task group 1 of 3
2024-06-11T11:11:28.051129177Z I0611 11:11:28.051118       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:11:28.051170482Z I0611 11:11:28.051145       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:11:28.063534781Z I0611 11:11:28.063489       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:11:31.193288124Z I0611 11:11:31.193224       1 tasks.go:76] ran task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:11:31.193288124Z I0611 11:11:31.193257       1 tasks.go:49] processing task group 2 of 3
2024-06-11T11:11:31.193399339Z I0611 11:11:31.193339       1 tasks.go:70] running task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:11:31.193399339Z I0611 11:11:31.193349       1 tasks.go:70] running task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:11:31.193399339Z I0611 11:11:31.193362       1 tasks.go:70] running task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:11:31.193507954Z I0611 11:11:31.193430       1 tasks.go:70] running task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:11:31.193673177Z I0611 11:11:31.193333       1 tasks.go:70] running task 2 of 16: UpdatingPrometheus
2024-06-11T11:11:31.193799094Z I0611 11:11:31.193472       1 tasks.go:70] running task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:11:31.193799094Z I0611 11:11:31.193786       1 tasks.go:76] ran task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:11:31.193858702Z I0611 11:11:31.193487       1 tasks.go:70] running task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:11:31.193952315Z I0611 11:11:31.193492       1 tasks.go:70] running task 3 of 16: UpdatingAlertmanager
2024-06-11T11:11:31.194239654Z I0611 11:11:31.193506       1 tasks.go:70] running task 8 of 16: UpdatingMetricsServer
2024-06-11T11:11:31.194289361Z I0611 11:11:31.193526       1 tasks.go:70] running task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:11:31.194434781Z I0611 11:11:31.193531       1 tasks.go:70] running task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:11:31.194857039Z I0611 11:11:31.193537       1 tasks.go:70] running task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:11:31.194899745Z I0611 11:11:31.193545       1 tasks.go:70] running task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:11:31.195097372Z I0611 11:11:31.193550       1 tasks.go:70] running task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:11:31.195195486Z I0611 11:11:31.193530       1 tasks.go:70] running task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:11:31.195330704Z I0611 11:11:31.193495       1 tasks.go:70] running task 4 of 16: UpdatingNodeExporter
2024-06-11T11:11:31.240656129Z I0611 11:11:31.240585       1 tasks.go:76] ran task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:11:31.243924978Z I0611 11:11:31.243851       1 tasks.go:76] ran task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:11:31.268347432Z I0611 11:11:31.264515       1 tasks.go:76] ran task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:11:31.293332164Z I0611 11:11:31.293240       1 tasks.go:76] ran task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:11:31.335859605Z I0611 11:11:31.335781       1 tasks.go:76] ran task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:11:32.280232573Z I0611 11:11:32.280176       1 tasks.go:76] ran task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:11:32.283165163Z I0611 11:11:32.283106       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodDisruptionBudgetCreated' Created PodDisruptionBudget.policy/alertmanager-main -n openshift-monitoring because it was missing
2024-06-11T11:11:32.317376409Z I0611 11:11:32.317312       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/thanos-querier-kube-rbac-proxy-web -n openshift-monitoring because it was missing
2024-06-11T11:11:32.327919810Z I0611 11:11:32.327857       1 tasks.go:76] ran task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:11:32.329845466Z I0611 11:11:32.329775       1 tasks.go:76] ran task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:11:32.337933440Z I0611 11:11:32.337894       1 tasks.go:76] ran task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:11:32.361026209Z I0611 11:11:32.360976       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountCreated' Created ServiceAccount/thanos-querier -n openshift-monitoring because it was missing
2024-06-11T11:11:32.388479957Z I0611 11:11:32.388441       1 tasks.go:76] ran task 4 of 16: UpdatingNodeExporter
2024-06-11T11:11:32.535157447Z I0611 11:11:32.535073       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/thanos-querier because it was missing
2024-06-11T11:11:32.556940242Z I0611 11:11:32.556866       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleCreated' Created ClusterRole.rbac.authorization.k8s.io/alertmanager-main because it was missing
2024-06-11T11:11:32.645442202Z I0611 11:11:32.645365       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleBindingCreated' Created ClusterRoleBinding.rbac.authorization.k8s.io/thanos-querier because it was missing
2024-06-11T11:11:32.673765265Z I0611 11:11:32.673260       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ClusterRoleBindingCreated' Created ClusterRoleBinding.rbac.authorization.k8s.io/alertmanager-main because it was missing
2024-06-11T11:11:32.687759625Z I0611 11:11:32.687689       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountCreated' Created ServiceAccount/alertmanager-main -n openshift-monitoring because it was missing
2024-06-11T11:11:32.732161925Z I0611 11:11:32.731333       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceCreated' Created Service/alertmanager-main -n openshift-monitoring because it was missing
2024-06-11T11:11:32.750807702Z I0611 11:11:32.750746       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/alertmanager-trusted-ca-bundle
2024-06-11T11:11:32.751593307Z I0611 11:11:32.751460       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/alertmanager-trusted-ca-bundle -n openshift-monitoring because it was missing
2024-06-11T11:11:33.220545320Z I0611 11:11:33.220470       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/alertmanager-trusted-ca-bundle
2024-06-11T11:11:33.321726265Z I0611 11:11:33.321649       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/kube-rbac-proxy -n openshift-monitoring because it was missing
2024-06-11T11:11:33.332593009Z I0611 11:11:33.332533       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/prometheus-k8s-kube-rbac-proxy-web -n openshift-monitoring because it was missing
2024-06-11T11:11:33.343261427Z I0611 11:11:33.343207       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceAccountCreated' Created ServiceAccount/prometheus-k8s -n openshift-monitoring because it was missing
2024-06-11T11:11:33.456848120Z I0611 11:11:33.456770       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleBindingCreated' Created RoleBinding.rbac.authorization.k8s.io/alertmanager-prometheusk8s -n openshift-monitoring because it was missing
2024-06-11T11:11:33.515671536Z I0611 11:11:33.515594       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleCreated' Created Role.rbac.authorization.k8s.io/prometheus-k8s-config -n openshift-monitoring because it was missing
2024-06-11T11:11:33.576241285Z I0611 11:11:33.576165       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleCreated' Created Role.rbac.authorization.k8s.io/prometheus-k8s -n default because it was missing
2024-06-11T11:11:33.641579067Z I0611 11:11:33.641507       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleCreated' Created Role.rbac.authorization.k8s.io/prometheus-k8s -n kube-system because it was missing
2024-06-11T11:11:33.668479441Z I0611 11:11:33.668386       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/thanos-querier-grpc-tls-dhqjjp8v87kee -n openshift-monitoring because it was missing
2024-06-11T11:11:33.716484220Z I0611 11:11:33.716339       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleCreated' Created Role.rbac.authorization.k8s.io/prometheus-k8s -n openshift-monitoring because it was missing
2024-06-11T11:11:33.899266008Z I0611 11:11:33.899187       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleCreated' Created Role.rbac.authorization.k8s.io/prometheus-k8s -n openshift-user-workload-monitoring because it was missing
2024-06-11T11:11:33.997173617Z I0611 11:11:33.997100       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleBindingCreated' Created RoleBinding.rbac.authorization.k8s.io/prometheus-k8s -n default because it was missing
2024-06-11T11:11:34.073044099Z I0611 11:11:34.072933       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleBindingCreated' Created RoleBinding.rbac.authorization.k8s.io/prometheus-k8s -n kube-system because it was missing
2024-06-11T11:11:34.154313898Z I0611 11:11:34.154223       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleBindingCreated' Created RoleBinding.rbac.authorization.k8s.io/prometheus-k8s -n openshift-monitoring because it was missing
2024-06-11T11:11:34.237736383Z I0611 11:11:34.237659       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleBindingCreated' Created RoleBinding.rbac.authorization.k8s.io/prometheus-k8s -n openshift-user-workload-monitoring because it was missing
2024-06-11T11:11:34.334051881Z I0611 11:11:34.333967       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'RoleBindingCreated' Created RoleBinding.rbac.authorization.k8s.io/prometheus-k8s-config -n openshift-monitoring because it was missing
2024-06-11T11:11:34.408558682Z I0611 11:11:34.408487       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceCreated' Created Service/prometheus-k8s -n openshift-monitoring because it was missing
2024-06-11T11:11:34.430135349Z I0611 11:11:34.427130       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ServiceCreated' Created Service/prometheus-k8s-thanos-sidecar -n openshift-monitoring because it was missing
2024-06-11T11:11:37.342745371Z I0611 11:11:37.342678       1 tasks.go:76] ran task 8 of 16: UpdatingMetricsServer
2024-06-11T11:11:37.461657672Z I0611 11:11:37.461571       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/prometheus-k8s-grpc-tls-9838dml7sm2ad -n openshift-monitoring because it was missing
2024-06-11T11:11:37.485832485Z I0611 11:11:37.485747       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodDisruptionBudgetCreated' Created PodDisruptionBudget.policy/prometheus-k8s -n openshift-monitoring because it was missing
2024-06-11T11:11:37.529506288Z I0611 11:11:37.529381       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/prometheus-trusted-ca-bundle -n openshift-monitoring because it was missing
2024-06-11T11:11:37.543777184Z I0611 11:11:37.543665       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'SecretCreated' Created Secret/prometheus-k8s-additional-alertmanager-configs -n openshift-monitoring because it was missing
2024-06-11T11:11:38.257261491Z I0611 11:11:38.257192       1 tasks.go:76] ran task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:11:42.755534151Z I0611 11:11:42.755466       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'PodDisruptionBudgetCreated' Created PodDisruptionBudget.policy/thanos-querier-pdb -n openshift-monitoring because it was missing
2024-06-11T11:11:42.803591884Z I0611 11:11:42.803522       1 tasks.go:76] ran task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:12:12.883686548Z I0611 11:12:12.883624       1 tasks.go:76] ran task 3 of 16: UpdatingAlertmanager
2024-06-11T11:12:15.645558792Z I0611 11:12:15.645503       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:12:15.647867061Z I0611 11:12:15.647378       1 operator.go:650] Triggering an update due to a change in *v1.Infrastructure/cluster
2024-06-11T11:12:17.154196886Z I0611 11:12:17.154137       1 reflector.go:351] Caches populated for *v1.ClusterVersion from github.com/openshift/client-go/config/informers/externalversions/factory.go:125
2024-06-11T11:12:17.220822372Z I0611 11:12:17.220767       1 operator.go:650] Triggering an update due to a change in *v1.APIServer/cluster
2024-06-11T11:12:18.440817837Z I0611 11:12:18.440726       1 reflector.go:351] Caches populated for *v1.AlertRelabelConfig from github.com/openshift/cluster-monitoring-operator/pkg/alert/relabel_controller.go:121
2024-06-11T11:12:18.466260310Z I0611 11:12:18.466199       1 reflector.go:351] Caches populated for *v1.Console from github.com/openshift/cluster-monitoring-operator/pkg/operator/operator.go:569
2024-06-11T11:12:18.466353921Z I0611 11:12:18.466288       1 operator.go:650] Triggering an update due to a change in Console.config.openshift.io/cluster
2024-06-11T11:12:18.498655596Z I0611 11:12:18.498601       1 reflector.go:351] Caches populated for *v1.AlertingRule from github.com/openshift/cluster-monitoring-operator/pkg/alert/rule_controller.go:118
2024-06-11T11:12:18.575679096Z I0611 11:12:18.575628       1 reflector.go:351] Caches populated for *v1.PrometheusRule from github.com/openshift/cluster-monitoring-operator/pkg/alert/rule_controller.go:117
2024-06-11T11:12:18.793085202Z I0611 11:12:18.793001       1 reflector.go:351] Caches populated for *v1.FeatureGate from github.com/openshift/client-go/config/informers/externalversions/factory.go:125
2024-06-11T11:12:57.664020403Z I0611 11:12:57.663961       1 tasks.go:76] ran task 2 of 16: UpdatingPrometheus
2024-06-11T11:12:57.664020403Z I0611 11:12:57.663996       1 tasks.go:49] processing task group 3 of 3
2024-06-11T11:12:57.664020403Z I0611 11:12:57.664009       1 tasks.go:70] running task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:12:57.714734774Z I0611 11:12:57.714662       1 tasks.go:76] ran task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:12:57.714734774Z I0611 11:12:57.714725       1 operator.go:863] Updating ClusterOperator status to done.
2024-06-11T11:12:57.714926995Z I0611 11:12:57.714871       1 event.go:364] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"openshift-monitoring", Name:"cluster-monitoring-operator", UID:"64fd8edf-3059-479c-9a58-cc1ecb598b3f", APIVersion:"apps/v1", ResourceVersion:"", FieldPath:""}): type: 'Normal' reason: 'ConfigMapCreated' Created ConfigMap/monitoring-shared-config -n openshift-config-managed because it was missing
2024-06-11T11:12:57.867870693Z I0611 11:12:57.867812       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T11:12:57.878872158Z I0611 11:12:57.878809       1 tasks.go:49] processing task group 1 of 3
2024-06-11T11:12:57.878872158Z I0611 11:12:57.878844       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:12:57.878919963Z I0611 11:12:57.878874       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:12:57.920979117Z I0611 11:12:57.920919       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:13:01.054861495Z I0611 11:13:01.054779       1 tasks.go:76] ran task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:13:01.054861495Z I0611 11:13:01.054816       1 tasks.go:49] processing task group 2 of 3
2024-06-11T11:13:01.054861495Z I0611 11:13:01.054844       1 tasks.go:70] running task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:13:01.054938901Z I0611 11:13:01.054916       1 tasks.go:70] running task 8 of 16: UpdatingMetricsServer
2024-06-11T11:13:01.054998505Z I0611 11:13:01.054931       1 tasks.go:70] running task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:13:01.055157518Z I0611 11:13:01.055084       1 tasks.go:70] running task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:13:01.055157518Z I0611 11:13:01.055116       1 tasks.go:70] running task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:13:01.055207122Z I0611 11:13:01.055155       1 tasks.go:70] running task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:13:01.055448340Z I0611 11:13:01.055384       1 tasks.go:70] running task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:13:01.055448340Z I0611 11:13:01.055404       1 tasks.go:70] running task 4 of 16: UpdatingNodeExporter
2024-06-11T11:13:01.055620354Z I0611 11:13:01.055568       1 tasks.go:70] running task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:13:01.055820469Z I0611 11:13:01.055780       1 tasks.go:70] running task 2 of 16: UpdatingPrometheus
2024-06-11T11:13:01.055894275Z I0611 11:13:01.055867       1 tasks.go:70] running task 3 of 16: UpdatingAlertmanager
2024-06-11T11:13:01.056028185Z I0611 11:13:01.055844       1 tasks.go:70] running task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:13:01.056115292Z I0611 11:13:01.055873       1 tasks.go:70] running task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:13:01.056164096Z I0611 11:13:01.055853       1 tasks.go:70] running task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:13:01.056357411Z I0611 11:13:01.055882       1 tasks.go:70] running task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:13:01.056559626Z I0611 11:13:01.055889       1 tasks.go:70] running task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:13:01.056662934Z I0611 11:13:01.056607       1 tasks.go:76] ran task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:13:01.099973692Z I0611 11:13:01.099928       1 tasks.go:76] ran task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:13:01.105453517Z I0611 11:13:01.105403       1 tasks.go:76] ran task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:13:01.117270333Z I0611 11:13:01.117227       1 tasks.go:76] ran task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:13:01.144861573Z I0611 11:13:01.144809       1 tasks.go:76] ran task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:13:01.184856174Z I0611 11:13:01.184795       1 tasks.go:76] ran task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:13:02.124638137Z I0611 11:13:02.124549       1 tasks.go:76] ran task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:13:02.145162928Z I0611 11:13:02.145111       1 tasks.go:76] ran task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:13:02.147760729Z I0611 11:13:02.147712       1 tasks.go:76] ran task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:13:02.161884524Z I0611 11:13:02.161837       1 tasks.go:76] ran task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:13:02.176341745Z I0611 11:13:02.176275       1 tasks.go:76] ran task 4 of 16: UpdatingNodeExporter
2024-06-11T11:13:04.237475936Z I0611 11:13:04.237389       1 tasks.go:76] ran task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:13:07.190255412Z I0611 11:13:07.190194       1 tasks.go:76] ran task 8 of 16: UpdatingMetricsServer
2024-06-11T11:13:08.132271324Z I0611 11:13:08.132211       1 tasks.go:76] ran task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:13:12.212783876Z I0611 11:13:12.212715       1 tasks.go:76] ran task 3 of 16: UpdatingAlertmanager
2024-06-11T11:13:16.371610158Z I0611 11:13:16.371550       1 tasks.go:76] ran task 2 of 16: UpdatingPrometheus
2024-06-11T11:13:16.371610158Z I0611 11:13:16.371589       1 tasks.go:49] processing task group 3 of 3
2024-06-11T11:13:16.371610158Z I0611 11:13:16.371602       1 tasks.go:70] running task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:13:16.403076190Z I0611 11:13:16.403013       1 tasks.go:76] ran task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:13:16.403076190Z I0611 11:13:16.403056       1 operator.go:863] Updating ClusterOperator status to done.
2024-06-11T11:13:24.374248000Z I0611 11:13:24.374170       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:13:24.410650278Z I0611 11:13:24.410597       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T11:13:24.414691042Z I0611 11:13:24.414624       1 tasks.go:49] processing task group 1 of 3
2024-06-11T11:13:24.414691042Z I0611 11:13:24.414659       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:13:24.414745747Z I0611 11:13:24.414693       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:13:24.428115051Z I0611 11:13:24.428060       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:13:27.555751206Z I0611 11:13:27.555675       1 tasks.go:76] ran task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:13:27.555751206Z I0611 11:13:27.555715       1 tasks.go:49] processing task group 2 of 3
2024-06-11T11:13:27.555825913Z I0611 11:13:27.555770       1 tasks.go:70] running task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:13:27.555825913Z I0611 11:13:27.555777       1 tasks.go:70] running task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:13:27.555825913Z I0611 11:13:27.555792       1 tasks.go:70] running task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:13:27.555846915Z I0611 11:13:27.555824       1 tasks.go:70] running task 3 of 16: UpdatingAlertmanager
2024-06-11T11:13:27.555911220Z I0611 11:13:27.555860       1 tasks.go:70] running task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:13:27.556039932Z I0611 11:13:27.555986       1 tasks.go:70] running task 4 of 16: UpdatingNodeExporter
2024-06-11T11:13:27.556072035Z I0611 11:13:27.555783       1 tasks.go:70] running task 2 of 16: UpdatingPrometheus
2024-06-11T11:13:27.556176544Z I0611 11:13:27.555889       1 tasks.go:70] running task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:13:27.556251651Z I0611 11:13:27.556233       1 tasks.go:76] ran task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:13:27.556337059Z I0611 11:13:27.555901       1 tasks.go:70] running task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:13:27.556337059Z I0611 11:13:27.555925       1 tasks.go:70] running task 8 of 16: UpdatingMetricsServer
2024-06-11T11:13:27.556451269Z I0611 11:13:27.555937       1 tasks.go:70] running task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:13:27.556595482Z I0611 11:13:27.555939       1 tasks.go:70] running task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:13:27.556803301Z I0611 11:13:27.555947       1 tasks.go:70] running task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:13:27.556893709Z I0611 11:13:27.555952       1 tasks.go:70] running task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:13:27.557080126Z I0611 11:13:27.555961       1 tasks.go:70] running task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:13:27.557392054Z I0611 11:13:27.555925       1 tasks.go:70] running task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:13:27.595079948Z I0611 11:13:27.595011       1 tasks.go:76] ran task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:13:27.600053796Z I0611 11:13:27.600013       1 tasks.go:76] ran task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:13:27.608961498Z I0611 11:13:27.608915       1 tasks.go:76] ran task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:13:27.645365676Z I0611 11:13:27.645288       1 tasks.go:76] ran task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:13:27.672185291Z I0611 11:13:27.672142       1 tasks.go:76] ran task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:13:28.611765904Z I0611 11:13:28.611690       1 tasks.go:76] ran task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:13:28.630507091Z I0611 11:13:28.630454       1 tasks.go:76] ran task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:13:28.632327755Z I0611 11:13:28.632252       1 tasks.go:76] ran task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:13:28.651541086Z I0611 11:13:28.651494       1 tasks.go:76] ran task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:13:28.660693110Z I0611 11:13:28.660654       1 tasks.go:76] ran task 4 of 16: UpdatingNodeExporter
2024-06-11T11:13:30.697639691Z I0611 11:13:30.697572       1 tasks.go:76] ran task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:13:33.697713304Z I0611 11:13:33.697657       1 tasks.go:76] ran task 8 of 16: UpdatingMetricsServer
2024-06-11T11:13:34.639109869Z I0611 11:13:34.639044       1 tasks.go:76] ran task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:13:38.710385662Z I0611 11:13:38.710327       1 tasks.go:76] ran task 3 of 16: UpdatingAlertmanager
2024-06-11T11:13:42.882547047Z I0611 11:13:42.882488       1 tasks.go:76] ran task 2 of 16: UpdatingPrometheus
2024-06-11T11:13:42.882598851Z I0611 11:13:42.882525       1 tasks.go:49] processing task group 3 of 3
2024-06-11T11:13:42.882598851Z I0611 11:13:42.882581       1 tasks.go:70] running task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:13:42.915140107Z I0611 11:13:42.915081       1 tasks.go:76] ran task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:13:42.915140107Z I0611 11:13:42.915130       1 operator.go:863] Updating ClusterOperator status to done.
2024-06-11T11:14:28.050844777Z I0611 11:14:28.050791       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T11:14:28.054462382Z I0611 11:14:28.054410       1 tasks.go:49] processing task group 1 of 3
2024-06-11T11:14:28.054462382Z I0611 11:14:28.054448       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:14:28.054514487Z I0611 11:14:28.054485       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:14:28.068972909Z I0611 11:14:28.068918       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:14:31.222616492Z I0611 11:14:31.222556       1 tasks.go:76] ran task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:14:31.222616492Z I0611 11:14:31.222588       1 tasks.go:49] processing task group 2 of 3
2024-06-11T11:14:31.222616492Z I0611 11:14:31.222610       1 tasks.go:70] running task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:14:31.222675897Z I0611 11:14:31.222650       1 tasks.go:70] running task 8 of 16: UpdatingMetricsServer
2024-06-11T11:14:31.222742203Z I0611 11:14:31.222683       1 tasks.go:70] running task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:14:31.222742203Z I0611 11:14:31.222726       1 tasks.go:70] running task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:14:31.222785606Z I0611 11:14:31.222758       1 tasks.go:70] running task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:14:31.222924218Z I0611 11:14:31.222883       1 tasks.go:70] running task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:14:31.223331553Z I0611 11:14:31.223116       1 tasks.go:70] running task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:14:31.223383757Z I0611 11:14:31.223345       1 tasks.go:70] running task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:14:31.224345738Z I0611 11:14:31.224268       1 tasks.go:70] running task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:14:31.224684967Z I0611 11:14:31.222892       1 tasks.go:70] running task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:14:31.225243514Z I0611 11:14:31.225212       1 tasks.go:70] running task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:14:31.225776359Z I0611 11:14:31.225738       1 tasks.go:70] running task 3 of 16: UpdatingAlertmanager
2024-06-11T11:14:31.226078085Z I0611 11:14:31.226004       1 tasks.go:70] running task 4 of 16: UpdatingNodeExporter
2024-06-11T11:14:31.226107387Z I0611 11:14:31.226077       1 tasks.go:70] running task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:14:31.226107387Z I0611 11:14:31.226102       1 tasks.go:76] ran task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:14:31.226131989Z I0611 11:14:31.226116       1 tasks.go:70] running task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:14:31.226504821Z I0611 11:14:31.226458       1 tasks.go:70] running task 2 of 16: UpdatingPrometheus
2024-06-11T11:14:31.275649573Z I0611 11:14:31.275267       1 tasks.go:76] ran task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:14:31.275711079Z I0611 11:14:31.275671       1 tasks.go:76] ran task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:14:31.286769913Z I0611 11:14:31.286716       1 tasks.go:76] ran task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:14:31.313162643Z I0611 11:14:31.313095       1 tasks.go:76] ran task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:14:31.344653104Z I0611 11:14:31.344587       1 tasks.go:76] ran task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:14:32.288348047Z I0611 11:14:32.288233       1 tasks.go:76] ran task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:14:32.311216879Z I0611 11:14:32.311158       1 tasks.go:76] ran task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:14:32.313803498Z I0611 11:14:32.313756       1 tasks.go:76] ran task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:14:32.321093014Z I0611 11:14:32.321053       1 tasks.go:76] ran task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:14:32.339035330Z I0611 11:14:32.338997       1 tasks.go:76] ran task 4 of 16: UpdatingNodeExporter
2024-06-11T11:14:34.384947110Z I0611 11:14:34.384882       1 tasks.go:76] ran task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:14:37.361031570Z I0611 11:14:37.360971       1 tasks.go:76] ran task 8 of 16: UpdatingMetricsServer
2024-06-11T11:14:38.285089984Z I0611 11:14:38.285030       1 tasks.go:76] ran task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:14:42.391599431Z I0611 11:14:42.391537       1 tasks.go:76] ran task 3 of 16: UpdatingAlertmanager
2024-06-11T11:14:46.552958357Z I0611 11:14:46.552884       1 tasks.go:76] ran task 2 of 16: UpdatingPrometheus
2024-06-11T11:14:46.552958357Z I0611 11:14:46.552932       1 tasks.go:49] processing task group 3 of 3
2024-06-11T11:14:46.552958357Z I0611 11:14:46.552944       1 tasks.go:70] running task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:14:46.586353064Z I0611 11:14:46.586284       1 tasks.go:76] ran task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:14:46.586415068Z I0611 11:14:46.586361       1 operator.go:863] Updating ClusterOperator status to done.
2024-06-11T11:15:54.367701385Z I0611 11:15:54.367613       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:15:54.443697403Z I0611 11:15:54.443638       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T11:15:54.450746224Z I0611 11:15:54.450674       1 tasks.go:49] processing task group 1 of 3
2024-06-11T11:15:54.450746224Z I0611 11:15:54.450712       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:15:54.451093750Z I0611 11:15:54.451047       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:15:54.470751103Z I0611 11:15:54.470692       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:15:57.613125865Z I0611 11:15:57.613054       1 tasks.go:76] ran task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:15:57.613125865Z I0611 11:15:57.613096       1 tasks.go:49] processing task group 2 of 3
2024-06-11T11:15:57.613125865Z I0611 11:15:57.613118       1 tasks.go:70] running task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:15:57.613196770Z I0611 11:15:57.613131       1 tasks.go:70] running task 3 of 16: UpdatingAlertmanager
2024-06-11T11:15:57.613196770Z I0611 11:15:57.613146       1 tasks.go:70] running task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:15:57.613213971Z I0611 11:15:57.613185       1 tasks.go:70] running task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:15:57.613226372Z I0611 11:15:57.613208       1 tasks.go:70] running task 2 of 16: UpdatingPrometheus
2024-06-11T11:15:57.613378982Z I0611 11:15:57.613333       1 tasks.go:70] running task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:15:57.613456687Z I0611 11:15:57.613424       1 tasks.go:70] running task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:15:57.613456687Z I0611 11:15:57.613446       1 tasks.go:70] running task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:15:57.613625798Z I0611 11:15:57.613339       1 tasks.go:70] running task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:15:57.613671901Z I0611 11:15:57.613366       1 tasks.go:70] running task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:15:57.613764507Z I0611 11:15:57.613348       1 tasks.go:70] running task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:15:57.615257007Z I0611 11:15:57.613399       1 tasks.go:70] running task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:15:57.615341912Z I0611 11:15:57.615318       1 tasks.go:76] ran task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:15:57.615341912Z I0611 11:15:57.613411       1 tasks.go:70] running task 8 of 16: UpdatingMetricsServer
2024-06-11T11:15:57.615731138Z I0611 11:15:57.613418       1 tasks.go:70] running task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:15:57.616717804Z I0611 11:15:57.614287       1 tasks.go:70] running task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:15:57.616871814Z I0611 11:15:57.613383       1 tasks.go:70] running task 4 of 16: UpdatingNodeExporter
2024-06-11T11:15:57.669412204Z I0611 11:15:57.669359       1 tasks.go:76] ran task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:15:57.673107149Z I0611 11:15:57.673017       1 tasks.go:76] ran task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:15:57.693719719Z I0611 11:15:57.693664       1 tasks.go:76] ran task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:15:57.709958597Z I0611 11:15:57.709906       1 tasks.go:76] ran task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:15:57.756147966Z I0611 11:15:57.756010       1 tasks.go:76] ran task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:15:58.689464864Z I0611 11:15:58.689365       1 tasks.go:76] ran task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:15:58.710083534Z I0611 11:15:58.710005       1 tasks.go:76] ran task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:15:58.715332083Z I0611 11:15:58.715281       1 tasks.go:76] ran task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:15:58.720789845Z I0611 11:15:58.720749       1 tasks.go:76] ran task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:15:58.738456919Z I0611 11:15:58.738411       1 tasks.go:76] ran task 4 of 16: UpdatingNodeExporter
2024-06-11T11:16:00.781146011Z I0611 11:16:00.781089       1 tasks.go:76] ran task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:16:03.765332295Z I0611 11:16:03.765249       1 tasks.go:76] ran task 8 of 16: UpdatingMetricsServer
2024-06-11T11:16:04.687676751Z I0611 11:16:04.687613       1 tasks.go:76] ran task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:16:08.771693608Z I0611 11:16:08.771587       1 tasks.go:76] ran task 3 of 16: UpdatingAlertmanager
2024-06-11T11:16:12.933437196Z I0611 11:16:12.933365       1 tasks.go:76] ran task 2 of 16: UpdatingPrometheus
2024-06-11T11:16:12.933437196Z I0611 11:16:12.933404       1 tasks.go:49] processing task group 3 of 3
2024-06-11T11:16:12.933437196Z I0611 11:16:12.933417       1 tasks.go:70] running task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:16:12.965002770Z I0611 11:16:12.964932       1 tasks.go:76] ran task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:16:12.965002770Z I0611 11:16:12.964983       1 operator.go:863] Updating ClusterOperator status to done.
2024-06-11T11:19:23.012901717Z I0611 11:19:23.012731       1 operator.go:650] Triggering an update due to a change in *v1.Infrastructure/cluster
2024-06-11T11:19:23.013807668Z I0611 11:19:23.013766       1 operator.go:650] Triggering an update due to a change in *v1.APIServer/cluster
2024-06-11T11:19:23.037070975Z I0611 11:19:23.037006       1 operator.go:650] Triggering an update due to a change in *v1.ClusterVersion/version
2024-06-11T11:19:23.040800785Z I0611 11:19:23.040750       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T11:19:23.044764008Z I0611 11:19:23.044653       1 tasks.go:49] processing task group 1 of 3
2024-06-11T11:19:23.044764008Z I0611 11:19:23.044679       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:19:23.044764008Z I0611 11:19:23.044710       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:19:23.056799084Z I0611 11:19:23.056753       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:19:26.175405062Z I0611 11:19:26.175337       1 tasks.go:76] ran task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:19:26.175405062Z I0611 11:19:26.175373       1 tasks.go:49] processing task group 2 of 3
2024-06-11T11:19:26.175479265Z I0611 11:19:26.175406       1 tasks.go:70] running task 2 of 16: UpdatingPrometheus
2024-06-11T11:19:26.175479265Z I0611 11:19:26.175423       1 tasks.go:70] running task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:19:26.175479265Z I0611 11:19:26.175449       1 tasks.go:70] running task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:19:26.175479265Z I0611 11:19:26.175465       1 tasks.go:70] running task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:19:26.175628373Z I0611 11:19:26.175571       1 tasks.go:70] running task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:19:26.175860084Z I0611 11:19:26.175591       1 tasks.go:70] running task 3 of 16: UpdatingAlertmanager
2024-06-11T11:19:26.175972590Z I0611 11:19:26.175621       1 tasks.go:70] running task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:19:26.176101196Z I0611 11:19:26.175617       1 tasks.go:70] running task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:19:26.176204001Z I0611 11:19:26.175630       1 tasks.go:70] running task 8 of 16: UpdatingMetricsServer
2024-06-11T11:19:26.176324207Z I0611 11:19:26.175636       1 tasks.go:70] running task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:19:26.176824632Z I0611 11:19:26.175638       1 tasks.go:70] running task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:19:26.176917737Z I0611 11:19:26.175634       1 tasks.go:70] running task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:19:26.177044443Z I0611 11:19:26.177017       1 tasks.go:76] ran task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:19:26.177141148Z I0611 11:19:26.175642       1 tasks.go:70] running task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:19:26.177141148Z I0611 11:19:26.175644       1 tasks.go:70] running task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:19:26.177141148Z I0611 11:19:26.175649       1 tasks.go:70] running task 4 of 16: UpdatingNodeExporter
2024-06-11T11:19:26.177141148Z I0611 11:19:26.175664       1 tasks.go:70] running task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:19:26.218811817Z I0611 11:19:26.218754       1 tasks.go:76] ran task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:19:26.220262189Z I0611 11:19:26.220211       1 tasks.go:76] ran task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:19:26.233925167Z I0611 11:19:26.233868       1 tasks.go:76] ran task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:19:26.257311728Z I0611 11:19:26.257241       1 tasks.go:76] ran task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:19:26.280680989Z I0611 11:19:26.280626       1 tasks.go:76] ran task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:19:27.229126779Z I0611 11:19:27.229040       1 tasks.go:76] ran task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:19:27.257291777Z I0611 11:19:27.257230       1 tasks.go:76] ran task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:19:27.259002162Z I0611 11:19:27.258947       1 tasks.go:76] ran task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:19:27.269645790Z I0611 11:19:27.269594       1 tasks.go:76] ran task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:19:27.280515730Z I0611 11:19:27.280462       1 tasks.go:76] ran task 4 of 16: UpdatingNodeExporter
2024-06-11T11:19:29.349442119Z I0611 11:19:29.349370       1 tasks.go:76] ran task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:19:32.332877104Z I0611 11:19:32.332812       1 tasks.go:76] ran task 8 of 16: UpdatingMetricsServer
2024-06-11T11:19:33.259339994Z I0611 11:19:33.259273       1 tasks.go:76] ran task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:19:37.350467151Z I0611 11:19:37.350383       1 tasks.go:76] ran task 3 of 16: UpdatingAlertmanager
2024-06-11T11:19:41.574269730Z I0611 11:19:41.574187       1 tasks.go:76] ran task 2 of 16: UpdatingPrometheus
2024-06-11T11:19:41.574269730Z I0611 11:19:41.574234       1 tasks.go:49] processing task group 3 of 3
2024-06-11T11:19:41.574269730Z I0611 11:19:41.574246       1 tasks.go:70] running task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:19:41.608633343Z I0611 11:19:41.608570       1 tasks.go:76] ran task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:19:41.608633343Z I0611 11:19:41.608622       1 operator.go:863] Updating ClusterOperator status to done.
2024-06-11T11:19:41.643328870Z I0611 11:19:41.643249       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T11:19:41.647530143Z I0611 11:19:41.647481       1 tasks.go:49] processing task group 1 of 3
2024-06-11T11:19:41.647530143Z I0611 11:19:41.647512       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:19:41.647568244Z I0611 11:19:41.647545       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:19:41.660787388Z I0611 11:19:41.660727       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:19:44.794890510Z I0611 11:19:44.794813       1 tasks.go:76] ran task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:19:44.794890510Z I0611 11:19:44.794854       1 tasks.go:49] processing task group 2 of 3
2024-06-11T11:19:44.794962914Z I0611 11:19:44.794893       1 tasks.go:70] running task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:19:44.795857161Z I0611 11:19:44.795793       1 tasks.go:70] running task 8 of 16: UpdatingMetricsServer
2024-06-11T11:19:44.795857161Z I0611 11:19:44.795817       1 tasks.go:70] running task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:19:44.795857161Z I0611 11:19:44.795831       1 tasks.go:70] running task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:19:44.795908864Z I0611 11:19:44.795851       1 tasks.go:70] running task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:19:44.796030471Z I0611 11:19:44.795994       1 tasks.go:70] running task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:19:44.796209180Z I0611 11:19:44.795796       1 tasks.go:70] running task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:19:44.796263783Z I0611 11:19:44.796027       1 tasks.go:70] running task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:19:44.796328287Z I0611 11:19:44.796032       1 tasks.go:70] running task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:19:44.796532898Z I0611 11:19:44.796045       1 tasks.go:70] running task 2 of 16: UpdatingPrometheus
2024-06-11T11:19:44.796626703Z I0611 11:19:44.796050       1 tasks.go:70] running task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:19:44.796798812Z I0611 11:19:44.796052       1 tasks.go:70] running task 3 of 16: UpdatingAlertmanager
2024-06-11T11:19:44.796922318Z I0611 11:19:44.796057       1 tasks.go:70] running task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:19:44.797120629Z I0611 11:19:44.796058       1 tasks.go:70] running task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:19:44.797337241Z I0611 11:19:44.796064       1 tasks.go:70] running task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:19:44.797417745Z I0611 11:19:44.797398       1 tasks.go:76] ran task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:19:44.797451247Z I0611 11:19:44.796044       1 tasks.go:70] running task 4 of 16: UpdatingNodeExporter
2024-06-11T11:19:44.864511729Z I0611 11:19:44.864451       1 tasks.go:76] ran task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:19:44.888109290Z I0611 11:19:44.888051       1 tasks.go:76] ran task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:19:44.898791860Z I0611 11:19:44.898739       1 tasks.go:76] ran task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:19:44.910486985Z I0611 11:19:44.910427       1 tasks.go:76] ran task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:19:44.972507099Z I0611 11:19:44.972447       1 tasks.go:76] ran task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:19:45.884985046Z I0611 11:19:45.884911       1 tasks.go:76] ran task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:19:45.905705553Z I0611 11:19:45.905650       1 tasks.go:76] ran task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:19:45.919860809Z I0611 11:19:45.919801       1 tasks.go:76] ran task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:19:45.920724055Z I0611 11:19:45.920693       1 tasks.go:76] ran task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:19:45.942370211Z I0611 11:19:45.942295       1 tasks.go:76] ran task 4 of 16: UpdatingNodeExporter
2024-06-11T11:19:47.983881674Z I0611 11:19:47.983817       1 tasks.go:76] ran task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:19:50.950462608Z I0611 11:19:50.950386       1 tasks.go:76] ran task 8 of 16: UpdatingMetricsServer
2024-06-11T11:19:51.852844450Z I0611 11:19:51.852775       1 tasks.go:76] ran task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:19:55.998846169Z I0611 11:19:55.998786       1 tasks.go:76] ran task 3 of 16: UpdatingAlertmanager
2024-06-11T11:20:00.129512573Z I0611 11:20:00.129426       1 tasks.go:76] ran task 2 of 16: UpdatingPrometheus
2024-06-11T11:20:00.129512573Z I0611 11:20:00.129472       1 tasks.go:49] processing task group 3 of 3
2024-06-11T11:20:00.129512573Z I0611 11:20:00.129486       1 tasks.go:70] running task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:20:00.174047458Z I0611 11:20:00.173986       1 tasks.go:76] ran task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:20:00.174047458Z I0611 11:20:00.174031       1 operator.go:863] Updating ClusterOperator status to done.
2024-06-11T11:20:15.261162759Z I0611 11:20:15.261080       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-config-managed/kubelet-serving-ca
2024-06-11T11:20:15.294967272Z I0611 11:20:15.294914       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T11:20:15.298505762Z I0611 11:20:15.298448       1 tasks.go:49] processing task group 1 of 3
2024-06-11T11:20:15.298505762Z I0611 11:20:15.298480       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:20:15.298544564Z I0611 11:20:15.298515       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:20:15.310771619Z I0611 11:20:15.310720       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:20:17.863527925Z I0611 11:20:17.863398       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/alertmanager-trusted-ca-bundle
2024-06-11T11:20:17.863527925Z I0611 11:20:17.863434       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/cluster-monitoring-config
2024-06-11T11:20:18.443780045Z I0611 11:20:18.443710       1 tasks.go:76] ran task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:20:18.443780045Z I0611 11:20:18.443740       1 tasks.go:49] processing task group 2 of 3
2024-06-11T11:20:18.443780045Z I0611 11:20:18.443770       1 tasks.go:70] running task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:20:18.443852949Z I0611 11:20:18.443790       1 tasks.go:70] running task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:20:18.443852949Z I0611 11:20:18.443805       1 tasks.go:70] running task 3 of 16: UpdatingAlertmanager
2024-06-11T11:20:18.443873150Z I0611 11:20:18.443855       1 tasks.go:70] running task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:20:18.443911352Z I0611 11:20:18.443874       1 tasks.go:70] running task 2 of 16: UpdatingPrometheus
2024-06-11T11:20:18.444005257Z I0611 11:20:18.443967       1 tasks.go:70] running task 4 of 16: UpdatingNodeExporter
2024-06-11T11:20:18.444005257Z I0611 11:20:18.443983       1 tasks.go:70] running task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:20:18.444005257Z I0611 11:20:18.443983       1 tasks.go:70] running task 8 of 16: UpdatingMetricsServer
2024-06-11T11:20:18.444044059Z I0611 11:20:18.444010       1 tasks.go:70] running task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:20:18.444148664Z I0611 11:20:18.444110       1 tasks.go:70] running task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:20:18.444203767Z I0611 11:20:18.444177       1 tasks.go:70] running task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:20:18.444348375Z I0611 11:20:18.444271       1 tasks.go:70] running task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:20:18.444474682Z I0611 11:20:18.444438       1 tasks.go:70] running task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:20:18.444562787Z I0611 11:20:18.444348       1 tasks.go:70] running task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:20:18.444614589Z I0611 11:20:18.443997       1 tasks.go:76] ran task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:20:18.444628990Z I0611 11:20:18.444374       1 tasks.go:70] running task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:20:18.444727495Z I0611 11:20:18.444357       1 tasks.go:70] running task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:20:18.490160732Z I0611 11:20:18.490097       1 tasks.go:76] ran task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:20:18.491576508Z I0611 11:20:18.491522       1 tasks.go:76] ran task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:20:18.500699997Z I0611 11:20:18.500654       1 tasks.go:76] ran task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:20:18.525944951Z I0611 11:20:18.525896       1 tasks.go:76] ran task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:20:18.558719509Z I0611 11:20:18.558657       1 tasks.go:76] ran task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:20:19.505232471Z I0611 11:20:19.505161       1 tasks.go:76] ran task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:20:19.529270460Z I0611 11:20:19.529215       1 tasks.go:76] ran task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:20:19.532552236Z I0611 11:20:19.532505       1 tasks.go:76] ran task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:20:19.533450384Z I0611 11:20:19.533417       1 tasks.go:76] ran task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:20:19.553281348Z I0611 11:20:19.553227       1 tasks.go:76] ran task 4 of 16: UpdatingNodeExporter
2024-06-11T11:20:21.602994727Z I0611 11:20:21.602921       1 tasks.go:76] ran task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:20:24.586704073Z I0611 11:20:24.586635       1 tasks.go:76] ran task 8 of 16: UpdatingMetricsServer
2024-06-11T11:20:25.510327683Z I0611 11:20:25.510253       1 tasks.go:76] ran task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:20:26.050312914Z I0611 11:20:26.050228       1 operator.go:681] Triggering an update due to ConfigMap or Secret: kube-system/extension-apiserver-authentication
2024-06-11T11:20:29.195391484Z I0611 11:20:29.195276       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/federate-client-certs
2024-06-11T11:20:29.195452687Z I0611 11:20:29.195414       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/metrics-client-certs
2024-06-11T11:20:29.195487789Z I0611 11:20:29.195465       1 operator.go:681] Triggering an update due to ConfigMap or Secret: openshift-monitoring/grpc-tls
2024-06-11T11:20:29.601279940Z I0611 11:20:29.601221       1 tasks.go:76] ran task 3 of 16: UpdatingAlertmanager
2024-06-11T11:20:33.757342846Z I0611 11:20:33.757227       1 tasks.go:76] ran task 2 of 16: UpdatingPrometheus
2024-06-11T11:20:33.757342846Z I0611 11:20:33.757269       1 tasks.go:49] processing task group 3 of 3
2024-06-11T11:20:33.757342846Z I0611 11:20:33.757283       1 tasks.go:70] running task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:20:33.792043980Z I0611 11:20:33.791971       1 tasks.go:76] ran task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:20:33.792043980Z I0611 11:20:33.792022       1 operator.go:863] Updating ClusterOperator status to done.
2024-06-11T11:20:33.824175679Z I0611 11:20:33.824104       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T11:20:33.827898976Z I0611 11:20:33.827835       1 tasks.go:49] processing task group 1 of 3
2024-06-11T11:20:33.827898976Z I0611 11:20:33.827878       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:20:33.827947078Z I0611 11:20:33.827910       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:20:33.839152671Z I0611 11:20:33.839094       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:20:36.998069586Z I0611 11:20:36.998006       1 tasks.go:76] ran task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:20:36.998069586Z I0611 11:20:36.998041       1 tasks.go:49] processing task group 2 of 3
2024-06-11T11:20:36.998147790Z I0611 11:20:36.998068       1 tasks.go:70] running task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:20:36.998147790Z I0611 11:20:36.998077       1 tasks.go:70] running task 2 of 16: UpdatingPrometheus
2024-06-11T11:20:36.998147790Z I0611 11:20:36.998087       1 tasks.go:70] running task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:20:36.998147790Z I0611 11:20:36.998096       1 tasks.go:70] running task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:20:36.998169091Z I0611 11:20:36.998141       1 tasks.go:70] running task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:20:36.998225194Z I0611 11:20:36.998173       1 tasks.go:70] running task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:20:36.998343900Z I0611 11:20:36.998290       1 tasks.go:70] running task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:20:36.998410903Z I0611 11:20:36.998394       1 tasks.go:76] ran task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:20:36.998537009Z I0611 11:20:36.998072       1 tasks.go:70] running task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:20:36.998648214Z I0611 11:20:36.998619       1 tasks.go:70] running task 3 of 16: UpdatingAlertmanager
2024-06-11T11:20:36.998742919Z I0611 11:20:36.998695       1 tasks.go:70] running task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:20:36.998818623Z I0611 11:20:36.998794       1 tasks.go:70] running task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:20:36.998899126Z I0611 11:20:36.998850       1 tasks.go:70] running task 8 of 16: UpdatingMetricsServer
2024-06-11T11:20:36.999014432Z I0611 11:20:36.998786       1 tasks.go:70] running task 4 of 16: UpdatingNodeExporter
2024-06-11T11:20:36.999147939Z I0611 11:20:36.998812       1 tasks.go:70] running task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:20:36.999506156Z I0611 11:20:36.998819       1 tasks.go:70] running task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:20:36.999731867Z I0611 11:20:36.998828       1 tasks.go:70] running task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:20:37.061384641Z I0611 11:20:37.061310       1 tasks.go:76] ran task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:20:37.065172924Z I0611 11:20:37.065118       1 tasks.go:76] ran task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:20:37.098189517Z I0611 11:20:37.098117       1 tasks.go:76] ran task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:20:37.109921983Z I0611 11:20:37.109851       1 tasks.go:76] ran task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:20:37.168530311Z I0611 11:20:37.168467       1 tasks.go:76] ran task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:20:38.079882580Z I0611 11:20:38.079799       1 tasks.go:76] ran task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:20:38.096044960Z I0611 11:20:38.095985       1 tasks.go:76] ran task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:20:38.099634433Z I0611 11:20:38.099578       1 tasks.go:76] ran task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:20:38.101455121Z I0611 11:20:38.101424       1 tasks.go:76] ran task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:20:38.142012178Z I0611 11:20:38.141956       1 tasks.go:76] ran task 4 of 16: UpdatingNodeExporter
2024-06-11T11:20:40.169110079Z I0611 11:20:40.169045       1 tasks.go:76] ran task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:20:43.151577071Z I0611 11:20:43.151514       1 tasks.go:76] ran task 8 of 16: UpdatingMetricsServer
2024-06-11T11:20:44.061651949Z I0611 11:20:44.061587       1 tasks.go:76] ran task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:20:48.171060355Z I0611 11:20:48.170990       1 tasks.go:76] ran task 3 of 16: UpdatingAlertmanager
2024-06-11T11:20:52.351333927Z I0611 11:20:52.351224       1 tasks.go:76] ran task 2 of 16: UpdatingPrometheus
2024-06-11T11:20:52.351333927Z I0611 11:20:52.351268       1 tasks.go:49] processing task group 3 of 3
2024-06-11T11:20:52.351333927Z I0611 11:20:52.351279       1 tasks.go:70] running task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:20:52.390995382Z I0611 11:20:52.390915       1 tasks.go:76] ran task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:20:52.390995382Z I0611 11:20:52.390980       1 operator.go:863] Updating ClusterOperator status to done.
2024-06-11T11:27:18.467315898Z I0611 11:27:18.467234       1 operator.go:650] Triggering an update due to a change in Console.config.openshift.io/cluster
2024-06-11T11:27:18.493282159Z I0611 11:27:18.493212       1 operator.go:842] Updating ClusterOperator status to InProgress.
2024-06-11T11:27:18.507908571Z I0611 11:27:18.507849       1 tasks.go:49] processing task group 1 of 3
2024-06-11T11:27:18.507908571Z I0611 11:27:18.507878       1 tasks.go:70] running task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:27:18.507951379Z I0611 11:27:18.507906       1 tasks.go:70] running task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:27:18.519045985Z I0611 11:27:18.518994       1 tasks.go:76] ran task 1 of 2: UpdatingMetricsScrapingClientCA
2024-06-11T11:27:21.643362590Z I0611 11:27:21.643266       1 tasks.go:76] ran task 2 of 2: UpdatingPrometheusOperator
2024-06-11T11:27:21.643362590Z I0611 11:27:21.643345       1 tasks.go:49] processing task group 2 of 3
2024-06-11T11:27:21.643447104Z I0611 11:27:21.643382       1 tasks.go:70] running task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:27:21.643447104Z I0611 11:27:21.643407       1 tasks.go:70] running task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:27:21.643447104Z I0611 11:27:21.643427       1 tasks.go:70] running task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:27:21.643469608Z I0611 11:27:21.643438       1 tasks.go:70] running task 8 of 16: UpdatingMetricsServer
2024-06-11T11:27:21.643485611Z I0611 11:27:21.643459       1 tasks.go:70] running task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:27:21.643845473Z I0611 11:27:21.643793       1 tasks.go:70] running task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:27:21.644142024Z I0611 11:27:21.644098       1 tasks.go:70] running task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:27:21.644142024Z I0611 11:27:21.644124       1 tasks.go:76] ran task 7 of 16: UpdatingPrometheusAdapter
2024-06-11T11:27:21.644142024Z I0611 11:27:21.644134       1 tasks.go:70] running task 4 of 16: UpdatingNodeExporter
2024-06-11T11:27:21.644452677Z I0611 11:27:21.644397       1 tasks.go:70] running task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:27:21.644703520Z I0611 11:27:21.643415       1 tasks.go:70] running task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:27:21.644737126Z I0611 11:27:21.644699       1 tasks.go:70] running task 2 of 16: UpdatingPrometheus
2024-06-11T11:27:21.644966865Z I0611 11:27:21.644927       1 tasks.go:70] running task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:27:21.644994770Z I0611 11:27:21.644965       1 tasks.go:70] running task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:27:21.645085686Z I0611 11:27:21.645028       1 tasks.go:70] running task 3 of 16: UpdatingAlertmanager
2024-06-11T11:27:21.645085686Z I0611 11:27:21.645065       1 tasks.go:70] running task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:27:21.645163199Z I0611 11:27:21.645133       1 tasks.go:70] running task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:27:21.679455790Z I0611 11:27:21.679395       1 tasks.go:76] ran task 13 of 16: UpdatingUserWorkloadPrometheusOperator
2024-06-11T11:27:21.688074070Z I0611 11:27:21.688016       1 tasks.go:76] ran task 9 of 16: UpdatingTelemeterClient
2024-06-11T11:27:21.699117968Z I0611 11:27:21.699067       1 tasks.go:76] ran task 15 of 16: UpdatingUserWorkloadAlertmanager
2024-06-11T11:27:21.731911801Z I0611 11:27:21.731862       1 tasks.go:76] ran task 11 of 16: UpdatingControlPlaneComponents
2024-06-11T11:27:21.750137032Z I0611 11:27:21.750071       1 tasks.go:76] ran task 1 of 16: UpdatingClusterMonitoringOperatorDeps
2024-06-11T11:27:22.694110290Z I0611 11:27:22.694022       1 tasks.go:76] ran task 6 of 16: UpdatingOpenshiftStateMetrics
2024-06-11T11:27:22.728290162Z I0611 11:27:22.728225       1 tasks.go:76] ran task 5 of 16: UpdatingKubeStateMetrics
2024-06-11T11:27:22.729892837Z I0611 11:27:22.729841       1 tasks.go:76] ran task 16 of 16: UpdatingUserWorkloadThanosRuler
2024-06-11T11:27:22.738186062Z I0611 11:27:22.738130       1 tasks.go:76] ran task 14 of 16: UpdatingUserWorkloadPrometheus
2024-06-11T11:27:22.752669050Z I0611 11:27:22.752623       1 tasks.go:76] ran task 4 of 16: UpdatingNodeExporter
2024-06-11T11:27:24.816228083Z I0611 11:27:24.815686       1 tasks.go:76] ran task 10 of 16: UpdatingThanosQuerier
2024-06-11T11:27:27.766991091Z I0611 11:27:27.766927       1 tasks.go:76] ran task 8 of 16: UpdatingMetricsServer
2024-06-11T11:27:28.705394926Z I0611 11:27:28.705325       1 tasks.go:76] ran task 12 of 16: UpdatingConsolePluginComponents
2024-06-11T11:27:32.796880912Z I0611 11:27:32.796821       1 tasks.go:76] ran task 3 of 16: UpdatingAlertmanager
2024-06-11T11:27:36.991466214Z I0611 11:27:36.991387       1 tasks.go:76] ran task 2 of 16: UpdatingPrometheus
2024-06-11T11:27:36.991466214Z I0611 11:27:36.991427       1 tasks.go:49] processing task group 3 of 3
2024-06-11T11:27:36.991466214Z I0611 11:27:36.991437       1 tasks.go:70] running task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:27:37.025633024Z I0611 11:27:37.025572       1 tasks.go:76] ran task 1 of 1: UpdatingConfigurationSharing
2024-06-11T11:27:37.025633024Z I0611 11:27:37.025625       1 operator.go:863] Updating ClusterOperator status to done.
