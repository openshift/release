# This template is being used for testing OpenShift Ansible image builds for Azure.
# At the moment it cannot be reused to launch cluster for Origin tests
kind: Template
apiVersion: template.openshift.io/v1

parameters:
- name: JOB_NAME_SAFE
  required: true
- name: JOB_NAME_HASH
  required: true
- name: NAMESPACE
  required: true
- name: CLUSTER_TYPE
  value: "azure"
  required: true
- name: AZURE_VM_SIZE
  value: "Standard_D2s_v3"
  required: true
- name: OPENSHIFT_RELEASE
  value: "3.11"
  required: true
- name: IMAGE_ANSIBLE
  required: true
- name: OPENSHIFT_USE_CRIO
  value: "False"
- name: DEPLOY_OS
  value: "rhel7"
  required: true

objects:

# We want the cluster to be able to access these images
- kind: RoleBinding
  apiVersion: authorization.openshift.io/v1
  metadata:
    name: ${JOB_NAME_SAFE}-image-puller
    namespace: ${NAMESPACE}
  roleRef:
    name: system:image-puller
  subjects:
  - kind: SystemGroup
    name: system:unauthenticated

# The build pod will create an instance and install openshift
- kind: Pod
  apiVersion: v1
  metadata:
    name: ${JOB_NAME_SAFE}
    namespace: ${NAMESPACE}
    annotations:
      # we want to gather the teardown logs no matter what
      ci-operator.openshift.io/wait-for-container-artifacts: teardown
      ci-operator.openshift.io/save-container-logs: "true"
  spec:
    restartPolicy: Never
    activeDeadlineSeconds: 10800
    terminationGracePeriodSeconds: 600
    volumes:
    - name: artifacts
      emptyDir: {}
    - name: shared-tmp
      emptyDir: {}
    - name: shared-data
      emptyDir: {}
    - name: cluster-secrets-azure
      secret:
        secretName: azure
    - name: openshift-azure
      emptyDir: {}

    containers:
    - name: buildimage
      image: ${IMAGE_ANSIBLE}
      imagePullPolicy: Always
      resources:
        requests:
          cpu: 1
          memory: 300Mi
        limits:
          cpu: 3
          memory: 4Gi
      volumeMounts:
      - name: shared-tmp
        mountPath: /tmp/shared
      - name: cluster-secrets-azure
        mountPath: /usr/share/ansible/openshift-ansible/inventory/dynamic/injected
      env:
      - name: HOME
        value: /usr/share/ansible/openshift-ansible
      - name: AZURE_VM_SIZE
        value: "${AZURE_VM_SIZE}"
      - name: JOB_NAME_SAFE
        value: "${JOB_NAME_SAFE}"
      - name: JOB_NAME_HASH
        value: "${JOB_NAME_HASH}"
      - name: OPENSHIFT_RELEASE
        value: "${OPENSHIFT_RELEASE}"
      - name: TYPE
        value: azure
      - name: DEPLOY_OS
        value: "${DEPLOY_OS}"
      - name: INSTANCE_PREFIX
        value: ${NAMESPACE}-${JOB_NAME_HASH}
      - name: OPENSHIFT_USE_CRIO
        value: ${OPENSHIFT_USE_CRIO}
      command:
      - /usr/local/bin/entrypoint-provider
      args:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        # error handling and sync code
        set -euo pipefail

        # We need to persist this variable so that we can clean it up when we exit
        echo "RESOURCEGROUP_PREFIX=${INSTANCE_PREFIX}-$(TZ=Etc/UTC date +%Y%m%d%H%M)" >>/tmp/shared/environment
        # TODO: Remove me after CRI-O becomes default
        if [[ ${OPENSHIFT_USE_CRIO} = "True" ]]; then
          echo "IMAGE_NAME=${DEPLOY_OS}-$OPENSHIFT_RELEASE-crio-$(TZ=Etc/UTC date +%Y%m%d%H%M)" >>/tmp/shared/environment
        else
          echo "IMAGE_NAME=${DEPLOY_OS}-$OPENSHIFT_RELEASE-$(TZ=Etc/UTC date +%Y%m%d%H%M)" >>/tmp/shared/environment
        fi

        trap 'rc=$?; if [[ $rc -ne 0 ]]; then
          touch /tmp/shared/exit;
        fi;
        az group delete -n ${RESOURCEGROUP_PREFIX}-image-build -y --no-wait
        exit $rc' EXIT
        trap 'kill $(jobs -p); exit 0' TERM

        # Get resource group and image name
        source /tmp/shared/environment
        export AZURE_OREG_URL='registry.access.redhat.com/openshift3/ose-${component}:${version}'
        export RESOURCEGROUP=${RESOURCEGROUP_PREFIX}-image-build
        echo "RESOURCEGROUP=${RESOURCEGROUP}"
        echo "IMAGE_NAME=${IMAGE_NAME}"

        source /usr/share/ansible/openshift-ansible/inventory/dynamic/injected/secret
        az login --service-principal -u ${AZURE_CLIENT_ID} -p ${AZURE_CLIENT_SECRET} --tenant ${AZURE_TENANT_ID} &>/dev/null
        # Unfortunately az login is not enough for the node build playbook, we also
        # have to source the following variables: AZURE_TENANT and AZURE_SECRET
        # instead of AZURE_TENANT_ID and AZURE_CLIENT_SECRET which are used elsewhere.
        cp /usr/share/ansible/openshift-ansible/inventory/dynamic/injected/secret /tmp/shared/credentials
        sed -i -e "s#TENANT_ID#TENANT#" /tmp/shared/credentials
        sed -i -e "s#CLIENT_SECRET#SECRET#" /tmp/shared/credentials
        source /tmp/shared/credentials
        
        AZURE_REPO_URL="https://rpms.svc.ci.openshift.org/openshift-origin-v3.11/"

        ansible-playbook \
          -e openshift_azure_resource_group_name=$RESOURCEGROUP \
          -e openshift_azure_resource_location=eastus \
          -e openshift_azure_input_image_ns=images \
          -e openshift_azure_input_image_prefix=${DEPLOY_OS}-base \
          -e openshift_azure_output_image_ns=images \
          -e openshift_azure_output_image_name=$IMAGE_NAME \
          -e openshift_azure_storage_account=openshiftimages \
          -e openshift_azure_storage_account_ns=images \
          -e openshift_azure_container=images \
          -e openshift_azure_vm_ssh_public_key="~/.ssh/id_rsa.pub" \
          -e openshift_azure_vm_size=$AZURE_VM_SIZE \
          -e openshift_use_crio=${OPENSHIFT_USE_CRIO} \
          -e oreg_url=$AZURE_OREG_URL \
          -e @/usr/share/ansible/openshift-ansible/inventory/dynamic/injected/certs.yaml \
          -e openshift_azure_install_repo=$AZURE_REPO_URL \
          playbooks/azure/openshift-cluster/build_node_image.yml

        touch /tmp/shared/image_create

    # Runs an install
    - name: setup
      image: registry.svc.ci.openshift.org/azure/test-base:latest
      imagePullPolicy: Always
      volumeMounts:
      - name: shared-tmp
        mountPath: /tmp/shared
      - name: openshift-azure
        mountPath: /go
      - name: cluster-secrets-azure
        mountPath: /etc/azure/credentials
      env:
      - name: TYPE
        value: ${CLUSTER_TYPE}
      - name: HOME
        value: /tmp/shared/home
      - name: OPENSHIFT_RELEASE
        value: "${OPENSHIFT_RELEASE}"
      - name: DEPLOY_OS
        value: "${DEPLOY_OS}"
      - name: RUNNING_UNDER_TEST
        value: "true"
      - name: RESOURCEGROUP_TTL
        value: 4h
      command:
      - /bin/bash
      - -c
      - |
       #!/bin/bash
        set -euo pipefail

        trap 'rc=$?; if [[ $rc -ne 0 ]]; then
          touch /tmp/shared/exit;
        fi;
        cp -r /go/src/github.com/openshift/openshift-azure/_data /tmp/shared &>/dev/null
        exit $rc' EXIT
        trap 'kill $(jobs -p); exit 0' TERM

        # Cluster creation specific configuration.
        mkdir -p "${HOME}"

        # wait until the setup job creates admin.kubeconfig
        echo "Waiting for image build to complete"
        while true; do
          if [[ -f /tmp/shared/image_create ]]; then
            break
          fi
          if [[ -f  /tmp/shared/exit ]]; then
             echo "Exiting.  Found /tmp/shared/exit."
             exit 1
          fi
          sleep 15 & wait
        done
        echo "Image build complete, proceeding with e2e testing"

        # aad integration configuration - we dont test aad so populate as dummy
        source /etc/azure/credentials/secret
        export AZURE_AAD_CLIENT_ID=$AZURE_CLIENT_ID
        export AZURE_AAD_CLIENT_SECRET=$AZURE_CLIENT_SECRET

        export DNS_DOMAIN=osadev.cloud
        export DNS_RESOURCEGROUP=dns
        export DEPLOY_VERSION=v${OPENSHIFT_RELEASE}
        export IMAGE_RESOURCEGROUP=images
        source /tmp/shared/environment
        echo "Using built image $IMAGE_NAME"
        export IMAGE_RESOURCENAME=${IMAGE_NAME}
        export AZURE_REGION=eastus
        export RESOURCEGROUP=${RESOURCEGROUP_PREFIX}-e2e

        # Clone openshift-azure by ourselves since it's not supported yet by the ci-operator
        # https://github.com/openshift/ci-operator/issues/142
        mkdir -p /go/src/github.com/openshift
        cd /go/src/github.com/openshift
        git clone https://github.com/openshift/openshift-azure
        cd openshift-azure/

        # copy over geneva secrets
        mkdir -p /go/src/github.com/openshift/openshift-azure/secrets
        cp /etc/azure/credentials/logging-int.cert \
          /etc/azure/credentials/logging-int.key \
          /etc/azure/credentials/metrics-int.cert \
          /etc/azure/credentials/metrics-int.key \
          /etc/azure/credentials/.dockerconfigjson \
          /etc/azure/credentials/system-docker-config.json \
        /go/src/github.com/openshift/openshift-azure/secrets/

        make create e2e
        touch /tmp/shared/e2e_tests

    - name: tagimage
      image: ${IMAGE_ANSIBLE}
      imagePullPolicy: Always
      resources:
        requests:
          cpu: 1
          memory: 300Mi
        limits:
          cpu: 3
          memory: 4Gi
      volumeMounts:
      - name: shared-tmp
        mountPath: /tmp/shared
      - name: cluster-secrets-azure
        mountPath: /etc/azure/credentials
      env:
      - name: HOME
        value: /usr/share/ansible/openshift-ansible
      - name: TYPE
        value: azure
      command:
      - /usr/local/bin/entrypoint-provider
      args:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        # error handling and sync code
        set -euo pipefail

        trap '[ "$?" == 0 ] || touch /tmp/shared/exit' EXIT
        trap 'kill $(jobs -p); exit 0' TERM

        # wait until testing our image has succeeded
        while true; do
          if [[ -f /tmp/shared/e2e_tests ]]; then
              break
          fi
          if [[ -f  /tmp/shared/exit ]]; then
             exit 1
          fi
          sleep 15 & wait
          continue
        done
        echo "Found e2e_tests marker file."

        # Get resource group and image name
        source /tmp/shared/environment

        # Source azure creds
        source /etc/azure/credentials/secret
        az login --service-principal -u ${AZURE_CLIENT_ID} -p ${AZURE_CLIENT_SECRET} --tenant ${AZURE_TENANT_ID} &>/dev/null

        ansible-playbook \
          -e openshift_azure_input_image_ns=images \
          -e openshift_azure_input_image_name=$IMAGE_NAME \
          playbooks/azure/openshift-cluster/tag_image_as_valid.yml

        touch /tmp/shared/exit

    # Performs cleanup of all created resources
    - name: teardown
      image: registry.svc.ci.openshift.org/azure/test-base:latest
      imagePullPolicy: Always
      volumeMounts:
      - name: artifacts
        mountPath: /tmp/artifacts
      - name: shared-tmp
        mountPath: /tmp/shared
      - name: openshift-azure
        mountPath: /go
      - name: cluster-secrets-azure
        mountPath: /etc/azure/credentials
      env:
      - name: TYPE
        value: ${CLUSTER_TYPE}
      - name: HOME
        value: /tmp/shared/home
      command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        function teardown() {
          set +e
          mkdir -p "${HOME}"
          export HOME=/tmp/shared
          export DNS_DOMAIN=osadev.cloud
          export DNS_RESOURCEGROUP=dns
          export KUBECONFIG=/tmp/shared/_data/_out/admin.kubeconfig

          cp -r /tmp/shared/_data /go/src/github.com/openshift/openshift-azure/
          cd /go/src/github.com/openshift/openshift-azure/
          source /etc/azure/credentials/secret
          az login --service-principal -u ${AZURE_CLIENT_ID} -p ${AZURE_CLIENT_SECRET} --tenant ${AZURE_TENANT_ID} &>/dev/null

          # Gather artifacts
          oc get po --all-namespaces -o wide > /tmp/artifacts/pods
          oc get no -o wide > /tmp/artifacts/nodes
          oc get events --all-namespaces > /tmp/artifacts/events
          oc logs sync-master-000000 -n kube-system > /tmp/artifacts/sync.log
          oc logs master-api-master-000000 -n kube-system > /tmp/artifacts/api-master-000000.log
          oc logs master-api-master-000001 -n kube-system > /tmp/artifacts/api-master-000001.log
          oc logs master-api-master-000002 -n kube-system > /tmp/artifacts/api-master-000002.log
          oc logs master-etcd-master-000000 -n kube-system > /tmp/artifacts/etcd-master-000000.log
          oc logs master-etcd-master-000001 -n kube-system > /tmp/artifacts/etcd-master-000001.log
          oc logs master-etcd-master-000002 -n kube-system > /tmp/artifacts/etcd-master-000002.log
          cm_leader=$(oc get cm -n kube-system kube-controller-manager -o yaml | grep -o 00000[0-3])
          oc logs controllers-master-$cm_leader -n kube-system > /tmp/artifacts/controller-manager.log
          # get leader journald logs
          ./hack/ssh.sh -c "sudo journalctl --since '1 hour ago'" -n ${cm_leader: -1} ${INSTANCE_PREFIX} &> /tmp/artifacts/journald.log
        }

        trap 'teardown' EXIT
        trap 'kill $(jobs -p); exit 0' TERM

        for i in `seq 1 120`; do
          if [[ -f /tmp/shared/exit ]]; then
            exit 0
          fi
          sleep 60 & wait
        done
