kind: Template
apiVersion: template.openshift.io/v1

parameters:
# Bushslicer-specific variables
- name: BUSHSLICER_TEST_CONFIG
- name: BUSHSLICER_TEST_ENVIRONMENT
- name: BUSHSLICER_TEST_FORMAT
- name: BUSHSLICER_TEST_RESULTS
- name: BUSHSLICER_USER
- name: BUSHSLICER_USER_PW_STRING
# OSA cluster version that is going to be deployed.
- name: DEPLOY_VERSION
  value: "v3.11"
  required: true
# DNS domain that is going to be used by the cluster.
# Needs to be a DNS zone created in Azure.
- name: DNS_DOMAIN
  value: osadev.cloud
  required: true
# Resource group of the DNS zone.
- name: DNS_RESOURCEGROUP
  value: dns
  required: true
# ci-operator specific variables
- name: JOB_NAME_SAFE
  required: true
# OSA-specific images
- name: IMAGE_AZURE
- name: IMAGE_AZURE_CONTROLLERS
- name: IMAGE_CANARY
- name: IMAGE_ETCDBACKUP
- name: IMAGE_METRICSBRIDGE
- name: IMAGE_SYNC
- name: IMAGE_STARTUP
- name: IMAGE_TLSPROXY
# The binary image built by ci-operator
- name: LOCAL_IMAGE_BIN
  required: true
# Temporary namespace created by ci-operator to run the template.
- name: NAMESPACE
  required: true
# Configure whether the test needs to wait for cluster deletion to complete.
# Most tests shouldn't care about it, useful for tests using the production OSA
# to measure cluster deletion times.
- name: NO_WAIT
  value: "true"
# Each test gets its own unique resource group for a couple of different reasons
# See https://github.com/openshift/openshift-azure/issues/651 for more info.
- name: RESOURCEGROUP_SUFFIX
  generate: expression
  from: "[a-z]{8}"
# OSA deployments can be configured to run under testing (control plane loglevel
# is higher, htpasswd access is enabled for e2e tests, etc.).
- name: RUNNING_UNDER_TEST
  value: "true"
# Test command to run.
- name: TEST_COMMAND
  value: "make e2e"
  required: true
# The image used by tests needs to be configurable to enable different types
# of tests to reuse the same template. So far we have:
# 1. OSA-specific tests
# 2. Origin conformance suite
# 3. Bushslicer
- name: TEST_IMAGE
  value: "registry.svc.ci.openshift.org/azure/test-base:latest"
# If set to "true", it means the production OSA RP is going to be used.
- name: TEST_IN_PRODUCTION

objects:

# We want the cluster to be able to access these images
- kind: RoleBinding
  apiVersion: authorization.openshift.io/v1
  metadata:
    name: ${JOB_NAME_SAFE}-image-puller
    namespace: ${NAMESPACE}
  roleRef:
    name: system:image-puller
  subjects:
  - kind: SystemGroup
    name: system:unauthenticated

- kind: RoleBinding
  apiVersion: authorization.openshift.io/v1
  metadata:
    name: ${JOB_NAME_SAFE}-view
    namespace: ${NAMESPACE}
  roleRef:
    name: view
  subjects:
  - kind: Group
    name: azure-team

- kind: Pod
  apiVersion: v1
  metadata:
    name: ${JOB_NAME_SAFE}
    namespace: ${NAMESPACE}
    annotations:
      # we want to gather the teardown logs no matter what
      ci-operator.openshift.io/wait-for-container-artifacts: teardown,test
      ci-operator.openshift.io/save-container-logs: "true"
  spec:
    restartPolicy: Never
    activeDeadlineSeconds: 14400
    terminationGracePeriodSeconds: 600
    volumes:
    - name: artifacts
      emptyDir: {}
    - name: cluster-secrets-azure
      secret:
        secretName: azure
    - name: shared-tmp
      emptyDir: {}

    containers:

    - name: test
      image: ${TEST_IMAGE}
      terminationMessagePolicy: FallbackToLogsOnError
      imagePullPolicy: Always
      volumeMounts:
      - name: artifacts
        mountPath: /tmp/artifacts
      - name: cluster-secrets-azure
        mountPath: /etc/azure/credentials
      - name: shared-tmp
        mountPath: /tmp/shared
      env:
      - name: ARTIFACT_DIR
        value: /tmp/artifacts
      - name: BUSHSLICER_TEST_CONFIG
        value: ${BUSHSLICER_TEST_CONFIG}
      - name: BUSHSLICER_TEST_ENVIRONMENT
        value: ${BUSHSLICER_TEST_ENVIRONMENT}
      - name: BUSHSLICER_TEST_FORMAT
        value: ${BUSHSLICER_TEST_FORMAT}
      - name: BUSHSLICER_TEST_RESULTS
        value: ${BUSHSLICER_TEST_RESULTS}
      - name: BUSHSLICER_USER
        value: ${BUSHSLICER_USER}
      - name: BUSHSLICER_USER_PW_STRING
        value: ${BUSHSLICER_USER_PW_STRING}
      - name: DEPLOY_VERSION
        value: ${DEPLOY_VERSION}
      - name: DNS_DOMAIN
        value: ${DNS_DOMAIN}
      - name: DNS_RESOURCEGROUP
        value: ${DNS_RESOURCEGROUP}
      - name: RESOURCEGROUP
        value: e2e-${RESOURCEGROUP_SUFFIX}
      - name: RUNNING_UNDER_TEST
        value: ${RUNNING_UNDER_TEST}
      - name: TEST_IN_PRODUCTION
        value: ${TEST_IN_PRODUCTION}
      command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash
        # error handling and sync code
        set -euo pipefail

        trap 'touch /tmp/shared/exit' EXIT
        trap 'kill $(jobs -p); exit 0' TERM

        # wait until the setup job completes successfully
        while true; do
          # exit if teardown is in progress
          if [[ -f  /tmp/shared/exit ]]; then
             exit 1
          fi
          if [[ ! -f  /tmp/shared/created ]]; then
            sleep 15 & wait
            continue
          fi
          break
        done
        echo "Cluster created, starting tests"

        source /etc/azure/credentials/secret

        # origin conformance specific code
        PATH=/usr/libexec/origin:$PATH
        function run-tests() {
          if which openshift-tests && [[ -n "${TEST_SUITE-}" ]]; then
            openshift-tests run "${TEST_SUITE}" --provider "${TEST_PROVIDER:-}" -o /tmp/artifacts/e2e.log --junit-dir /tmp/artifacts/junit
            exit 0
          fi
          # TODO: remove everything after this point once we fork templates by release - starting with 4.0
          if ! which extended.test; then
            echo "must provide TEST_SUITE variable"
            exit 1
          fi
          if [[ -n "${TEST_FOCUS:-}" ]]; then
            ginkgo -v -noColor -nodes="${TEST_PARALLELISM:-30}" $( which extended.test ) -- \
              -ginkgo.focus="${TEST_FOCUS}" -ginkgo.skip="${TEST_SKIP:-"\\[local\\]"}" \
              -e2e-output-dir /tmp/artifacts -report-dir /tmp/artifacts/junit \
              -test.timeout=2h ${PROVIDER_ARGS-} || rc=$?
          fi
          if [[ -n "${TEST_FOCUS_SERIAL:-}" ]]; then
            ginkgo -v -noColor -nodes=1 $( which extended.test ) -- \
              -ginkgo.focus="${TEST_FOCUS_SERIAL}" -ginkgo.skip="${TEST_SKIP_SERIAL:-"\\[local\\]"}" \
              -e2e-output-dir /tmp/artifacts -report-dir /tmp/artifacts/junit/serial \
              -test.timeout=2h ${PROVIDER_ARGS-} || rc=$?
          fi
          exit ${rc:-0}
        }

        # bushslicer specific code
        if [[ "${TEST_IMAGE}" =~ "bushslicer" ]]; then
          export BUSHSLICER_TEST_CLUSTER=$(awk '/^  fqdn:/{ print $2}' /tmp/shared/openshift-azure/_data/containerservice.yaml)
          PASSWD=$(awk "/${BUSHSLICER_USER_PW_STRING}:/{ print \$2 }" /tmp/shared/openshift-azure/_data/containerservice.yaml)
          oc login -u "${BUSHSLICER_USER}" -p "${PASSWD}" --server=https://${BUSHSLICER_TEST_CLUSTER} --insecure-skip-tls-verify=true
          export BUSHSLICER_TEST_TOKEN=$(oc whoami -t)
        elif [[ "${TEST_IMAGE}" =~ "origin-v3.11:tests" ]]; then
          export KUBECONFIG=/tmp/shared/openshift-azure/_data/_out/admin.kubeconfig
        else
          mkdir -p /go/src/github.com/openshift/
          cp -r /tmp/shared/openshift-azure /go/src/github.com/openshift/
          cd /go/src/github.com/openshift/openshift-azure/
        fi
        ${TEST_COMMAND}

    # Runs an install
    - name: setup
      image: ${LOCAL_IMAGE_BIN}
      terminationMessagePolicy: FallbackToLogsOnError
      imagePullPolicy: Always
      volumeMounts:
      - name: shared-tmp
        mountPath: /tmp/shared
      - name: cluster-secrets-azure
        mountPath: /etc/azure/credentials
      env:
      - name: AZURE_IMAGE
        value: ${IMAGE_AZURE}
      - name: AZURE_CONTROLLERS_IMAGE
        value: ${IMAGE_AZURE_CONTROLLERS}
      - name: DEPLOY_VERSION
        value: ${DEPLOY_VERSION}
      - name: DNS_DOMAIN
        value: ${DNS_DOMAIN}
      - name: DNS_RESOURCEGROUP
        value: ${DNS_RESOURCEGROUP}
      - name: ETCDBACKUP_IMAGE
        value: ${IMAGE_ETCDBACKUP}
      - name: HOME
        value: /tmp/shared/home
      - name: METRICSBRIDGE_IMAGE
        value: ${IMAGE_METRICSBRIDGE}
      - name: RESOURCEGROUP
        value: e2e-${RESOURCEGROUP_SUFFIX}
      - name: RESOURCEGROUP_TTL
        value: 4h
      - name: RUNNING_UNDER_TEST
        value: ${RUNNING_UNDER_TEST}
      - name: SYNC_IMAGE
        value: ${IMAGE_SYNC}
      - name: STARTUP_IMAGE
        value: ${IMAGE_STARTUP}
      - name: TEST_IN_PRODUCTION
        value: ${TEST_IN_PRODUCTION}
      - name: TLSPROXY_IMAGE
        value: ${IMAGE_TLSPROXY}
      - name: CANARY_IMAGE
        value: ${IMAGE_CANARY}
      - name: ARTIFACT_DIR
        value: /tmp/artifacts
      command:
      - /bin/bash
      - -c
      - |
       #!/bin/bash
        set -euo pipefail

        # skip setting up the fake rp in case we are testing in production
        if [[ -n $TEST_IN_PRODUCTION ]]; then
            cp -r /go/src/github.com/openshift/openshift-azure /tmp/shared
            touch /tmp/shared/created
            exit 0
        fi

        trap 'rc=$?; if [[ $rc -ne 0 ]]; then
          cp -r /go/src/github.com/openshift/openshift-azure /tmp/shared
          touch /tmp/shared/exit
        fi
        exit $rc' EXIT
        trap 'kill $(jobs -p); exit 0' TERM

        # aad integration configuration - we dont test aad so populate as dummy
        source /etc/azure/credentials/secret
        export AZURE_AAD_CLIENT_ID=$AZURE_CLIENT_ID
        export AZURE_AAD_CLIENT_SECRET=$AZURE_CLIENT_SECRET
        export AZURE_AAD_GROUP_ADMINS_ID=$AZURE_AAD_GROUP_ADMINS_ID

        if [[ -n "$AZURE_IMAGE" ]]; then
          export SYNC_IMAGE="$AZURE_IMAGE"
          export STARTUP_IMAGE="$AZURE_IMAGE"
          export ETCDBACKUP_IMAGE="$AZURE_IMAGE"
          export AZURE_CONTROLLERS_IMAGE="$AZURE_IMAGE"
          export METRICSBRIDGE_IMAGE="$AZURE_IMAGE"
          export TLSPROXY_IMAGE="$AZURE_IMAGE"
          export CANARY_IMAGE="$AZURE_IMAGE"
        fi

        echo "Using sync image ${SYNC_IMAGE}"
        echo "Using startup image ${STARTUP_IMAGE}"
        echo "Using etcdbackup image ${ETCDBACKUP_IMAGE}"
        echo "Using azure-controllers image ${AZURE_CONTROLLERS_IMAGE}"
        echo "Using metricsbridge image ${METRICSBRIDGE_IMAGE}"
        echo "Using tlsproxy image ${TLSPROXY_IMAGE}"
        echo "Using canary image ${CANARY_IMAGE}"

        # copy over geneva secrets
        cd /go/src/github.com/openshift/openshift-azure/
        mkdir -p /go/src/github.com/openshift/openshift-azure/secrets
        cp /etc/azure/credentials/logging-int.cert \
          /etc/azure/credentials/logging-int.key \
          /etc/azure/credentials/metrics-int.cert \
          /etc/azure/credentials/metrics-int.key \
          /etc/azure/credentials/.dockerconfigjson \
          /etc/azure/credentials/system-docker-config.json \
        /go/src/github.com/openshift/openshift-azure/secrets/

        # start cluster
        make create

        # delete sync deployment to disable sync pod
        if [[ "${TEST_IMAGE}" =~ "origin-v3.11:tests" ]]; then
          KUBECONFIG=/tmp/shared/openshift-azure/_data/_out/admin.kubeconfig oc --namespace=kube-system delete deployment sync
        fi

        # Share openshift-azure code with the test container since
        # the test container will not include it because we have made
        # the test image configurable for origin-tests or bushslicer
        # and instead of LOCAL_IMAGE_BIN we can only use the azure test-base
        # for openshift-azure tests.
        cp -r /go/src/github.com/openshift/openshift-azure /tmp/shared

        # notify other containers that the cluster was created
        touch /tmp/shared/created
        true

    # Performs cleanup of all created resources
    - name: teardown
      image: ${LOCAL_IMAGE_BIN}
      terminationMessagePolicy: FallbackToLogsOnError
      imagePullPolicy: Always
      volumeMounts:
      - name: artifacts
        mountPath: /tmp/artifacts
      - name: cluster-secrets-azure
        mountPath: /etc/azure/credentials
      - name: shared-tmp
        mountPath: /tmp/shared
      env:
      - name: DNS_DOMAIN
        value: ${DNS_DOMAIN}
      - name: DNS_RESOURCEGROUP
        value: ${DNS_RESOURCEGROUP}
      - name: NO_WAIT
        value: ${NO_WAIT}
      - name: RESOURCEGROUP
        value: e2e-${RESOURCEGROUP_SUFFIX}
      - name: TEST_IN_PRODUCTION
        value: ${TEST_IN_PRODUCTION}
      command:
      - /bin/bash
      - -c
      - |
        #!/bin/bash

        # teardown is collecting debug data and deleting all used resources
        function teardown() {
          # Gather artifacts
          if [[ -z "$TEST_IN_PRODUCTION" ]]; then
            export KUBECONFIG=/tmp/shared/openshift-azure/_data/_out/admin.kubeconfig
            oc get po --all-namespaces -o wide > /tmp/artifacts/pods
            oc get deployments --all-namespaces -o wide > /tmp/artifacts/deployments
            oc get statefulsets --all-namespaces -o wide > /tmp/artifacts/statefulsets
            oc get daemonsets --all-namespaces -o wide > /tmp/artifacts/daemonsets
            oc get no -o wide > /tmp/artifacts/nodes
            oc get events --all-namespaces > /tmp/artifacts/events
            oc logs sync-master-000000 -n kube-system > /tmp/artifacts/sync.log
            oc logs master-api-master-000000 -n kube-system > /tmp/artifacts/api-master-000000.log
            oc logs master-api-master-000001 -n kube-system > /tmp/artifacts/api-master-000001.log
            oc logs master-api-master-000002 -n kube-system > /tmp/artifacts/api-master-000002.log
            oc logs master-etcd-master-000000 -n kube-system > /tmp/artifacts/etcd-master-000000.log
            oc logs master-etcd-master-000001 -n kube-system > /tmp/artifacts/etcd-master-000001.log
            oc logs master-etcd-master-000002 -n kube-system > /tmp/artifacts/etcd-master-000002.log
            cm_leader=$(oc get cm -n kube-system kube-controller-manager -o yaml | grep -o 00000[0-3])
            oc logs controllers-master-$cm_leader -n kube-system > /tmp/artifacts/controller-manager.log
            oc logs deploy/prometheus-operator -n openshift-monitoring > /tmp/artifacts/prometheus-operator.log
            oc exec -n openshift-monitoring -it $(oc get po -n openshift-monitoring -l k8s-app=prometheus-operator --no-headers | awk '{print $1}') wget -- -O - localhost:8080/debug/pprof/goroutine?debug=2 >  /tmp/artifacts/prometheus-operator-pprof-goroutine
            oc logs deploy/cluster-monitoring-operator -n openshift-monitoring > /tmp/artifacts/cluster-monitoring-operator.log
          fi

          cp -r /tmp/shared/openshift-azure/_data /go/src/github.com/openshift/openshift-azure/
          cd /go/src/github.com/openshift/openshift-azure/
          mkdir -p /go/src/github.com/openshift/openshift-azure/secrets
          source /etc/azure/credentials/secret

          cp /etc/azure/credentials/logging-int.cert \
            /etc/azure/credentials/logging-int.key \
            /etc/azure/credentials/metrics-int.cert \
            /etc/azure/credentials/metrics-int.key \
            /etc/azure/credentials/.dockerconfigjson \
            /etc/azure/credentials/system-docker-config.json \
          /go/src/github.com/openshift/openshift-azure/secrets/
          make delete
        }

        trap 'teardown' EXIT
        trap 'kill $(jobs -p); exit 0' TERM

        # teardown is triggered on file marker
        for i in `seq 1 1440`; do
          if [[ -f /tmp/shared/exit ]]; then
            exit 0
          fi
          sleep 5 & wait
        done
