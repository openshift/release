ref:
  as: baremetalds-e2e-test
  from: tests
  grace_period: 10m
  commands: baremetalds-e2e-test-commands.sh
  timeout: 10800s
  resources:
    requests:
      cpu: "3"
      memory: 600Mi
    limits:
      memory: 2Gi
  env:
  - name: RUN_UPGRADE_TEST
    default: "false"
    documentation: Not used anymore. It is necessary to remove its definition from all the jobs before removing it from this step
  - name: TEST_TYPE
    default: "suite"
    documentation: |
      The type of test to perform.
      * 'suite' - Run the test suite defined by TEST_SUITE. By default this executes the
                  OpenShift parallel conformance suite. All product components must run the
                  default suite on pull requests prior to merge.
      * 'suite-conformance' - Runs the test suite defined by TEST_SUITE, then runs the product conformance
                  suite to verify the cluster is still functional. This is typically used for testing
                  disruption from one suite, then confirming that the disruption did not degrade the
                  product.
      * 'upgrade' - Perform an upgrade to the image defined by OPENSHIFT_UPGRADE_RELEASE_IMAGE_OVERRIDE.
                  The TEST_UPGRADE_OPTIONS flag may be optionally set. All product components
                  must run the default upgrade test (verify an upgrade completes) on pull requests
                  prior to merge.
      * 'upgrade-conformance' - Performs the 'upgrade' test and then executes the full conformance
                  suite after upgrade completes. Does not honor TEST_SUITE but will respect
                  TEST_UPGRADE_OPTIONS. All product releases must pass the conformance suite after
                  an upgrade completes or have explicit logic in their test to tolerate behavior after
                  upgrade.
  - name: TEST_SUITE
    default: openshift/conformance/parallel
    documentation: The test suite to run.  Use 'openshift-test run --help' to list available suites.
  - name: TEST_SKIPS
    default: |-
      \[Conformance\]\[sig-api-machinery\]\[Feature:APIServer\] local kubeconfig .* should be present on all masters and work
      \[k8s.io\] Container Runtime blackbox test when running a container with a new image should be able to pull from private registry with secret
      \[k8s.io\] \[sig-node\] Pods Extended \[k8s.io\] Pod Container Status should never report success for a pending container
      \[sig-api-machinery\] API priority and fairness should ensure that requests can be classified by testing flow-schemas/priority-levels
      \[sig-api-machinery\] CustomResourcePublishOpenAPI \[Privileged:ClusterAdmin\] works for CRD with validation schema
      \[sig-api-machinery\]\[Feature:APIServer\]\[Late\] kube-apiserver terminates within graceful termination period
      \[sig-api-machinery\]\[Feature:APIServer\]\[Late\] kubelet terminates kube-apiserver gracefully
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs  should adhere to Three Laws of Controllers
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs adoption will orphan all RCs and adopt them back when recreated
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs generation should deploy based on a status version bump
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs keep the deployer pod invariant valid should deal with cancellation after deployer pod succeeded
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs paused should disable actions on deployments
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs rolled back should rollback to an older deployment
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs should respect image stream tag reference policy resolve the image pull spec
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs viewing rollout history should print the rollout history
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs when changing image change trigger should successfully trigger from an updated image
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs when run iteratively should only deploy the last deployment
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs when tagging images should successfully tag the deployed image
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs with custom deployments should run the custom deployment steps
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs with enhanced status should include various info in status
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs with env in params referencing the configmap should expand the config map key to a value
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs with failing hook should get all logs from retried hooks
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs with minimum ready seconds set should not transition the deployment to Complete before satisfied
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs with multiple image change triggers should run a successful deployment with a trigger used by different containers
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs with multiple image change triggers should run a successful deployment with multiple triggers
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs with revision history limits should never persist more old deployments than acceptable after being observed by the controller
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs with test deployments should run a deployment to completion and then scale to zero
      \[sig-apps\]\[Feature:DeploymentConfig\] deploymentconfigs won't deploy RC with unresolved images when patched with empty image
      \[sig-apps\]\[Feature:Jobs\] Users should be able to create and run a job in a user project
      \[sig-arch\] Managed cluster should ensure control plane pods do not run in best-effort QoS
      \[sig-arch\] Managed cluster should have no crashlooping pods in core namespaces over four minutes
      \[sig-arch\] Managed cluster should only include cluster daemonsets that have maxUnavailable update of 10 or 33 percent
      \[sig-arch\]\[Early\] Managed cluster should start all core operators
      \[sig-auth\] \[Feature:NodeAuthenticator\] The kubelet can delegate ServiceAccount tokens to the API server
      \[sig-auth\] \[Feature:NodeAuthenticator\] The kubelet's main port 10250 should reject requests with no credentials
      \[sig-auth\]\[Feature:HTPasswdAuth\] HTPasswd IDP should successfully configure htpasswd and be responsive
      \[sig-auth\]\[Feature:LDAP\] LDAP IDP should authenticate against an ldap server
      \[sig-auth\]\[Feature:OAuthServer\] \[Headers\] expected headers returned from the authorize URL
      \[sig-auth\]\[Feature:OAuthServer\] \[Headers\] expected headers returned from the grant URL
      \[sig-auth\]\[Feature:OAuthServer\] \[Headers\] expected headers returned from the login URL for the allow all IDP
      \[sig-auth\]\[Feature:OAuthServer\] \[Headers\] expected headers returned from the login URL for the bootstrap IDP
      \[sig-auth\]\[Feature:OAuthServer\] \[Headers\] expected headers returned from the login URL for when there is only one IDP
      \[sig-auth\]\[Feature:OAuthServer\] \[Headers\] expected headers returned from the logout URL
      \[sig-auth\]\[Feature:OAuthServer\] \[Headers\] expected headers returned from the root URL
      \[sig-auth\]\[Feature:OAuthServer\] \[Headers\] expected headers returned from the token URL
      \[sig-auth\]\[Feature:OAuthServer\] \[Headers\] expected headers returned from the token request URL
      \[sig-auth\]\[Feature:OAuthServer\] \[Token Expiration\] Using a OAuth client with a non-default token max age to generate tokens that do not expire works as expected when using a code authorization flow
      \[sig-auth\]\[Feature:OAuthServer\] \[Token Expiration\] Using a OAuth client with a non-default token max age to generate tokens that do not expire works as expected when using a token authorization flow
      \[sig-auth\]\[Feature:OAuthServer\] \[Token Expiration\] Using a OAuth client with a non-default token max age to generate tokens that expire shortly works as expected when using a code authorization flow
      \[sig-auth\]\[Feature:OAuthServer\] \[Token Expiration\] Using a OAuth client with a non-default token max age to generate tokens that expire shortly works as expected when using a token authorization flow
      \[sig-auth\]\[Feature:SCC\]\[Early\] should not have pod creation failures during install
      \[sig-auth\]\[Feature:SecurityContextConstraints\]  TestPodDefaultCapabilities
      \[sig-builds\]\[Feature:Builds\] Multi-stage image builds should succeed
      \[sig-builds\]\[Feature:Builds\] Optimized image builds  should succeed
      \[sig-builds\]\[Feature:Builds\] build can reference a cluster service  with a build being created from new-build should be able to run a build that references a cluster service
      \[sig-builds\]\[Feature:Builds\] build have source revision metadata  started build should contain source revision information
      \[sig-builds\]\[Feature:Builds\] build with empty source  started build should build even with an empty source in build config
      \[sig-builds\]\[Feature:Builds\] build without output image  building from templates should create an image from a S2i template without an output image reference defined
      \[sig-builds\]\[Feature:Builds\] build without output image  building from templates should create an image from a docker template without an output image reference defined
      \[sig-builds\]\[Feature:Builds\] clone repository using git:// protocol  should clone using git:// if no proxy is configured
      \[sig-builds\]\[Feature:Builds\] custom build with buildah  being created from new-build should complete build with custom builder image
      \[sig-builds\]\[Feature:Builds\] imagechangetriggers  imagechangetriggers should trigger builds of all types
      \[sig-builds\]\[Feature:Builds\] oc new-app  should fail with a --name longer than 58 characters
      \[sig-builds\]\[Feature:Builds\] oc new-app  should succeed with a --name of 58 characters
      \[sig-builds\]\[Feature:Builds\] oc new-app  should succeed with an imagestream
      \[sig-builds\]\[Feature:Builds\] prune builds based on settings in the buildconfig  buildconfigs should have a default history limit set when created via the group api
      \[sig-builds\]\[Feature:Builds\] prune builds based on settings in the buildconfig  should prune builds after a buildConfig change
      \[sig-builds\]\[Feature:Builds\] prune builds based on settings in the buildconfig  should prune canceled builds based on the failedBuildsHistoryLimit setting
      \[sig-builds\]\[Feature:Builds\] prune builds based on settings in the buildconfig  should prune completed builds based on the successfulBuildsHistoryLimit setting
      \[sig-builds\]\[Feature:Builds\] prune builds based on settings in the buildconfig  should prune errored builds based on the failedBuildsHistoryLimit setting
      \[sig-builds\]\[Feature:Builds\] prune builds based on settings in the buildconfig  should prune failed builds based on the failedBuildsHistoryLimit setting
      \[sig-builds\]\[Feature:Builds\] result image should have proper labels set  Docker build from a template should create a image from .* template with proper Docker labels
      \[sig-builds\]\[Feature:Builds\] result image should have proper labels set  S2I build from a template should create a image from .* template with proper Docker labels
      \[sig-builds\]\[Feature:Builds\] s2i build with a quota  Building from a template should create an s2i build with a quota and run it
      \[sig-builds\]\[Feature:Builds\] s2i build with a root user image should create a root build and pass with a privileged SCC
      \[sig-builds\]\[Feature:Builds\] verify /run filesystem contents  are writeable using a simple Docker Strategy Build
      \[sig-builds\]\[Feature:Builds\] verify /run filesystem contents  do not have unexpected content using a simple Docker Strategy Build
      \[sig-builds\]\[Feature:Builds\]\[pullsecret\] docker build using a pull secret  Building from a template should create a docker build that pulls using a secret run it
      \[sig-builds\]\[Feature:Builds\]\[timing\] capture build stages and durations  should record build stages and durations for docker
      \[sig-builds\]\[Feature:Builds\]\[timing\] capture build stages and durations  should record build stages and durations for s2i
      \[sig-builds\]\[Feature:Builds\]\[valueFrom\] process valueFrom in build strategy environment variables  should fail resolving unresolvable valueFrom in docker build environment variable references
      \[sig-builds\]\[Feature:Builds\]\[valueFrom\] process valueFrom in build strategy environment variables  should fail resolving unresolvable valueFrom in sti build environment variable references
      \[sig-builds\]\[Feature:Builds\]\[valueFrom\] process valueFrom in build strategy environment variables  should successfully resolve valueFrom in docker build environment variables
      \[sig-builds\]\[Feature:Builds\]\[valueFrom\] process valueFrom in build strategy environment variables  should successfully resolve valueFrom in s2i build environment variables
      \[sig-cli\] CLI can run inside of a busybox container
      \[sig-cli\] oc adm must-gather runs successfully
      \[sig-cli\] oc adm must-gather runs successfully for audit logs
      \[sig-cli\] oc adm must-gather runs successfully with options
      \[sig-cli\] oc debug deployment configs from a build
      \[sig-cli\] oc debug does not require a real resource on the server
      \[sig-cli\] oc debug ensure it works with image streams
      \[sig-cli\] oc explain should contain proper fields description for special types
      \[sig-cli\] oc explain should contain proper spec+status for CRDs
      \[sig-cli\] oc observe works as expected
      \[sig-cli\] oc rsh rsh specific flags should work well when access to a remote shell
      \[sig-cli\] oc rsh specific flags should work well when access to a remote shell
      \[sig-cluster-lifecycle\] Pods cannot access the /config/master API endpoint
      \[sig-devex\] check registry.redhat.io is available and samples operator can import sample imagestreams run sample related validations
      \[sig-devex\]\[Feature:Templates\] templateinstance readiness test  should report failed soon after an annotated objects has failed
      \[sig-devex\]\[Feature:Templates\] templateinstance readiness test  should report ready soon after all annotated objects are ready
      \[sig-imageregistry\]\[Feature:ImageAppend\] Image append should create images by appending them
      \[sig-imageregistry\]\[Feature:ImageExtract\] Image extract should extract content from an image
      \[sig-imageregistry\]\[Feature:ImageInfo\] Image info should display information about images
      \[sig-imageregistry\]\[Feature:ImageLayers\] Image layer subresource should return layers from tagged images
      \[sig-imageregistry\]\[Feature:ImageLookup\] Image policy should perform lookup when the Deployment gets the resolve-names annotation later
      \[sig-imageregistry\]\[Feature:ImageLookup\] Image policy should perform lookup when the object has the resolve-names annotation
      \[sig-imageregistry\]\[Feature:ImageLookup\] Image policy should update standard Kube object image fields when local names are on
      \[sig-imageregistry\]\[Feature:ImageTriggers\] Annotation trigger reconciles after the image is overwritten
      \[sig-imageregistry\]\[Feature:Image\] oc tag should change image reference for internal images
      \[sig-imageregistry\]\[Feature:Image\] oc tag should preserve image reference for external images
      \[sig-imageregistry\]\[Feature:Image\] oc tag should work when only imagestreams api is available
      \[sig-instrumentation\] Prometheus when installed on the cluster should have a AlertmanagerReceiversNotConfigured alert in firing state
      \[sig-instrumentation\] Prometheus when installed on the cluster should have important platform topology metrics
      \[sig-instrumentation\] Prometheus when installed on the cluster should have non-Pod host cAdvisor metrics
      \[sig-instrumentation\] Prometheus when installed on the cluster should provide ingress metrics
      \[sig-instrumentation\] Prometheus when installed on the cluster should provide named network metrics
      \[sig-instrumentation\] Prometheus when installed on the cluster should start and expose a secured proxy and unsecured metrics
      \[sig-instrumentation\] Prometheus when installed on the cluster shouldn't have failing rules evaluation
      \[sig-instrumentation\] Prometheus when installed on the cluster shouldn't report any alerts in firing state apart from Watchdog and AlertmanagerReceiversNotConfigured
      \[sig-instrumentation\]\[Late\] Alerts should have a Watchdog alert in firing state the entire cluster run
      \[sig-instrumentation\]\[Late\] Alerts shouldn't report any alerts in firing state apart from Watchdog and AlertmanagerReceiversNotConfigured
      \[sig-instrumentation\]\[Late\] Alerts shouldn't report any alerts in firing or pending state apart from Watchdog and AlertmanagerReceiversNotConfigured and have no gaps in Watchdog firing
      \[sig-instrumentation\]\[sig-builds\]\[Feature:Builds\] Prometheus when installed on the cluster should start and expose a secured proxy and verify build metrics
      \[sig-network-edge\]\[Conformance\]\[Area:Networking\]\[Feature:Router\] The HAProxy router should be able to connect to a service that is idled because a GET on the route will unidle it
      \[sig-network\] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service
      \[sig-network\] Conntrack should be able to preserve UDP traffic when server pod cycles for a NodePort service
      \[sig-network\] DNS should provide /etc/hosts entries for the cluster
      \[sig-network\] DNS should provide DNS for ExternalName services
      \[sig-network\] DNS should provide DNS for pods for Hostname
      \[sig-network\] DNS should provide DNS for pods for Subdomain
      \[sig-network\] DNS should provide DNS for services
      \[sig-network\] DNS should provide DNS for the cluster
      \[sig-network\] DNS should resolve DNS of partial qualified names for services
      \[sig-network\] DNS should resolve DNS of partial qualified names for the cluster
      \[sig-network\] Internal connectivity for TCP and UDP on ports 9000-9999 is allowed
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should allow egress access on one named port
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should allow egress access to server in CIDR block
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should allow ingress access from namespace on one named port
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should allow ingress access from updated namespace
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should allow ingress access from updated pod
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should allow ingress access on one named port
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should deny ingress access to updated pod
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce egress policy allowing traffic to a server in a different namespace based on PodSelector and NamespaceSelector
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce except clause while egress access to server in CIDR block
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce multiple egress policies with egress allow-all policy taking precedence
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce multiple ingress policies with ingress allow-all policy taking precedence
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce multiple, stacked policies with overlapping podSelectors
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce policies to check ingress and egress policies can be controlled independently based on PodSelector
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce policy based on NamespaceSelector with MatchExpressions
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce policy based on PodSelector and NamespaceSelector
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce policy based on PodSelector or NamespaceSelector
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce policy based on PodSelector with MatchExpressions
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce policy based on Ports
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce policy to allow traffic from pods within server namespace based on PodSelector
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce policy to allow traffic only from a different namespace, based on NamespaceSelector
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce policy to allow traffic only from a pod in a different namespace based on PodSelector and NamespaceSelector
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should enforce updated policy
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should ensure an IP overlapping both IPBlock.CIDR and IPBlock.Except is allowed
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should not allow access by TCP when a policy specifies only SCTP
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should stop enforcing policies after they are deleted
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should support a 'default-deny-all' policy
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should support a 'default-deny-ingress' policy
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should support allow-all policy
      \[sig-network\] NetworkPolicy \[LinuxOnly\] NetworkPolicy between server and client should work with Ingress,Egress specified together
      \[sig-network\] Networking Granular Checks: Services should function for client IP based session affinity: udp
      \[sig-network\] Networking should provide Internet connection for containers
      \[sig-network\] Services should be able to switch session affinity for NodePort service
      \[sig-network\] Services should be able to switch session affinity for service with type clusterIP
      \[sig-network\] Services should have session affinity timeout work for NodePort service
      \[sig-network\] Services should have session affinity timeout work for service with type clusterIP
      \[sig-network\] Services should have session affinity work for NodePort service
      \[sig-network\] Services should have session affinity work for service with type clusterIP
      \[sig-network\] services basic functionality should allow connections to another pod on a different node via a service IP
      \[sig-network\] services basic functionality should allow connections to another pod on the same node via a service IP
      \[sig-network\] services when using a plugin that does not isolate namespaces by default should allow connections to pods in different namespaces on different nodes via service IPs
      \[sig-network\] services when using a plugin that does not isolate namespaces by default should allow connections to pods in different namespaces on the same node via service IPs
      \[sig-network\]\[Feature:Router\] The HAProxy router should enable openshift-monitoring to pull metrics
      \[sig-network\]\[Feature:Router\] The HAProxy router should expose a health check on the metrics port
      \[sig-network\]\[Feature:Router\] The HAProxy router should expose prometheus metrics for a route
      \[sig-network\]\[Feature:Router\] The HAProxy router should expose the profiling endpoints
      \[sig-network\]\[Feature:Router\] The HAProxy router should override the route host for overridden domains with a custom value
      \[sig-network\]\[Feature:Router\] The HAProxy router should override the route host with a custom value
      \[sig-network\]\[Feature:Router\] The HAProxy router should respond with 503 to unrecognized hosts
      \[sig-network\]\[Feature:Router\] The HAProxy router should run even if it has no access to update status
      \[sig-network\]\[Feature:Router\] The HAProxy router should serve a route that points to two services and respect weights
      \[sig-network\]\[Feature:Router\] The HAProxy router should serve routes that were created from an ingress
      \[sig-network\]\[Feature:Router\] The HAProxy router should serve the correct routes when scoped to a single namespace and label set
      \[sig-network\]\[Feature:Router\] The HAProxy router should support reencrypt to services backed by a serving certificate automatically
      \[sig-network\]\[endpoints\] admission TestEndpointAdmission
      \[sig-node\] Managed cluster should report ready nodes the entire duration of the test run
      \[sig-operator\] an end user can use OLM can subscribe to the operator
      \[sig-storage\] GCP Volumes GlusterFS should be mountable
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Inline-volume (default fs)\] subPath should be able to unmount after the subpath directory is deleted
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Inline-volume (default fs)\] subPath should support existing directories when readOnly specified in the volumeSource
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Inline-volume (default fs)\] subPath should support existing directory
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Inline-volume (default fs)\] subPath should support existing single file
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Inline-volume (default fs)\] subPath should support file as subpath
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Inline-volume (default fs)\] subPath should support non-existent path
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Inline-volume (default fs)\] subPath should support readOnly directory specified in the volumeMount
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Inline-volume (default fs)\] subPath should support readOnly file specified in the volumeMount
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Inline-volume (default fs)\] volumes should allow exec of files on the volume
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Inline-volume (default fs)\] volumes should store data
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Pre-provisioned PV (default fs)\] subPath should be able to unmount after the subpath directory is deleted
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Pre-provisioned PV (default fs)\] subPath should support existing directories when readOnly specified in the volumeSource
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Pre-provisioned PV (default fs)\] subPath should support existing directory
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Pre-provisioned PV (default fs)\] subPath should support existing single file
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Pre-provisioned PV (default fs)\] subPath should support file as subpath
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Pre-provisioned PV (default fs)\] subPath should support non-existent path
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Pre-provisioned PV (default fs)\] subPath should support readOnly directory specified in the volumeMount
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Pre-provisioned PV (default fs)\] subPath should support readOnly file specified in the volumeMount
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Pre-provisioned PV (default fs)\] volumes should allow exec of files on the volume
      \[sig-storage\] In-tree Volumes \[Driver: gluster\] \[Testpattern: Pre-provisioned PV (default fs)\] volumes should store data
      \[sig-storage\] In-tree Volumes \[Driver: nfs\] \[Testpattern: Dynamic PV (default fs)\] provisioning should provision storage with mount options
      \[sig-storage\] In-tree Volumes \[Driver: nfs\] \[Testpattern: Dynamic PV (default fs)\] subPath should support existing directories when readOnly specified in the volumeSource
      \[sig-storage\] In-tree Volumes \[Driver: nfs\] \[Testpattern: Dynamic PV (default fs)\] subPath should support existing directory
      \[sig-storage\] In-tree Volumes \[Driver: nfs\] \[Testpattern: Dynamic PV (default fs)\] subPath should support existing single file
      \[sig-storage\] In-tree Volumes \[Driver: nfs\] \[Testpattern: Dynamic PV (default fs)\] subPath should support file as subpath
      \[sig-storage\] In-tree Volumes \[Driver: nfs\] \[Testpattern: Dynamic PV (default fs)\] subPath should support non-existent path
      \[sig-storage\] In-tree Volumes \[Driver: nfs\] \[Testpattern: Dynamic PV (default fs)\] subPath should support readOnly directory specified in the volumeMount
      \[sig-storage\] In-tree Volumes \[Driver: nfs\] \[Testpattern: Dynamic PV (default fs)\] subPath should support readOnly file specified in the volumeMount
      \[sig-storage\] In-tree Volumes \[Driver: nfs\] \[Testpattern: Dynamic PV (default fs)\] volumes should allow exec of files on the volume
      \[sig-storage\] In-tree Volumes \[Driver: nfs\] \[Testpattern: Dynamic PV (default fs)\] volumes should store data
      \[sig-storage\] In-tree Volumes \[Driver: nfs\] \[Testpattern: Pre-provisioned PV (default fs)\] subPath should support existing directory
      \[sig-storage\]\[Late\] Metrics should report short attach times
      \[sig-storage\]\[Late\] Metrics should report short mount times
      \[sig-network\] Networking Granular Checks: Services should function for client IP based session affinity: http
    documentation: Regular expression (POSIX basic regular expression) of tests to skip. Note that the current list it's just a temporary measure for the baremetal platform.
  - name: TEST_UPGRADE_OPTIONS
    default: "abort-at=100"
    documentation: Options controlling how an upgrade is performed. See `openshift-test run-upgrade --help` for more details.
  - name: TEST_MINIMAL_LIST
    default: |-
      "[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance] [sig-node] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[k8s.io] Lease lease API should be available [Conformance] [sig-node] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[k8s.io] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance] [sig-node] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Secrets should fail to create secret due to empty secret key [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Secrets should patch a secret [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-apps] ReplicationController should release no longer matching pods [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-network] Proxy version v1 should proxy logs on node using proxy subresource  [Suite:openshift/conformance/parallel] [Suite:k8s]"
      "[sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource  [Suite:openshift/conformance/parallel] [Suite:k8s]"
      "[sig-network] Services should find a service from listing all namespaces [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-network] Services should provide secure master service  [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
      "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance] [Suite:openshift/conformance/parallel/minimal] [Suite:k8s]"
    documentation: This is a minimal list of working tests to be used when test images mirroring is not supported by openshift-test (baremetal ipi only)
  dependencies:
  - name: "release:latest"
    env: OPENSHIFT_UPGRADE_RELEASE_IMAGE_OVERRIDE
  documentation: |-
    The Baremtal DS E2E step executes the common end-to-end test suite.
