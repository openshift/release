workflow:
  as: redhat-chaos-hog-scenarios-io
  steps:
    test:
      - ref: redhat-chaos-hog-scenarios-io
    env:
      TOTAL_CHAOS_DURATION: "600"
      IO_BLOCK_SIZE: "1m"
      IO_WORKERS: "5"
      IO_WRITE_BYTES: "90%"
      TARGET_NAMESPACE: "default"
      NODE_SELECTORS: "node-role.kubernetes.io/worker="
      ENABLE_ALERTS: "True"
      ALERTS_PATH: "/root/kraken/config/alerts"       
      CHECK_CRITICAL_ALERTS: "True"
      WAIT_DURATION: "100"      
      TELEMETRY_ENABLED: "True"
      TELEMETRY_API_URL: "https://ulnmf9xv7j.execute-api.us-west-2.amazonaws.com/production"
      TELEMETRY_USERNAME: "redhat-chaos"
      TELEMETRY_RUN_TAG: "prow-hog-cpu"
      TELEMETRY_PROMETHEUS_BACKUP: "True"
      TELEMETRY_FULL_PROMETHEUS_BACKUP: "True"
      TELEMTRY_BACKUP_THREADS: "5"
      TELEMETRY_ARCHIVE_PATH: "/tmp"
      TELEMETRY_MAX_RETRIES: "0"
      TELEMETRY_ARCHIVE_SIZE: "1000000"
  documentation: >-
    This step runs the krkn-hub config workload in the deployed cluster to hog IO and validate SLOs to identify components that do not have proper memory limits set to avoid performance throttling or having an impact on stability/availability.
