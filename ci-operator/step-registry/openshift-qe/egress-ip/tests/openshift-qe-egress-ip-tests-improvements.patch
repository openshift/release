--- openshift-qe-egress-ip-tests-commands.sh.orig
+++ openshift-qe-egress-ip-tests-commands.sh
@@ -13,6 +13,16 @@
 # Configuration
 EIP_NAME="${EIP_NAME:-egressip1}"
 POD_KILL_RETRIES="${POD_KILL_RETRIES:-10}"
 REBOOT_RETRIES="${REBOOT_RETRIES:-5}"
+
+# Configurable timeouts
+POD_READY_TIMEOUT="${POD_READY_TIMEOUT:-300}"
+NODE_READY_TIMEOUT="${NODE_READY_TIMEOUT:-450}"
+MIGRATION_TIMEOUT="${MIGRATION_TIMEOUT:-900}"
+OVN_STABILIZATION_WAIT="${OVN_STABILIZATION_WAIT:-30}"
+WORKLOAD_READY_TIMEOUT="${WORKLOAD_READY_TIMEOUT:-120}"
+CLEANUP_TIMEOUT="${CLEANUP_TIMEOUT:-120}"
+
 NAMESPACE="openshift-ovn-kubernetes"
 
 # Test artifacts directory
@@ -31,9 +41,26 @@
 NC='\033[0m'
 
 # Logging functions
-log_info() { echo -e "${BLUE}[INFO]${NC} [$(date +'%Y-%m-%d %H:%M:%S')] $1"; }
-log_success() { echo -e "${GREEN}[SUCCESS]${NC} [$(date +'%Y-%m-%d %H:%M:%S')] $1"; }
-log_warning() { echo -e "${YELLOW}[WARNING]${NC} [$(date +'%Y-%m-%d %H:%M:%S')] $1"; }
-log_error() { echo -e "${RED}[ERROR]${NC} [$(date +'%Y-%m-%d %H:%M:%S')] $1"; }
+log_info() { echo -e "${BLUE}[INFO]${NC} [$(date +'%Y-%m-%d %H:%M:%S')] $*"; }
+log_success() { echo -e "${GREEN}[SUCCESS]${NC} [$(date +'%Y-%m-%d %H:%M:%S')] $*"; }
+log_warning() { echo -e "${YELLOW}[WARNING]${NC} [$(date +'%Y-%m-%d %H:%M:%S')] $*"; }
+log_error() { echo -e "${RED}[ERROR]${NC} [$(date +'%Y-%m-%d %H:%M:%S')] $*"; }
+
+# Helper functions
+validate_node_name() {
+    local node_name="$1"
+    if ! [[ "$node_name" =~ ^[a-zA-Z0-9._-]+$ ]]; then
+        log_error "Invalid node name format: $node_name"
+        return 1
+    fi
+}
+
+check_prerequisites() {
+    # Check if required tools are available
+    for tool in oc jq; do
+        if ! command -v "$tool" >/dev/null 2>&1; then
+            error_exit "$tool command not found - required for test execution"
+        fi
+    done
+}
 
 error_exit() {
@@ -42,6 +69,8 @@
 }
 
+check_prerequisites
+
 # Enhanced metrics collection functions
 collect_enhanced_ovn_metrics() {
     local phase="${1:-unknown}"
@@ -58,8 +87,16 @@
 EOF
 
     # Collect egress IP status and events
-    local eip_status
-    eip_status=$(oc get egressip "$EIP_NAME" -o json 2>/dev/null | jq -c '.status // {}' 2>/dev/null || echo '{}')
+    local eip_status eip_json
+    eip_json=$(oc get egressip "$EIP_NAME" -o json 2>/dev/null || echo '{}')
+    if [[ -n "$eip_json" && "$eip_json" != '{}' ]]; then
+        eip_status=$(echo "$eip_json" | jq -c '.status // {}' 2>/dev/null || echo '{}')
+        if [[ -z "$eip_status" ]]; then
+            eip_status='{}'
+        fi
+    else
+        eip_status='{}'
+    fi
     echo "    \"current_status\": $eip_status," >> "$metrics_file"
     
     # Collect recent egress IP events
@@ -98,7 +135,11 @@
 EOF
 
     # Enhanced node network state information
-    local node_ip egress_ip_assigned
+    local node_ip egress_ip_assigned assigned_node
+    
+    # Get assigned node first
+    assigned_node=$(oc get egressip "$EIP_NAME" -o jsonpath='{.status.items[0].node}' 2>/dev/null || echo "")
+    
     node_ip=$(oc get node "$ASSIGNED_NODE" -o jsonpath='{.status.addresses[?(@.type=="InternalIP")].address}' 2>/dev/null || echo "unknown")
     egress_ip_assigned=$(oc get egressip "$EIP_NAME" -o jsonpath='{.spec.egressIPs[0]}' 2>/dev/null || echo "unknown")
     
@@ -234,9 +275,23 @@
 
 cleanup_test_workload() {
     log_info "Cleaning up test workload..."
-    oc delete namespace test-egress --ignore-not-found=true || true
+    if oc get namespace test-egress &>/dev/null; then
+        oc delete namespace test-egress --ignore-not-found=true || true
+        
+        # Wait for namespace deletion with timeout
+        local cleanup_elapsed=0
+        while [[ $cleanup_elapsed -lt $CLEANUP_TIMEOUT ]]; do
+            if ! oc get namespace test-egress &>/dev/null; then
+                log_success "Test namespace successfully deleted"
+                return 0
+            fi
+            sleep 5
+            cleanup_elapsed=$((cleanup_elapsed + 5))
+        done
+        log_warning "Test namespace deletion timed out - may require manual cleanup"
+    fi
 }
 
+
 # Set up test workload
 setup_test_workload()
 
@@ -217,8 +258,8 @@
     # Wait for pod to be running
     log_info "Waiting for test workload to be ready..."
-    local timeout=120
+    local timeout=$WORKLOAD_READY_TIMEOUT
     local elapsed=0
     while [[ $elapsed -lt $timeout ]]; do
-        if oc get pod test-workload -n test-egress -o jsonpath='{.status.phase}' 2>/dev/null | grep -q "Running"; then
+        if oc get pod test-workload -n test-egress -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null | grep -q "True"; then
             log_success "Test workload is running and generating egress traffic"
             return 0
         fi
@@ -264,7 +305,11 @@
     
     # Find ovnkube-node pod on that node
     local pod_name
-    pod_name=$(oc get pods -n "$NAMESPACE" -o wide | grep "$current_node" | awk '/ovnkube-node/{print $1}' | head -1)
+    validate_node_name "$current_node" || return 1
+    
+    pod_name=$(oc get pods -n "$NAMESPACE" -l app=ovnkube-node \
+        --field-selector spec.nodeName="$current_node" \
+        -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
     if [[ -z "$pod_name" ]]; then
         log_error "No ovnkube-node pod found on node $current_node"
         return 1
@@ -272,6 +317,11 @@
     
     log_info "Deleting pod $pod_name on node $current_node..."
     oc delete pod -n "$NAMESPACE" "$pod_name" --ignore-not-found --wait=false
+    
+    # Wait for old pod to actually terminate
+    local termination_wait=30
+    sleep $termination_wait
+    log_info "Waited ${termination_wait}s for pod termination..."
     
     # Wait for new pod to be ready
     local elapsed=0
@@ -279,7 +329,9 @@
     local new_pod=""
     local ready="false"
     
-    while [[ $elapsed -lt $pod_ready_timeout ]]; do
-        new_pod=$(oc get pods -n "$NAMESPACE" -o wide | grep "$current_node" | awk '/ovnkube-node/{print $1}' | head -1)
+    while [[ $elapsed -lt $POD_READY_TIMEOUT ]]; do
+        new_pod=$(oc get pods -n "$NAMESPACE" -l app=ovnkube-node \
+            --field-selector spec.nodeName="$current_node" \
+            -o jsonpath='{.items[0].metadata.name}' 2>/dev/null)
         
         if [[ -n "$new_pod" ]] && [[ "$new_pod" != "$pod_name" ]]; then
             ready=$(oc get pod -n "$NAMESPACE" "$new_pod" -o jsonpath='{.status.containerStatuses[?(@.name=="ovnkube-controller")].ready}' 2>/dev/null || echo "false")
@@ -295,11 +347,11 @@
     done
     
-    if [[ -z "$new_pod" ]] || [[ "$new_pod" == "$pod_name" ]] || [[ "$ready" != "true" ]]; then
-        log_error "Failed to detect ready new pod on $current_node after ${pod_ready_timeout}s"
+    if [[ -z "$new_pod" ]] || [[ "$new_pod" == "$pod_name" ]] || [[ "$ready" != "true" ]]; then
+        log_error "Failed to detect ready new pod on $current_node after ${POD_READY_TIMEOUT}s"
         return 1
     fi
     
     # Wait for OVN to stabilize
-    sleep 15
+    sleep $OVN_STABILIZATION_WAIT
     
     # Check NAT count
@@ -439,6 +491,7 @@
         # Method 1: Standard systemctl reboot with better error handling
         log_info "Attempting standard systemctl reboot..."
+        validate_node_name "$selected_node" || return 1
         local debug_output
         debug_output=$(oc debug node/"$selected_node" --quiet -- chroot /host bash -c "sync && systemctl reboot" 2>&1)
         local debug_exit_code=$?
@@ -492,7 +545,7 @@
     # Wait for node to go NotReady (increased timeout for robustness)
     log_info "⏳ Waiting for node to go NotReady..."
     local not_ready_detected=false
-    for ((attempt=1; attempt<=90; attempt++)); do
+    for ((attempt=1; attempt<=$((NODE_READY_TIMEOUT/5)); attempt++)); do
         local status
         status=$(oc get node "$selected_node" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
         if [[ "$status" != "True" ]]; then
@@ -504,7 +557,7 @@
     done
     
     if [[ "$not_ready_detected" == "false" ]]; then
-        log_error "❌ Node $selected_node did not go NotReady within 7.5 minutes"
+        log_error "❌ Node $selected_node did not go NotReady within $((NODE_READY_TIMEOUT/60)) minutes"
         return 1
     fi
     
@@ -512,7 +565,7 @@
     log_info "⏳ Waiting for node to become Ready again..."
     local ready_detected=false
     
-    for ((attempt=1; attempt<=120; attempt++)); do
+    for ((attempt=1; attempt<=$((NODE_READY_TIMEOUT*2/10)); attempt++)); do
         local status
         status=$(oc get node "$selected_node" -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' 2>/dev/null || echo "Unknown")
         if [[ "$status" == "True" ]]; then
@@ -524,7 +577,7 @@
     done
     
     if [[ "$ready_detected" == "false" ]]; then
-        log_error "❌ Node $selected_node did not become Ready within 20 minutes"
+        log_error "❌ Node $selected_node did not become Ready within $((NODE_READY_TIMEOUT*2/60)) minutes"
         return 1
     fi
     
@@ -684,7 +737,7 @@
     
     # Wait for egress IP to migrate
     log_info "Waiting for egress IP to migrate to $target_node..."
-    local migration_timeout=600  # Increased from 300s to 600s (10 minutes)
+    local migration_timeout=$MIGRATION_TIMEOUT
     local elapsed=0
     local migration_successful=false
     
@@ -871,7 +924,11 @@
 log_info "  - Total Tests: $TOTAL_TESTS"
 log_info "  - Passed: $PASSED_TESTS"
 log_info "  - Failed: $FAILED_TESTS" 
-log_info "  - Success Rate: $(( PASSED_TESTS * 100 / TOTAL_TESTS ))%"
+if [[ $TOTAL_TESTS -gt 0 ]]; then
+    log_info "  - Success Rate: $(( PASSED_TESTS * 100 / TOTAL_TESTS ))%"
+else
+    log_info "  - Success Rate: N/A (no tests run)"
+fi
 log_info "==============================="
 
 if [[ $FAILED_TESTS -eq 0 ]]; then