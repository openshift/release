base_images:
  assisted-service-scripts:
    name: ocm-2.13
    namespace: edge-infrastructure
    tag: assisted-service-scripts
  dev-scripts:
    name: test
    namespace: ocp-kni
    tag: dev-scripts
  hypershift-operator:
    name: hypershift-operator
    namespace: hypershift
    tag: latest
  hypershift-tests:
    name: hypershift-tests
    namespace: hypershift
    tag: latest
  test-bin:
    name: "4.18"
    namespace: ocp
    tag: hypershift-tests
  upi-installer:
    name: "4.18"
    namespace: ocp
    tag: upi-installer
releases:
  latest:
    candidate:
      product: ocp
      stream: nightly
      version: "4.18"
resources:
  '*':
    requests:
      cpu: 100m
      memory: 200Mi
tests:
- as: control-plane-6nodes
  cron: 0 2 9,16 * *
  steps:
    allow_skip_on_success: true
    cluster_profile: equinix-ocp-hcp
    env:
      DEVSCRIPTS_CONFIG: |
        IP_STACK=v4
        NUM_WORKERS=3
        NUM_MASTERS=3
        MASTER_VCPU=16
        MASTER_MEMORY=40960
        NETWORK_TYPE=OVNKubernetes
        VM_EXTRADISKS=true
        VM_EXTRADISKS_LIST=vda
        VM_EXTRADISKS_SIZE=100G
        NUM_EXTRA_WORKERS=6
        EXTRA_WORKER_VCPU=4
        EXTRA_WORKER_MEMORY=16384
      ES_SECRETS_PATH: /prod-secret
      LVM_OPERATOR_SUB_CHANNEL: stable-4.18
      MCE_VERSION: "2.8"
      PPROF: "false"
    test:
    - chain: openshift-qe-control-plane
    workflow: openshift-qe-installer-hypershift-mce-agent-metal3
- as: ovs-timeout-stress-test
  cron: 0 6 * * 1,3,5
  steps:
    allow_skip_on_success: true
    cluster_profile: equinix-ocp-hcp
    env:
      DEVSCRIPTS_CONFIG: |
        IP_STACK=v4
        NUM_WORKERS=3
        NUM_MASTERS=3
        MASTER_VCPU=16
        MASTER_MEMORY=40960
        NETWORK_TYPE=OVNKubernetes
        VM_EXTRADISKS=true
        VM_EXTRADISKS_LIST=vda
        VM_EXTRADISKS_SIZE=100G
        NUM_EXTRA_WORKERS=6
        EXTRA_WORKER_VCPU=4
        EXTRA_WORKER_MEMORY=16384
      ES_SECRETS_PATH: /prod-secret
      LVM_OPERATOR_SUB_CHANNEL: stable-4.18
      MCE_VERSION: "2.8"
      PPROF: "false"
      # OVS timeout test specific configuration
      OVS_TIMEOUT_TEST_PODS: "1000"
      OVS_TIMEOUT_MAX_WAIT: "2400"
      HYPERSHIFT_HC_RELEASE_IMAGE: "registry.build07.ci.openshift.org/ci-ln-l477g5k/release:latest"
      TEST_PURPOSE: "OCPBUGS-66075-ovs-timeout-validation"
    test:
    - as: ovs-timeout-validation
      cli: latest
      commands: |
        #!/bin/bash
        set -euo pipefail
        
        # OVS Timeout Fix Validation for OCPBUGS-66075
        # Tests the 90-second OVS timeout fix under high concurrent pod creation load
        
        echo "Starting OVS Timeout Fix Validation for OCPBUGS-66075"
        echo "Testing OVS timeout increase from 30s to 90s in HyperShift HCP environment"
        echo "Using custom release: ${HYPERSHIFT_HC_RELEASE_IMAGE}"
        echo "Target pods: ${OVS_TIMEOUT_TEST_PODS}"
        
        # Function to log with timestamp
        log() {
          echo "[$(date '+%Y-%m-%d %H:%M:%S')] [OCPBUGS-66075] $*"
        }
        
        log "Creating test deployment with ${OVS_TIMEOUT_TEST_PODS} pods..."
        
        # Create the stress test deployment
        cat <<EOF | oc apply -f -
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: ovs-timeout-test-deployment
          namespace: default
          labels:
            app: ovs-timeout-test
            test-id: "OCPBUGS-66075"
            test-purpose: "ovs-timeout-validation"
          annotations:
            test.openshift.io/description: "OVS timeout fix validation for OCPBUGS-66075"
            test.openshift.io/expected-timeout: "90s"
            test.openshift.io/custom-release: "${HYPERSHIFT_HC_RELEASE_IMAGE}"
        spec:
          replicas: ${OVS_TIMEOUT_TEST_PODS}
          strategy:
            type: RollingUpdate
            rollingUpdate:
              maxSurge: 500
              maxUnavailable: 0
          selector:
            matchLabels:
              app: ovs-timeout-test
          template:
            metadata:
              labels:
                app: ovs-timeout-test
                test-phase: "concurrent-pod-creation"
            spec:
              terminationGracePeriodSeconds: 5
              containers:
              - name: test-container
                image: registry.access.redhat.com/ubi8/ubi-minimal:latest
                command:
                - /bin/bash
                - -c
                - |
                  echo "Pod \${HOSTNAME} started at \$(date)"
                  echo "Testing OVS timeout fix for OCPBUGS-66075"
                  echo "Expected OVS timeout: 90 seconds (was 30 seconds)"
                  while true; do
                    echo "Pod \${HOSTNAME} alive at \$(date)"
                    sleep 600
                  done
                resources:
                  requests:
                    memory: "32Mi"
                    cpu: "5m"
                  limits:
                    memory: "64Mi"
                    cpu: "10m"
                env:
                - name: POD_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: metadata.name
                - name: NODE_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: spec.nodeName
              restartPolicy: Always
        EOF
        
        log "Monitoring pod creation progress..."
        
        start_time=$(date +%s)
        max_pods_ready=0
        timeout_errors=0
        
        # Monitor for up to MAX_WAIT seconds
        while true; do
          current_time=$(date +%s)
          elapsed=$((current_time - start_time))
          
          if [ $elapsed -gt ${OVS_TIMEOUT_MAX_WAIT} ]; then
            log "ERROR: Test timed out after ${OVS_TIMEOUT_MAX_WAIT} seconds"
            break
          fi
          
          # Get pod statistics
          running_pods=$(oc get pods -l app=ovs-timeout-test --no-headers 2>/dev/null | grep "Running" | wc -l || echo 0)
          pending_pods=$(oc get pods -l app=ovs-timeout-test --no-headers 2>/dev/null | grep -E "Pending|ContainerCreating" | wc -l || echo 0)
          failed_pods=$(oc get pods -l app=ovs-timeout-test --no-headers 2>/dev/null | grep -vE "Running|Pending|ContainerCreating" | wc -l || echo 0)
          
          # Track maximum pods reached
          if [ $running_pods -gt $max_pods_ready ]; then
            max_pods_ready=$running_pods
          fi
          
          # Check for OVS timeout errors
          new_timeout_errors=$(oc get events --field-selector reason=FailedCreatePodSandBox -o json 2>/dev/null | \
            jq -r '[.items[] | select(.message | test("timeout.*ovs|ovs.*timeout|timeout.*30|timeout.*90", "i"))] | length' 2>/dev/null || echo 0)
          timeout_errors=$new_timeout_errors
          
          log "Progress: ${running_pods}/${OVS_TIMEOUT_TEST_PODS} Running, ${pending_pods} Pending, ${failed_pods} Failed | Time: ${elapsed}s | Timeout Errors: ${timeout_errors}"
          
          # Success condition
          if [ $running_pods -eq ${OVS_TIMEOUT_TEST_PODS} ]; then
            log "SUCCESS: All ${OVS_TIMEOUT_TEST_PODS} pods are running!"
            break
          fi
          
          # Check for high failure rate
          if [ $failed_pods -gt $((OVS_TIMEOUT_TEST_PODS / 4)) ]; then
            log "ERROR: High failure rate detected: ${failed_pods} failed pods"
            break
          fi
          
          sleep 15
        done
        
        # Final results and cleanup
        end_time=$(date +%s)
        total_elapsed=$((end_time - start_time))
        
        log "=== FINAL TEST RESULTS ==="
        log "Custom Release: ${HYPERSHIFT_HC_RELEASE_IMAGE}"
        log "Target pods: ${OVS_TIMEOUT_TEST_PODS}"
        log "Maximum pods running: ${max_pods_ready}"
        log "Final running pods: ${running_pods}"
        log "Failed pods: ${failed_pods}"
        log "Total elapsed time: ${total_elapsed} seconds"
        log "OVS timeout errors: ${timeout_errors}"
        
        # Collect debug info
        echo "=== Recent Events ==="
        oc get events --sort-by='.lastTimestamp' | tail -30
        
        echo "=== Node Resources ==="
        oc adm top nodes || echo "Node metrics not available"
        
        # Cleanup
        log "Cleaning up test deployment..."
        oc delete deployment ovs-timeout-test-deployment --ignore-not-found=true --timeout=120s
        
        # Determine test result
        success_threshold=$((OVS_TIMEOUT_TEST_PODS * 85 / 100))  # 85% success rate
        
        if [ $timeout_errors -eq 0 ] && [ $max_pods_ready -ge $success_threshold ]; then
          log "üéâ TEST RESULT: PASSED ‚úÖ"
          log "‚úÖ Zero OVS timeout errors - 90s timeout fix is working"
          log "‚úÖ Successfully created ${max_pods_ready} concurrent pods (‚â•${success_threshold} required)"
          exit 0
        else
          log "üí• TEST RESULT: FAILED ‚ùå"
          if [ $timeout_errors -gt 0 ]; then
            log "‚ùå Found ${timeout_errors} OVS timeout errors"
          fi
          if [ $max_pods_ready -lt $success_threshold ]; then
            log "‚ùå Only reached ${max_pods_ready} pods (required ‚â•${success_threshold})"
          fi
          exit 1
        fi
      
      from: test-bin
      resources:
        requests:
          cpu: 100m
          memory: 200Mi
    workflow: openshift-qe-installer-hypershift-mce-agent-metal3
zz_generated_metadata:
  branch: main
  org: openshift-eng
  repo: ocp-qe-perfscale-ci
  variant: hypershift_bm-4.18-nightly-x86
