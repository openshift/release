build_root:
  project_image:
    dockerfile_literal: |
      FROM registry.ci.openshift.org/ocp/ubi-python-311:9
      USER 0
      RUN dnf install -y podman
images:
- dockerfile_path: Containerfile
  to: lightspeed-service-api
- dockerfile_path: Containerfile.redis
  to: lightspeed-service-redis
promotion:
  to:
  - namespace: ols
    tag: latest
releases:
  latest:
    release:
      architecture: multi
      channel: stable
      version: "4.15"
resources:
  '*':
    limits:
      memory: 8Gi
    requests:
      cpu: 100m
      memory: 4Gi
tests:
- as: verify
  commands: pip install black ruff mypy && make verify && make check-types
  container:
    from: src
- as: unit
  commands: |
    export CODECOV_TOKEN=$(cat /tmp/secret/CODECOV_TOKEN)
    make install-deps && make install-deps-test && make test-unit
  container:
    from: src
  secret:
    mount_path: /tmp/secret
    name: ols-codecov-token
- as: integration
  commands: |
    export CODECOV_TOKEN=$(cat /tmp/secret/CODECOV_TOKEN)
    make install-deps && make install-deps-test && make test-integration
  container:
    from: src
  secret:
    mount_path: /tmp/secret
    name: ols-codecov-token
- as: e2e-ols-cluster-4-15
  cluster_claim:
    architecture: amd64
    cloud: aws
    labels:
      region: us-east-1
    owner: ols
    product: ocp
    timeout: 1h0m0s
    version: "4.15"
  cron: 10 2 * * *
  presubmit: true
  run_if_changed: ^(Containerfile.*|Makefile|manifests/.*|ols/.*|pyproject.toml|pdm.lock|scripts/.*|tests/.*)$
  steps:
    test:
    - as: e2e
      cli: latest
      commands: |
        export BAM_PROVIDER_KEY_PATH=/var/run/bam/token
        export AZUREOPENAI_PROVIDER_KEY_PATH=/var/run/azure_openai/token
        export AZUREOPENAI_ENTRA_ID_TENANT_ID=$(cat /var/run/azureopenai-entra-id/tenant_id)
        export AZUREOPENAI_ENTRA_ID_CLIENT_ID=$(cat /var/run/azureopenai-entra-id/client_id)
        export AZUREOPENAI_ENTRA_ID_CLIENT_SECRET=$(cat /var/run/azureopenai-entra-id/client_secret)
        export OPENAI_PROVIDER_KEY_PATH=/var/run/openai/token
        export WATSONX_PROVIDER_KEY_PATH=/var/run/watsonx/token
        export AWS_BUCKET_PATH=/var/run/aws-bucket/aws-bucket
        export AWS_ACCESS_KEY_ID_PATH=/var/run/aws-access-key-id/aws-access-key-id
        export AWS_REGION_PATH=/var/run/aws-region/aws-region
        export AWS_SECRET_ACCESS_KEY_PATH=/var/run/aws-secret-access-key/aws-secret-access-key

        export PROVIDER_KEY_PATH=/var/run/openai/token
        export PROVIDER=openai
        export MODEL=gpt-3.5-turbo-1106

        export CP_OFFLINE_TOKEN=$(cat /var/run/insights-stage-upload-offline-token/token)

        tests/scripts/test-e2e-cluster.sh
      credentials:
      - mount_path: /var/run/azure_openai
        name: azureopenai-apitoken
        namespace: test-credentials
      - mount_path: /var/run/azureopenai-entra-id
        name: azureopenai-entra-id
        namespace: test-credentials
      - mount_path: /var/run/bam
        name: bam-apitoken
        namespace: test-credentials
      - mount_path: /var/run/openai
        name: openai-apitoken
        namespace: test-credentials
      - mount_path: /var/run/watsonx
        name: watsonx-apitoken
        namespace: test-credentials
      - mount_path: /var/run/insights-stage-upload-offline-token
        name: insights-stage-upload-offline-token
        namespace: test-credentials
      - mount_path: /var/run/aws-bucket
        name: aws-bucket
        namespace: test-credentials
      - mount_path: /var/run/aws-access-key-id
        name: aws-access-key-id
        namespace: test-credentials
      - mount_path: /var/run/aws-region
        name: aws-region
        namespace: test-credentials
      - mount_path: /var/run/aws-secret-access-key
        name: aws-secret-access-key
        namespace: test-credentials
      dependencies:
      - env: OLS_IMAGE
        name: lightspeed-service-api
      from: src
      resources:
        requests:
          cpu: 100m
    workflow: generic-claim
- as: e2e-ols-cluster-4-16
  cluster_claim:
    architecture: amd64
    cloud: aws
    labels:
      region: us-east-1
    owner: ols
    product: ocp
    timeout: 1h0m0s
    version: "4.16"
  cron: 10 2 * * *
  presubmit: true
  run_if_changed: ^(Containerfile.*|Makefile|manifests/.*|ols/.*|pyproject.toml|pdm.lock|scripts/.*|tests/.*)$
  steps:
    test:
    - as: e2e
      cli: latest
      commands: |
        export BAM_PROVIDER_KEY_PATH=/var/run/bam/token
        export AZUREOPENAI_PROVIDER_KEY_PATH=/var/run/azure_openai/token
        export AZUREOPENAI_ENTRA_ID_TENANT_ID=$(cat /var/run/azureopenai-entra-id/tenant_id)
        export AZUREOPENAI_ENTRA_ID_CLIENT_ID=$(cat /var/run/azureopenai-entra-id/client_id)
        export AZUREOPENAI_ENTRA_ID_CLIENT_SECRET=$(cat /var/run/azureopenai-entra-id/client_secret)
        export OPENAI_PROVIDER_KEY_PATH=/var/run/openai/token
        export WATSONX_PROVIDER_KEY_PATH=/var/run/watsonx/token
        export AWS_BUCKET_PATH=/var/run/aws-bucket/aws-bucket
        export AWS_ACCESS_KEY_ID_PATH=/var/run/aws-access-key-id/aws-access-key-id
        export AWS_REGION_PATH=/var/run/aws-region/aws-region
        export AWS_SECRET_ACCESS_KEY_PATH=/var/run/aws-secret-access-key/aws-secret-access-key

        export PROVIDER_KEY_PATH=/var/run/openai/token
        export PROVIDER=openai
        export MODEL=gpt-3.5-turbo-1106

        export CP_OFFLINE_TOKEN=$(cat /var/run/insights-stage-upload-offline-token/token)

        tests/scripts/test-e2e-cluster.sh
      credentials:
      - mount_path: /var/run/azure_openai
        name: azureopenai-apitoken
        namespace: test-credentials
      - mount_path: /var/run/azureopenai-entra-id
        name: azureopenai-entra-id
        namespace: test-credentials
      - mount_path: /var/run/bam
        name: bam-apitoken
        namespace: test-credentials
      - mount_path: /var/run/openai
        name: openai-apitoken
        namespace: test-credentials
      - mount_path: /var/run/watsonx
        name: watsonx-apitoken
        namespace: test-credentials
      - mount_path: /var/run/insights-stage-upload-offline-token
        name: insights-stage-upload-offline-token
        namespace: test-credentials
      - mount_path: /var/run/aws-bucket
        name: aws-bucket
        namespace: test-credentials
      - mount_path: /var/run/aws-access-key-id
        name: aws-access-key-id
        namespace: test-credentials
      - mount_path: /var/run/aws-region
        name: aws-region
        namespace: test-credentials
      - mount_path: /var/run/aws-secret-access-key
        name: aws-secret-access-key
        namespace: test-credentials
      dependencies:
      - env: OLS_IMAGE
        name: lightspeed-service-api
      from: src
      resources:
        requests:
          cpu: 100m
    workflow: generic-claim
- as: e2e-ols-cluster-4-17
  cluster_claim:
    architecture: amd64
    cloud: aws
    labels:
      region: us-east-1
    owner: ols
    product: ocp
    timeout: 1h0m0s
    version: "4.17"
  cron: 10 2 * * *
  presubmit: true
  run_if_changed: ^(Containerfile.*|Makefile|manifests/.*|ols/.*|pyproject.toml|pdm.lock|scripts/.*|tests/.*)$
  steps:
    test:
    - as: e2e
      cli: latest
      commands: |
        export BAM_PROVIDER_KEY_PATH=/var/run/bam/token
        export AZUREOPENAI_PROVIDER_KEY_PATH=/var/run/azure_openai/token
        export AZUREOPENAI_ENTRA_ID_TENANT_ID=$(cat /var/run/azureopenai-entra-id/tenant_id)
        export AZUREOPENAI_ENTRA_ID_CLIENT_ID=$(cat /var/run/azureopenai-entra-id/client_id)
        export AZUREOPENAI_ENTRA_ID_CLIENT_SECRET=$(cat /var/run/azureopenai-entra-id/client_secret)
        export OPENAI_PROVIDER_KEY_PATH=/var/run/openai/token
        export WATSONX_PROVIDER_KEY_PATH=/var/run/watsonx/token
        export AWS_BUCKET_PATH=/var/run/aws-bucket/aws-bucket
        export AWS_ACCESS_KEY_ID_PATH=/var/run/aws-access-key-id/aws-access-key-id
        export AWS_REGION_PATH=/var/run/aws-region/aws-region
        export AWS_SECRET_ACCESS_KEY_PATH=/var/run/aws-secret-access-key/aws-secret-access-key

        export PROVIDER_KEY_PATH=/var/run/openai/token
        export PROVIDER=openai
        export MODEL=gpt-3.5-turbo-1106

        export CP_OFFLINE_TOKEN=$(cat /var/run/insights-stage-upload-offline-token/token)

        tests/scripts/test-e2e-cluster.sh
      credentials:
      - mount_path: /var/run/azure_openai
        name: azureopenai-apitoken
        namespace: test-credentials
      - mount_path: /var/run/azureopenai-entra-id
        name: azureopenai-entra-id
        namespace: test-credentials
      - mount_path: /var/run/bam
        name: bam-apitoken
        namespace: test-credentials
      - mount_path: /var/run/openai
        name: openai-apitoken
        namespace: test-credentials
      - mount_path: /var/run/watsonx
        name: watsonx-apitoken
        namespace: test-credentials
      - mount_path: /var/run/insights-stage-upload-offline-token
        name: insights-stage-upload-offline-token
        namespace: test-credentials
      - mount_path: /var/run/aws-bucket
        name: aws-bucket
        namespace: test-credentials
      - mount_path: /var/run/aws-access-key-id
        name: aws-access-key-id
        namespace: test-credentials
      - mount_path: /var/run/aws-region
        name: aws-region
        namespace: test-credentials
      - mount_path: /var/run/aws-secret-access-key
        name: aws-secret-access-key
        namespace: test-credentials
      dependencies:
      - env: OLS_IMAGE
        name: lightspeed-service-api
      from: src
      resources:
        requests:
          cpu: 100m
    workflow: generic-claim
- as: security
  optional: true
  steps:
    workflow: openshift-ci-security
zz_generated_metadata:
  branch: main
  org: openshift
  repo: lightspeed-service
