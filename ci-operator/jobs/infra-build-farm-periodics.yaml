periodics:
- agent: kubernetes
  cluster: build04
  decorate: true
  decoration_config:
    timeout: 8h0m0s
  extra_refs:
  - base_ref: master
    org: openshift
    repo: release
    workdir: true
  interval: 5m
  labels:
    pj-rehearse.openshift.io/can-be-rehearsed: "true"
  max_concurrency: 1
  name: periodic-ipi-deprovision-aws
  reporter_config:
    slack:
      channel: '#ops-testplatform'
      job_states_to_report:
      - failure
      - error
      report_template: '@aws-ci-admin Job *{{.Spec.Job}}* failed. <{{.Status.URL}}|View
        logs>'
  spec:
    containers:
    - command:
      - ./core-services/ipi-deprovision/aws.sh
      env:
      - name: HOME
        value: /tmp
      - name: AWS_SHARED_CREDENTIALS_FILE
        value: /aws/.awscred
      - name: CLUSTER_TTL
        value: 30 minutes ago
      image: quay-proxy.ci.openshift.org/openshift/ci:ci_ipi-deprovision_latest
      imagePullPolicy: Always
      name: ipi-deprovision
      resources:
        requests:
          cpu: "1"
          memory: 600Mi
      volumeMounts:
      - mountPath: /aws
        name: cluster-secrets-aws
    nodeSelector:
      beta.kubernetes.io/arch: amd64
    serviceAccountName: ipi-deprovisioner
    volumes:
    - name: cluster-secrets-aws
      secret:
        items:
        - key: .awscred
          path: .awscred
        secretName: cluster-secrets-aws
- agent: kubernetes
  cluster: build04
  decorate: true
  decoration_config:
    timeout: 8h0m0s
  extra_refs:
  - base_ref: master
    org: openshift
    repo: release
    workdir: true
  interval: 5m
  labels:
    pj-rehearse.openshift.io/can-be-rehearsed: "true"
  max_concurrency: 1
  name: periodic-ipi-deprovision-aws-2
  reporter_config:
    slack:
      channel: '#ops-testplatform'
      job_states_to_report:
      - failure
      - error
      report_template: '@aws-ci-admin Job *{{.Spec.Job}}* failed. <{{.Status.URL}}|View
        logs>'
  spec:
    containers:
    - command:
      - ./core-services/ipi-deprovision/aws.sh
      env:
      - name: HOME
        value: /tmp
      - name: AWS_SHARED_CREDENTIALS_FILE
        value: /aws/.awscred
      - name: CLUSTER_TTL
        value: 30 minutes ago
      image: quay-proxy.ci.openshift.org/openshift/ci:ci_ipi-deprovision_latest
      imagePullPolicy: Always
      name: ipi-deprovision
      resources:
        requests:
          cpu: "1"
          memory: 600Mi
      volumeMounts:
      - mountPath: /aws
        name: cluster-secrets-aws
    nodeSelector:
      beta.kubernetes.io/arch: amd64
    serviceAccountName: ipi-deprovisioner
    volumes:
    - name: cluster-secrets-aws
      secret:
        items:
        - key: .awscred
          path: .awscred
        secretName: cluster-secrets-aws-2
- agent: kubernetes
  cluster: build04
  decorate: true
  decoration_config:
    timeout: 8h0m0s
  extra_refs:
  - base_ref: master
    org: openshift
    repo: release
    workdir: true
  interval: 5m
  labels:
    pj-rehearse.openshift.io/can-be-rehearsed: "true"
  max_concurrency: 1
  name: periodic-ipi-deprovision-aws-3
  reporter_config:
    slack:
      channel: '#ops-testplatform'
      job_states_to_report:
      - failure
      - error
      report_template: '@aws-ci-admin Job *{{.Spec.Job}}* failed. <{{.Status.URL}}|View
        logs>'
  spec:
    containers:
    - command:
      - ./core-services/ipi-deprovision/aws.sh
      env:
      - name: HOME
        value: /tmp
      - name: AWS_SHARED_CREDENTIALS_FILE
        value: /aws/.awscred
      - name: CLUSTER_TTL
        value: 30 minutes ago
      image: quay-proxy.ci.openshift.org/openshift/ci:ci_ipi-deprovision_latest
      imagePullPolicy: Always
      name: ipi-deprovision
      resources:
        requests:
          cpu: "1"
          memory: 600Mi
      volumeMounts:
      - mountPath: /aws
        name: cluster-secrets-aws
    nodeSelector:
      beta.kubernetes.io/arch: amd64
    serviceAccountName: ipi-deprovisioner
    volumes:
    - name: cluster-secrets-aws
      secret:
        items:
        - key: .awscred
          path: .awscred
        secretName: cluster-secrets-aws-3
- agent: kubernetes
  cluster: build04
  decorate: true
  decoration_config:
    timeout: 8h0m0s
  extra_refs:
  - base_ref: master
    org: openshift
    repo: release
    workdir: true
  interval: 5m
  labels:
    pj-rehearse.openshift.io/can-be-rehearsed: "true"
  max_concurrency: 1
  name: periodic-ipi-deprovision-aws-4
  reporter_config:
    slack:
      channel: '#ops-testplatform'
      job_states_to_report:
      - failure
      - error
      report_template: '@aws-ci-admin Job *{{.Spec.Job}}* failed. <{{.Status.URL}}|View
        logs>'
  spec:
    containers:
    - command:
      - ./core-services/ipi-deprovision/aws.sh
      env:
      - name: HOME
        value: /tmp
      - name: AWS_SHARED_CREDENTIALS_FILE
        value: /aws/.awscred
      - name: CLUSTER_TTL
        value: 30 minutes ago
      image: quay-proxy.ci.openshift.org/openshift/ci:ci_ipi-deprovision_latest
      imagePullPolicy: Always
      name: ipi-deprovision
      resources:
        requests:
          cpu: "1"
          memory: 600Mi
      volumeMounts:
      - mountPath: /aws
        name: cluster-secrets-aws
    nodeSelector:
      beta.kubernetes.io/arch: amd64
    serviceAccountName: ipi-deprovisioner
    volumes:
    - name: cluster-secrets-aws
      secret:
        items:
        - key: .awscred
          path: .awscred
        secretName: cluster-secrets-aws-4
- agent: kubernetes
  cluster: build04
  decorate: true
  decoration_config:
    timeout: 8h0m0s
  extra_refs:
  - base_ref: master
    org: openshift
    repo: release
    workdir: true
  interval: 5m
  labels:
    pj-rehearse.openshift.io/can-be-rehearsed: "true"
  max_concurrency: 1
  name: periodic-ipi-deprovision-aws-5
  reporter_config:
    slack:
      channel: '#ops-testplatform'
      job_states_to_report:
      - failure
      - error
      report_template: '@aws-ci-admin Job *{{.Spec.Job}}* failed. <{{.Status.URL}}|View
        logs>'
  spec:
    containers:
    - command:
      - ./core-services/ipi-deprovision/aws.sh
      env:
      - name: HOME
        value: /tmp
      - name: AWS_SHARED_CREDENTIALS_FILE
        value: /aws/.awscred
      - name: CLUSTER_TTL
        value: 30 minutes ago
      image: quay-proxy.ci.openshift.org/openshift/ci:ci_ipi-deprovision_latest
      imagePullPolicy: Always
      name: ipi-deprovision
      resources:
        requests:
          cpu: "1"
          memory: 600Mi
      volumeMounts:
      - mountPath: /aws
        name: cluster-secrets-aws
    nodeSelector:
      beta.kubernetes.io/arch: amd64
    serviceAccountName: ipi-deprovisioner
    volumes:
    - name: cluster-secrets-aws
      secret:
        items:
        - key: .awscred
          path: .awscred
        secretName: cluster-secrets-aws-5
- agent: kubernetes
  cluster: build04
  decorate: true
  decoration_config:
    timeout: 8h0m0s
  extra_refs:
  - base_ref: master
    org: openshift
    repo: release
    workdir: true
  interval: 5m
  labels:
    ci.openshift.io/role: cloud-gcp
    pj-rehearse.openshift.io/can-be-rehearsed: "true"
  max_concurrency: 1
  name: periodic-ipi-deprovision-gcp
  reporter_config:
    slack:
      channel: '#ops-testplatform'
      job_states_to_report:
      - failure
      - error
      report_template: '@gcp-ci-admin Job *{{.Spec.Job}}* failed. <{{.Status.URL}}|View
        logs>'
  spec:
    containers:
    - command:
      - ./core-services/ipi-deprovision/gcp.sh
      env:
      - name: HOME
        value: /tmp
      - name: GCP_PROJECT
        value: openshift-gce-devel-ci
      - name: GOOGLE_APPLICATION_CREDENTIALS
        value: /gcp/gce.json
      - name: CLUSTER_TTL
        value: 30 minutes ago
      image: quay-proxy.ci.openshift.org/openshift/ci:ci_ipi-deprovision_latest
      imagePullPolicy: Always
      name: ipi-deprovision
      resources:
        requests:
          cpu: "1"
          memory: 600Mi
      volumeMounts:
      - mountPath: /gcp
        name: cluster-secrets-gcp
    nodeSelector:
      beta.kubernetes.io/arch: amd64
    serviceAccountName: ipi-deprovisioner
    volumes:
    - name: cluster-secrets-gcp
      secret:
        items:
        - key: gce.json
          path: gce.json
        secretName: cluster-secrets-gcp
- agent: kubernetes
  cluster: build04
  decorate: true
  decoration_config:
    timeout: 8h0m0s
  extra_refs:
  - base_ref: master
    org: openshift
    repo: release
    workdir: true
  interval: 5m
  labels:
    ci.openshift.io/role: cloud-gcp
    pj-rehearse.openshift.io/can-be-rehearsed: "true"
  max_concurrency: 1
  name: periodic-ipi-deprovision-gcp-3
  reporter_config:
    slack:
      channel: '#ops-testplatform'
      job_states_to_report:
      - failure
      - error
      report_template: '@gcp-ci-admin Job *{{.Spec.Job}}* failed. <{{.Status.URL}}|View
        logs>'
  spec:
    containers:
    - command:
      - ./core-services/ipi-deprovision/gcp.sh
      env:
      - name: HOME
        value: /tmp
      - name: GCP_PROJECT
        value: openshift-gce-devel-ci-3
      - name: GOOGLE_APPLICATION_CREDENTIALS
        value: /gcp/gce.json
      - name: CLUSTER_TTL
        value: 30 minutes ago
      image: quay-proxy.ci.openshift.org/openshift/ci:ci_ipi-deprovision_latest
      imagePullPolicy: Always
      name: ipi-deprovision
      resources:
        requests:
          cpu: "1"
          memory: 600Mi
      volumeMounts:
      - mountPath: /gcp
        name: cluster-secrets-gcp
    nodeSelector:
      beta.kubernetes.io/arch: amd64
    serviceAccountName: ipi-deprovisioner
    volumes:
    - name: cluster-secrets-gcp
      secret:
        items:
        - key: gce.json
          path: gce.json
        secretName: cluster-secrets-gcp-3
- agent: kubernetes
  cluster: build04
  decorate: true
  decoration_config:
    timeout: 8h0m0s
  extra_refs:
  - base_ref: master
    org: openshift
    repo: release
    workdir: true
  interval: 5m
  labels:
    ci.openshift.io/role: cloud-gcp
    pj-rehearse.openshift.io/can-be-rehearsed: "true"
  max_concurrency: 1
  name: periodic-ipi-deprovision-gcp-2
  reporter_config:
    slack:
      channel: '#ops-testplatform'
      job_states_to_report:
      - failure
      - error
      report_template: '@gcp-ci-admin Job *{{.Spec.Job}}* failed. <{{.Status.URL}}|View
        logs>'
  spec:
    containers:
    - command:
      - ./core-services/ipi-deprovision/gcp.sh
      env:
      - name: HOME
        value: /tmp
      - name: GCP_PROJECT
        value: openshift-gce-devel-ci-2
      - name: GOOGLE_APPLICATION_CREDENTIALS
        value: /gcp/gce.json
      - name: CLUSTER_TTL
        value: 30 minutes ago
      image: quay-proxy.ci.openshift.org/openshift/ci:ci_ipi-deprovision_latest
      imagePullPolicy: Always
      name: ipi-deprovision
      resources:
        requests:
          cpu: "1"
          memory: 600Mi
      volumeMounts:
      - mountPath: /gcp
        name: cluster-secrets-gcp-openshift-gce-devel-ci-2
    nodeSelector:
      beta.kubernetes.io/arch: amd64
    serviceAccountName: ipi-deprovisioner
    volumes:
    - name: cluster-secrets-gcp-openshift-gce-devel-ci-2
      secret:
        items:
        - key: gce.json
          path: gce.json
        secretName: cluster-secrets-gcp-openshift-gce-devel-ci-2
- agent: kubernetes
  cluster: build04
  cron: '@daily'
  decorate: true
  name: periodic-openshift-dptp-3312-hypershift-leaks-cleaner
  spec:
    containers:
    - command:
      - /cleanup-hypershift-leaks.sh
      env:
      - name: KUBECONFIG
        value: /kubeconfig/kubeconfig
      image: quay-proxy.ci.openshift.org/openshift/ci:ci_dptp-3312-hypershift-leaks-cleaner_latest
      imagePullPolicy: Always
      name: ""
      resources:
        requests:
          cpu: 500m
      volumeMounts:
      - mountPath: /cluster-profiles/aws
        name: aws-token
        readOnly: true
      - mountPath: /cluster-profiles/aws-2
        name: aws-2-token
        readOnly: true
      - mountPath: /cluster-profiles/aws-3
        name: aws-3-token
        readOnly: true
      - mountPath: /cluster-profiles/aws-4
        name: aws-4-token
        readOnly: true
      - mountPath: /cluster-profiles/aws-5
        name: aws-5-token
        readOnly: true
      - mountPath: /kubeconfig
        name: hive
        readOnly: true
    volumes:
    - name: aws-token
      secret:
        secretName: cluster-secrets-aws
    - name: aws-2-token
      secret:
        secretName: cluster-secrets-aws-2
    - name: aws-3-token
      secret:
        secretName: cluster-secrets-aws-3
    - name: aws-4-token
      secret:
        secretName: cluster-secrets-aws-4
    - name: aws-5-token
      secret:
        secretName: cluster-secrets-aws-5
    - name: hive
      secret:
        secretName: hypershift-workload-credentials
- agent: kubernetes
  cluster: build04
  cron: '@daily'
  decorate: true
  decoration_config:
    timeout: 1h0m0s
  labels:
    pj-rehearse.openshift.io/can-be-rehearsed: "true"
  name: periodic-openshift-dptp-4552-clusterpool-pruner
  reporter_config:
    slack:
      channel: '#team-hive-alert'
      job_states_to_report:
      - failure
      - error
      - success
      report_template: 'Job {{.Spec.Job}}: <{{.Status.URL}}|View logs>'
  spec:
    containers:
    - command:
      - sh
      - -c
      - |
        set -e
        set -o pipefail
        echo "Discovering configured ClusterPools..."
        find clusters/hosted-mgmt/hive/pools -type f -name '*.yaml' | xargs grep 'kind: ClusterPool' | awk -F: '{print $1}' | xargs /tmp/yq e '[.metadata.namespace, .metadata.name] | join(" ")' | sort > /tmp/clusterpools.configured
        if ! [[ -s /tmp/clusterpools.configured ]]; then
          echo "ERROR: Discovered no configured ClusterPools. This probably means something is wrong. Aborting."
          exit 1
        fi
        echo "Getting extant ClusterPools..."
        oc --context hosted-mgmt get clusterpool -A -o jsonpath='{range .items[*]}{.metadata.namespace} {.metadata.name}{"\n"}{end}' | sort > /tmp/clusterpools.extant
        comm -13 /tmp/clusterpools.configured /tmp/clusterpools.extant > /tmp/clusterpools.stale
        if [[ -s /tmp/clusterpools.stale ]]; then
          stale_count=$(wc -l < /tmp/clusterpools.stale)
          echo "Found $stale_count zombie clusterpool(s) to clean up:"
          while read ns name; do
            if [[ $JOB_NAME == rehearse-* ]]; then
              echo "    [REHEARSAL] Would delete: oc --context hosted-mgmt delete clusterpool -n $ns $name"
            else
              echo "Deleting zombie clusterpools"
              oc --context hosted-mgmt delete clusterpool -n $ns $name
            fi
          done < /tmp/clusterpools.stale
        else
          echo "No zombie clusterpools to delete!"
        fi
      env:
      - name: KUBECONFIG
        value: /kubeconfig/kubeconfig
      image: quay-proxy.ci.openshift.org/openshift/ci:ocp_cli-yq_latest
      imagePullPolicy: Always
      name: ""
      resources:
        requests:
          cpu: 500m
      volumeMounts:
      - mountPath: /kubeconfig
        name: kc
        readOnly: true
    volumes:
    - name: kc
      secret:
        secretName: hive-hive-credentials
