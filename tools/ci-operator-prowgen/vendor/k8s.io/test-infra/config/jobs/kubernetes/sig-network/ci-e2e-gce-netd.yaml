presets:
- labels:
    preset-kubernetes-e2e-enable-netd: "true"
  env:
  - name: KUBE_CUSTOM_NETD_YAML
    # we want to keep extra spaces for the yaml file.
    value: |2+
        kind: ClusterRole
        apiVersion: rbac.authorization.k8s.io/v1
        metadata:
          name: netd
          namespace: kube-system
          labels:
            kubernetes.io/cluster-service: "true"
            addonmanager.kubernetes.io/mode: EnsureExists
        rules:
        - apiGroups: [""]
          resources: ["nodes"]
          verbs: ["get"]
        ---
        kind: ServiceAccount
        apiVersion: v1
        metadata:
          name: netd
          namespace: kube-system
          labels:
            kubernetes.io/cluster-service: "true"
            addonmanager.kubernetes.io/mode: EnsureExists
        ---
        kind: ClusterRoleBinding
        apiVersion: rbac.authorization.k8s.io/v1
        metadata:
          name: netd
          labels:
            kubernetes.io/cluster-service: "true"
            addonmanager.kubernetes.io/mode: EnsureExists
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: netd
        subjects:
        - kind: ServiceAccount
          name: netd
          namespace: kube-system
        ---
        kind: ConfigMap
        apiVersion: v1
        metadata:
          name: netd-config
          namespace: kube-system
          labels:
            addonmanager.kubernetes.io/mode: EnsureExists
        data:
          cni_spec_template: |-
            {
              "name": "k8s-pod-network",
              "cniVersion": "0.3.1",
              "plugins": [
                {
                  "type": "ptp",
                  "mtu": 1460,
                  "ipam": {
                      "type": "host-local",
                      "ranges": [
                      @ipv4Subnet@ipv6SubnetOptional
                      ],
                      "routes": [
                        {"dst": "0.0.0.0/0"}@ipv6RouteOptional
                      ]
                  }
                },
                {
                  "type": "portmap",
                  "capabilities": {
                    "portMappings": true
                  },
                  "noSnat": true
                }
              ]
            }
          cni_spec_name: "10-k8s-ptp.conflist"
          enable_policy_routing: "true"
          enable_masquerade: "true"
          enable_calico_network_policy: "false"
          enable_private_ipv6_access: "false"
        ---
        kind: DaemonSet
        apiVersion: extensions/v1beta1
        metadata:
          name: netd
          namespace: kube-system
          labels:
            k8s-app: netd
            addonmanager.kubernetes.io/mode: EnsureExists
        spec:
          selector:
            matchLabels:
              k8s-app: netd
          template:
            metadata:
              labels:
                k8s-app: netd
            spec:
              priorityClassName: system-node-critical
              serviceAccountName: netd
              terminationGracePeriodSeconds: 0
              nodeSelector:
                beta.kubernetes.io/kube-netd-ready: "true"
              hostNetwork: true
              initContainers:
              - image: gcr.io/google-containers/netd-amd64:0.1.5
                name: install-cni
                command: ["sh", "/install-cni.sh"]
                env:
                  - name: CNI_SPEC_TEMPLATE
                    valueFrom:
                      configMapKeyRef:
                        name: netd-config
                        key: cni_spec_template
                  - name: CNI_SPEC_NAME
                    valueFrom:
                      configMapKeyRef:
                        name: netd-config
                        key: cni_spec_name
                  - name: ENABLE_CALICO_NETWORK_POLICY
                    valueFrom:
                      configMapKeyRef:
                        name: netd-config
                        key: enable_calico_network_policy
                  - name: ENABLE_PRIVATE_IPV6_ACCESS
                    valueFrom:
                      configMapKeyRef:
                        name: netd-config
                        key: enable_private_ipv6_access
                volumeMounts:
                - mountPath: /host/etc/cni/net.d
                  name: cni-net-dir
              containers:
              - image: gcr.io/google-containers/netd-amd64:0.1.5
                name: netd
                imagePullPolicy: Always
                securityContext:
                  privileged: true
                  capabilities:
                    add: ["NET_ADMIN"]
                args:
                - --enable-policy-routing=$(ENABLE_POLICY_ROUTING)
                - --enable-masquerade=$(ENABLE_MASQUERADE)
                - --logtostderr
                env:
                  - name: ENABLE_POLICY_ROUTING
                    valueFrom:
                      configMapKeyRef:
                        name: netd-config
                        key: enable_policy_routing
                  - name: ENABLE_MASQUERADE
                    valueFrom:
                      configMapKeyRef:
                        name: netd-config
                        key: enable_masquerade
              volumes:
              - name: cni-net-dir
                hostPath:
                  path: /etc/cni/net.d
  - name: KUBE_UP_AUTOMATIC_CLEANUP
    value: true
  - name: KUBE_GCE_ENABLE_IP_ALIASES
    value: true
  - name: KUBE_ENABLE_NETD
    value: true

- labels:
    preset-kubernetes-e2e-enable-netd-calico: "true"
  env:
  - name: KUBE_CUSTOM_NETD_YAML
    # we want to keep extra spaces for the yaml file.
    value: |2+
        kind: ClusterRole
        apiVersion: rbac.authorization.k8s.io/v1
        metadata:
          name: netd
          namespace: kube-system
          labels:
            kubernetes.io/cluster-service: "true"
            addonmanager.kubernetes.io/mode: EnsureExists
        rules:
        - apiGroups: [""]
          resources: ["nodes"]
          verbs: ["get"]
        ---
        kind: ServiceAccount
        apiVersion: v1
        metadata:
          name: netd
          namespace: kube-system
          labels:
            kubernetes.io/cluster-service: "true"
            addonmanager.kubernetes.io/mode: EnsureExists
        ---
        kind: ClusterRoleBinding
        apiVersion: rbac.authorization.k8s.io/v1
        metadata:
          name: netd
          labels:
            kubernetes.io/cluster-service: "true"
            addonmanager.kubernetes.io/mode: EnsureExists
        roleRef:
          apiGroup: rbac.authorization.k8s.io
          kind: ClusterRole
          name: netd
        subjects:
        - kind: ServiceAccount
          name: netd
          namespace: kube-system
        ---
        kind: ConfigMap
        apiVersion: v1
        metadata:
          name: netd-config
          namespace: kube-system
          labels:
            addonmanager.kubernetes.io/mode: EnsureExists
        data:
          cni_spec_template: |-
            {
              "name": "k8s-pod-network",
              "cniVersion": "0.3.1",
              "plugins": [
                {
                  "type": "ptp",
                  "mtu": 1460,
                  "ipam": {
                      "type": "host-local",
                      "ranges": [
                      @ipv4Subnet@ipv6SubnetOptional
                      ],
                      "routes": [
                        {"dst": "0.0.0.0/0"}@ipv6RouteOptional
                      ]
                  }
                },
                {
                  "type": "portmap",
                  "capabilities": {
                    "portMappings": true
                  },
                  "noSnat": true
                }
              ]
            }
          cni_spec_name: "10-k8s-ptp.conflist"
          enable_policy_routing: "true"
          enable_masquerade: "true"
          enable_calico_network_policy: "true"
          enable_private_ipv6_access: "false"
        ---
        kind: DaemonSet
        apiVersion: extensions/v1beta1
        metadata:
          name: netd
          namespace: kube-system
          labels:
            k8s-app: netd
            addonmanager.kubernetes.io/mode: EnsureExists
        spec:
          selector:
            matchLabels:
              k8s-app: netd
          template:
            metadata:
              labels:
                k8s-app: netd
            spec:
              priorityClassName: system-node-critical
              serviceAccountName: netd
              terminationGracePeriodSeconds: 0
              nodeSelector:
                beta.kubernetes.io/kube-netd-ready: "true"
              hostNetwork: true
              initContainers:
              - image: gcr.io/google-containers/netd-amd64:0.1.5
                name: install-cni
                command: ["sh", "/install-cni.sh"]
                env:
                  - name: CNI_SPEC_TEMPLATE
                    valueFrom:
                      configMapKeyRef:
                        name: netd-config
                        key: cni_spec_template
                  - name: CNI_SPEC_NAME
                    valueFrom:
                      configMapKeyRef:
                        name: netd-config
                        key: cni_spec_name
                  - name: ENABLE_CALICO_NETWORK_POLICY
                    valueFrom:
                      configMapKeyRef:
                        name: netd-config
                        key: enable_calico_network_policy
                  - name: ENABLE_PRIVATE_IPV6_ACCESS
                    valueFrom:
                      configMapKeyRef:
                        name: netd-config
                        key: enable_private_ipv6_access
                volumeMounts:
                - mountPath: /host/etc/cni/net.d
                  name: cni-net-dir
              containers:
              - image: gcr.io/google-containers/netd-amd64:0.1.5
                name: netd
                imagePullPolicy: Always
                securityContext:
                  privileged: true
                  capabilities:
                    add: ["NET_ADMIN"]
                args:
                - --enable-policy-routing=$(ENABLE_POLICY_ROUTING)
                - --enable-masquerade=$(ENABLE_MASQUERADE)
                - --logtostderr
                env:
                  - name: ENABLE_POLICY_ROUTING
                    valueFrom:
                      configMapKeyRef:
                        name: netd-config
                        key: enable_policy_routing
                  - name: ENABLE_MASQUERADE
                    valueFrom:
                      configMapKeyRef:
                        name: netd-config
                        key: enable_masquerade
              volumes:
              - name: cni-net-dir
                hostPath:
                  path: /etc/cni/net.d
  - name: KUBE_UP_AUTOMATIC_CLEANUP
    value: true
  - name: KUBE_GCE_ENABLE_IP_ALIASES
    value: true
  - name: KUBE_ENABLE_NETD
    value: true
  - name: KUBE_CUSTOM_CALICO_NODE_DAEMONSET_YAML
    value: |2+
        kind: DaemonSet
        apiVersion: extensions/v1beta1
        metadata:
          name: calico-node
          namespace: kube-system
          labels:
            kubernetes.io/cluster-service: "true"
            addonmanager.kubernetes.io/mode: Reconcile
            k8s-app: calico-node
        spec:
          selector:
            matchLabels:
              k8s-app: calico-node
          updateStrategy:
            type: RollingUpdate
          template:
            metadata:
              labels:
                k8s-app: calico-node
              annotations:
                scheduler.alpha.kubernetes.io/critical-pod: ''
            spec:
              priorityClassName: system-node-critical
              nodeSelector:
                projectcalico.org/ds-ready: "true"
              hostNetwork: true
              serviceAccountName: calico
              # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a "force
              # deletion": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
              terminationGracePeriodSeconds: 0
              containers:
                # Runs calico/node container on each Kubernetes node.  This
                # container programs network policy and routes on each
                # host.
                - name: calico-node
                  image: gcr.io/projectcalico-org/node:v3.1.3
                  env:
                    - name: CALICO_DISABLE_FILE_LOGGING
                      value: "true"
                    - name: CALICO_NETWORKING_BACKEND
                      value: "none"
                    - name: DATASTORE_TYPE
                      value: "kubernetes"
                    - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
                      value: "ACCEPT"
                    - name: FELIX_HEALTHENABLED
                      value: "true"
                    - name: FELIX_IPTABLESMANGLEALLOWACTION
                      value: "RETURN"
                    - name: FELIX_IPV6SUPPORT
                      value: "false"
                    - name: FELIX_LOGSEVERITYSYS
                      value: "none"
                    - name: FELIX_LOGSEVERITYSCREEN
                      value: "info"
                    - name: FELIX_IGNORELOOSERPF
                      value: "true"
                    - name: FELIX_PROMETHEUSMETRICSENABLED
                      value: "true"
                    - name: FELIX_REPORTINGINTERVALSECS
                      value: "0"
                    - name: FELIX_TYPHAK8SSERVICENAME
                      value: "calico-typha"
                    - name: IP
                      value: ""
                    - name: NO_DEFAULT_POOLS
                      value: "true"
                    - name: NODENAME
                      valueFrom:
                        fieldRef:
                          fieldPath: spec.nodeName
                    - name: WAIT_FOR_DATASTORE
                      value: "true"
                  securityContext:
                    privileged: true
                  livenessProbe:
                    httpGet:
                      path: /liveness
                      port: 9099
                    periodSeconds: 10
                    initialDelaySeconds: 10
                    failureThreshold: 6
                  readinessProbe:
                    httpGet:
                      path: /readiness
                      port: 9099
                    periodSeconds: 10
                  volumeMounts:
                    - mountPath: /lib/modules
                      name: lib-modules
                      readOnly: true
                    - mountPath: /etc/calico
                      name: etc-calico
                      readOnly: true
                    - mountPath: /var/run/calico
                      name: var-run-calico
                      readOnly: false
                    - mountPath: /var/lib/calico
                      name: var-lib-calico
                      readOnly: false
                # This container installs the Calico CNI binaries
                # and CNI network config file on each node.
                - name: install-cni
                  image: gcr.io/projectcalico-org/cni:v3.1.3
                  command: ["/install-cni.sh"]
                  env:
                    - name: CNI_CONF_NAME
                      value: "10-calico.conflist"
                    - name: CNI_NETWORK_CONFIG
                      value: |-
                        {
                          "name": "k8s-pod-network",
                          "cniVersion": "0.3.0",
                          "plugins": [
                            {
                              "type": "calico",
                              "mtu": 1460,
                              "log_level": "debug",
                              "datastore_type": "kubernetes",
                              "nodename": "__KUBERNETES_NODE_NAME__",
                              "ipam": {
                                "type": "host-local",
                                "subnet": "usePodCidr"
                              },
                              "policy": {
                                "type": "k8s",
                                "k8s_auth_token": "__SERVICEACCOUNT_TOKEN__"
                              },
                              "kubernetes": {
                                "k8s_api_root": "https://__KUBERNETES_SERVICE_HOST__:__KUBERNETES_SERVICE_PORT__",
                                "kubeconfig": "__KUBECONFIG_FILEPATH__"
                              }
                            },
                            {
                              "type": "portmap",
                              "capabilities": {"portMappings": true},
                              "snat": true
                            }
                          ]
                        }
                    - name: KUBERNETES_NODE_NAME
                      valueFrom:
                        fieldRef:
                          fieldPath: spec.nodeName
                  volumeMounts:
                    - mountPath: /host/opt/cni/bin
                      name: cni-bin-dir
                    - mountPath: /host/etc/cni/net.d
                      name: cni-net-dir
              volumes:
                # Used to ensure proper kmods are installed.
                - name: lib-modules
                  hostPath:
                    path: /lib/modules
                # Mount in the Felix config file from the host.
                - name: etc-calico
                  hostPath:
                    path: /etc/calico
                # Used to install CNI binaries.
                - name: cni-bin-dir
                  hostPath:
                    path: __CALICO_CNI_DIR__
                # Used to install CNI network config.
                - name: cni-net-dir
                  hostPath:
                    path: /etc/cni/net.d
                - name: var-run-calico
                  hostPath:
                    path: /var/run/calico
                - name: var-lib-calico
                  hostPath:
                    path: /var/lib/calico
              tolerations:
                # Make sure calico/node gets scheduled on all nodes.
                - effect: NoSchedule
                  operator: Exists
                - effect: NoExecute
                  operator: Exists
                - key: CriticalAddonsOnly
                  operator: Exists
  - name: KUBE_CUSTOM_TYPHA_DEPLOYMENT_YAML
    value: |2+
        apiVersion: extensions/v1beta1
        kind: Deployment
        metadata:
          name: calico-typha
          namespace: kube-system
          labels:
            kubernetes.io/cluster-service: "true"
            addonmanager.kubernetes.io/mode: Reconcile
            k8s-app: calico-typha
        spec:
          revisionHistoryLimit: 2
          template:
            metadata:
              labels:
                k8s-app: calico-typha
              annotations:
                scheduler.alpha.kubernetes.io/critical-pod: ''
            spec:
              priorityClassName: system-cluster-critical
              tolerations:
              - key: CriticalAddonsOnly
                operator: Exists
              hostNetwork: true
              serviceAccountName: calico
              containers:
              - image: gcr.io/projectcalico-org/typha:v0.7.4
                name: calico-typha
                ports:
                - containerPort: 5473
                  name: calico-typha
                  protocol: TCP
                env:
                  - name: TYPHA_LOGFILEPATH
                    value: "none"
                  - name: TYPHA_LOGSEVERITYSYS
                    value: "none"
                  - name: TYPHA_LOGSEVERITYSCREEN
                    value: "info"
                  - name: TYPHA_PROMETHEUSMETRICSENABLED
                    value: "true"
                  - name: TYPHA_CONNECTIONREBALANCINGMODE
                    value: "kubernetes"
                  - name: TYPHA_REPORTINGINTERVALSECS
                    value: "0"
                  - name: TYPHA_PROMETHEUSMETRICSPORT
                    value: "9093"
                  - name: TYPHA_DATASTORETYPE
                    value: "kubernetes"
                  - name: TYPHA_MAXCONNECTIONSLOWERLIMIT
                    value: "1"
                  - name: TYPHA_HEALTHENABLED
                    value: "true"
                volumeMounts:
                - mountPath: /etc/calico
                  name: etc-calico
                  readOnly: true
                livenessProbe:
                  httpGet:
                    path: /liveness
                    port: 9098
                  periodSeconds: 30
                  initialDelaySeconds: 30
                readinessProbe:
                  httpGet:
                    path: /readiness
                    port: 9098
                  periodSeconds: 10
              volumes:
              - name: etc-calico
                hostPath:
                  path: /etc/calico

- labels:
    preset-kubernetes-e2e-containerd: "true"
  env:
  - name: LOG_DUMP_SYSTEMD_SERVICES
    value: containerd containerd-installation
  - name: KUBE_MASTER_EXTRA_METADATA
    value: user-data=/go/src/github.com/containerd/cri/test/e2e/master.yaml,containerd-configure-sh=/go/src/github.com/containerd/cri/cluster/gce/configure.sh,containerd-env=/workspace/test-infra/jobs/e2e_node/containerd/cri-master/env
  - name: KUBE_NODE_EXTRA_METADATA
    value: user-data=/go/src/github.com/containerd/cri/test/e2e/node.yaml,containerd-configure-sh=/go/src/github.com/containerd/cri/cluster/gce/configure.sh,containerd-env=/workspace/test-infra/jobs/e2e_node/containerd/cri-master/env
  - name: KUBE_CONTAINER_RUNTIME
    value: remote
  - name: KUBE_CONTAINER_RUNTIME_ENDPOINT
    value: unix:///run/containerd/containerd.sock
  - name: KUBE_CONTAINER_RUNTIME_NAME
    value: containerd
  - name: KUBE_LOAD_IMAGE_COMMAND
    value: /home/containerd/usr/local/bin/ctr cri load
  - name: KUBELET_TEST_ARGS
    value: --runtime-cgroups=/system.slice/containerd.service

- labels:
    preset-kubernetes-e2e-enable-calico: "true"
  env:
  - name: KUBE_UP_AUTOMATIC_CLEANUP
    value: true
  - name: KUBE_CUSTOM_CALICO_NODE_DAEMONSET_YAML
    value: |2+
        kind: DaemonSet
        apiVersion: extensions/v1beta1
        metadata:
          name: calico-node
          namespace: kube-system
          labels:
            kubernetes.io/cluster-service: "true"
            addonmanager.kubernetes.io/mode: Reconcile
            k8s-app: calico-node
        spec:
          selector:
            matchLabels:
              k8s-app: calico-node
          updateStrategy:
            type: RollingUpdate
          template:
            metadata:
              labels:
                k8s-app: calico-node
              annotations:
                scheduler.alpha.kubernetes.io/critical-pod: ''
            spec:
              priorityClassName: system-node-critical
              nodeSelector:
                projectcalico.org/ds-ready: "true"
              hostNetwork: true
              serviceAccountName: calico
              # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a "force
              # deletion": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
              terminationGracePeriodSeconds: 0
              containers:
                # Runs calico/node container on each Kubernetes node.  This
                # container programs network policy and routes on each
                # host.
                - name: calico-node
                  image: gcr.io/projectcalico-org/node:v3.1.3
                  env:
                    - name: CALICO_DISABLE_FILE_LOGGING
                      value: "true"
                    - name: CALICO_NETWORKING_BACKEND
                      value: "none"
                    - name: DATASTORE_TYPE
                      value: "kubernetes"
                    - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
                      value: "ACCEPT"
                    - name: FELIX_HEALTHENABLED
                      value: "true"
                    - name: FELIX_IPTABLESMANGLEALLOWACTION
                      value: "RETURN"
                    - name: FELIX_IPV6SUPPORT
                      value: "false"
                    - name: FELIX_LOGSEVERITYSYS
                      value: "none"
                    - name: FELIX_LOGSEVERITYSCREEN
                      value: "info"
                    - name: FELIX_IGNORELOOSERPF
                      value: "true"
                    - name: FELIX_PROMETHEUSMETRICSENABLED
                      value: "true"
                    - name: FELIX_REPORTINGINTERVALSECS
                      value: "0"
                    - name: FELIX_TYPHAK8SSERVICENAME
                      value: "calico-typha"
                    - name: IP
                      value: ""
                    - name: NO_DEFAULT_POOLS
                      value: "true"
                    - name: NODENAME
                      valueFrom:
                        fieldRef:
                          fieldPath: spec.nodeName
                    - name: WAIT_FOR_DATASTORE
                      value: "true"
                  securityContext:
                    privileged: true
                  livenessProbe:
                    httpGet:
                      path: /liveness
                      port: 9099
                    periodSeconds: 10
                    initialDelaySeconds: 10
                    failureThreshold: 6
                  readinessProbe:
                    httpGet:
                      path: /readiness
                      port: 9099
                    periodSeconds: 10
                  volumeMounts:
                    - mountPath: /lib/modules
                      name: lib-modules
                      readOnly: true
                    - mountPath: /etc/calico
                      name: etc-calico
                      readOnly: true
                    - mountPath: /var/run/calico
                      name: var-run-calico
                      readOnly: false
                    - mountPath: /var/lib/calico
                      name: var-lib-calico
                      readOnly: false
                # This container installs the Calico CNI binaries
                # and CNI network config file on each node.
                - name: install-cni
                  image: gcr.io/projectcalico-org/cni:v3.1.3
                  command: ["/install-cni.sh"]
                  env:
                    - name: CNI_CONF_NAME
                      value: "10-calico.conflist"
                    - name: CNI_NETWORK_CONFIG
                      value: |-
                        {
                          "name": "k8s-pod-network",
                          "cniVersion": "0.3.0",
                          "plugins": [
                            {
                              "type": "calico",
                              "mtu": 1460,
                              "log_level": "debug",
                              "datastore_type": "kubernetes",
                              "nodename": "__KUBERNETES_NODE_NAME__",
                              "ipam": {
                                "type": "host-local",
                                "subnet": "usePodCidr"
                              },
                              "policy": {
                                "type": "k8s",
                                "k8s_auth_token": "__SERVICEACCOUNT_TOKEN__"
                              },
                              "kubernetes": {
                                "k8s_api_root": "https://__KUBERNETES_SERVICE_HOST__:__KUBERNETES_SERVICE_PORT__",
                                "kubeconfig": "__KUBECONFIG_FILEPATH__"
                              }
                            },
                            {
                              "type": "portmap",
                              "capabilities": {"portMappings": true},
                              "snat": true
                            }
                          ]
                        }
                    - name: KUBERNETES_NODE_NAME
                      valueFrom:
                        fieldRef:
                          fieldPath: spec.nodeName
                  volumeMounts:
                    - mountPath: /host/opt/cni/bin
                      name: cni-bin-dir
                    - mountPath: /host/etc/cni/net.d
                      name: cni-net-dir
              volumes:
                # Used to ensure proper kmods are installed.
                - name: lib-modules
                  hostPath:
                    path: /lib/modules
                # Mount in the Felix config file from the host.
                - name: etc-calico
                  hostPath:
                    path: /etc/calico
                # Used to install CNI binaries.
                - name: cni-bin-dir
                  hostPath:
                    path: __CALICO_CNI_DIR__
                # Used to install CNI network config.
                - name: cni-net-dir
                  hostPath:
                    path: /etc/cni/net.d
                - name: var-run-calico
                  hostPath:
                    path: /var/run/calico
                - name: var-lib-calico
                  hostPath:
                    path: /var/lib/calico
              tolerations:
                # Make sure calico/node gets scheduled on all nodes.
                - effect: NoSchedule
                  operator: Exists
                - effect: NoExecute
                  operator: Exists
                - key: CriticalAddonsOnly
                  operator: Exists
  - name: KUBE_CUSTOM_TYPHA_DEPLOYMENT_YAML
    value: |2+
        apiVersion: extensions/v1beta1
        kind: Deployment
        metadata:
          name: calico-typha
          namespace: kube-system
          labels:
            kubernetes.io/cluster-service: "true"
            addonmanager.kubernetes.io/mode: Reconcile
            k8s-app: calico-typha
        spec:
          revisionHistoryLimit: 2
          template:
            metadata:
              labels:
                k8s-app: calico-typha
              annotations:
                scheduler.alpha.kubernetes.io/critical-pod: ''
            spec:
              priorityClassName: system-cluster-critical
              tolerations:
              - key: CriticalAddonsOnly
                operator: Exists
              hostNetwork: true
              serviceAccountName: calico
              containers:
              - image: gcr.io/projectcalico-org/typha:v0.7.4
                name: calico-typha
                ports:
                - containerPort: 5473
                  name: calico-typha
                  protocol: TCP
                env:
                  - name: TYPHA_LOGFILEPATH
                    value: "none"
                  - name: TYPHA_LOGSEVERITYSYS
                    value: "none"
                  - name: TYPHA_LOGSEVERITYSCREEN
                    value: "info"
                  - name: TYPHA_PROMETHEUSMETRICSENABLED
                    value: "true"
                  - name: TYPHA_CONNECTIONREBALANCINGMODE
                    value: "kubernetes"
                  - name: TYPHA_REPORTINGINTERVALSECS
                    value: "0"
                  - name: TYPHA_PROMETHEUSMETRICSPORT
                    value: "9093"
                  - name: TYPHA_DATASTORETYPE
                    value: "kubernetes"
                  - name: TYPHA_MAXCONNECTIONSLOWERLIMIT
                    value: "1"
                  - name: TYPHA_HEALTHENABLED
                    value: "true"
                volumeMounts:
                - mountPath: /etc/calico
                  name: etc-calico
                  readOnly: true
                livenessProbe:
                  httpGet:
                    path: /liveness
                    port: 9098
                  periodSeconds: 30
                  initialDelaySeconds: 30
                readinessProbe:
                  httpGet:
                    path: /readiness
                    port: 9098
                  periodSeconds: 10
              volumes:
              - name: etc-calico
                hostPath:
                  path: /etc/calico
  - name: NETWORK_POLICY_PROVIDER
    value: calico

periodics:
- interval: 2h
  name: ci-kubernetes-e2e-gci-gce-netd
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-kubernetes-e2e-enable-netd: "true"
  spec:
    containers:
    - args:
      - "--timeout=340"
      - --root=/go/src
      - "--repo=k8s.io/kubernetes=release-1.11"
      - "--repo=k8s.io/examples=master"
      - --scenario=kubernetes_e2e
      - --
      - --extract=gs://koonwah-repo-pub/devel/v1.11.2-beta.0.20+21777efd99bd59
      - --check-leaked-resources
      - --gcp-node-image=gci
      - --gcp-zone=asia-southeast1-a
      - --provider=gce
      - --test_args=--ginkgo.focus=\[sig-network\] --ginkgo.skip=\[Slow\]|\[Flaky\]|\[Feature:NetworkPolicy\]|\[Feature:Networking-IPv6\]|\[Disruptive\]|\[Feature:ServiceLoadBalancer\]|\[Feature:PerformanceDNS\] --minStartupPods=8
      - --timeout=120m
      image: gcr.io/k8s-testimages/kubekins-e2e:v20180730-8b7ab3104-master

- interval: 2h
  name: ci-kubernetes-e2e-gci-gce-netd-calico
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-kubernetes-e2e-enable-netd-calico: "true"
  spec:
    containers:
    - args:
      - "--timeout=340"
      - --root=/go/src
      - "--repo=k8s.io/examples=master"
      - --scenario=kubernetes_e2e
      - --
      - --extract=gs://koonwah-repo-pub/devel/v1.11.2-beta.0.20+21777efd99bd59
      - --check-leaked-resources
      - --gcp-node-image=gci
      - --gcp-zone=asia-southeast1-a
      - --provider=gce
      - --test_args=--ginkgo.focus=\[sig-network\] --ginkgo.skip=\[Slow\]|\[Flaky\]|\[Feature:Networking-IPv6\]|\[Disruptive\]|\[Feature:ServiceLoadBalancer\]|\[Feature:PerformanceDNS\] --minStartupPods=8
      - --timeout=120m
      image: gcr.io/k8s-testimages/kubekins-e2e:v20180730-8b7ab3104-master
      env:
      - name: NETWORK_POLICY_PROVIDER
        value: calico

- interval: 2h
  name: ci-kubernetes-e2e-ubuntu-gce-netd
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-kubernetes-e2e-enable-netd: "true"
  spec:
    containers:
    - args:
      - "--timeout=340"
      - --root=/go/src
      - "--repo=k8s.io/kubernetes=release-1.11"
      - "--repo=k8s.io/examples=master"
      - --scenario=kubernetes_e2e
      - --
      - --extract=gs://koonwah-repo-pub/devel/v1.11.2-beta.0.20+21777efd99bd59
      - --check-leaked-resources
      - --image-family=ubuntu-gke-1604-lts
      - --image-project=ubuntu-os-gke-cloud
      - --gcp-zone=asia-southeast1-a
      - --provider=gce
      - --test_args=--ginkgo.focus=\[sig-network\] --ginkgo.skip=\[Slow\]|\[Flaky\]|\[Feature:NetworkPolicy\]|\[Feature:Networking-IPv6\]|\[Disruptive\]|\[Feature:ServiceLoadBalancer\]|\[Feature:PerformanceDNS\] --minStartupPods=8
      - --timeout=120m
      image: gcr.io/k8s-testimages/kubekins-e2e:v20180730-8b7ab3104-master

- interval: 2h
  name: ci-kubernetes-e2e-ubuntu-gce-netd-calico
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-kubernetes-e2e-enable-netd-calico: "true"
  spec:
    containers:
    - args:
      - "--timeout=340"
      - --root=/go/src
      - --scenario=kubernetes_e2e
      - "--repo=k8s.io/examples=master"
      - --
      - --extract=gs://koonwah-repo-pub/devel/v1.11.2-beta.0.20+21777efd99bd59
      - --check-leaked-resources
      - --image-family=ubuntu-gke-1604-lts
      - --image-project=ubuntu-os-gke-cloud
      - --gcp-zone=asia-southeast1-a
      - --provider=gce
      - --test_args=--ginkgo.focus=\[sig-network\] --ginkgo.skip=\[Slow\]|\[Flaky\]|\[Feature:Networking-IPv6\]|\[Disruptive\]|\[Feature:ServiceLoadBalancer\]|\[Feature:PerformanceDNS\] --minStartupPods=8
      - --timeout=120m
      image: gcr.io/k8s-testimages/kubekins-e2e:v20180730-8b7ab3104-master
      env:
      - name: NETWORK_POLICY_PROVIDER
        value: calico

- interval: 2h
  name: ci-kubernetes-e2e-containerd-gce-netd
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-kubernetes-e2e-enable-netd: "true"
    preset-kubernetes-e2e-containerd: "true"
  spec:
    containers:
    - args:
      - "--timeout=340"
      - --root=/go/src
      - --repo=github.com/containerd/cri=master
      - "--repo=k8s.io/examples=master"
      - --scenario=kubernetes_e2e
      - --
      - --check-leaked-resources
      - --env=KUBE_MASTER_EXTRA_METADATA=user-data=/go/src/github.com/containerd/cri/test/e2e/master.yaml,containerd-configure-sh=/go/src/github.com/containerd/cri/cluster/gce/configure.sh,containerd-env=/workspace/test-infra/jobs/e2e_node/containerd/containerd-master/env
      - --env=KUBE_NODE_EXTRA_METADATA=user-data=/go/src/github.com/containerd/cri/test/e2e/node.yaml,containerd-configure-sh=/go/src/github.com/containerd/cri/cluster/gce/configure.sh,containerd-env=/workspace/test-infra/jobs/e2e_node/containerd/containerd-master/env
      - --extract=gs://koonwah-repo-pub/devel/v1.11.2-beta.0.20+21777efd99bd59
      - --gcp-node-image=gci
      - --gcp-nodes=4
      - --gcp-zone=asia-southeast1-a
      - --ginkgo-parallel=30
      - --provider=gce
      - --test_args=--ginkgo.focus=\[sig-network\] --ginkgo.skip=\[Slow\]|\[Flaky\]|\[Feature:NetworkPolicy\]|\[Feature:Networking-IPv6\]|\[Disruptive\]|\[Feature:ServiceLoadBalancer\]|\[Feature:PerformanceDNS\] --minStartupPods=8
      - --timeout=120m
      image: gcr.io/k8s-testimages/kubekins-e2e:v20180730-8b7ab3104-master

- interval: 2h
  name: ci-kubernetes-e2e-containerd-gce-netd-calico
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-kubernetes-e2e-containerd: "true"
    preset-kubernetes-e2e-enable-netd-calico: "true"
  spec:
    containers:
    - args:
      - "--timeout=340"
      - --root=/go/src
      - --repo=github.com/containerd/cri=master
      - "--repo=k8s.io/examples=master"
      - --scenario=kubernetes_e2e
      - --
      - --check-leaked-resources
      - --env=KUBE_MASTER_EXTRA_METADATA=user-data=/go/src/github.com/containerd/cri/test/e2e/master.yaml,containerd-configure-sh=/go/src/github.com/containerd/cri/cluster/gce/configure.sh,containerd-env=/workspace/test-infra/jobs/e2e_node/containerd/containerd-master/env
      - --env=KUBE_NODE_EXTRA_METADATA=user-data=/go/src/github.com/containerd/cri/test/e2e/node.yaml,containerd-configure-sh=/go/src/github.com/containerd/cri/cluster/gce/configure.sh,containerd-env=/workspace/test-infra/jobs/e2e_node/containerd/containerd-master/env
      - --extract=gs://koonwah-repo-pub/devel/v1.11.2-beta.0.20+21777efd99bd59
      - --gcp-node-image=gci
      - --gcp-nodes=4
      - --gcp-zone=asia-southeast1-a
      - --ginkgo-parallel=30
      - --provider=gce
      - --test_args=--ginkgo.focus=\[sig-network\] --ginkgo.skip=\[Slow\]|\[Flaky\]|\[Feature:Networking-IPv6\]|\[Disruptive\]|\[Feature:ServiceLoadBalancer\]|\[Feature:PerformanceDNS\] --minStartupPods=8
      - --timeout=120m
      image: gcr.io/k8s-testimages/kubekins-e2e:v20180730-8b7ab3104-master
      env:
      - name: NETWORK_POLICY_PROVIDER
        value: calico

- interval: 2h
  name: ci-kubernetes-e2e-containerd-gce-calico
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-kubernetes-e2e-containerd: "true"
    preset-kubernetes-e2e-enable-calico: "true"
  spec:
    containers:
    - args:
      - "--timeout=340"
      - --root=/go/src
      - --repo=github.com/containerd/cri=master
      - "--repo=k8s.io/examples=master"
      - --scenario=kubernetes_e2e
      - --
      - --check-leaked-resources
      - --env=KUBE_MASTER_EXTRA_METADATA=user-data=/go/src/github.com/containerd/cri/test/e2e/master.yaml,containerd-configure-sh=/go/src/github.com/containerd/cri/cluster/gce/configure.sh,containerd-env=/workspace/test-infra/jobs/e2e_node/containerd/containerd-master/env
      - --env=KUBE_NODE_EXTRA_METADATA=user-data=/go/src/github.com/containerd/cri/test/e2e/node.yaml,containerd-configure-sh=/go/src/github.com/containerd/cri/cluster/gce/configure.sh,containerd-env=/workspace/test-infra/jobs/e2e_node/containerd/containerd-master/env
      - --extract=gs://koonwah-repo-pub/devel/v1.11.2-beta.0.20+21777efd99bd59
      - --gcp-node-image=gci
      - --gcp-nodes=4
      - --gcp-zone=asia-southeast1-a
      - --ginkgo-parallel=30
      - --provider=gce
      - --test_args=--ginkgo.focus=\[sig-network\] --ginkgo.skip=\[Slow\]|\[Flaky\]|\[Feature:Networking-IPv6\]|\[Disruptive\]|\[Feature:ServiceLoadBalancer\]|\[Feature:PerformanceDNS\] --minStartupPods=8
      - --timeout=120m
      image: gcr.io/k8s-testimages/kubekins-e2e:v20180730-8b7ab3104-master

- interval: 2h
  name: ci-kubernetes-e2e-containerd-gce-calico-serial
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-kubernetes-e2e-containerd: "true"
    preset-kubernetes-e2e-enable-calico: "true"
  spec:
    containers:
    - args:
      - "--timeout=180"
      - --root=/go/src
      - --repo=github.com/containerd/cri=master
      - "--repo=k8s.io/examples=master"
      - --scenario=kubernetes_e2e
      - --
      - --check-leaked-resources
      - --env=KUBE_MASTER_EXTRA_METADATA=user-data=/go/src/github.com/containerd/cri/test/e2e/master.yaml,containerd-configure-sh=/go/src/github.com/containerd/cri/cluster/gce/configure.sh,containerd-env=/workspace/test-infra/jobs/e2e_node/containerd/containerd-master/env
      - --env=KUBE_NODE_EXTRA_METADATA=user-data=/go/src/github.com/containerd/cri/test/e2e/node.yaml,containerd-configure-sh=/go/src/github.com/containerd/cri/cluster/gce/configure.sh,containerd-env=/workspace/test-infra/jobs/e2e_node/containerd/containerd-master/env
      - --extract=gs://koonwah-repo-pub/devel/v1.11.2-beta.0.20+21777efd99bd59
      - --gcp-node-image=gci
      - --gcp-nodes=4
      - --gcp-zone=asia-southeast1-a
      - --ginkgo-parallel=1
      - --provider=gce
      - --test_args=--ginkgo.focus=\[sig-network\].*\[Disruptive\]|\[sig-network\].*\[Serial\]|\[Feature:PerformanceDNS\] --minStartupPods=8
      - --timeout=120m
      image: gcr.io/k8s-testimages/kubekins-e2e:v20180730-8b7ab3104-master

- interval: 2h
  name: ci-kubernetes-e2e-containerd-gce-netd-calico-serial
  labels:
    preset-service-account: "true"
    preset-k8s-ssh: "true"
    preset-kubernetes-e2e-containerd: "true"
    preset-kubernetes-e2e-enable-netd-calico: "true"
  spec:
    containers:
    - args:
      - "--timeout=180"
      - --root=/go/src
      - --repo=github.com/containerd/cri=master
      - "--repo=k8s.io/examples=master"
      - --scenario=kubernetes_e2e
      - --
      - --check-leaked-resources
      - --env=KUBE_MASTER_EXTRA_METADATA=user-data=/go/src/github.com/containerd/cri/test/e2e/master.yaml,containerd-configure-sh=/go/src/github.com/containerd/cri/cluster/gce/configure.sh,containerd-env=/workspace/test-infra/jobs/e2e_node/containerd/containerd-master/env
      - --env=KUBE_NODE_EXTRA_METADATA=user-data=/go/src/github.com/containerd/cri/test/e2e/node.yaml,containerd-configure-sh=/go/src/github.com/containerd/cri/cluster/gce/configure.sh,containerd-env=/workspace/test-infra/jobs/e2e_node/containerd/containerd-master/env
      - --extract=gs://koonwah-repo-pub/devel/v1.11.2-beta.0.20+21777efd99bd59
      - --gcp-node-image=gci
      - --gcp-nodes=4
      - --gcp-zone=asia-southeast1-a
      - --ginkgo-parallel=1
      - --provider=gce
      - --test_args=--ginkgo.focus=\[sig-network\].*\[Disruptive\]|\[sig-network\].*\[Serial\]|\[Feature:PerformanceDNS\] --minStartupPods=8
      - --timeout=120m
      image: gcr.io/k8s-testimages/kubekins-e2e:v20180730-8b7ab3104-master
      env:
      - name: NETWORK_POLICY_PROVIDER
        value: calico
